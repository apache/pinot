
@@21004489 @1004489/ <h> Engineering Hall of Fame <p> BROUGHT TO YOU BY <h> At the end of each year , the editors of Electronic Design nominate new candidates for our Engineering Hall of Fame , and then select a group of new inductees based on level of contribution , industry impact , lasting achievement and feedback from our readers . We would like to thank all the engineers and other readers who help us in this process , for sharing your enthusiasm , and for your support of us and these important innovators . We are proud to salute these legends on your behalf . <p> Shuji Nakamura is one of 2013 's inductees to Electronic Design 's Hall of Fame . He successfully built on earlier efforts to create semiconductor diodes from III/V compounds with band gaps that would result in the emission of blue-light ... 
@@21004490 @1004490/ <p> Technology has changed everything from the way television is watched , to the way we find directions , to the way we order food , but the medical industry has been surprisingly resistant to technology 's transformative effects " until now. - <p> The convergence of cheap wireless transmitters , compact sensors , and low-power processors is driving the recent wave of fitness trackers , smartwatches , and wearable devices . While many of these wearables are aimed at the consumer market , a growing number of device makers are seeing the potential of wearable technology in transforming healthcare . <p> An increasing number of wearable medical devices , including skin patches , glucose monitors , and more , are shifting the focus of healthcare from the hospital to the home ( Fig. 1 ) . By allowing remote health monitoring , diagnosis , and even treatment , these wearable devices empowered by Bluetooth and NFC technology are changing the face of preventative medicine and the lives of those suffering from chronic disease . <p> Wearable Healthcare <p> Traditional healthcare has focused on the hospital and clinic as @ @ @ @ @ @ @ @ @ @ happen in the doctor 's office . Drugs and treatments are prescribed , but the doctor is unable to monitor or diagnose the patient until they come into the treatment center . <p> Telemedicine flips this dynamic , bringing healthcare to the patient 's home . Powered by the convergence of wearable devices , smartphone apps , and wireless connectivity , telemedicine is about bringing diagnostic and monitoring to the patient . Instead of having to wait for an appointment , today 's patients can use wearable medical devices to monitor and take charge of their own health . <p> 1 . Wearable medical devices enable remote health monitoring . <p> - <p> Wearable devices have been life-changing for those with chronic disease like diabetes . Smart glucose monitors like the Dexcom G5 can be placed on the body and link wirelessly with smartphones to provide continuous blood-sugar monitoring . An app can alert users to low or high blood-sugar events , and can share data with loved ones or caregivers . <p> Quell is another example of wearable technology that 's changing the lives of those with chronic health @ @ @ @ @ @ @ @ @ @ it tracks activity and sleep patterns to adjust its pain-management intensity , as well as provide proactive relief throughout the night to improve sleep quality for patients dealing with chronic pain . <p> For elderly populations , wearables are improving quality of life by providing greater independence while ensuring safety . The UnaliWear Kanega is a prime example that combines a vital-sign monitor with an accelerometer and GPS tracking . It detects if elderly users have fallen and can transmit GPS coordinates as well as sensor information to loved ones . <p> Besides monitoring and notification , wearable medical devices also have the potential to provide automated or remote treatment . The OmniPod is an example of a wearable insulin pump that coordinates with a glucose monitor to automatically administer correct dosage . More drastically , ZOLL 's LifeVest is a wearable defibrillator worn by patients at risk of a heart attack . It monitors heart rhythms and in the event of a heart attack , releases conductive gel from its electrodes and administers a life-saving electrical shock to restore normal heart rhythms . <p> More than just helping those @ @ @ @ @ @ @ @ @ @ possibilities in early detection and prevention of disease . Wearables with fitness and heart rate or EKG tracking capabilities are helping people maintain active lifestyles and track their heart health to ward off diabetes and heart disease . <p> While wearable medical devices vary greatly in shape , form , and function , they 're united by wireless connectivity that allows these compact devices to be worn unobtrusively . At the same time , wireless connectivity , especially Bluetooth Smart technology , allows these devices to connect with smartphones " sensor data can be analyzed through apps for self-diagnosis and shared with loved ones or caregivers . <p> Bluetooth Low Energy for Wireless Health <p> For wearable devices , Bluetooth Low Energy ( BLE ) is undoubtedly the most important wireless technology today . Not only is it power-efficient and easy to implement on embedded systems , but because of Bluetooth 's widespread compatibility , a BLE-supported device can be accessed by any modern smartphone made within the last three years . <p> Technically speaking , Bluetooth wireless technology consists of two separate sub-protocols. - Bluetooth classic is the original @ @ @ @ @ @ @ @ @ @ and other devices that need to transfer significant amounts of data . Bluetooth Low Energy , also known as Bluetooth Smart , uses the same 2.4-GHz radio as Bluetooth Classic , but a significantly different stack implementation . Its messaging protocol is optimized for short , infrequent bursts of data instead of streams . <p> Bluetooth devices can either support Bluetooth classic , Bluetooth Low Energy , or both . Smartphones , laptops , and tablets generally support dual-mode Bluetooth , but for power-conscious wearables it makes sense to support just Bluetooth Low Energy . <p> Unlike other wireless protocols that may need a custom receiver module , with BLE devices , users can connect with their wearable simply through their smartphone with a compatible app . Subsequently , this data can also easily be shared with loved ones or caregivers through the phone 's 3G or 4G connection . <p> For hospital and home environments where Wi-Fi , Bluetooth , and other wireless devices on the 2.4-GHz band may be present , interference is a concern . Bluetooth Low Energy uses adaptive frequency hopping to select channels with less @ @ @ @ @ @ @ @ @ @ with Wi-Fi or other Bluetooth devices in the mix . <p> Besides ubiquitous smartphone support , BLE also is an extremely power-efficient protocol . Peak power consumption when transmitting or receiving is much lower than Bluetooth classic . Transmissions and connection sequences are optimized for bursty messaging to significantly reduce messaging and connection times , and thus power requirements . While sending a sensor reading using a Bluetooth-classic device may take a hundred milliseconds as it connects and another hundred to send the data , the same process would take a Bluetooth Low Energy device just a few milliseconds . <p> Security <p> With wireless communications , security is always a concern . Bluetooth Low Energy employs 128-bit AES-CCM encryption , and since the release of Bluetooth 4.2 ( released December 2014 ) , it also uses Elliptic Curve Diffie " Hellman for key generation with strong protection against passive eavesdropping . For extra security against man-in-the-middle attacks , numeric comparison , passkey entry , or out-of-band pairing can be used . <p> Implementation <p> With the widespread popularity of Bluetooth , designers benefit from a range of cheap , @ @ @ @ @ @ @ @ @ @ ; and easy-to-use development kits . Many Bluetooth radio modules available today come in a SoC design with an integrated microcontroller that can also process sensor data and run application logic . For most medical wearables , this integrated approach will result in the smallest , cheapest , and most power-efficient end product . <p> Alternatively , for devices that need more processing power or memory ( or is already available ) , Bluetooth Low Energy modules can also be interfaced through the standardized host controller interface ( HCI ) using UART or USB . In this case , the Bluetooth module is purely used for radio communications ; the application and upper layers of the Bluetooth stack are run on a separate microcontroller . This allows devices with larger software footprints or processing requirements to use a separate , more powerful host processor and relegate the Bluetooth module purely for BLE communications . <p> One final benefit for BLE-driven wearable devices is over-the-air firmware updates . Many Bluetooth modules on the market today , such as those from Texas Instruments and Nordic Semiconductor , feature this capability . When @ @ @ @ @ @ @ @ @ @ patches , or bug fixes , users can easily download the firmware update through their smartphone and update their wearable wirelessly , with no USB cables required . <p> NFC : Tap-and-Go Technology <p> Bluetooth Low Energy , which maintains ubiquitous smartphone support , a usable real-world range of 10 to 30 meters that is perfect for indoor environments , and strong power efficiency , is the undisputed king of wireless communications for wearable medical devices . However , near-field communication ( NFC ) is a strong second-place contender . With an even smaller form factor , lower power usage , and tap-and-go functionality , it provides a complementary wireless technology with unbeatable ease of use . <p> Unlike Bluetooth , which let 's users move around a room or area while staying connected , NFC requires devices to be within 10 cm , or practically touching , in order to activate . This physical limitation of NFC keeps it from being a direct competitor with Bluetooth , but is also the key to its value as a complementary wireless standard . <p> The close proximity of NFC connections allows for @ @ @ @ @ @ @ @ @ @ Instead of choosing from a list of nearby devices and entering passcodes , users simply tap the devices together and it automatically triggers an NFC communication sequence . The intuitive nature of NFC is especially attractive for elderly populations , as well as for hospitals where it reduces or eliminates the need to train staff . <p> NFC 's maximum bit rate of 424 kb/s is much slower than Bluetooth Low Energy 's 1 Mb/s , but NFC interactions can still be quite fast . Two NFC devices can connect , transmit sensor data , and close the connection , all well within a second of the user touching the devices together . With Bluetooth , the same process could involve several seconds , as the user manually selects the correct device to pair with and initiates a sensor reading . <p> While it 's being built into ever-more smartphones , NFC 's main weakness is that it still does n't have the universal support like that of BLE . One way to get around this , an approach taken by Abbot 's Freestyle Libre glucose monitor , is to @ @ @ @ @ @ @ @ @ @ is also less of an issue in clinical settings , where compatible devices can be administered by staff . <p> In fact , in clinical settings , NFC may be better suited than BLE for many applications involving simple sensor readings and transactions , such as checking temperature or blood sugar , or transferring a medical record . Because of the ephemeral connections established by NFC , it works better than BLE when caregivers need to easily and quickly read multiple devices . Instead of establishing paired connections per device as with BLE , users simply tap their phone or tablet to each NFC device in turn to read it . <p> Besides acting as the main wireless transport , NFC also works well as a simple and secure handover to another longer range or higher bandwidth wireless protocol . NFC handovers are natively supported in the Bluetooth specification as an out-of-band pairing method , and can also be used to setup a Wi-Fi connection . This provides the simplified proximity pairing and authentication of NFC to Bluetooth or Wi-Fi connections . NFC connection handover is especially attractive in clinical @ @ @ @ @ @ @ @ @ @ Wi-Fi devices in connection range and connecting to the right one is critical . <p> Power <p> While Bluetooth Low Energy is extremely power-efficient , NFC can literally require no on-board power . NFC devices may be either active battery-powered devices , or passive devices . Passive NFC devices can be powered entirely by the RF field generated by an active NFC device connecting to it . This means extremely compact , completely battery-less designs are able to be made and used indefinitely . The power generated is typically around 4 mA at 3.3 V " enough for simple sensor readings . <p> NFC 's small size and ability to work purely off harvested RF energy makes it ideal for simple , compact wearables such as single-sensor skin patches , or electronic health record tags , both of which benefit from a small , flexible form factor and do n't need to perform complex sensor fusion or run application logic . <p> Security <p> By requiring devices to be in extremely close proximity , NFC provides physical security by making it extremely difficult to eavesdrop or create man-in-the-middle attacks . @ @ @ @ @ @ @ @ @ @ is being connected to , which simplifies pairing and authentication . For many applications , this provides a reasonable amount of security . However , for payment applications and applications transmitting sensitive information , Elliptical Curve Diffie-Hellman key exchange and AES encryption can be used for additional security . <p> Implementation <p> The NFC specification allows three modes of operation : peer-to-peer , read/write , or card emulation . Read/write , supported by simpler devices such as passively powered tags , allows for data to be written or read from a NFC device . This supports sensor readings applicable to medical wearables . Peer-to-Peer mode enables data exchange between two NFC devices , and is used for connection handovers and file transfers . With card emulation , an active NFC device can emulate a contactless smart card . This mode allows smartphones and active NFC devices to be used for payments or authentication applications , such as security access . <p> When it comes to NFC modules , designers have a huge range of options , from tags that store and transmit static data , to dynamic transponders that can @ @ @ @ @ @ @ @ @ @ for battery-powered devices . <p> Static NFC tags for healthcare can be used to store personal health records in a wearable wristband or keychain , making it easy for hospital staff or emergency personnel to check personal medical history , allergies , and drug contraindications . <p> When passively powered , dynamic NFC transponders can be made extremely small , suiting them for skin patches or even implantable devices . NFC transponders like the TI RF430FRL152H ( Fig. 2 ) are often specifically designed for these kinds of sensor applications , usually integrating an ADC and SPI/I2C interface , and with the ability to be passively powered . <p> For battery-powered active NFC devices , multi-radio modules like the Nordic nRF51822 ( Fig. 3 ) combine the ease of use and physical security of NFC with the range of other protocols . Bluetooth Low Energy + NFC modules are particularly compelling , as they combine the compatibility and range of BLE and the ease of use of NFC . Users with NFC-capable smartphones could exploit NFC to do a simple sensor reading or make a connection handover to Bluetooth for @ @ @ @ @ @ @ @ @ @ , such as those with iPhones , could still interact with the device , albeit in BLE-only mode . <p> The Internet of Medical Things <p> Simply put , wearable medical devices using Bluetooth Low Energy and NFC are transforming modern healthcare , improving the lives of the elderly , those living with chronic diseases , and those at risk of heart disease or other ailments . Monitoring solutions are reducing the occurrence of heart disease and diabetes , while automated treatment devices improve quality of life for those with chronic pain or illness . <p> Perhaps most promising of all , by connecting to our smartphones and tablets , the data provided by these wearables can enhance not only the health of the users themselves , but may help doctors and researchers better understand and treat the diseases and ailments that affect us all . 
@@21004495 @1004495/ <p> Over the next 15 years , global healthcare will transform due to a perfect storm of clinical imperative , financial burden , and increasingly informed and empowered patients . A growing population , steadily decreasing healthcare budgets , and the rise of chronic diseases are putting pressure on doctors , healthcare providers , and governments to look to technology to provide the solution to these challenges . <p> As a result , global healthcare and wellness is ideally placed to drive the adoption and maturity of the Internet of Things ( IoT ) . The smart technologies commonly found on a person such as the smartphone , smartwatch , and new emerging technologies like smart plasters , will be at the heart of this revolution , providing insights that will deliver benefits to the physical , emotional , and mental self . <p> Director of Healthcare and Emerging Technologies , ARM Inc . <p> - <p> The smartphone is seen by many as their primary compute device " nearly two-thirds of American adults ( 64% ) now own a smartphone according to survey done in 2015 by Pew @ @ @ @ @ @ @ @ @ @ camera , and the ability to connect via Bluetooth to activity monitors and medical devices like blood pressure monitors and ECG machines . Sensors are delivering ever more valuable and accurate data , and in the future we will see an increasing number of these distributed over the body cooperatively collecting and processing continuous data . <p> Moving forward , multiple sensors will be delivered within fabric garments , adhesive patches , and jewelry-type form factors , depending on personal choice and monitoring requirements . Together , this will transform the smartphone into an effective , personal vehicle for health management . Evidence of this can already be seen , with leading insurance providers in the U.S. subsidizing the cost of the Apple watch for their patients . <p> Impact on Healthcare , Personal Health , and the Market <p> Based primarily on face-to-face interactions between physician and patient ( visit to the doctor , flu shot at work , or annual exam ) , existing protocols of treating patients are outdated and place undue pressure on current government and non-government structures . Remote health monitoring opens up a brand @ @ @ @ @ @ @ @ @ @ with continuous information being collected from the patient " for example , someone coping with a chronic disease such as diabetes or congestive heart failure. - <p> With this approach , physicians and loved ones are in a position to learn and provide better quality of care via deeper , more meaningful engagement with the patient . More actionable information is being continuously captured , ultimately reducing cost to the system . It will also result in curbing the growth of chronic diseases : Genomic research will rapidly spread to the clinical coalface , and this information must be enhanced with lifestyle monitoring to accurately predict the onset of chronic disease with enough warning to allow effective treatment . <p> One example of the direction of connected healthcare is Unison 's Wearable OS platform , which supports all of the latest sensors , radios , MCUs , and MPUs for designing wearable devices off-the-shelf . <p> - <p> The connected health market is expected to see something close to $117 billion revenue by 2020 . As the smartphone and smartwatch evolve into the key vehicles for personal health , this @ @ @ @ @ @ @ @ @ @ , on , and off the body , and on the smartphone itself . New and emerging OEMs will be able to monetize the data collected versus just the hardware , enabling a vibrant ecosystem to develop. - This stands in stark contrast to today 's model , which is limited to current major OEMs . <p> How Must Technology Evolve to Make This a Reality ? <p> Three of the key areas we need to consider for the success of healthcare IoT can be broadly split into the categories of low-power medical and wearable devices ; communication between sensors , smartphones ( gateways ) and the cloud ; and security : <p> For wearable and medical devices , battery life is imperative . ARM and many of our partners are looking into near-threshold voltage for embedded-class devices . The race is on to get to the lowest power with sufficient compute to obtain the maximum number of critical biometrics . <p> Key biometrics to be obtained include body fat ; photoplethysmogram ( PPG ) for heart rate and respiration ; electrocardiogram ( ECG ) to measure heart rate , @ @ @ @ @ @ @ @ @ @ temperature ; blood oxygen ( SpO2 ) ; blood glucose ; and blood pressure . Together , these form the crux of the core biometrics required to manage chronic diseases including , but not limited to , hypertension , diabetes , congestive heart failure , and COPD , as well as many of the patients who have comorbidities . <p> With a long history of ultra-low power and high performance , the ARM Cortex-M family of processors can run many of the algorithms involved in collecting these biometrics . Non-toxic batteries are also important to extend the usage of wearable devices over a long period of time . <p> The smartphone is an ideal gateway platform for aggregating data from various medical sensors and for engaging with patients . It 's critical to have sufficient security and privacy in place to ensure that data is not stolen , and there 's sufficient ability to authenticate and validate the data from user and device . <p> As sensors on the body need to be able to last for multiple days without recharging , it 's imperative that the power budget used @ @ @ @ @ @ @ @ @ @ compatibility across billions of smartphones already deployed into the market . Already designed into billions of smartphones , Bluetooth Low Energy ( BLE ) is the most ubiquitous , low-cost radio solution for transmitting data from wearable sensors to be able to talk to the smartphone . ARM Cordio BLE solutions provide a platform for silicon vendors looking to design low-power silicon solutions for medical wearable applications to talk to the smartphone . <p> Finally , in the cloud , beyond securing the data , we also need to act upon the data . Predictive analytics and machine learning can play a key role in reshaping the healthcare industry , starting with enabling device manufacturers , caregivers , and pharmaceutical players to improve the quality and the delivery of care we provide to the patient . <p> The ultra-low cost of BLE combined with low-power embedded processors such as the ARM Cortex-M family can enable developers to easily and cost-effectively integrate connectivity into billions of previously unconnected medical sensors and diagnostics tools . For example we will see connectivity being added to diagnostic devices ranging from HIV , glucose , @ @ @ @ @ @ @ @ @ @ . <p> ARM 's TrustZone and CryptoCell help ensure data is secure from data acquistion at the sensor to the smartphone . <p> - <p> It 's self-evident and imperative that data from such devices is kept secure , private , and only shared with trusted third parties with whom the patient consents to share this data . Solutions such as ARM CryptoCell and ARM TrustZone on both the sensors and the gateway are designed to ensure that data is kept absolutely secure and private from the time of acquiring that data ( at the sensor ) to the data validation , identity tagging , and consent acquisition of that data at the smartphone . As a result , that data can then be shared with trusted entities in the cloud whom the patient provides digital consent ( for example , by swiping their fingerprint ) . 
@@21004500 @1004500/ <p> 1 . This tee-attenuator pad is used for explaining the three-measurement approach and analysis . <p> - <p> While a network analyzer is normally used to measure attenuator characteristics , all low-frequency attenuator parameters may be derived from just three measurements of dc resistance . Figure 1 shows the tee ( T ) representation of the attenuator ; note that the pi ( - ) representation can also be used , but requires more complex calculations . <p> First , measure dc resistance between the input and output ( A ) , then between input and common ( B ) and between output and common ( C ) . <p> This results in three equations with three unknowns : <p> Solving for R1 , R2 , and R3 yields : <p> The pad attenuation in a system with equal in/out impedances Zo is given by : <p> The input and output impedances can now be calculated as : <p> The input and output return losses are given by : <p> while the input and output SWR is : <p> 2 . The pi network can also be analyzed @ @ @ @ @ @ @ @ @ @ The equivalent pi network can also be calculated ( Fig. 2 ) . The equations for this transformation are : <p> It is interesting to calculate the pad 's average impedance Z , based on the measured values of R1 , R2 , and R3. - The average value ( R ) of R1 and R2 is calculated , forcing the pad to be symmetrical , with identical input and output impedances : <p> The input resistance of the pad ( Z ) is calculated as follows , with Z also providing the termination : <p> Solving for Z and using : <p> yields this expression for the pad average impedance : <p> This value should be close to the pad nominal impedance . <p> Using three DCR measurements makes it possible to calculate all low-frequency parameters of a pad. - Minimum-loss L pads will give R1 or R2 equal to zero . These calculations are independent of the internal pad configuration ( tee or pi ) , and also work with cascaded pads . <p> Figure 3 shows the worst-case results of Monte Carlo simulations on pad attenuation with @ @ @ @ @ @ @ @ @ @ and C resistance measurements . Simulations of attenuation accuracy , assuming that all DCR measurements have 1% error in the same direction , yields an error of only 0.001 dB . <p> 3 . The Monte Carlo simulation of the analysis approach shows the high level of accuracy it yields , even with measurement errors in the same direction . <p> Jacques Audet received an Electrical Engineering degree from Laval University ( Quebec , Canada ) . His main interests are analog simulation , filters , RF circuits , and antenna experimentation and simulation . Other interests include automated test systems to gather data and process the measured results , as well as developing new test techniques . He can be reached at email protected . 
@@21004502 @1004502/ <p> Fifty companies , including Dell and Ubuntu founder Canonical , are throwing support behind a new open standard for edge computing . The project , called EdgeX Foundry , is the latest endorsement for standard gateways that sit between sensors inside factories , office buildings , and city infrastructure and the cloud . <p> The standard , which is still under construction , debuted at the Hannover Messe trade show this week in Germany . It aims to lower the cost and complexity of installing gateways , enabling simple data analysis and device control much closer to sensor nodes . These gateways will not always need to communicate with the cloud , where the most intense data-crunching takes place . <p> Developing gateways with EdgeX requires little more than snippets of standard code , which will be free . The code organizes the transfer of information from sensors in things like manufacturing robots , offices , and shipping trucks to gateways or servers on the edge . That allows companies to mix-and-match operating systems , hardware , and software for Internet of Things systems , saving money . @ @ @ @ @ @ @ @ @ @ help anyone easily build edge computing solutions with preferred hardware , software , standards and services while minimizing reinvention , " said Jason Shepherd , director of Internet of Things strategy and partnerships at Dell , which supports the standard , in a statement . <p> The project is supervised by the Linux Foundation , the industry group behind the open-source operating system . But support for EdgeX also stems from the organizations behind the wireless energy harvesting standard EnOcean and cloud application standard Cloud Foundry . <p> The standardized code originated from a Dell project codenamed Fuse , which was revealed last year to rally the concept of edge computing and drive sales of Dells gateway boxes . With EdgeX , gateways will contain around 125,000 lines of code , which erect a software layer between different messaging protocols . <p> That code will enable the gateways to send automatic commands , provision devices , and clean up metadata so that it can be organized faster and more accurately . With these services standardized , businesses will have less work to do updating an Internet of Things system . @ @ @ @ @ @ @ @ @ @ A rival project called Kura is aiming to standardize code for internet gateways used in fog computing , a term coined by Cisco for shifting basic cloud functions to the edge of a businesss network . Kura would define how gateways sift through feedback from sensors , sending only the most vital information or worst failure alerts to the cloud . 
@@21004503 @1004503/ <h> BeagleBone Robots Takes a Bite of Bluetooth <p> A pleasant surprise for me at Embedded World this year was BeagleBoard.org 's BeagleBone Blue ( Fig. 1 ) . It targets robots and mobile embedded devices with plenty of control interfaces and Bluetooth connectivity . <p> What I like about the BeagleBone family is its open-source industrial design and integrated software that gets developers started more quickly than most other platforms in this space . I have used the BeagleBone Black in the past and look forward to trying out the new BeagleBone Blue . <p> The $79 BeagleBone Blue runs a 1-GHz Octavo Systems OSD3358 that is a System-in-Package ( SiP ) . The SiP is built around Texas Instruments ' ( TI ) Sitara AM3358 system-on-chip ( SoC ) that has an ARM CortexA8 core . The 27-mm by 27-mm SiP contains 512 Mbytes of DDR3 RAM and integrated power management . The AM3358 has a 12-bit , 8-channel SAR ADC , gigabit Ethernet support , a pair of USB 2.0 host/OTG with PHY , and an LCD controller with 3D graphics support . It also has @ @ @ @ @ @ @ @ @ @ ) . <p> The board has 4 Gbytes of eMMC flash storage programmed with Debian Linux . It also has an ARM Cortex-M3 . There is a two-cell LiPo battery socket with balancing , 9-18V charger input support . The board adds 802.11bgn , Bluetooth 4.1 , and BLE wireless . <p> The motor control ports are extensive , with eight 6V servo outputs , four DC motor outputs , and four quadrature encoder inputs . Sensors include a nine-axis IMU and a barometer . There are 11 user-programmable LEDs and a pair of user-programmable buttons . There are connections for GPS and DSM2 radio . About half the board is relegated to connectors . <p> The BeagleBone Blue is already finding a home in robots and drones ( Fig. 2 ) . The EduMiP is a self-balancing robot . It is an open source project on GitHub where the 3D print files are stored . The BeagleMAV is a three-printed hexacopter . BeagleMAV only weighs 500 grams ( 1.1 lb . ) . The monocoque structure was designed iteratively using modal finite element analysis at DroneLab at the University @ @ @ @ @ @ @ @ @ @ BeagleBone Blue is ideal for robots like the EduMiP ( a ) and drones like the BeagleMAV ( b ) . <p> Octavo Systems OSD335x is available separately with up to 1 Gbyte of DRAM . It can handle 0 to 85-C . The 400 ball BGA has a 1.27 mm pitch . The BeagleBone TH Module is a more compact module with the OSD3358 SiP . <p> There is also a BeagleBone Black Wireless with Wi-Fi support and a wireless BeagleBone Green from Seeed Studio . The BeagleBone Black Wireless has the same headers as the original BeagleBone Black , as does the BeagleBone Green . The BeagleBone Black Wireless also uses the Octavo Systems SiP , while the other uses the TI chip directly . 
@@21004506 @1004506/ <h> The Evolution Of LTE <p> The Third Generation Partnership Project ( 3GPP ) , the international organization that developed the widely used UMTS WCDMA/HSPA 3G standards , also developed Long-Term Evolution ( LTE ) . Release 8 was completed in 2010 , followed by release 9 . Available now , release 10 defines LTE-Advanced ( LTE-A ) . <p> Multiple cell-phone technologies designated by generations have led to LTE-A ( see the figure ) . The first generation was analog ( FM ) technology , which is no longer available . The second generation ( 2G ) brought digital technology with its benefits to the industry . Multiple incompatible 2G standards were developed . Only two , GSM and IS-95A CDMA , have survived . <p> Cellular radio standards really left FM technologies behind in 1990 with 2G standards like GSM and IS-95A cdma . More than 20 years later , we 're approaching true 4G with LTE-Advanced . <p> The third generation ( 3G ) standards were created next . Again , multiple standards were developed , notably WCDMA by the 3GPP and cdma2000 by Qualcomm . @ @ @ @ @ @ @ @ @ @ 3G standards were continually updated into what is known as 3.5G . WCDMA was upgraded to HSPA , and cdma2000 was expanded with 1xRTT EV-DO releases A and B. Both are still widely deployed . <p> In fact , in many places around the world , carriers are still adding 3G or upgrading their 3G systems . In the U.S. , AT&amp;T and T-Mobile use GSM/WCDMA/HSPA while Verizon , Sprint , and MetroPCS use cdma2000/EV-DO . All of these carriers are building LTE networks . <p> LTE was created as an upgrade to the 3G standards . The cellular industry recognized its major benefits , and virtually every mobile carrier has embraced it as the next generation . All cellular operators are now on the path to implementing LTE . While 3GPP still defines LTE as a 3.9G technology , all of the current LTE networks are marketed at 4G . The real 4G as designated by 3GPP is LTE-A . <p> Currently , LTE is alive and functioning in many U.S. cellular companies and in others worldwide . The networks are not fully built out , and most of @ @ @ @ @ @ @ @ @ @ . Since LTE coverage is not universal , most cell phones incorporate 2G and 3G systems for voice in areas where LTE is not yet deployed . LTE-A deployment is expected in 2014 and beyond . <p> LTE brings amazing new capabilities to the cellular business . First , it expands carrier capacity , meaning more subscribers can be added for a given spectrum assignment . Second , it provides the high data rates needed by growing new applications , mainly video downloads to smart phones and other Internet access . Third , it makes cellular connectivity more reliable . All of these needs are important to maintaining growth and profitability in the wireless business. - See related article An Introduction to LTE-Advanced : - The Real 4G- LONG ... 
@@21004509 @1004509/ <h> The Future of AM Radio <p> Can you believe AM radio is still around ? Me and a few others still do use it . I listen mostly in the car for traffic , weather , and news , though sometimes I listen to talk programs on a small AM/FM kitchen radio . Seems so retro , but it is still useful . <p> Nevertheless , AM radio has been in decline for years , with many AM stations going out of business each year . Now there are only 4,684 left as of the end of 2015 . That stands in contrast to the 6,701 commercial FM stations that are thriving , a number that does not include an additional 4,095 educational FM stations and 1,433 low power stations . All this is still analog , remember . So some big questions come to mind : Why is AM dying , and what can be done to save it ? <p> AM is dying for a lack of listeners . Only 10 to 20 % of all radio listeners listen to it , and that depends upon @ @ @ @ @ @ @ @ @ @ in some places . If stations ca n't get listeners , they can not get the advertising that keeps them alive . Most of the listeners moved on to FM or other radio sources . These other sources include satellite and Internet radio , along with things like iPods or smartphones loaded with songs and podcasts . Satellite radio is now in most vehicles . <p> Then there is digital radio , although this is not a popular option . The U.S. version ( called HD Radio ) is available on both the AM and FM bands , but few receive it . The digital version simulcasts the analog content in an OFDM overlay on the same frequency . You need a special radio to get it , an expense justified by its proclaimed benefits of less noise and greater fidelity . I 've tried it , but it seems about the same to me . Some cars have HD Radio , but otherwise you need a unique receiver . There are not too many sources . Canada launched Digital Audio Broadcast ( DAB ) in the L microwave band @ @ @ @ @ @ @ @ @ @ successful , either . FM still thrives there . <p> In addition to the many multiple competitive sources of content , AM is also failing because of technical problems inherent in the AM process , along with some unyielding regulations . For example , AM stations lose listeners at night because the FCC makes them cut power or shut down completely to avoid interference to other stations on the same frequency . AM signal propagation in the 535 to 1,705 kHz range changes drastically from day to night . <p> During the day propagation is primarily by ground wave with a range of no more than 200 miles , so stations can transmit full power . At night there is less upper layer ionization , so the AM signal refracts off the upper layers , causing the signal to skip hundreds or even thousands of miles . This causes interference to other stations . Some stations use complex and expensive directional antenna systems to solve the problem . <p> Another issue is noise . The AM band is very noisy , with interference from power lines , auto ignition , @ @ @ @ @ @ @ @ @ @ equipment with switch-mode power supplies , which includes almost every product today . Weak signals are swamped by noise , and even strong signals suffer from it . Noise makes listening annoying at best , and off-putting to the max . <p> Realizing these problems , back in October of 2013 , the FCC issued a Notice of Proposed Rule Making ( NPRM ) designated 13-249 Revitalization of the AM Radio Service . The FCC solicited input from all sources on how to solve AM 's problems . Just recently , it announced the first of several solutions . The new rules allow some AM stations to use FM translators . A translator rebroadcasts a station 's content on an available FM frequency . In this way , stations can continue to transmit at night , thereby retaining a greater audience . <p> Other solutions are on the way , including something called Modulation Dependent Carrier Level ( MDCL ) control . MDCL allows stations to decrease carrier level and adjust sideband power to save power and improve efficiency . Also on the way are other changes that lessen the @ @ @ @ @ @ @ @ @ @ what else the FCC comes up with . <p> AM is worth saving ; it is a valuable local community resource . AM radio serves a public safety purpose for emergency conditions . It provides valuable services to ethnic and religious populations , as well as high school sports coverage . And still does a great job of news , weather , and traffic coverage . Talk shows are also popular . In short , analog still lives . <p> What do you recommend to save AM ? Or should we just let it go ? With spectrum in short supply could n't we just repurpose this band ? And if so , to what ? 
@@21004511 @1004511/ <p> Ngai Zhang , a patent lawyer at Pillsbury Winthrop Shaw Pittman in Virginia , who handles cases from video games to security , says these questions are seldom talked about . It is difficult to predict how human-like software will clash with discrimination or- privacy law . Artificial intelligence- could also force us to reexamine the idea of creativity itself . <p> For decades , engineers have used intelligent software in everything from the design of toothbrush bristles to the verification of computer circuits . But it is much harder to assign copyrights when humans stop using software as a tool and instead collaborate with it to design a manufacturing process , or let it work alone to- write- music . <p> Mr. Zhang will be talking more about this topic and others at the Industrial Design &amp; Engineering Show , sponsored by Electronic Design 's sister publication Machine Design . But in a recent interview , he touched on how artificial intelligence intersects with patent law and industrial technology . This interview has been edited and condensed . <p> Register for the ID&amp;E show and use the @ @ @ @ @ @ @ @ @ @ from March 7th to March 31st . Visit the website here for a full schedule of the event , which is co-located with the Manufacturing &amp; Technology Conference in Cleveland . <p> Why does artificial intelligence pose legal problems ? <p> Take AlphaGo . They started training the program by supervising it , giving it datasets to learn and then they let it go ahead and do some unsupervised training . It played a bunch of games with itself and watched human Go players as it played . And the reason why that is important is that it provides much faster , more intuitive decision-making . <p> The reason why humans make mistakes is that our decisions are not based on probability . One of the things that Elon Musk , the founder of Tesla and SpaceX , says is that humans like to make analogies versus actually looking down at the fundamentals . And that is how he approached building his rockets . Instead of buying someone else 's , he went down to the fundamentals and built a rocket from scratch . <p> What does that have to @ @ @ @ @ @ @ @ @ @ " or software that is more or less humanlike " is cleaning the air for those program to make these analogies , because they can be significantly faster and use significantly less resources . Because they are mimicking human cognitive function , they are going to develop biases or stereotypes . <p> Because it is using an analogous method of learning , there could be issues with discrimination , even if you look at algorithms that are not necessarily A.I. I think there was an issue with Google : you typed in C.E.O . and rather than showing an appropriate number of women it was basically all men . Or there is the allegation that software targets ads for lower paying jobs to women . <p> The stance many patent examiners had taken is that even if the software you 're trying to protect or patent is something that a human can do " even given several humans doing it and it taking- a thousand years " it is not patent eligible . But the artificial intelligence field is trying to mimic a human 's fast intuitive judgment . And @ @ @ @ @ @ @ @ @ @ <p> How about- manufacturing and industrial engineering ? <p> Imagine machines that generate new code for manufacturing , detect inefficiencies , and change programs so that everything runs more smoothly . If I went ahead and invented something that improved the technical field of manufacturing or a specific product , it would arguably be patent eligible . <p> Like if a software program independently found a new way to machine a part or lay out a circuit board . How would copyright law work that situation out today ? <p> If you create something with an artificial intelligence program , it might be elibigle for copyright protection. - If you contribute the creative aspect , it 's clear that copyright protection is obtainable. - The question is harder with artificial intelligence because you do n't know who contributed the creative aspect . <p> How do you think the rise of artificial intelligence as a collaborator " and not just a tool " will affect human innovation ? <p> A.I. programmed to learn and specialize in a particular technology or technical field can certainly accelerate human innovations. - For example , @ @ @ @ @ @ @ @ @ @ can identify potential issues and suggest technical solutions for them to explore. - Even when the A.I. program is unable to provide more concrete answers , it may ask insightful questions . <p> Some have proposed giving intelligent software the ability to file patents . <p> I do n't know if giving the ownership rights to artificial intelligence program will solve any problems . For now , an artificially intelligent robot ca n't get rights to patent . Like animals ca n't get rights to copyright . There was once- this copyright case with a monkey that took a selfie . An- artist tried to sell the image and the court basically said that copyrights are n't for monkeys . <p> How might patent law be modified to better handle the artificial intelligence problem ? <p> The law always lags behind technology . It would always be great if lawmakers would think ahead and create laws based on what they think is coming rather than trying to fix the problem many years after technology is introduced. - I do n't have any specific ideas but one thing would be to @ @ @ @ @ @ @ @ @ @ to think ahead but unfortunately it has n't happened . <p> It seems like law firms are mulling over how software can make them more efficient . How do you think that artificial intelligence will change a lawyer 's job ? <p> What Ross does is keep track of law reviews and case law . It may make certain suggestions about current cases . It can also be used in discovery and document review : attorneys can spend hours and hours , days and days , and maybe even weeks pouring over documents to check what 's relevant to submit . <p> Things like that " in the next ten years " artificial intelligence will probably be able to do . If they take my job , I hope I 'll be retired by then . 
@@21004512 @1004512/ <p> Last year , SiFive went fishing for engineers to test out chips based on the RISC-V instruction set , releasing an embedded core called Rocket that anyone could download and modify . But now the company , whose founders invented RISC-V , is using richer bait for more ambitious customers . <p> Last week , SiFive started selling two cores under the brand Coreplex for applications like wearables and servers . The company aims to make it easy for engineers trained on Intel or ARM instruction sets to take RISC-V for a spin . But it is working against the fact that few engineers appear to be turned off by the licensing fees or inflexibility of rival technology . <p> Licensing the cores takes little more than signing an online contract and making a one-time payment , which will cost less than a million dollars . It is also making the register transfer level more commonly known as the RTL available immediately , so that chip designers can simulate particular designs . <p> The announcement is a mile marker for the year-old business . SiFive is trying to @ @ @ @ @ @ @ @ @ @ starting instructions for creating a chip and which promises to reduce the millions of dollars and years of development required to make chips for markets like the Internet of Things . <p> SiFive is using the new instruction set to design chips ahead of time , filling in the blanks with its own custom technology or working with customers on unique designs . Its business model is similar to how Red Hat Software started selling its expertise with the free Linux operating system . <p> " Since the company was founded , we have actually had lots of requests from customers , " said Jack Kang , SiFives vice president of product and business development , in an interview last week . " They said , its nice to have open-source cores , but we want a commercial license that a company is behind and is well-supported . " <p> The Coreplex intellectual property includes two designs . The E31 core is a 32-bit processor that can replace the ARM Cortex M3 inside sensors and wearables , while the E51 core is a 64-bit embedded processor designed to serve as @ @ @ @ @ @ @ @ @ @ is trying to make it as easy as possible for engineers to experiment with its chips , since its biggest hurdle is building a community of RISC-V developers . It is not charging royalty fees , meaning that it gets nothing more than the one-time payment of $275,000 for the E31 and $595,000 for the E51 . <p> Its sales strategy aims to eliminates many of the usual snags for licensing cores : engineers will not have to contact a salesperson or sign a non-disclosure agreement to view datasheets and specifications . If companies want to purchase the cores , they only have to sign a seven-page contract . There is no need for negotiation . <p> " In royalty-based models , companies have to know exactly what you are making and how many there will be , " Kang said . " But you can buy enterprise software online directly without talking to anyone . So we asked : why not bring that to hardware ? " <p> RISC-V let 's companies modify the basic instructions inside their chips , using a modular design that allows engineers to add custom @ @ @ @ @ @ @ @ @ @ of which tightly control their instruction sets . Using RISC-V , companies control more of the chip 's design , cutting down on money and time required for customization . <p> That has clearly intrigued companies looking into custom chips , especially ones trying to squeeze performance out of data centers . The RISC-V Foundation , which maintains the instruction set , includes members like Google , Microsoft , and Oracle , as well as IBM . Their engineers are frequent attendees at RISC-V meetings . <p> But the instruction set has also won over large semiconductor companies . After evaluating ARM , MIPS , and other embedded architectures , Nvidia started using RISC-V in the controllers for its graphics chips . Microsemi , one of SiFive 's first customers , is already using Coreplex technology in its Igloo and other FPGA chips . <p> Investors are also betting on open hardware . SiFive , whose founders Krste Asanovic , Yunsup Lee and Andrew Waterman are also active with the RISC-V specification , announced Monday that it had raised $8.5 million from Spark Capital and other investors . The start-up @ @ @ @ @ @ @ @ @ @ <p> The start-up also said Monday that it had sold over a thousand of its Freedom development boards , which it released in November through a crowd-funding campaign . Its customers can tinker with the register transfer level inside the chips , offering customization that SiFive handles itself in the Coreplex designs . <p> The company does n't view Coreplex as a repudiation of its open-source roots , though . " Its still the early days for RISC-V , so lots of companies initially decided to try it without actually understanding what free and open means , " said Kang . " The biggest surprise is that it is n't exactly what they were initially looking for . " <p> " But I think the sign of momentum is that companies say that they want more from us , " said Kang . " We 've really been surprised by how quickly RISC-V has grown . " 
@@21004519 @1004519/ <h> Making Sense of Wireless Sensor Power Consumption <p> Wireless sensors and meters surround us in almost every aspect of modern life . From the hundreds of sensors inside our cars that monitors driving operations and safety to the water , gas , and electrical meters in our homes that transmits our consumption wirelessly to the utilities companies , modern conveniences simply would not be possible without these sensors and meters . The proliferation of these wireless sensors and meters means that these devices must be trusted to properly operate for long periods of time . <p> Jan 09 , 2017 <p> Brought to you by Type <p> On-Demand Webinar <h> Speaker <p> Steven Lee Application Specialist Keysight Technologies <h> Description <p> Why this webcast is important : <p> Wireless sensors and meters surround us in almost every aspect of modern life . From the hundreds of sensors inside our cars that monitors driving operations and safety to the water , gas , and @ @ @ @ @ @ @ @ @ @ to the utilities companies , modern conveniences simply would not be possible without these sensors and meters . The proliferation of these wireless sensors and meters means that these devices must be trusted to properly operate for long periods of time . <p> Designers of such wireless sensors and meters must carefully analyze the battery drain characteristics to optimize and validate the battery run time of their devices . This means testing several elements of their device : the sub circuits , the battery , and the device as a whole . <p> In this webcast , we will discuss the needs and challenges of analyzing battery drain characteristics of common battery powered wireless sensors . <p> Who should attend : <p> Designers of wireless sensors who need to characterize power consumption in order to maximize battery run time . 
@@21004520 @1004520/ <h> The Case of the Curious Curie 96Board <p> The 96Board specification was created by Linaro , launched to foster the ARM ecosystem . The 96Board specification is actually a collection of three platforms for Cortex-A and Cortex-M platforms , including the Consumer Edition ( CE ) , Enterprise Edition ( EE ) , and IoT Edition ( IE ) . The latter is only 30 by 60 mm . <p> All are based around a low speed , 2- by 20-pin mezzanine expansion connector with a 2-mm pitch . The connector supports up to a pair of UARTs , an SPI bus , up to two I2C interfaces , an optional I2S interface , and a dozen GPIOs . There are power and reset connections , as well . A 3.3 V version is defined with a 2 by 15 pin header with a 2.54-mm/0.1-in pitch . <p> Somewhere along the line the designers forgot about the ARM connection and started delivering boards based on other processor architectures like Intel 's x86 platforms . These tended to be larger chips and suitable for the larger form factors like @ @ @ @ @ @ @ @ @ @ Enter Intel 's Quark , a 32-bit platform designed for- low power applications . The architecture has been used on a number of platforms targeting the Internet of Things ( IoT ) , including Intel 's Curie module . The Curie is built around a 32-MHz Quark SE SoC with 384 Kbytes of flash and 80 Kbytes of SRAM . There is also a 6-axis accelerator/gyroscope and a Bluetooth Low Energy ( BLE ) wireless interface . There is an ARC-EM4 microcontroller for handling the sensors . <p> The Curie is also the basis for the Gumstix Radium 96bie ( Fig. 1 ) . This IE platform was actually designed using- Gumstix 's Geppetto . Geppetto is a web-based board design tool that now includes Curie as an option . The open-source board design can be changed using Geppetto . The upfront cost for a new board design is only $1,999. - This is for delivery of completed boards like the Radium 96bie , not just a blank PCB . It is also possible to design 96Board platforms with other modules and processors . <p> The board has a pair @ @ @ @ @ @ @ @ @ @ other is for debugging . The header provides the standard 96Board support . There is also a connector for a Bluetooth antenna . Power can be provided by the header or the USB debug port . <p> The other piece to the Curie puzzle is General Vision 's neural network , which is built in . It has 128 neurons ( Fig. 2 ) . It is actually an embedded binarized neural network ( eBNN ) that can be used for classification . It is significantly more powerful than anything that could be implemented on the CPU , and many-higher performance systems as well . Deep neural networks ( DNN ) are the hot artificial intelligence ( AI ) topic these days . The Curie may not be running a self-driving car but its network can do some interesting analysis . <p> 2 . The Curie has neural network hardware with 128 neurons . <p> There are a couple of ways to get started with the Radium 96bie board since it is functionally the same as the Arduino 101 , another Curie-based board . In fact , you can switch @ @ @ @ @ @ @ @ @ @ <p> The two I worked with include the Arduino development platform and Intel 's Open Developer Kit ( ODK ) . The Arduino approach is more amenable for the casual developer . It concentrates on the Curie as an x86 platform , but it is possible to program the neural network as well . The network can learn , so typically a developer will have two applications for the platform . One will be used for training . The other would be the application to be deployed that would use the training results . Of course , it is possible to have one application that does both . <p> The CurieNeurons library is used to work with the neural network . It provides services like data acquisition and feature extraction . There is a Knowledge Builder application that can handle offline training . There are a number of examples , including a gesture recognition system that works with the 6-axis accelerometer and gyro . <p> Video recognition is possible with the Arduino 101 board and an ArduCam Shield . The Gumstix board does not have a camera interface , so @ @ @ @ @ @ @ @ @ @ Intel ODK is based on Eclipse and also works with a range of boards , including the Arduino 101 and the Radium 96bie . One advantage of the ODK is support for Zephyr , a compact , real-time operating system ( RTOS ) that targets lightweight IoT platforms , including those for wearable applications . Zephyr is platform neutral , so the Curie is just one of many platforms that it will work with . The ODK has Zephyr projects in the mix , making it easy to get started . <p> Zephyr is actually based on Wind River 's VxWorks Microkernel Profile for VxWorks . The open-source platform is designed for commercial applications . It was designed to be modular and secure . I will do more on Zephyr sometime in the future . <p> For now , the installation of the ODK was straightforward , but more extensive than the Arduino tool install . I installed it on Ubuntu 14.04. because I had a virtual machine handy , but it also works with the latest 16.04 version . Getting started with the same projects was slightly more involved @ @ @ @ @ @ @ @ @ @ is significant especially when taking advantage of other plug-ins available . <p> The other piece to the ODK puzzle is the Arc32 toolchain for the ARC-EM4 microcontroller . It did not work with this portion , but looks to be just another project configuration in Eclipse . <p> Dealing with the Curie can be a more involved project because of its neural network and sensor microcontroller . It is possible to use these without major programming efforts . The same is true for the Bluetooth stack . Most will use it as is . <p> The Radium 96bie board is a nice , compact platform . It can be used as is , but it is the 96Board expansion that really makes it interesting . The community is not as vast as those of the Arduino and Raspberry Pi but there are 96Board mezzanine cards available . The advantage is the cards are easy to design and inexpensive to make . Popping a battery on a mezzanine card provides a mobile wireless platform . 
@@21004522 @1004522/ <p> As demand grows for more bandwidth throughput , the requirement to synchronize network functions is becoming more critical . The biggest driver of synchronization is the explosion of wireless networks , whose nodes must all be in lock-step . <p> The IEEE 1588 network timing standard has been the cornerstone protocol used to implement synchronous networks in wireless backhaul , carrier Ethernet , routers , and data-center interconnects . Its popularity has led to it also being leveraged in markets outside of communications , such as industrial applications like smart grids , machine-vision cameras , and industrial automation . <p> While it 's relatively easy to implement IEEE 1588 across most of the network , challenges arise when implementing IEEE 1588 clients . Thus , four critical decisions need to be made when creating complete client/save solutions . <p> Figure 1 shows some of the key points of an IEEE 1588 network . <p> 1 . Here is a typical example of an IEEE 1588 network , which includes the grandmaster clock , switches/gateways , and client or slave devices . <p> It all starts with a grandmaster @ @ @ @ @ @ @ @ @ @ . In addition , there are likely numerous Ethernet switches , gateways , and access points that need to be aware of the IEEE 1588 protocol . Finally , client or slave devices reside at the end of the network . <p> To ensure the most accurate timing across the network , all nodes in the network should be IEEE 1588-aware . One interesting characteristic of IEEE 1588 is that it will still work even when unaware nodes populate a network , although the accuracy of the recovered network clock will not be as precise . For the most precise synchronization , all switches and client devices should support the IEEE 1588 protocol. - Knowing this background on the networking standard , what steps should be taken to implement an IEEE 1588 design ? <p> Many vendors make grandmaster clocks that can plug into an Ethernet network . These may be packaged boxes or boards or module-type solutions . Getting a switch is also straightforward , but it has to support the IEEE 1588 protocol . This is often part of the switching support software that 's purchased with an @ @ @ @ @ @ @ @ @ @ is n't quite as simple . There 's typically only one Ethernet port into the device , so buying a multi-port switch is often overkill . But , how else do you obtain the network clock ? - To obtain a recovered clock , a client or slave device requires four main elements : - <p> An Ethernet PHY to time-stamp the IEEE 1588 packets . <p> A processor that can run the IEEE 1588 Precision Time Protocol ( PTP ) . <p> The processor also has to run a servo algorithm and interface to an adjustable phase-locked loop ( PLL ) . <p> A high-precision PLL that supports IEEE 1588 accuracy and then outputs the network clock . <p> Semiconductor vendors will often have pieces of a client/slave design , but not a complete solution . To implement this complete IEEE 1588 client/slave design ( Fig. 2 ) , architects need to make several decisions . <p> 2 . To achieve a complete IEEE 1588 client/slave solution such as that shown , designers must make multiple key decisions . <p> Decision #1 : - Leverage host processor or use @ @ @ @ @ @ @ @ @ @ engineers must make is whether to use the host processor to run the IEEE 1588 PTP and servo algorithm , or use a dedicated processor . Of course , using the host processor does n't add cost to the design , but it has some major drawbacks . For example , if the host processor is fairly heavily loaded and the response time from being interrupted is non-deterministic , this becomes a problem because the IEEE 1588 PTP must be monitored and reacted to in a timely manner . If this does n't happen , the PLL will not be adjusted often enough , which will decrease the accuracy of the recovered network clock. - <p> If a design uses a dedicated processor for the IEEE 1588 PTP and servo algorithm , then the performance would be assured and , consequently , a mid-range performance microcontroller could actually be used , such as an ARM Cortex M3 . The M3 would be dedicated to running the IEEE 1588 software timing routine and the algorithm to control the PLL . This software monitors the network clock and adjusts the PLL if @ @ @ @ @ @ @ @ @ @ also be required to interface to the Ethernet PHY and the necessary interface buses to simplify system host integration. - <p> Using an ARM Cortex M3-based FPGA for these functions would minimize system software integration and testing because the performance would be known . An M3-based FPGA solution also allows for quicker field updates when new IEEE 1588 profiles or enhancements are available . <p> Some PLL vendors will provide the PLL and then suggest a third-party IP provider for the IEEE 1588 PTP and servo algorithm . Purchasing from a third-party provider gives a designer the flexibility to choose any PHY and PLL , but the processor selection may be limited and support issues could be a problem . <p> If the IP provider 's servo algorithm does n't work , do you call the IP company or the PLL vendor ? - These conflicts could result in longer debug and validation cycles . Often , it 's better to choose a PLL and the IEEE 1588 PTP and servo algorithm from the same company . Even better is if the vendor can demonstrate that its PLL was tested @ @ @ @ @ @ @ @ @ @ will operate as intended. - In addition , if there are issues with the design , you can call the silicon vendor who has both components. - <p> Decision #3 : What PLL vendor capabilities are most important ? <p> When selecting a PLL , engineers may need to consider the heritage of the silicon vendor . If the product is going to be deployed in a network with equipment from other vendors , you want to use a vendor with a sizable market share to give you the best possibility of interoperation . If your network is closed , this is n't as important. - <p> If you anticipate making many different types of IEEE 1588 slave/client products , you should look for a vendor who has a range of different types of PLLs . It 's best to pick a vendor who can support IEEE 1588 and SyncE , can select multiple sources to switch between , and so on . Lastly , using a vendor that provides not only PLLs , but also the servo algorithm , is a wise choice in order to minimize debug issues @ @ @ @ @ @ @ @ @ @ an embedded solution ? <p> Module solutions are available for IEEE 1588 client/slave implementations that should , theoretically , be the simplest to implement . The tradeoff of a module is that they 're usually a superset solution , and thus cost more . Vendors that provide modules are also smaller-size companies , and if longevity of supply is important , this may be a concern . The alternative is to use a multichip embedded solution. - Figure 3 offers an example of a complete IEEE 1588 solution from Microsemi . <p> 3 . This complete IEEE 1588 client/slave solution developed by Microsemi includes a Cortex M3-based FPGA that runs the protocol . <p> Although this type of implementation may require more board space , it has several positives . First , the Cortex M3-based FPGA that runs the protocol can leverage the FPGA fabric for acceleration functions if modifications are needed . Another benefit is that the PLL choice can be flexible , only needing driver changes in the software . <p> For simpler designs , choose a single PLL source device . If your design requires multiple clock @ @ @ @ @ @ @ @ @ @ higher-end PLL . The solution will be the same with just software driver changes , making the software host interface uniform across multiple designs. - Lastly , this solution has validated performance ; therefore , implementing it as shown will ensure the clock accuracy in the provided reports. - <p> More system designers are being asked to implement IEEE 1588 . The steps as outlined here are a great place to start " determine the grandmaster clock , what switches and gateways will be used , and then determine the needs for the client/slave devices . The decisions for selecting the optimal IEEE 1588 solution will depend largely on your corporation 's knowledge of the protocol . Look for vendors that can provide complete solutions , as well as enable their customers to leverage this experience so they have the flexibility to implement the optimal network timing design for their specific requirements . 
@@21004523 @1004523/ <h> A Jewel of a Joule <p> It came near the end of Intel 's CEO 's keynote speech at the Intel Developers Forum , but the Intel Joule ( Fig. 1 ) module looks to be a winner . It is designed for high-volume production and is essentially a PC on a module . <p> The Joule module ( Fig. 2 ) is based on a 1.7-GHz , quad-core T5700 Atom with a 2.4-GHz burst mode . The Intel HD Graphics can drive 4K displays . The module has 4 Gbytes of LPDDR4 RAM and 16 Gbytes of eMMC flash storage . Wireless support includes 802.11ac Wi-Fi with MIMO and Bluetooth 4.1 . <p> The module is designed for production , not just prototyping . It has four mounting holes and a pair of connectors on the back ( Fig. 3 ) . The connectors expose the video interface along with USB 3.0 and MPI CSI and DSI interfaces , along with multiple GPIO , I2C , and UART interfaces . <p> Small modules like the Joule have been available , and there are quite a few that @ @ @ @ @ @ @ @ @ @ that it is x86 and available directly from Intel . The design is solid and the functionality is on par with a laptop from a few years ago , but able to drive the latest 4K displays . It supports software that is optimized for Intel 's 3D RealSense camera . <p> 2 . Intel+ ? ? s Joule packs in a quad core Atom with wireless support and video output that can handle 4K displays . <p> - <p> I remember seeing a number of robot platforms like the iRobot Create running around carrying a small laptop that was the controller . The Joule module does everything that laptop would do while using a lot less power . Raspberry Pis handle this chore nowadays , but the Joule is more powerful and more compact . <p> The Joule kit ( Fig. 4 ) available from Intel includes a Joule and Tuchuck carrier board . The module comes with Ostro Linux and will run a variety of operating systems , including Ubuntu Core ( more about Ubuntu Core in the near future ) . It could have a significant impact @ @ @ @ @ @ @ @ @ @ and security . <p> 3 . The Joule has a pair of connectors on the back that provides access to USB 3.0 and MPI CSI and DSI interfaces , plus multiple GPIO , I2C , UAR , T and video interfaces . <p> - <p> The latest RealSense technology was also highlighted at IDF and part of the kit . Intel 's Diana Shea wore a set of safety glasses ( Fig. 5 ) with a Joule and RealSense camera built in . This was not an augmented reality application , per se . Instead , the output of the RealSense camera is analyzed by the Joule based what the user sees . It identifies items in the field of view and determines if the process the user is performing is correct , audibly warning the user if an error occurs . The example was placing bolts into an airplane door that might be done during the construction process . <p> 4 . The Joule kit provides a starting point for developers . It includes a RealSense camera . <p> - <p> The scenario addressed the possibility that the video @ @ @ @ @ @ @ @ @ @ then see what was going on . They could converse with the user , as well . The augmented reality would be from the remote user 's perspective . This significantly reduces the complexity and weight from the user 's point of view while providing an overall benefit . <p> The cables shown in the image were to provide video output to IDF attendees . The unit would normally operate wirelessly without the cables using on-board batteries . <p> 5 . Intel+ ? ? s Diana Shea wears a set of safety glasses with a Joule and RealSense camera . The cables provided video output that was displayed at the show . The unit would normally operate without the cables . <p> - <p> The Joule does not operate by itself . It needs a carrier board , and one is available in the kit . The Joule is supported by Gumstix Geppetto . I think this is very significant because the web-based design tool is easy to operate using a drag-and-drop interface . It handles all wiring transparent to the user , and the result is a fully populated @ @ @ @ @ @ @ @ @ @ a $1,999 start-up fee . That is a fraction of what it would cost to do it in-house or through a contract design house . Gumstix has already used the tool to generate half-a-dozen designs like the AeroCore 2 ( Fig. 6 ) that are available for only a per-board charge . That is pretty impressive given Gumstix turned this around in about a month , including integrating and testing the Joule support within the tool itself . The AeroCore 2 actually has an ARM Cortex-M4 on it to provide real-time control capabilities to the Joule . There are other modules that would be ideal for applications like digital signage . <p> I am looking forward to getting my hands on the Joule and the RealSense camera . That mix alone makes it interesting . The compact size , rugged design , and support from Intel make it an excellent platform for product systems that currently use boards or other modules . It is not for all applications , and some may think it too large for wearable applications , but it will all depend upon what the application is @ @ @ @ @ @ @ @ @ @ Curie or other very compact ARM platforms designed for a smartwatch , but that is only a fraction of the wearable applications out there . There are even more applications where small size and video input and output will be important . 
@@21004525 @1004525/ <h> How To Get Big Sounds From Small Speakers <p> Sponsored By : Texas Instruments A new generation of " smart amplifiers , " - incorporating new driver topologies and DSP technology is significantly improving the quality and volume of sound from speakers . <p> One consumer-electronics trend that shows no signs of slowing down is the drive toward ever-smaller devices . Desktop PCs become laptops and then tablets . Portable devices become wearables . And , of course , every succeeding generation is thinner than the last. - <p> In the midst of this rapid change , every smartphone and laptop still depends heavily on an invention that 's remained substantially the same for over 90 years : - the moving-coil loudspeaker , first patented in 1925 . After that initial breakthrough , speaker performance showed only incremental improvement for many years . Sadly , there is n't a Moore 's Law for speakers . The same applied to techniques for driving them , at least until recent improvements such as Class-D amplifiers . <p> In recent years , though , a new generation of " smart amplifiers @ @ @ @ @ @ @ @ @ @ DSP ) technology . As a result , designers are able to make big improvements in both the quality and volume of sound from speakers , particularly from the very small and cheap units used in many portable devices . <p> Smart Bass : Automatically adjusts the bass response to accommodate for larger excursions when there 's increases in signal amplitude . The algorithm uses a combination of the speaker model , psychoacoustics knowledge , and a user-selected target response . <p> Protection : Models the current state of the speaker to adaptively change amplifier characteristics to avoid over-temperature and over-excursion . <p> To understand why this technology produces better sound , let 's first take a quick look at moving coil speaker construction . Figure 2 shows a typical loudspeaker . It consists of a cylindrical coil connected to a cone made of paper or a composite material . The coil assembly is positioned between the poles of a permanent magnet and is free to move in the axial ( y ) direction . The loudspeaker frame secures the cone at the larger end . A flexible mount ( @ @ @ @ @ @ @ @ @ @ - <p> Since the coil is in a magnetic field , a current applied to the coil moves it according to the Lorentz Force Principle ( Fig. 3 ) . As the current changes , the back-and-forth motion of the coil is transferred to the cone , producing longitudinal waves of sound . <p> 3 . In loudspeaker operation , the coil moves due to a current that 's applied to it , according to the Lorentz Force Principle . ( Source : Lulea University ) <p> - <p> Where Speakers Go To Die <p> Along with sound quality , a primary task of the audio system designer is to ensure the amplifier does n't overdrive the speaker and cause its early demise . Unlike the legendary elephant 's graveyard , speakers do n't all end up in the same place at end of life . Failures vary with the application , but they tend to fall into one of two broad categories : <p> Thermal failure <p> Loudspeakers are very inefficient transducers . Up to 95% of the energy input is turned into heat in the voice coil ; @ @ @ @ @ @ @ @ @ @ protection . Thermal failure occurs when the speaker is fed more power than it is designed to safely handle , causing the voice coil to get too hot . <p> There are two main thermal failure mechanisms : <p> The adhesives used to hold the voice coil together can soften , resulting in the coil coming apart . <p> If the coil gets too hot , it can melt or burn the wires ; an open circuit is the most likely result . <p> Mechanical failure <p> Under normal operation , a speaker coil moves just a fraction of an inch . Mechanical failure can occur when the drive signal demands movement from the speaker coil that exceeds the design limits . At one extreme , the coil may strike the backplate of the speaker assembly , causing an audible clicking sound . At the other extreme , the coil may pop out of its slot altogether and fail to return correctly , resulting in a permanent misalignment . <p> Excessive excursion can also cause stress in the cone due to stretching and vibration , or tear the fabric spider @ @ @ @ @ @ @ @ @ @ even cause the coil connecting wires to fray and eventually break . <p> The Smart Way to Prevent Speaker Failure <p> Increasing the power delivered to the speaker while maintaining audio quality requires controlling the voice-coil temperature and keeping the cone excursion within safe limits . <p> In high-power systems , a fuse or polyswitch ( PPTC device ) can interrupt current to the loudspeaker when it exceeds a safe level . In portable applications , the traditional approach limits the amplifier output to a level that 's guaranteed safe under worst-case conditions . This is effective at preventing damage , but restricts the loudspeaker output across its whole performance envelope . <p> The process begins with a precise characterization of the speaker to be used , then matching the smart amplifier response to the speaker characteristics . Using continuous speaker modeling , the system constantly optimizes the output power peaks for maximum power and reliability. - <p> A 5-W speaker can use a much larger amplifier , 50 W say , with no risk of potential damage , while maintaining reliablity . Peaks in the audio are no longer @ @ @ @ @ @ @ @ @ @ intelligibility . <p> Alternatively , designers can choose to decrease their speaker size for the same power rating . This will ultimately shrink the form factor and save cost . <p> Characterizing the Loudspeaker <p> The first step in the process is a detailed understanding of speaker parameters and performance . <p> 4 . A full lumped-parameter model of a loudspeaker includes elements related to electrical , acoustical , and mechanical properties . ( Source : Wikibooks ) <p> - <p> A loudspeaker is a complex electromechanical system . Electrically , it 's a combination of resistive and both capacitive and inductance reactance . A full lumped-parameter model includes elements related to electrical , acoustical , and mechanical properties ( Fig. 4 ) . <p> The impedance of a loudspeaker is far from linear over the audio frequency range . Each speaker is different , of course . However , Figure 5 shows the general form , with a low-frequency resonance and a mid-range inflection point at the nominal specified impedance . <p> The frequency response of the speaker system depends on both the speaker itself and its enclosure . @ @ @ @ @ @ @ @ @ @ , but the other parameters must be calculated based on a series of acoustic tests that measure the speaker output over its full range . <p> The tests require specialized software and a highly linear reference microphone . To compensate for room acoustics , the results combine the low-frequency response of a near-field measurement with the high-frequency response of a far-field measurement ( Fig. 6 ) . Go here to see a detailed description of the audio characterization process . <p> Smart amplifier manufacturers offer hardware and software tools to automate this process . Together they help the designer gather detailed measurements of the target speaker excursion , output level ( SPL ) , and temperature to fully understand the speaker 's capabilities . The result is a configuration file that the production microcontroller downloads into the smart amplifier DSP on boot up . <p> Improving Sound Quality <p> Given the speaker 's nonlinear performance , using an amplifier with a flat frequency response over the audio range of 20 Hz to 20 kHz will not result in a flat response for the listener . With an accurate model of @ @ @ @ @ @ @ @ @ @ to modify the characteristics of a smart amplifier to compensate for speaker shortcomings . <p> Figure 7 shows the improvement in frequency response from an accurate characterization and well-chosen EQ settings . It 's also possible to incorporate psychoacoustics information to compensate for the fact that the ear 's frequency response itself is not linear . <p> 7 . Tests on a compensated speaker show a flat high-frequency response ( Source : TI ) <p> - <p> All About Bass : Psychoacoustics and the " Missing Fundamental " <p> With an increasing amount of low-frequency content in popular music and film soundtracks , consumers expect to hear a faithful reproduction on their mobile devices . But unlike that annoying music from the vehicle stuck in traffic next to you , a teeth-rattling bass response is n't usually touted as a feature of the typical smartphone or iPod . <p> As the size of the cellphone decreases , the volume of air behind a speaker cone becomes smaller . This smaller size limits the cone 's range of motion , so the speaker does n't produce sufficient force to compress the @ @ @ @ @ @ @ @ @ @ of the speaker cone , which in turn lowers the output . The frequencies affected the most are those with the largest amount of displacement , i.e. , low frequencies at higher volumes . <p> Improved bass response is one very obvious difference when comparing a smart amplifier to a standard solution . For example , check out this video : <p> It accomplishes this by employing psychoacoustics , the field of research concentrating on the acoustic response of the ear and the brain 's perception of sound . Essentially , a smart amplifier fools the brain into hearing low frequencies that are n't actually there . <p> A musical note normally contains a fundamental tone that defines the pitch , plus harmonic overtones at multiples of the fundamental . When the overtones are present , but not the fundamental , the listener can still perceive the lower note , a phenomenon known as the missing fundamental . Researchers believe that the brain processes the information in the overtones to calculate the fundamental frequency . The precise mechanism is still a matter of debate , but the processing seems to @ @ @ @ @ @ @ @ @ @ auditory nerve . - <p> Smart amplifiers split the audio signal by frequency . Higher frequencies that can be safely reproduced by the speaker are unaffected . But the amplifier DSP analyzes lower frequencies , synthesizes the harmonics above the fundamentals , and then adds them back into the audio signal to create the perception of a powerful bass response . This results in great bass performance at all volume levels . <p> Conclusion <p> A smart amplifier helps overcome fundamental limitations in the performance of small speakers , with a system-on-a-chip ( SoC ) approach that includes both precision analog and DSP circuitry . When combined with automated development tools , designers can perform characterization and tuning to match the system performance to the particular speaker being used. - <p> In use , DSP technology and adaptive software can significantly boost the volume while still protecting against speaker failure , and improve frequency response across the entire audio range . 
@@21004527 @1004527/ <h> A Brief History Of Telemedicine <p> It may seem that the piqued interest in telemedicine over the last few years can be attributed to telecom advances . The truth is that telemedicine has been around since the 1960s , when astronauts first went into space . In fact , NASA built telemedicine technology into early spacecraft and spacesuits to monitor astronauts ' physiological parameters . Yet other milestones mark telemedicine 's journey to where it is today . <p> 1964 : Under a grant from the U.S. National Institute for Mental Health ( NMH ) , the Nebraska Psychiatric Institute began using a two-way closed-circuit TV link between the Institute itself and Norfolk State Hospital about 112 miles away . The link was used for education and consultations between specialists and general practitioners . <p> 1967 : A medical station was established at Boston 's Logan International Airport and linked to Massachusetts General Hospital ( MGH ) , miles away within the city of Boston . Physicians at MGH provided medical care to patients at the airport 24 hours a day , using a two-way microwave audio/video link @ @ @ @ @ @ @ @ @ @ 's Lister Hill National Center for Biomedical Communication chose 26 sites in Alaska to verify the reliability of telemedicine via satellite communications . NASA 's ATS-1 satellite was used for this experiment . <p> 1972 : NASA began trial runs of its Space Technology Applied to Rural Papago Advanced Health Care ( STARPAHC ) program for telemedical help for people living in remote locations with little or no medical services , like Arizona 's Papago Indian Reservation . Engineered by NASA and Lockheed Missiles and Space Co. ( now Lockheed-Martin ) , the system used two-way microwave transmissions to link paramedical personnel located in mobile ( vans ) and fixed stations with medical experts at hospitals in Tucson and Phoenix . The program lasted until 1975 . <p> 1972 : The Health Care Technology Division of the U.S. Department of Health , Education and Welfare ( HEW ) funded seven telemedicine research and demonstration projects : the Illinois Mental Health Institutes in Chicago , Ohio 's Case Western Reserve University in Cleveland , Massachusetts ' Cambridge Hospital , Illinois ' Bethany/Garfield Medical Center in Chicago , Minnesota 's Lakeview Clininc @ @ @ @ @ @ @ @ @ @ , N.H. , and the Mount Sinai School of Medicine in New York City . The next year , the U.S. National Science Foundation ( NSF ) funded two more telemedicine projects : the Boston Nursing Home project for geriatric patients , and the Miami-Dade project between Florida 's Dade County and Miami 's Jackson Memorial Hospital . <p> 1977 : Canada 's Memorial University of Newfoundland participated in a Canadian Space Program for distance education and medical care , using the joint Canadian/U.S . Hermes satellite . <p> 1984 : The North-West Telemedicine project was set up in Australia to pilot test the Australia government 's Q-Network satellite communications network . The project 's goal was to provide health care to people in five remote towns south of the Gulf of Carpentaria . <p> 1989 : After a massive earthquake hit the Soviet Republic of Armenia , the U.S. offered the Soviet Union , under the auspices of the U.S./U.S.S.R . Joint Working Group on Space Biology , use of a one-way international telemedicine network for consultations between Yerevan , Armenia , and four medical centers in the U.S. @ @ @ @ @ @ @ @ @ @ Russia . 
@@21004528 @1004528/ <h> Every Step in Infineon 's Failed Acquisition of Wolfspeed <p> The rigamarole- of Cree 's Wolfspeed sale has flown under the radar for months . Last year , Infineon said that it would pay $850 million for the business , which would expand its portfolio of chips for power management and wireless equipment. - But that is a drop of the chip industry 's billions of dollars in consolidation . <p> But the- story changed last month when the United States security panel that approves such deals withheld its blessing . One possibility is that regulators- were worried about losing Wolfspeed's- gallium nitride expertise . The ruling set off hand-wringing at both companies involved in the deal , which quickly fell apart. - <p> When layered on other semiconductors , gallium nitride can handle higher voltages and higher temperatures than normal silicon . It has gradually- spread into everything from antiballistic missile radar to cellular equipment . Wolfspeed also fills custom chip orders for- the- Department of Defense and contractors like Lockheed Martin . <p> In recent years , the regulators have rejected several deals that would have @ @ @ @ @ @ @ @ @ @ . But the failure of the- latest deal hints at how worried the United States is of losing its edge in semiconductors. - Infineon- is based in- Germany , a traditional ally . <p> After the announcement , Electronic Design covered the deal sparingly . But its sister publication , Microwaves &amp; RF has followed every step of the- closing process . Here is all the reporting that the magazine has done on the deal : 
@@21004532 @1004532/ <p> The RISC-V instruction set failed more than a hundred tests related to how software running inside a high-end chip stored and retrieved information from memory . The flaws that caused the failures are already being repaired and only affect a high-performance core using the open-source architecture . <p> Margaret Martonosi , a professor of computer science at Princeton University , and her colleagues published a paper that identified holes in the RISC-V specification , which is supposed to ensure that processors take turns accessing shared memory . The researchers found that one type of RISC-V hardware cheated on memory ordering tests . <p> Princetons paper , released at the ACM International Conference on Architectural Support for Programming Languages and Operating Systems , warned that the holes could cause errors in software running on high-performance hardware based on the RISC-V instruction set , which lays out the most basic functions of chips like memory and logic . <p> " Incorrect memory access orderings can result in software performing calculations using the wrong values , " Martonosi said in a statement . " These in turn can lead to hard-to-debug @ @ @ @ @ @ @ @ @ @ to be vulnerable to security exploits . " <p> Krste Asanovi- , chairman of the RISC-V Foundation , said in an April blog post that the failed tests had been taken the wrong way . " It is important to note that failed litmus tests do not correspond one-to-one with errors in the memory consistency models , " he said . <p> " A single change to the RISC-V ISA specification could eliminate all these errors , " he added . <p> Asanovi- said that the holes in the memory consistency model were first identified in late 2015 . They would be fixed in the latest release of the RISC-V specification . Daniel Lustig , a research scientist at Nvidia and one of the papers authors , is overseeing changes to the memory model . <p> " Everythings under control , " Lustig said last month in a Shanghai workshop . " There is nothing really to worry about , " he said , adding that the changes should chiefly concern engineers using high-performance cores with more aggressive rules for scheduling memory access . <p> But the impending changes will @ @ @ @ @ @ @ @ @ @ freely download . " The changes will be backwards compatible , such that existing simpler cores would run code written to the new specification correctly , " Asanovi- assured . <p> Lustig and other engineers revising the instruction set have downplayed the seriousness of the memory ordering flaws . RISC-V is facing stiff headwinds , including the fact that few engineers appeared to be running away from rival technology from Intel and ARM , which sells its blueprints or more basic hardware designs that chip suppliers can build upon . <p> The new instruction set , which can be freely used and modified , has intrigued companies looking into custom chips . Many electrical engineers from Google , Microsoft , Oracle , and IBM are a frequent presence at RISC-V meetings . Nvidia has used the instruction set to create a custom controller for its graphics chips . <p> An open-instruction set architecture , RISC-V could reduce the massive investment required to develop custom chips . It allows companies to create chips for a fraction of the cost and with better power consumption and performance than closed architectures , while @ @ @ @ @ @ @ @ @ @ architecture was first developed by computer scientists at the University of California , Berkeley Krste Asanovi- , Yunsup Lee , and Andrew Waterman who recently started a company called SiFive to sell cores that serve as a starting point for custom Internet of Things and data center chips . <p> The holes found inside the RISC-V specification are related to memory consistency models , which set ground rules for how programs inside chips take turns dipping into memory . The models can be affected by slight changes to the machine level , compiler , and high-level programming language of the chips . <p> Other architectures have suffered from issues with memory consistency models . Similar flaws affected ARM processors used in several versions of the Galaxy Nexus and Nexus 6 smartphones , the researchers said . In 2011 , ARM acknowledged the bug and repaired it with changes to the compiler level of its chips . <p> Asanovi- pushed back against holding RISC-V to a higher standard than other technology . He said that " no proprietary ISA vendor has published a formal memory model that they guarantee their products @ @ @ @ @ @ @ @ @ @ consistency model , the Princeton researchers built a hardware debugging tool called TriCheck , which runs tests using formal specifications of memory ordering rules , also known as axioms . The high-performance hardware that headlined the recent research paper failed 144 out of 1,701 litmus tests . <p> Asanovi- , a professor of electrical engineering and computer science at the University of California-Berkeley , said that RISC-V Foundation is considering input from chip designers and software developers to " fill the gaps and the holes and getting a spec that everyone can agree on . " He added : " The memory model is part of that . " <p> Correction : This article has additional responses to recent research that exposed holes in the RISC-V specification . An implementation of RISC-V failed " litmus tests " that do not always correspond to actual errors in memory ordering , said the chairman of the RISC-V Foundation . 
@@21004534 @1004534/ <h> Speaking of Orders : Who 's Winning ? <p> Products that integrated with Amazon 's Echo/Alexa , Google 's Home ( Fig. 1 ) , and others like Apple 's Siri and Microsoft Cortana were out in force at the recent 2017 Consumer Electronics Show . Alexa is Amazon 's recognition and command processing software , while Echo is the hardware platform . These systems employ artificial intelligence ( AI ) and voice recognition to provide human-like interaction with people . They do so by always listening for commands they can respond to , from playing a particular song to ordering another box of diapers . They can also look up information like nearby restaurants . <p> 1 . Amazon+ ? ? s Echo ( left ) and Google+ ? ? s Home ( right ) are the wireless , voice-activate systems that can be linked to a wide range of third-party applications and devices . <p> - <p> These platforms require the cloud to do the heavy lifting for voice recognition and analysis , as well as fulfilling many of the actions initiated by voice commands . @ @ @ @ @ @ @ @ @ @ is an example of how Internet-of-Things ( IoT ) devices can be controlled by these systems . Integration with these platforms is relatively straightforward in terms of registering devices and commands . Things get a bit more difficult when trying to replicate platforms like Amazon Echo or Google Home since this requires a robust voice-capture platform . <p> One of the platforms available for Amazon 's Alexa system is the Conexant AudioSmart 2-Mic Development Kit for Amazon AVS ( Fig. 2 ) . It is based on Conexant 's AudioSmart CX20921 Voice Input Processor and it can be attached to a host system like the popular Raspberry Pi . The Proprietary Smart Source Pickup ( SSP ) system isolates voice and cancels noise from all directions . The platform is designed to recognize the command prefix even when loud music or audio playback is occurring . <p> 2 . The Conexant AudioSmart 2-Mic Development Kit for Amazon AVS can be linked to platforms like the Raspberry Pi to provide additional functionality , as well as voice-capture . <p> - <p> Conexant was also showing a four-microphone system that provides directional @ @ @ @ @ @ @ @ @ @ of voice users . <p> Amazon appears to have an edge , more from being first and having a massive store available for orders . IoT devices from thermostats to electric cycles and charging systems had links to platforms like Alexa . <p> IoT devices typically link to only one of these platforms , although some tie into open IoT environments like Google Nest . That does mean customers will have to pick compatible IoT devices once they choose a platform like Google Home or Amazon Echo . Customers will also have to decide if having a system continually upload audio from their home or office to the cloud . In theory , this information will not be recorded , but analyzed for commands and then discarded . <p> The systems employ cutting-edge voice recognition and AI and will continue to improve , since the bulk of the analysis will be done in the cloud . Security and privacy issues will continue to be a point of discussion , and should be a consideration when employing these systems , although these are rarely discussed in their advertising . Still , @ @ @ @ @ @ @ @ @ @ are the IoT peripherals that can be controlled by them using voice commands or other , possibly less-intentional uses . 
@@21004535 @1004535/ <h> Speed of Engineering Quiz <p> Play the Speed of Engineering Quiz ! Sponsored by Bud Industries . <p> Feb 19 , 2017 <p> How much do you know about the speed of engineering ? Take the Bud Industries Speed of Engineering quiz just for playing , you 'll be entered to win a home automation package , including Amazon Echo , NEST thermostat , Samsung SmartThings Hub , Ring door bell , smart light bulb and dimmer , and smart outlet , worth $850 . Home automation gets you exactly what you need quickly , just like working with Bud . 
@@21004538 @1004538/ <p> Littelfuse , a major supplier of circuit protection devices , invested $15 million to take majority ownership of Monolith Semiconductor , a startup that has developed power devices for applications in renewable energy and electric vehicles. - <p> Monolith makes power diodes and switches out of silicon carbide , an advanced semiconductor- that allows devices to switch faster , handle higher voltages , and suppress heat better than silicon chips . It also has the potential to significantly cut the energy lost in power conversion , making it a popular replacement for silicon . <p> Though small , the investment shows how the- center of gravity in power electronics is sliding away from silicon. - The current generation of silicon carbide arrived with a more somber tone than previous years , but it has clearly matured . Tesla is using silicon carbide , more commonly known as SiC , - in its charging stations , while Toyota plugged it- in- an experimental hybrid . <p> " With the increasing needs to make power electronic devices that will be stronger and more efficient , we are excited about the @ @ @ @ @ @ @ @ @ @ , chief technology officer and general manager of the semiconductor products business at- Littelfuse , in a statement . <p> Littelfuse , founded in 1927 , is known for selling circuit protection devices as well as automotive sensors and fuses . But last year- it became the latest to start offering a number of- SiC devices , ones that handle- either 650 or 1200 volts . The company said that it would invest in Monolith again as the business hits milestones . <p> Co-founded in 2013- by- Kiran- Chatty , a former engineer at- SemiSouth- Laboratories , Monolith released its first products- last- year , a pair of diodes rated for 1200 volts and said to reduce losses by over 50% . The company moved from Ithaca , N.Y. , to Round Rock , Texas , after it signed a- production- deal with- X-Fab- in 2014 . <p> The technology- could allow aircraft companies- to slough off- 1,000 pounds from a passenger jet and reduce the weight of a locomotive by 5% , - according to estimates from- GE- Global Research . It could also vastly improve the efficiency of @ @ @ @ @ @ @ @ @ @ range of electric vehicles . <p> But it has been a long road from silicon carbide 's origins as an industrial abrasive to an advanced semiconductor. - The market has been slowed down by the complex and costly- process- of carefully etching patterns into SiC wafers . Silicon is also not dying out anytime soon , - with companies pushing devices to- higher voltages with lower losses . <p> One possible solution to these obstacles is the production from 4-inch- to 6-inch wafers , which can yield more devices. - General Electric is part of- the New York Power Electronics Manufacturing Consortium , which is- building an SiC foundry for 6-inch wafers in Utica , N.Y . The foundry X-Fab- is also offering- a 6-inch process . <p> In an earlier stage is another advanced semiconductor called gallium nitride , or GaN , which has made a big splash in the power electronics industry for promising the same performance as SiC with lower costs , since it can be layered onto cheap silicon wafers . GaN , which also has applications in antiballistic missile radar and lighting , has been @ @ @ @ @ @ @ @ @ @ acqusition of International Rectifier- in 2014- set off a wave of investment in the- sector. - Transphorm , a gallium-nitride power electronics startup , has raised over $212 million , with its most recent funding round hitting $70 million . Another big name is Efficient Power Conversion , which was founded by Alex Lidow , a former chief executive of International Rectifier. - <p> Sales of advanced semiconductors have lagged , but the market 's slow start- has not exhausted the optimism of industry analysts . Richard Eden , who follows the power- semiconductor market for IHS- Markit , estimates that sales of silicon carbide and gallium nitride chips reached $210 million in 2015 , rising to around $1.265 billion in 2020 . <p> Eden said in a report last year that silicon carbide was already fighting in price with superjunction Mosfets , a type of high-voltage silicon transistor , - at around 900 volts . He estimated that- that GaN layered on cheap silicon substrates would match the price of silicon MOSFETs and insulated-gate bipolar transistors ( IGBTs ) by 2020. 
@@21004543 @1004543/ <p> Since professors R.P. Sallen and E.L . Key described it in 1955 , the Sallen-Key low-pass filter has become one of the most widely used filters in electronic systems . Perhaps because the mathematics can be somewhat daunting , however , little has been written to help working engineers specify the correct components to achieve their objectives . For example , few realize the limitations of Sallen-Key filters at high frequencies . <p> The following describes the basic operations of a Sallen-Key low-pass filter and offers a simplified way of working with such circuits . Based on laboratory research , it also demonstrates some of this filter 's limitations at high frequencies . <p> Sallen-Key basics : The two-stage RC network shown in Figure 1 forms a second-order low-pass filter . This circuit has the limitation that its Q is always less than one-half . With R1 = R2 and C1 = C2 , then Q = 1/3 . Q approaches the maximum value of one-half when the impedance of the second RC is much larger than the first . But most filters usually require larger Qs than @ @ @ @ @ @ @ @ @ @ in positive feedback . With that feedback localized to the filter 's cutoff frequency , almost any Q can be realized . Mostly , it 's only limited by the physical constraints of the power supply and component tolerances . The Sallen-Key low-pass filter shown in Figure 2 is an example of how an amplifier is used in this manner . C2 is no longer connected to ground , but rather provides a positive feedback path around the amplifier . <p> The operation can be described qualitatively . At low frequencies , where C1 and C2 appear as open circuits , the signal is simply amplified to the output . R3 and R4 are chosen to give the desired gain . At high frequencies , C1 and C2 appear as short circuits , and the signal is shunted to ground at the amplifier 's input . The amplifier amplifies this input to its output , and the signal does n't appear at VO . Near the cutoff frequency , where the impedance of C1 and C2 are on the same order as R1 and R2 , positive feedback via C2 @ @ @ @ @ @ @ @ @ @ things somewhat , but there 's interaction between fC and Q. <p> The design should start by setting the gain and Q based on m , n , and K , and then selecting C and calculating R to set fC . It may be observed that K = 1 + ( m+1 ) / ( mn ) results in Q = GP . With larger values , Q becomes negative . In other words , the poles move into the right half of the s-plane and the circuit oscillates . The most frequently designed filters require low Q values , so this should rarely be a design issue . <p> This keeps the gain equal to 1 in the pass band . But again , there 's interaction between fC and Q. Design should start by choosing the ratios m and n to set Q , and then selecting C and calculating R to set fC . <p> The main motivation behind setting the capacitors equal is the limited selection of values in comparison with resistors . Interaction exists between setting fC and Q. Design should start with choosing @ @ @ @ @ @ @ @ @ @ the circuit before choosing C and calculating R to set fC . <p> Now fC and Q are independent of one another . Design is greatly simplified , although it 's simultaneously limited . Q is now determined by the gain of the circuit . The choice of RC sets fC . The capacitor should be chosen , and the resistor calculated . One minor drawback is that because the gain controls the Q of the circuit , further gain or attenuation may be necessary to achieve the desired signal gain in the passband . <p> Values of K that are very close to 3 result in high Qs that are sensitive to variations in the component values of R3 and R4 . Setting K = 2.9 results in a nominal Q of 10 . A worst-case analysis with 1% resistors results in Q = 16 . In contrast , if setting K = 2 for a Q of 1 , worst-case analysis with the same 1% resistors results in Q = 1.02 . Resistor values where K = 3 leads to Q = GP . And with larger values @ @ @ @ @ @ @ @ @ @ right half of the s-plane and the circuit will oscillate . The most frequently designed filters require low Q values , so this should rarely become a design issue . <p> Non-ideal circuit operation : Up to now , we 've assumed that the circuit was ideal , but there comes a time ( or actually a frequency ) when this is no longer valid . Simple logic tells us that the amplifier must be an active component at the frequencies of interest or else we have problems . But what are these problems ? <p> As mentioned previously , there are three basic modes of operation : below cutoff , above cutoff , and in the area of cutoff . Assuming that the amplifier has adequate frequency response beyond cutoff , the filter works as expected . At frequencies well above cutoff , the high-frequency model depicted in Figure 3 is used to show the expected circuit operation . The assumption made here is that C1 and C2 are effective shorts when compared to the impedance of R1 and R2 , so the amplifier 's input is at ac @ @ @ @ @ @ @ @ @ @ ground at its output limited only by its output impedance , ZO . The formula shows the transfer function of this particular model . <p> ZO is the closed-loop output impedance . It depends on the loop transmission and the open-loop output impedance , zo : <p> where a(f) is the open-loop gain of the amplifier and b is the feedback factor . This feedback factor is constant " set by resistors R3 and R4 . But the open-loop gain , a(f) , depends on frequency . <p> With dominant-pole compensation , the amplifier 's open-loop gain decreases by 20 dB/decade over the usable frequencies of operation . Assuming zo is mainly resistive ( usually a valid assumption up to a few hundred megahertz ) , ZO increases at a rate of 20 dB/decade . The transfer function appears to be a first-order high pass . <p> At frequencies above 100 MHz ( or so ) , the parasitic inductance in the output starts playing a role and the transfer function transitions to a second-order high pass . Plus , at higher frequency , the high-pass transfer function will roll @ @ @ @ @ @ @ @ @ @ the high-frequency model as exemplified in Figure 3 , where the input is at ground and the output impedance controls the transfer function . The Spice model used for the THS3001 includes an LRC network for the output impedance . Again , Figure 5 shows the frequency response as simulated in Spice , but this time it 's symbolized by curve ( b ) . The magnitude of the signal at the output is seen to cross curve ( a ) at about 7 MHz . Above this frequency , the output impedance causes the switch in the transfer function , which is described above . <p> Look to Figure 4c for the simulation circuit using the Spice model with the LCR output impedance . Figure 5 's curve ( c ) shows the frequency response for this model . With the output impedance , the attenuation caused by the circuit follows curve ( a ) until it crosses curve ( b ) , at which point it follows curve ( b ) . Figure 4d reveals the circuit as tested in the lab , with curve ( d ) @ @ @ @ @ @ @ @ @ @ the simulated data . <p> Comments about component selection : Until now , the choosing of resistor and capacitor values has been left without mention . Theoretically , any values of R and C that satisfy the equations may be used . But practical considerations call for certain guidelines to be followed . Given a specific corner frequency , the values of C and R are inversely proportional to one another . By making C larger , R becomes smaller and vice versa . <p> In the case of the low-pass Sallen-Key filter , the ratio between the output impedance of the amplifier and the value of filter component R sets the transfer functions seen at frequencies well above cutoff . The larger the resistor 's value , the lower the transmission of signals at high frequency . Making R too large may result in C becoming so small that the parasitic capacitors , including the input capacitance of the amplifier , cause errors . The best choice of component values depends on the particulars of your circuit and the tradeoffs you 're willing to make . <p> Here are @ @ @ @ @ @ @ @ @ @ avoid capacitors with values less than 100 pF . If at all possible , use an NPO type . X7R is okay in a pinch , but avoid Z5U and other low-quality dielectrics . In critical applications , even higher-quality dielectrics , like polyester , polycarbonate , Mylar , etc. , may be required . As for resistors , values in the range of a few hundred to a few thousand ohms are the best bet . You also should choose metal-film resistors that possess low temperature coefficients . Finally , use 1%-tolerance capacitors and resistors , preferably those of the surface-mount variety . 
@@21004544 @1004544/ <h> The IoT Requires A New Type Of Low-Power Processor <p> Every chip and OEM device manufacturer now building components and solutions for the Internet of Things , especially wearable and battery-powered devices , faces a performance and power paradox challenge that is driving the need for a new type of low-power processor . <p> Why is it called the Internet of Things ( IoT ) , anyway ? Why is n't it called the Internet of Everything , since everything is becoming connected ? The devices and objects that once were autonomous are becoming more connected to each other , to the Internet , or , more commonly , to both . Every chip and OEM device manufacturer now building components and solutions for the IoT , especially wearable and battery-powered devices , faces a performance and power paradox challenge that is driving the need for a new type of low-power processor . <p> More data , more sensors , faster responses , more connectivity , and smarter user interfaces all make these devices great to use . But these features all come at a price : more @ @ @ @ @ @ @ @ @ @ and more heat . While general-purpose or standard processors are popular for running applications in deeply embedded systems and subsystems , they typically are n't optimized for dedicated tasks like those required to support IoT applications . <p> As a result , achieving the required processor performance can lead to exceeding the power budget of the embedded function , resulting in a bigger package and battery . The paradox happens right at the point where the power requirement for the application exceeds the specifications of the battery , packaging , or both . A new type of low-power processor that is efficient , configurable , and extensible is needed . <p> Consider wearable fitness bands . Processors in these devices need to do a lot of controlling , sensing , processing , storing , and interfacing while consuming very little power and area . Using a more standard processor with 1.25 DMIPs/MHz with a maximum CPU speed of 300 MHz while consuming a minimum of 30 -W/MHz could result in a fitness device that is too large to fit on the wrist , would n't be able to use as @ @ @ @ @ @ @ @ @ @ the end of the week . Using a more efficient , configurable , and extendable CPU with 1.77 DMIPs/MHz , up to 337 MHz and 11 -W/MHz , the band could be sleeker in design , utilize more sensors , and still run for more than 10 days without recharging . <p> Configurability And Extensibility <p> Processor configurability is very important to achieving the right balance of performance , power , and area in IoT applications . The ability to easily configure the processor by selecting , minimizing , adjusting , or reducing features to tailor its performance for specific application requirements is essential . <p> For example , selecting and optimizing the number of registers , the type of multiplier , and the number of interrupts and levels enables the core gate count and area to be modified to suit the application performance levels without wasting area and power . Additional adjustments to external bus type , code density options , program counter widths , and divider options enable further processor optimizations . The process should be automated and repeatable to allow simulation of different configurations to refine , @ @ @ @ @ @ @ @ @ @ Extensibility is also key to designing a processor that supports next-generation IoT applications . It enables designers to add user-defined hardware like arithmetic logic unit ( ALU ) instructions , condition codes , core and auxiliary registers , and external interface signals to the processor core . By adding user-defined extensions to the processor , a new level of CPU performance efficiency can be achieved . <p> Energy for the same performance could be reduced by lowering the clock frequency ( less dynamic power ) for mature technologies or by switching off the processor after it has finished ( less leakage ) for newer technologies . Or , designers can get more performance for the same energy used , executing more dedicated functions at the same clock frequency . New functionality such as functions with real-time requirements that could n't be executed previously without hardware support now can be executed as well . This new level of performance efficiency is not achievable by a more standard CPU that ca n't be extended and can only run its standard set of instructions . <p> Using Processor Extensions To Reduce Power <p> @ @ @ @ @ @ @ @ @ @ and extensible 32-bit RISC microarchitecture , was developed to address the power/performance paradox in IoT and other applications . It can be optimized with configurable hardware extensions for a sensor application , for instance , specifically aimed at reducing power or energy consumption . <p> A typical wearable fitness band monitors metrics such as steps walked or run , heart rate , calories burned , and quality of sleep ( Fig. 1 ) . The ARC EM4 Processor would be used to filter and process multiple sensor data and then provide the results to a Bluetooth wireless transceiver . It also manages power and system control functions across the device . <p> 1 . Despite their size , wearable fitness monitors pack a lot of functionality that all requires power , presenting many design challenges . <p> This fitness monitor illustrates the energy reduction achievable by implementing hardware extensions on an ARC EM4 Processor . In this case , the extensions will be in the form of floating-point functions used to process data from multiple sensors , also known as sensor fusion . <p> Figure 2 depicts two ARC EM4 @ @ @ @ @ @ @ @ @ @ does not include any floating-point extensions . Configuration 2 corresponds to an ARC EM4 that includes floating-point hardware from both a standard ARC FPX floating-point extension and other extensions for floating-point divide and square root . <p> 2 . The Synopsys DesignWare ARC EM4 Processor can be configured with or without floating-point hardware extensions . <p> Using a TSMC 90-nm LP library and a clock frequency of 10 MHz , configuration 2 requires only 11% of the cycles to execute the same sensor application as configuration 1 ( see the table ) . This means the algorithm would execute in almost one-tenth of the time using the extensions . The added processor extensions in configuration 2 result in a small increase in area ( 4.5% ) and a small increase in instantaneous dynamic power of the core ( 7.2% ) . Although seemingly detrimental , these power and area increases are mitigated by the one-tenth application completion time made possible with the extensions . <p> Power is defined as the amount of energy consumed per second . To get the energy consumption of the sensor application , the power numbers @ @ @ @ @ @ @ @ @ @ The execution time of the sensor application can be calculated by dividing the measured cycle count by the clock frequency . The power number and the cycle count is better for configuration 2 , reducing the total energy consumption of the sensor application by a factor of 9.55x from 1271 nJ to ( 1271 x 0.106 x 0.988 ) = 133 nJ ( Fig. 3 ) . <p> 3 . Configuration 2 requires much less power than configuration 1 . <p> Conclusion <p> The goal of virtually every wearable and portable IoT device is to be able to provide more functionality and processing capability while using minimum power . Achieving this goal gives users a much better experience and maintains or extends the device 's battery life . <p> This ever-increasing demand for smaller devices with more functionality , longer battery life , and shorter time-to-market has accelerated the need for a new breed of low-power embedded processors and subsystems . Standard and general-purpose processors are less and less suited to the demands of these kinds of applications . <p> The configurable and extensible ARC EM4 Processor , with its @ @ @ @ @ @ @ @ @ @ cores , configurability , and extensibility , is an example of the new breed of processors that is needed to better meet the needs of these demanding applications . <p> Paul Garden is the product marketing manager for DesignWare ARC Processors at Synopsys . He brings 20 years of experience in the field of CPU processor IP and 8- , 16 , and 32-bit microcontrollers . Prior to joining Synopsys , he held a variety of engineering and marketing positions at Microchip , Renesas , and ARM , where he was product marketing manager for the ARM- CortexG-M3 MCU core and the ARM926EJ-SG application processor CPU . He holds a bachelor of engineering degree in electronic engineering from the University of Plymouth in the U.K. 
@@21004545 @1004545/ <h> IGBTs Or MOSFETs : Which Is Better For Your Design ? <p> Until the MOSFET came along in the 1970s , the bipolar transistor was the only " real " power transistor . It provided the benefits of a solid-state solution for many applications , but its performance was limited by several drawbacks : It requires a high base current to turn on , it has relatively slow turn-off characteristics ( known as current tail ) , and it 's susceptible to thermal runaway due to its negative temperature coefficient . Also , the lowest attainable on-state voltage or conduction loss is governed by the collector-emitter saturation voltage ( VCE ( SAT ) ) . <p> In contrast , the MOSFET is a device controlled by voltage rather than current . It has a positive temperature coefficient , preventing thermal runaway . And , its on-state resistance has no theoretical limit , so its on-state losses can be far lower than those of a bipolar part . The MOSFET also has a body-drain diode , which is particularly useful in dealing with limited free-wheeling currents . All these @ @ @ @ @ @ @ @ @ @ made the MOSFET the device of choice for power switch designs . <p> Then in the 1980s , the insulated-gate bipolar transistor ( IGBT ) came along . This device is a cross between the bipolar and MOSFET transistors . It has the output switching and conduction characteristics of a bipolar transistor , but it 's voltage-controlled like a MOSFET . Generally , this means it combines the high-current-handling capability of a bipolar part with the ease of control of a MOSFET . <p> Unfortunately , the IGBT still has the disadvantages of a comparatively large current tail and the lack of a body-drain diode . Early IGBT versions were prone to latch up , too , but this has been largely eliminated . Another potential hazard with some IGBT types is the negative temperature coefficient , which can lead to thermal runaway . It also makes the paralleling of devices hard to effectively achieve . Currently , this problem is being addressed in the latest generations of IGBTs that are based on non-punch-through ( NPT ) technology . This development maintains the same basic IGBT structure , but it @ @ @ @ @ @ @ @ @ @ material that both IGBTs and MOSFETs have historically used . <p> + ? ? MOSFET and IGBT structures look very similar , but there is one basic difference " the addition of a p-substrate beneath the n-substrate in the IGBT ( Fig. 1 ) . <p> This variation is sufficient to produce some clear distinctions as to which device serves which applications better . Certainly , the IGBT is the choice for breakdown voltages above 1000 V , while the MOSFET is for device breakdown voltages below 250 V. <p> Device selection is n't so clear , though , when the breakdown voltage is between 250 and 1000 V. In this range , some components vendors advocate the use of MOSFETs . Others make a case for IGBTs . Choosing between them is a very application-specific task in which cost , size , speed , and thermal requirements should all be considered . <p> IGBTs have been the preferred device under the conditions of low duty cycle , low frequency ( &lt; 20 kHz ) , and small line or load variations . They also have been the device of @ @ @ @ @ @ @ @ @ @ V ) , high allowable junction temperatures ( &gt; 100-C ) , and high output powers ( &gt; 5 kW ) . <p> Some typical IGBT applications include motor control where the operating frequency is &lt; 20 kHz and short circuit/in-rush limit protection is required ; uninterruptible power supplies with constant load and typically low frequency ; welding , which requires a high average current and low frequency ( &lt; 50 kHz ) ; zero-voltage-switched ( ZVS ) circuitry ; and low-power lighting with operation at low frequencies ( &lt; 100 kHz ) . <p> Typical MOSFET applications include switch-mode power supplies using hard switching above 200 kHz or ZVS below 1000 W. Battery charging is another common use for MOSFETs . <p> Of course , nothing is as easy as it seems . Tradeoffs and overlaps occur in many applications . The purpose of this article is to examine the " crossover region " that includes applications operating above 250 V , switching between 10 and 200 kHz , and power levels above 500 W. In these cases , final device selection is based on other factors such as @ @ @ @ @ @ @ @ @ @ packaging . A ZVS power-factor-correction ( PFC ) circuit is one example of an application that falls into the crossover area between IGBTs and MOSFETs . <p> Yet the losses of an IGBT like International Rectifier 's IRG4PC40W are approximately equal to the losses of the company 's IRFP460 if the switching speed is reduced to 50 kHz . This could let a smaller IGBT replace the larger MOSFET in some applications . Such was the state of technology in 1997 , when IGBTs had a slight edge over MOSFETs at 50 kHz and were making inroads into designs up to 100 kHz . <p> When both device types are tested in hard-switching applications , measurements show that the MOSFETs exhibit lower losses ( Fig. 3 ) . <p> Recent advances , though , have given the advantage back to MOSFETs . The lower-charge MOSFETs now available have reduced the losses at high frequency . They have , therefore , reasserted MOSFETs ' dominance in hard-switching applications above 50 kHz . <p> When the application uses zero-voltage switching , results vary with operating temperature . With 50-kHz switching and a @ @ @ @ @ @ @ @ @ @ the 7-W MOSFET losses at room temperature ( Fig. 4 ) . <p> When the temperature is raised to reflect operating conditions , the MOSFET 's conduction losses rise more quickly than the IGBT 's switching losses . The losses at elevated temperatures increase 60% for the MOSFET , while the IGBT 's total losses increase only 20% . At 300 W , this makes the power losses almost equal . At 500 W , the advantage goes to the IGBT . <p> If output power remains at 500 W and the switching frequency is raised to 134 kHz at the higher temperature , the IGBT will exhibit slightly worse losses ( 25.2 W ) than the MOSFET ( 23.9 W ) . If the same measurements are taken at room temperature , losses are 17.8 and 15.1 W , respectively . The increase in switching losses at the higher frequency eliminates the advantage that the IGBT had at high temperature when the switching frequency was lower . <p> These examples illustrate that there is no iron-clad rule that can be used to determine which device will offer the best @ @ @ @ @ @ @ @ @ @ of IGBT or MOSFET will vary from application to application , depending on the exact power level , the devices being considered , and the latest technology available for each type of transistor . <p> In the battle between MOSFETs and IGBTs , either device can be shown to provide an advantage in the same circuit , depending on operating conditions . Then how does a designer select the right device for his application ? The best approach is to understand the relative performance of each device and realize that if the component looks too good to be true , it probably is . <p> There are a few simple things to keep in mind about specifications . Test data , supplier claims , or advertisements which select conditions at maximum current and temperature will favor the IGBT in a given application . Take , for example , a motor-control application where a forklift is lifting its maximum-rated load while moving up an inclined ramp in the desert at noon . <p> In this particular scenario , the IGBT appears to be the device of choice . But when the @ @ @ @ @ @ @ @ @ @ the maximum torque of the forklift motor is needed only 15% of the time , and the average torque load of the motor is only 25% of the rated torque . Under average or typical conditions , a MOSFET provides the longest battery life while meeting all peak-performance lev els " and usually at a lower cost . <p> Data that are based on applications at the highest switching frequency , the shortest pulse width , or the lowest current will tend to favor the MOSFET over the IGBT . For instance , a power supply operating at room temperature with nominal load and line voltage will make the MOSFET appear to be better than the IGBT . Conversely , if the power supply is operated at the maximum case temperature , maximum load , and minimum line voltage , the IGBT will look better . Actual performance , however , is almost never under " nominal conditions . " Variations in ambient temperature , line voltage , and load are more realistic , and they should be considered . <p> Presently , some of the newest IGBTs can offer @ @ @ @ @ @ @ @ @ @ W and up , operating at switching frequencies of 100 kHz and above . Nevertheless , in all other power-supply applications , the MOSFET continues to reign supreme . <p> There seems to be an industry-wide perception that MOSFETs are a mature product category that will not offer significant performance improvements in applications , while IGBTs are a new technology that will replace MOSFETs in all applications above 300 V. Such generalizations are n't true . 
@@21004548 @1004548/ <h> Power Cycle Boosts Efficiency of Fossil Fuel Generators <p> Because renewables still only account for a fraction of energy consumed in the United States , the Department of Energy is searching for more efficient ways to generate electricity with fossil fuels . Sandia National Laboratories , recently revealed plans to design a fossil fuel system based on a supercritical carbon-dioxide Brayton cycle . <p> The energy conversion system will transfer heat from burning fossil fuels into a supercritical CO2 fluida state of carbon dioxide that has a liquid density while in a gaseous state . The supercritical CO2 will turn a turbine that generates electricity as it turns . Due to its high thermal stability , the fluid will significantly reduce the amount of energy lost to operate the turbines . <p> The project will be based out of Sandias Brayton Laboratory in Albuquerque , N.M . The laboratory is planning pilot tests using a 6-megawatt turbine developed by Peregrine Turbine Technologies . The turbine , currently under development , will use supercritical-CO2 as the working fluid . David Stapp , Peregrine 's chief executive , said that @ @ @ @ @ @ @ @ @ @ than current steam technology . <p> Gary Rochau , manager of Sandias Advanced Nuclear Concepts department , said that the research was focused on advancing the " commercial readiness " of the S-CO2 Brayton cycle . He added that the conversion system would consume less fuel than traditional Rankine cycles while producing the same amount of energy . The Brayton cycle has environmental advantages , reducing the cost and emissions of fossil-fueled power plants . <p> Rochau said that while the program is focused on fossil fuel systems , it could result in big improvements to nuclear , geothermal , and solar production . The energy department , for instance , recently disclosed that it was testing the Brayton cycle process in concentrating solar power plants . <p> Other organizations participating in the research include Vacuum Process Engineering ; Mid-South Engineering ; CFD Research Corp. ; the U.S. Space and Rocket Center at NASAs Marshall Space Flight Center ; Government Energy Solutions ; and the Energy Huntsville Initiative. 
@@21004553 @1004553/ <p> The increasingly super-fast , super-complex , single-core solution has given way to multicore architectures as chip designers have bumped into electrical and power limitations associated with increased clock rates . A single core may be easier to program , but many applications benefit from multiple cores " such as video processing in applications like advanced driver assistance systems ( ADAS ) in automotive settings . In this case , it is better to have more cores available . <p> Imagination Technologies ' new 64-bit I6500 Warrior core will be finding a home many multicore solutions , ranging from compact SoCs to very large , heterogeneous clusters ( Fig. 1 ) . These cores can include IO coherent units ( IOCU ) and up to six I6500 CPU cores . All cores support up to 31 secure execution domains that implement Imagination 's OmniShield IO virtualization , which allows software reconfiguration of a domain including " support for a virtualized global interrupt controller ( GIC ) . <p> The cluster architecture is based around an eight-core cluster node with a common coherency manager , the latter of which includes @ @ @ @ @ @ @ @ @ @ storage and four non-coherent AXI- ports designed for low latency peripherals . The cores can include up to six CPU cores . The IOCUs can be linked to application specific features . <p> The CPU supports Simultaneous Multi-Threading ( SMT ) with up to four threads per CPU core ( Fig. 2 ) . The threads feed a pair of execution pipelines . The L1 CPU cache can be utilized as scratch pad RAM ( SPRAM ) for deterministic application operation . The system utilizes a 256-bit memory bus . <p> 2 . The I6500 supports Simultaneous Multi-Threading ( SMT ) with up to four threads per CPU core . <p> Designers can customize the CPU core by selecting features like the maximum number of threads , the L1 cache and SPRAM sizes , and support for SIMD and floating point instructions . The operating frequency and voltages can be adjusted at runtime . <p> The cluster nodes are linked using the ACE coherent fabric . This fabric also supports Imagination 's PowerVR GPUs . These GPUs can share the same memory space as the CPUs , reducing copying and @ @ @ @ @ @ @ @ @ @ heterogeneous configuration outside the cluster node as well as inside it . <p> The OmniShield IO virtualization mentioned earlier provides significant advantages when it comes to security . The isolation of a domain is managed in hardware down to the peripheral level , even though a core might be running up to four threads from different domains . There is no additional overhead if four threads will be sufficient , compared to a time-sliced approach where a hypervisor handles the switching ( Fig. 3 ) . <p> The I6500 is designed for high performance applications . Although it is possible to have a single-core CPU it is more likely to show up in platforms that incorporate at least a single cluster that can run 24 threads simultaneously . A 64 cluster system can support up to 1536 threads and at least 128 IOCUs . Of course , configurations for applications like ADAS may be optimized with a different mix for CPU cores. 
@@21004554 @1004554/ <h> Advantages of ASICs <p> Sponsored by Mentor Graphics <p> Mar 23 , 2017 <p> Do you know all the advantages of ASICs ? Here is a sample of one of our most popular white papers on ASIC design myths , advantages , and availability : <p> " ASICs have a host of other important benefits beyond the low cost of production . ASICs can offer greater performance , lower power , higher voltages , reduced footprint/bill of materials and thus increased reliability . Also important , ASICs offer higher IP security , as an ASIC is far harder to reverse engineer than a microcontroller or FPGA design , where the IP is stored in easy-to-read memory . " <p> Other highlights include : breaking the myth of ASIC costs , the ASIC advantage , and wide availability of re-usable IP. 
@@21004556 @1004556/ <p> The automotive industry makes extensive use of light-emitting diodes ( LEDs ) in high-beam headlights , brake and position lights , and side and rear direction lights . In an LED driver design , the brightness intensity of the various illuminating devices is not equal ; rather , it depends on their specific function . <p> Needless to say , then , that LEDs operate at different brightness levels " for example , at full brightness for braking and from 10% to 25% for the rear lights . LED dimming circuits are used to differentiate the brightness level through a pulse-width-modulation ( PWM ) driving technique , which modulates the width of the current pulses applied to the LEDs . LED driver solutions integrate a PWM system to control the brightness by providing a ramp generator , thus simplifying the driver design . <p> PWM has been adopted as the preferred dimming technique for high-quality LED lighting . An essential aspect of the lighting control system is the power management provided by integrated-circuit ( IC ) drivers in several configurations , such as buck and buck-boost topologies . @ @ @ @ @ @ @ @ @ @ system . <p> LED Driver Features <p> LED solutions require a constant current in order to produce uniform brightness . The accuracy of the source and the fluctuations in terms of voltage and other parameters are the fundamental design parameters for the correct driver . Fluctuations that occur with the vehicle 's power supply must therefore be strongly considered . Moreover , other requirements , which are reflected in the design phase , include temperature and humidity , voltage range , electromagnetic interference ( EMI ) and compatibility ( EMC ) , as well as the reliability requirements dictated by the qualification tests . <p> 1 . The delay exhibited by the LED driver is in response to its PWM signal . These delays result in the contrast ratio ( CR ) factor of the system . Here , tD represents the propagation delay from when VDIM ( PWM signal ) goes high to when there 's a response from the If ( forward current ) driving the LED ( tSU and tSD are the LED forward-current slew-up time and slew-down time , respectively ) . DMIN and DMAX are @ @ @ @ @ @ @ @ @ @ High-reliability demands in automotive applications indicates that protection circuitry is essential within the IC driver , which provides protection from overvoltage , undervoltage , reverse polarity , overcurrent , short circuits , and higher and lower temperatures that do n't belong in the working range . Harsh automotive environments require protection circuits to prevent problems in case of failures . The devices also should demonstrate reliable operation over an extended temperature and humidity range , and the ability to withstand continuous vibration . <p> The ability to adjust light intensity in interior lighting systems is a normal requirement . For outdoor lighting applications , however , the same LED must have different levels of brightness . For example , the stop and position lights or low-beam and high-beam headlights are defined at two brightness levels . In some cases , integrating a suitable driver into the design can satisfy both situations with the same LED . <p> The main drivers have generally been designed with integrated PWM dimming . Many chips incorporate a PWM generator to determine the driver 's ON and OFF cycle . A key factor in the @ @ @ @ @ @ @ @ @ @ of this frequency is determined by the eye 's sensitivity to flicker . Lowering fDIM generally facilitates a higher contrast ratio ( CR ) , expressed as the inverse of the minimum on-time ( Fig. 1 ) . <p> Driver Topologies <p> LEDs typically require constant current to produce a uniform light output . Therefore , an LED driver must be able to vary the output voltage to maintain a constant current . The output voltage is related to many parameters , such as the temperature of the LED matrix and the number of LEDs in series . The designer must be able to predict with great accuracy the maximum output voltage in order to select the optimal regulator topology and , therefore , the driver IC and associated components . <p> The right power supply enables high-quality lighting with maximum conversion efficiency ( in terms of lumens per watt ) , thereby prolonging the life of LEDs . The quality of the light produced is determined primarily by the light-intensity stability , which requires a precise regulation of the current with constant working points in all voltage and temperature @ @ @ @ @ @ @ @ @ @ integrated or external transistors , depending on the power of the given LEDs . However , the integration of the MOSFET for the LED driver reduces the number of external components , thus saving space on the board and simplifying the circuit . <p> 2. - Energy is stored through the inductor in this buck-converter design , with the production of an output voltage always lower than input . <p> The LED driver can be divided into three categories : linear regulators ; charge pumps characterized by a capacitor ; and the switching driver characterized by an inductor ( reactive electronic component ) . The latter have found a wide range of applications , thanks to their flexibility and ever-increasing efficiency . Moreover , they allow wide ranges of input voltage to be accepted , and have the potential to be electrically insulated for operation in high temperatures . <p> Linear regulators provide a simple control and do n't require filters for EMI . However , their power dissipation can become excessive for high-power applications . Switching drivers come in four flavors : buck , boost , buck/boost , and @ @ @ @ @ @ @ @ @ @ in a typical switched-mode device , a switch controls the transfer of energy . The output voltage of an ideal buck converter ( Fig. 2 ) depends on the product of the switching cycle time and its supply voltage . The boost converter , instead , consists of four main elements : inductor , power switch ( MOSFET , IGBT ) , diode , and capacitor . <p> The buck-boost configuration ( Fig. 3 ) , which employs an inductor in parallel to the input voltage , provides an advantage in terms of flexibility . The SEPIC converter ( Fig. 4 ) topology is a buck/boost converter without the inverted voltage . It requires an additional inductor and a blocking capacitor , which is the disadvantage to this design . <p> 3 . The inductor , which is discharged through the diode , provides current to the load in this buck-boost converter . <p> Depending on whether the LED application is automotive or general lighting , use of a multi-topology LED driver with maximum flexibility of input- and output-voltage range makes it easier to select the correct driver . The @ @ @ @ @ @ @ @ @ @ 16 V ( nominal 14 V ) and includes extreme conditions , such as reversal of the battery polarity ( 12 V ) , fault conditions like load dump ( which occurs when the battery is disconnected from the alternator ) , and other transient voltages . <p> Among their other benefits , the buck-boost SEPIC configurations ensure constant brightness in all battery-voltage variations . When the need arises to control several LEDs in series , a buck-boost topology can address a variety of application requirements , including the ability to manage extreme voltage values . <p> In some automotive exterior-lighting applications , the LED array or matrix may be located at a distance from the driver/controller . In these cases , a boost converter can be a more appropriate topology choice . Carefully choosing the buck regulator can allow for PWM dimming frequencies in the kilohertz range . While this feature perhaps is n't necessary for traditional lighting , it can be effective in applications such as high-speed stroboscopic effect for recognition activities ( imaging ) in the industrial and automotive sectors . <p> 4 . A SEPIC is @ @ @ @ @ @ @ @ @ @ advantage of a non-inverted output ( the output voltage has the same polarity of the input voltage ) and isolation between input and output ( provided by a capacitor in series ) . <p> LEDs Create a Better Driving Experience <p> LED lighting and other secondary optics solutions significantly boost road safety simply due to well-lighted vision and overall improved efficiency of night driving . The characteristics of longer-duration LEDs " high performance , high brightness efficiency , and low-heat-dissipation energy consumption " are the main features of an ideal automotive lighting solution . <p> As more lighting technologies come onto the scene , new LED driver technologies for internal and external lighting help produce an added level comfort in a wide range of vehicles . The goal is to provide linear LED dimming with a large contrast ratio . The correct procedure is to operate the LEDs at the manufacturer-recommended forward current/forward voltage . <p> Conclusion <p> LEDs are becoming a significant force in the lighting market due to their long lifetime and the ability to control specific lighting requirements . More integration of systems-on-a-chip ( SoCs ) will @ @ @ @ @ @ @ @ @ @ to faster product development cycles and accurate management of high-level lighting features . <p> The LED driver market for lighting is estimated to have a compound annual growth rate ( CAGR ) of about 27% in the near future . The key driving factors responsible for the upswing in the LED driver market includes the greater efficiency exhibited by power-management circuits and the strong demand for LEDs in commercial and industrial applications . 
@@21004558 @1004558/ <p> Industrial equipment manufacturers have a tough job today preparing products to be ready for the IoT . Even with all the work that has been invested towards making the IoT a reality , there are still many open questions on how the IoT will be rolled out and reach the volumes that analysts have predicted . Product designers must design to many requirements " long life in the field for industrial applications , flexibility to integrate with one of several different cloud services , and support for multiple wireless protocols . On top of this , specific IoT applications need different levels of processing capacity at the edge , and of course there is still the specter of securing these vast networks of interconnected devices . <p> NXP can bridge this gap to deploying the IoT with our scalable ARM Cortex A based QorIQ Layerscape family of SoCs . With integrated support for virtual machines , cloud service providers can easily integrate their software and move cloud-based analytics straight to the network edge . A family of processors that ranges from a single A53 core to eight A72 @ @ @ @ @ @ @ @ @ @ size the platform for the application . The Layerscape family integrates many IO interfaces , ensuring direct interconnect with different wireless ICs , and designers can take advantage of the wide NXP portfolio for low power wireless standards , in addition to high speed Wi-Fi and cellular modems . Finally , designers can rest assured that their design will be secure , using the the QorIQ Layerscape Secure Platform built on the Trust Architecture to ensure that devices are secure from the time of manufacture until they are decommissioned. 
@@21004568 @1004568/ <p> Gesture recognition is the ability of a device to identify a series of human body movements . This electronic technology relies on the aid of a camera and the IC devices that identify and scan the scene in a 2D or 3D profile . It also uses the time-of-flight ( ToF ) technique , which comprises sending an infrared beam on the target to be analyzed , resulting in reflection of the processed signal by means of the receiving electronics . <p> Various IC solutions " with the aid of software algorithms for the recognition of gestures " create a depth map of the received images . As a result , they can respond in real time to the movements of the body . The algorithms also include a number of mathematical functions for facial recognition and voice- and eye-tracking . <p> On this front , automobiles are rapidly becoming camera-enabled . Taking advantage of one or multiple image sensors , the cameras can represent the three-dimensional space with the possibility to develop products that transform imaging data into meaningful operations . <p> One key sensor-enabled technology is @ @ @ @ @ @ @ @ @ @ on the road while still controlling several functions safely . In the automotive market , the ToF technique is seen as a promising solution for implementing gesture interaction technology ( Fig. 1 ) . - <p> 1 . The base components of a ToF camera system for gesture recognition are the image sensor , an objective lens , and an infrared illumination light source that emits RF modulated light . The processor and software algorithmscan the images to analyze the gesture and proceed to the recognition . <p> How Does It Work ? <p> The goal of a ToF camera is to screen a whole image of a scene . These cameras consist of a transmitter ( a lightning block that illuminates the region of interest with the modulated light ) and the receiving sensor ( constituted by an array of pixels that collects light from the same region of interest ) . The vision-control algorithm will have to scan the images to analyze the gesture and proceed to the recognition . <p> The objective of ToF sensors is to demodulate the reflected light , measuring the position of each @ @ @ @ @ @ @ @ @ @ . The pixels collect light from separate parts of a scene . By recombining them , they create a reconstructed stage . <p> All of the sensor 's pixels are controlled by an input of the correlation/demodulation block and the modulation block . The demodulation of the pixels is synchronous with the modulation of the transmitted light signal . In the simplest form , each pixel can be approximated by the model shown in Figure 2 . <p> In reset mode , the pixel is reset by the RST signal ( Reset signal ) to a preset voltage value . During integration time , the photocurrent is directed to Node-A or Node-B , which activates the suitable demodulation signals . In the reading stage , the demodulation is stopped and the decoding address signals are activated to read the entire array in a programmed sequence . The ToF sensors use the pixel technology based on a Current Assisted Photonic Demodulator ( CAPD ) . <p> Node-A and Node B ( Fig. 2 , again ) consist of reverse-biased diodes . Modulation is accomplished by alternately changing the direction of the @ @ @ @ @ @ @ @ @ @ this modulation field is applied within the substrate , the generated electrons can be collected , which contributes to higher sensitivity . The voltage used for demodulation controls the intensity of the electric field and , thus , the drift velocity of the electrons generated . <p> Stochastic functions adjust the conversion of photons ( reflected light on the array ) into electrons in a quantum process . In particular , the rate of photon generation uses a Poisson distribution . Similarly , the signal of the reflected photons from the target and the relative conversion of the same into electrons within the pixel also involve quantum processes with a Poisson distribution . In these cases , not all of the light that strikes the pixel converts into electrons . <p> 2 . Shown is a wiring diagram representative of a single pixel . The pixels are tasked with collecting light from separate parts of a scene . By recombining them with a software algorithm , they create a reconstructed image used in vision-machine or gesture-recognition systems . <p> To check the quality of the system , it 's best @ @ @ @ @ @ @ @ @ @ wavelength of the light used in the transmission : <p> n(++) = ne/np <p> where ne is the number of electrons produced and np is the number of photons that activate the corresponding pixels . <p> The number of electrons is formed by two components : one produced by the modulated light and the other relative to the ambient light , which corresponds to the effect of noise contributing to the system signal-to-noise ratio ( SNR ) . Considering the quantum efficiency described in the equation above , we can defined the responsivity as : <p> R(++) = n(++) ( ++qe/hc ) <p> where c is the speed of light ; h is the Planck constant ; qe is the charge of a single electron ; and ++ is the wavelength of the used light . When DMIX0 is low and DMIX1 is high ( Fig. 2 , again ) , all of the generated electrons are collected by Node-A , while none are collected from Node-B . Here , it 's said that the demodulation is perfect . <p> On the contrary , when DMIX1 is low and DMIX0 @ @ @ @ @ @ @ @ @ @ acquired from Node-B and none from Node-A . In practice , this condition is never verified . The phenomenon of non-ideality is called demodulation contrast . The ideal value is equal to one . The demodulation contrast is only responsible for rearranging the electrons , not for their generation . As a result , SNR increases in proportion to the demodulation contrast . <p> When designing a ToF system , field of view ( FoV ) must be chosen appropriately according to the scene coverage requirements . For example , in gesture recognition for laptops , a large FoV is more suitable because the subjects are close to the camera . On the other hand , for televisions , a narrower FoV may be appropriate because the subjects are distant . <p> Eye-Tracking <p> Suppose we want to start the rear wipers just by moving our eyes to the rear-view mirror or turn on the radio by simply moving our eyes to the console . These are among the many examples and functions that the control algorithm must be able to decode in real time . <p> One critical feature @ @ @ @ @ @ @ @ @ @ have negative consequences while driving , such as extreme fatigue . Modern eye-tracking systems use infrared LED ( IRED ) as the source of illumination and high-resolution cameras to detect the reflected light . The algorithms process raw data and calculate the position of the pupils . <p> 3 . An eye-tracking system generally comprises two components : a light source directed toward the eye , and a camera . The goal of the camera is to track the reflection of the light source along with ocular features . Other components such as a display and processor can be included in eye-tracking systems for medical applications . <p> In reference to the frontal images of the driver , the system can trace back to the area where the user is looking . The infrared lighting ensures good contrast between the iris and pupil , the color of the eyes , and environmental conditions ( Fig. 3 ) . <p> The Future <p> Many challenges must be overcome for the automotive sector to fully adopt and implement gesture-recognition technology . The first systems will be testbeds that support the development of @ @ @ @ @ @ @ @ @ @ time-to-market . <p> The new technology is already enabling automobile manufacturers to integrate high-tech features in their cars , so that the driver can check the safety of the vehicle control systems . Interpreting such information incorrectly , however , might jeopardize the safety of the driver or others around the vehicle . For example , an approaching hand might activate the infotainment system in cars , while tilting the head can turn on the direction indicator . <p> Multimodal human-machine interaction ( HMI ) is used in today 's vehicles to offer the driver various redundant ways to control functions . Voice and touch have already become standard features . But for gesture recognition in cars to succeed in simplifying driving , comfort , or infotainment features , these systems must ensure that they 're reading gestures appropriately . Thus , manufacturers are turning to the science of gesture recognition , which interprets human gestures as input commands by using mathematical algorithms . This may include small changes in facial expression , but also body motion . <p> It 's expected that the gesture-recognition system will be the next-generation @ @ @ @ @ @ @ @ @ @ developing the hardware and software algorithms to enable user command input with natural hand and finger movements . 
@@21004570 @1004570/ <p> 32 universities in the U.S. will go head-to-head in a single elimination tournament that lasts 5 weeks in March . Each week the university that receives the most votes will advance to the next round . <p> The top U.S. based universities have been selected according to a criteria set by our editorial staff . The goal is to highlight universities that are highly active in a number of engineering communities ( design competitions , hackathons , robotics , research , incubators ) . <p> The best way to see your favorite university advance is by sharing this page with your friends and returning each week to vote <p> *If winning university is already an ANSYS customer : 1 . ) This prize will be provided above and beyond their current licenses and can not be used as payment for existing products . 2 . ) If equivalent licenses are already in place ANSYS will provide valuable mentoring , advanced support and/or partnership opportunity with benefits based on individual need at a minimum value of $25k or higher . <p> ANSYS simulation software is used to predict how @ @ @ @ @ @ @ @ @ @ by 96 of the top 100 industrial companies on the Fortune 500 list , thousands of universities globally , and leading research teams . Win an ANSYS Academic Research Mechanical and CFD License for your university that has an equivalent commercial value of over $4,000,000 USD ! * <p> 25 user license , valid for one year . <p> Software can be leveraged by your professors , students and researchers for any academic research or teaching activity . <h> Vote and register for a chance to win one of these Amazon prizes <p> Five random winners that vote and register in all rounds will be eligible to win <p> Three random winners that vote and register in a single round will be eligible to win ( 3 winners per round ) <p> Sponsors <p> ANSYS - Founded in 1970 , ANSYS employs nearly 3,000 professionals and works with thousands of companies to develop and optimize the world 's leading products . ANSYS offers a free version of their industry-leading engineering simulation software for students . It is perfect for homework , Capstone projects , team projects , and more ! @ @ @ @ @ @ @ @ @ @ most challenging engineering problems and develop the best products , which is why employers look for this skill on resumes . The software can be installed on most MS Windows 64-bit machines running MS Windows 10 , 8 or 7 . <p> Schneider Electric - Schneider Electric Motion USA is a manufacturer of motion control components for automation equipment . The company is a proven leader in innovative motion control solutions for stepper motors and electronic controls , and the world leader in integrated motor drives with the MDrive- product line . MDrive , as the world leading integrated motor brand , offering a broad range of products and features . Schneider Electric Motion USA fosters the ideas and innovative designs of those with a passion for science and engineering with our integrated motor products , knowledge and resources . Our experienced team of engineers continue to develop innovative solutions in brushless motor technology and electronic controls . <p> Maxon Motors - With over 50 years of experience in drive technology , maxon works closely with engineers designing high-tech innovations . Maxon fosters the Young Engineer Program ( YEP ) @ @ @ @ @ @ @ @ @ @ with our know-how , tools and resources necessary for their unique design challenges . Maxon 's engineers have been true partners in the quest to create the right solution for each of our customers . Prototypes , custom systems , or large series : Whatever your requirements may be , we are here to be of assistance in selecting the right combination for your drive system . <p> Texas Instruments - The Texas Instruments University Program is dedicated to supporting engineering educators , researchers and students worldwide . Since 1982 , the program has facilitated the inclusion of TI analog and embedded processing technology in the learning experience for engineering students , including : teaching materials , research labs , design projects , and course curricula . By doing this , TI aims to bridge the gap between the industry and academia , bringing real world engineering concepts to life for thousands of students every year . <p> ACE Controls Inc. , is a leading innovator in deceleration , motion control and vibration isolation technology . We engineer shock absorber , gas spring and vibration control solutions for any industry @ @ @ @ @ @ @ @ @ @ for your application , we have the tools and services to ensure you get the right product every time . With 24/7 online sizing software , YouTube videos and a strong bench of experience application engineers , support is only a click or call away . <p> Keysight - Students are the next generation of engineers , with the opportunity to shape how our world innovates , designs , and builds the technology of the future . But are they prepared to accept this challenge ? What if they could get their hands on the same lab equipment used in the top industry labs around the world ? Using industry-grade lab equipment in college will help students gain the confidence and expertise needed to excel after graduation . They 'll be able to test their college projects faster , and transition to an engineering career with ease with the help of Keysight 's test and measurement equipment . <p> Tektronix - Headquartered in Beaverton , Oregon , Tektronix has been at the forefront of digital age for 70 years , delivering advance , precise , and most-capable test and measurement @ @ @ @ @ @ @ @ @ @ and electronic designs . Tektronix Education helps prepare future engineers for tomorrow 's challenges with comprehensive solutions and product portfolio that provide the latest skills and knowledge students need beyond classroom instructions . <p> Altech Corporation , who values the education of future engineers , is an established United States based supplier of components and devices used in industrial control , instrumentation and automation applications . ISO 9001:2000 certified , the Altech product line includes circuit protection , DC-UPS , digital meters , terminal blocks , contactors , industrial relays , motor disconnect switches , pin &amp; sleeve devices , foot switches , push buttons and many other products . Altech 's products meet UL and many international standards . <p> At Lapp Group , we understand the critical role our brand and products play in a wide array of industries and manufacturing applications . Our business partners depend on the quality , performance , and durability of our total electrical connectivity solutions to keep their facilities and lines up and running even in the most demanding conditions . Manufacturers deal with all types of challenging environments that put our @ @ @ @ @ @ @ @ @ @ products have a proven record of standing up to the most extreme conditions by providing the ideals level of resistance to vibration , temperature , oil , water , corrosion , and wash-downs. 
@@21004574 @1004574/ <p> IoT devices are create , process and transmit more data every day , but can your software handle this deluge of data ? This whitepaper shares ways for you to ensure your embedded designs are optimized to thrive in this data-rich age . <p> May 08 , 2017 <p> Brought to you by <p> The amount of data IoT devices create , process and transmit is increasing at a daunting rate . Can your software handle this deluge of data ? Read the new whitepaper by Datalight , Mentor Graphics and Raima , Optimize Your Software Stack for Industrial Internet of Things Devices , to learn how you can ensure your embedded designs to thrive in this data-rich age . 
@@21004575 @1004575/ <p> In a nutshell , RISC-V is an instruction set architecture ( ISA ) that scales from 16-bit to 128-bit register platforms . The E310 is targets the Cortex-M0 space , but it can run at 320 MHz while sipping power " making it an interesting solution for the Internet of Things ( IoT ) . The chip is available on the HiFive1 board ( see figure ) that has an Arduino form factor . <p> The idea behind RISC-V is not new . MIPS and even ARM have RISC-like architectures . Issues like code density and ISA functionality have fallen by the wayside , making other factors more important when deciding whether to use RISC-V . The performance or power efficiency is more a function of the microarchitecture implementation rather than the choice of ISA . Much of the success of the x86 CISC architecture is due to the plethora of software and platforms like Microsoft Windows . Much of ARM 's popularity is due to Linux and platforms like Android that are built on it . <p> So what does RISC-V offer ? Customization at a lower @ @ @ @ @ @ @ @ @ @ that essentially live off of licensing fees . These costs are passed on for standard parts like those available from micro vendors like Microchip , Qualcomm , and Texas Instruments and amortized across millions of chips . The infrastructures surrounding these two architectures are part of the benefit of using them . Availability of developers familiar with the platforms is another . <p> This type of community is what the E310 is designed to inspire . Likewise , the use of the IP in FPGAs is another option . Microsemi is supporting RISC-V . This makes a lot of sense as its competitors , Altera and Xilinx , have their own soft core processors ( NIOS and MicroBlaze , respectively ) . Of course , RISC-V is one that can span all the FPGA vendors . The Cortex-M0 and -M1 are another , licensable option . <p> Now , the E310 core IP is open-source , but not all RISC-V implementations will be . There is the open-source Rocket core IP generator , which provides a good implementation for free . However , it is n't necessarily optimized like many @ @ @ @ @ @ @ @ @ @ the micro vendors utilize . Still , the Rocket solutions may be more than sufficient for many developers . There are open-source peripheral and accelerator IP that can be used to create a final system-on-chip . <p> One reason this alternative to MIPS and ARM is of interest in the IoT space are aspects like customization requirements and cost , which can be significant . Low power and performance are typically on the checkbox list , but RISC-V fits nicely with all these aspects . SiFive can deliver a customized version of the E310 for about $100,000 . That is a lot less than many alternatives . <p> Going with a custom chip for IoT applications has many advantages , ranging from optimizing power and performance to incorporating custom peripherals . Custom chips make reverse-engineering more difficult . Of course , using open-source or low-cost hardware helps the bottom line . <p> While processor chip vendors might consider adding RISC-V platforms to their stable , I think that will unlikely given the infrastructure and community they have already built up . The migration to ARM or MIPS platforms has taken @ @ @ @ @ @ @ @ @ @ take these issues into account . <p> Custom IoT designs can benefit from an existing infrastructure and community , but are not as beholden to them . Likewise , much of this infrastructure is generic , such as the use of Eclipse-based IDEs and standard compiler technologies . <p> RISC-V is certainly worth watching . It may well fit into your IoT plans . 
@@21004580 @1004580/ <p> Precise motor control has gained greater significance as electrification takes over the automotive industry . Whether for electronic power steering , electronic stability control , automatic braking systems , or for the self-driving vehicle , precise control of these motors is required to ensure safe and efficient operation . <p> In this article , I will discuss the challenges in measuring in-line motor phase current . I will review how these are addressed by various current-sense amplifiers and introduce a new approach to addressing the challenge . Finally , I will discuss how using precision current measurement can optimize the motor control solution . <p> Why Measure Current for Motor Control ? <p> There are two primary reasons why current is measured in motor-control circuitry : <p> Fault protection <p> Input for motor control algorithm <p> Overcurrent protection circuitry is used to detect out-of-range operational conditions that may indicate a fault in the system . This circuitry is used to identify a stall condition , a bad connection , or even the motor 's health . By detecting when the overcurrent condition occurs , it allows the system @ @ @ @ @ @ @ @ @ @ range from simple overcurrent-detection circuitry to complex current monitoring by the control circuitry . <p> The motor controller uses current measurement to garner information primarily on motor torque . The current measurement is directly proportional to the motor torque . Current measurement can also be used to determine the speed at which the motor is turning . Such speed information can be calculated by understanding how the control algorithm affects the current level . <p> Three-Phase Motor-Control Current-Monitoring Options <p> This article 's focus will be on measuring the current for a three-phase topology . The topology , commonly used on brushless dc ( BLDC ) motors that are electrically commutated , offers four operating modes : run , coast , brake , and reverse . This is the most complex motor arrangement . There are four ways to monitor the current in this topology : high-side dc-link sensing , low-side dc-link sensing , low-side phase sensing , and in-line phase sensing ( Fig. 1 ) . <p> 1 . This example circuitry shows the four current-measurement methods used for three-phase motor-control systems . <p> - <p> High-side dc-link sensing @ @ @ @ @ @ @ @ @ @ the advantage of having a stable common-mode voltage and enables motor fault detection . However , depending on the motor , the common-mode voltage could be very high , limiting the choice of devices able to be used in this implementation . In addition , the driver current , which is actually what 's being measured , does n't necessarily equal motor phase current . <p> Low-side dc-link sensing is also typically only used for fault detection . It has the advantage of having a common-mode voltage that 's essentially 0 V , broadening the range of available solutions . However , it does n't allow for motor fault detection . Furthermore , the driver current , which is actually what 's being measured , does n't necessarily equal the motor phase current . Determining the phase current at this location requires very high-speed , high-slew-rate amplifiers and fairly complex algorithms in the controller . <p> Low-side phase sensing allows for easier determination of the motor phase currents , but it 's not an exact equivalent . Therefore , an error is potentially introduced relative to the true phase current @ @ @ @ @ @ @ @ @ @ the motor relative to system ground . Due to the location of the sense element , fault detection is limited in this implementation . <p> It does offer the advantage of having more options for implementation , as the common-mode voltage is essentially ground , which enables the use of low-voltage amplifiers . However , due to the nature of the current through the drivers , a high-slew-rate amplifier is again required to respond to the dynamic nature of the current being monitored in each leg . In many cases , only two of the phases are measured , with the third phase calculated in the controller . <p> 2 . These current-sense amplifier outputs show the required settling time when exposed to a common-mode PWM signal with a 40-V/10-+-s slew rate . <p> - <p> Finally , in-line phase sensing offers true motor phase-current measurement for optimizing the quality of the information being provided to the motor-control algorithm . The major challenge is that the common-mode voltage is a pulse-width-modulated ( PWM ) signal , which causes a disruption of the output signal unless good PWM rejection circuitry is @ @ @ @ @ @ @ @ @ @ current-sense amplifier , which must have both very good dc and ac common-mode rejection ratio ( CMRR ) . <p> In-line Phase Current Measurement <p> When measuring in-line , there 's no guess work on the phase current . However , as I pointed out earlier , the common-mode voltage seen by the current-sense amplifier is a high-voltage PWM that must be rejected . The frequency of the signal seen by the current-sense amplifier has two contributors : <p> An ideal in-line current-sense amplifier would only process the differential signal , while rejecting the common-mode signal . This high voltage combined with high + " V/+ " T poses a steep challenge that limits the availability of suitable current-sense amplifiers . This tends to limit the adoption of this topology to only those applications that require precise phase-current measurement , such as that for electronic power-steering systems . <p> Minimizing the PWM Effect on the Amplifier Output <p> The common-mode PWM signal causes an unbalanced input that disrupts the output of the current-sense amplifier . An ideal system would ignore this disturbance on the input and have a stable output @ @ @ @ @ @ @ @ @ @ control use high bandwidth to settle the disturbance ( Fig. 2 ) . <p> This settling time requires the system designer to add blanking time to the control algorithm . This blanking time is used to ignore the output of the current-sense amplifier until the output reaches an acceptable level of settling . The desired level of settling ( e.g. , 5% , 1% , or 0.1% ) will directly impact how long of blanking time must be implemented . Longer blanking times require a lower PWM frequency . <p> 3 . The output response reflects the required settling time when exposed to a common-mode PWM signal with a 40-V/10-+-s slew rate when using the INA240 . <p> If accurate representation of the phase current is critical to the system 's operation , then in-line motor sensing is the best option . In-line current sensing provides a faster response and higher precision , thus improving motor-control system efficiency . It reproduces a continuous proportional signal of the phase current , which does n't need further processing . <p> However , the PWM common-mode signal presents challenges for the current-sense amplifier @ @ @ @ @ @ @ @ @ @ the PWM signal is critical to maximizing the performance of your motor-control system . <p> If you have questions about this article , you can pose your questions to the TI E2E Community Forum for Current Sensing . 
@@21004582 @1004582/ <h> In Search of a Secured Gateway <p> I am searching for a secured gateway that is easy to use and knows about the devices on the local area network ( LAN ) it protects . Part of the challenge is that the devices on the LAN do not care about cooperative security . <p> Most people have a home gateway , and quite a few commercial and industrial installations also sit behind a gateway . These typically include basic firewall support to prevent systems on the internet from probing devices on the LAN . The protection tends to be outward with respect to the internet but , these days , devices on the LAN can be compromised " making the outward looking firewall useless in stopping these devices from doing something they should not , such as participating in a distributed denial of service ( DDOS ) attack . <p> For devices like PCs , tablets , and smartphones , limiting access on the internet does not make much sense . But for other devices , such as those covered under the Internet of Things ( IoT ) @ @ @ @ @ @ @ @ @ @ , most IoT devices have a very limited connectivity . For example , they often only communicate with a known server on the internet . Likewise , updates are often only delivered from a known host . If our secured gateway knew about these hosts then it could restrict the device to only these connections . It could alert a user if the device tried to communicate with any other host on the internet , since this would typically indicate a compromised device . <p> A secure gateway could work cooperatively with the device and the hosts on the internet if a suitable secure protocol could be set up . This would allow the system to be configured with minimal user interaction while providing the user with a map of known devices , hosts , and communication links . A more advanced system might include cooperation for features such over-the-air updates . <p> I have actually done some of this work on a Linux-based gateway since I know the IP address of my devices , including Nest thermostats . These communicate with a host on the internet ; the gateway @ @ @ @ @ @ @ @ @ @ to the known host . Of course , any changes on the internet side require changes on my gateway , and this type of configuration is not for the faint of heart . <p> Let 's go back to those PCs , tablets , and smartphones . This system might be extended to include these if devices could isolate communication on a per-application basis . Applications like web browsers would need to be more open , but other applications could be more restricted . Some PC security software already does checking on applications and limits them to some degree , but rarely pairs this with limitations on the host side . Essentially an application that is allowed network access can do so without restriction . <p> Most current set-ups ( like mine ) need to deal with IP addresses , although it is possible to utilize domain names . Using a secure DNS connection would make using domain names preferable and secure . This would likely be the way any cooperative protocol would work . <p> A secured home gateway would be great but the amount of cooperation needed to @ @ @ @ @ @ @ @ @ @ and Google are unlikely to want to give up the control of their walled gardens to make such a configuration universally available . <p> On the other hand , industrial and commercial systems are already more custom , making a secured gateway approach more of a possibility . Some systems have already been set up using this approach of limited connections between devices , hosts , and gateways . It can provide improved security for legacy devices that may have limited security . For example , if polling a device on a LAN can only be done from a fixed host on the internet , then even compromised devices can be identified and isolated . 
@@21004586 @1004586/ <p> The ever-increasing demand for rich content and instant access to information is dividing the communications industry into two camps : one based on tried and true non-return to zero ( NRZ ) binary ( two-level ) transmission , and a newcomer called multi-level signaling ( MLS ) . <p> A silent battle is being fought to continue making more bandwidth available to consumers , many of whom are now mobile . The ever-increasing demand for rich content and instant access to information is dividing the communications industry into two camps : one based on tried and true non-return to zero ( NRZ ) binary ( two-level ) transmission , and a newcomer called multi-level signaling ( MLS ) . <p> So why leave the old standard and move to an alternative way to move digital bits ? It comes down to physical limitations with our current technology . But which is more efficient for ultra-high speed communications in modern data centers , and soon the back office or your home ? This is the NRZ versus MLS smack-down ! <p> Binary communication is as old as smoke signals @ @ @ @ @ @ @ @ @ @ the era of Morse . Today , the computer world is essentially binary , where information based on binary principles is processed in logic . The advantage of binary is that it is extremely simple . There are only two states : 0 ( zero ) or off , and 1 ( one ) or on . This simplicity allows logical functions to be broken down into a set of switches . <p> Early electronic computers used tubes , and today 's modern CPUs use FINFETs . In the end , a one or a zero still determines the state . Binary communications is an extension of this concept , and information is communicated by signals sent over a medium that represents these two states . <p> NRZ is binary with a twist . It prevents long strings of zeros or ones in a transmission by periodically forcing or inserting a state change . The receiver knows of these insertions and removes them at the end . These insertions allow ac coupling and prevents base-line wander " or a dc shift in an electrical medium due to charging of the @ @ @ @ @ @ @ @ @ @ coding scheme , one that is limited to just two levels . These two levels represent a single-bit symbol , that is , a symbol or mechanism to represent the 1 or 0 . If you increase the number of bits represented by a single symbol , then theoretically you increase the capacity of the channel to carry information by compressing N-bits into M-symbols . <p> For example , if you encode two bits into four symbols representing 00 , 01 , 10 , and 11 , then each symbol change represents two bits " a compression of 2:1 . However , this degrades the signal-to-noise-ratio ( SNR ) due to smaller signal level changes . The more levels , the smaller the differences between them ( see the figure ) . <p> Increasing the number of bits per symbol reduces the signal level between each state , effectively reducing the SNR . <p> In general , it may seem that symbol-encoding the information would benefit in both the utilization of the available bandwidth and energy-per-bit used to transmit the data . But things in our physical world are not @ @ @ @ @ @ @ @ @ @ limits what is possible . <p> Shannon-Hartley <p> The Shannon-Hartley Capacity Theorem describes the theoretical limit for a given communications channel to carry information . It is based on the available bandwidth of the channel and the SNR : <p> Note that C represents the maximum channel capacity in bits per second , and B represents the available bandwidth . S/N represents the linear division of the average received power by the Gaussian noise interference power . By improving SNR or the bandwidth , either allows a channel to carry more information . <p> Given that the bandwidth is fixed , the only other two variables are received signal power and noise . By coding bits into symbols , the amount of information per state increases . But simultaneously the signal level ( the difference between each symbol ) decreases , causing a loss in the SNR term . <p> Metrics And BER <p> To compare the efficiencies of MLS versus NRZ , there must be a normalized method to examine how much energy is required to transport the information error free . Normalization removes the transmission speed and equalizes @ @ @ @ @ @ @ @ @ @ in : <p> - <p> Increasing the number of bits per symbol reduces the signal level between each state , effectively reducing the SNR . <p> This is the energy to move one bit error free in the channel and is expressed as Joules per bit-meter . W is the total watts for both the transmitter and receiver , R is the data rate in bits per second , and d is the length of the channel in meters . The resulting metric is independent of the transmission speed and distance and allows a normalized comparison assuming similar bit error rates ( BERs ) . <p> In modern communications systems , BERs are on the order of 10 " 12 or better . This suggests that one bit out of 1012 bits transmitted is incorrectly received . As noise and channel loss increases , this number quickly degrades and additional coding layers are required to ensure error-free transmission . All of that coding adds complexity and power . <p> Comparing Coding Levels <p> To compare MLS and NRZ , we need a standard that occupies both camps . A good @ @ @ @ @ @ @ @ @ @ incorporate both NRZ coding and multi-level . In many enterprise networks , 1000 Base-CX ( short-haul copper ) uses 8b/10b NRZ encoding over shielded twisted pair for a data rate of 1 Gbit/s ( line rate of 1.25 Gbits/s ) . <p> There is also the ubiquitous 1000 BaseT ( 802.3ab ) standard found in most laptops and computers today . This standard uses four pairs of category 5 ( or better ) bi-directionally via echo cancellation with pulse amplitude modulation or PAM-5 ( 5 level ) encoding . The symbol rate is 125 Msymbols/s per pair , and coding is used to improve the SNR , which uses additional power . <p> To compare these similar technologies , let 's examine two theoretical channels : one using 1000 Base-CX , and the other using 1000 Base-T . For the first channel we 'll select a buffer/repeater required to remove loss in the channel through equalization and de-emphasis . The DS25BR100 , which can run up to 3.125 Gbits/s , has a power dissipation of roughly 0.25 W for each end , for a total power of 0.5 W over @ @ @ @ @ @ @ @ @ @ ( PHY ) consumes roughly 1.1 W for each end , for a total of 2.2 W. It can drive over 100 meters of cable ( a farther reach than the DS25BR100 ) . Using our formula to compare both standards at maximum length , we get NRZ at 2 x 10 " 11 J/b-m ( Joules per bit-meter ) and PAM-5 at 2.2 x 10 " 11 J/b-m . <p> Intuitively , the difference in efficiency should be very large , but in reality it is very close . So when the distance that the PHY can drive is considered , the differences are not as great . But in this smack-down , NRZ wins by 0.2 x 10 " 11 J/b-m . <p> Conclusion <p> As rates and coding levels increase beyond 10 Gbits/s , the difference between NRZ and MLS widens quickly . However , MLS may be the only way to exceed the 25-Gbit/s+ NRZ rates now being implemented by switch and infrastructure vendors . In the end , which camp will win ? <p> There will always be a place for both since short-haul copper @ @ @ @ @ @ @ @ @ @ to density and energy concerns . MLS may one day win the 250-Gbit/s over copper battle , but wireless and optical solutions will also be major contenders . <p> Richard Zarr- is a technologist at Texas Instruments focused on high-speed signal and data path technology . He has more than 30 years of practical engineering experience and has published numerous papers and articles worldwide . He is a member of the IEEE and holds a BSEE from the University of South Florida as well as several patents in LED lighting and cryptography. 
@@21004589 @1004589/ <h> WAN , MAN , LAN , PAN , And SAN : Evolution , Not Revolution <p> During the past several years of economic downturn , changes in networking technology have been incremental rather than major . <p> Louis E. Frenzel Jun 15 , 2003 <p> During the past several years of economic downturn , changes in networking technology have been incremental rather than major . Progress has been made by upgrading and fine-tuning the existing technologies or by applying existing technology to new applications . And it 's pretty clear that we 'll stay on that path for the immediate future . <p> The undisputed major trend in networking , as expected , is higher speeds . The increased use of fiber-optic links to get that extra speed supports that trend . High-speed digital chips with lower power consumption continue to flow out of the semiconductor companies , while optical component manufacturers who have survived the turmoil of the past years have produced improved higher-speed , multiwavelength parts including affordable tunable lasers . <p> Each of the popular communications networking systems has a unique place in the market @ @ @ @ @ @ @ @ @ @ . These long-haul rings and backbones are universally optical . The typical upper speed is 2.5 Gbits/s ( OC-48 ) . Today , with the telecom industry in the dumps and overcapacity the norm , carriers are n't spending the bucks to expand their networks . Instead , they 're upgrading what they have . While 10-Gbit/s Sonet ( OC-192 ) equipment is available , few are opting for it in any volume . Some work on 40-Gbit/s Sonet ( OC-768 ) components continues in the background , but no commercial systems are yet available . It will take a return of the good times to see 10-Gbit/s systems widely adopted and 40-Gbit/s parts come to market . It will no doubt be another year or so before the good times roll again . In the meantime , software technologies like multiprotocol label switching ( MPLS ) will greatly improve the use of existing WANs . Another growth area is the implementation of security measures . Security is becoming easier with the new , faster encryption chips . Yet security is still mostly a software issue . <p> MANs Metropolitan-area @ @ @ @ @ @ @ @ @ @ While there are pockets of new MANs , mostly everyone is still hunkering down and waiting for better conditions . In the past , most MANs used Sonet . MANs implemented during this downturn are cheaper and made with 1-Gbit Ethernet ( 1GE ) or 10-Gbit Ethernet ( 10GE ) . They 're inexpensive and ideal for extending or interconnecting existing Ethernet LANs because they require no protocol conversion . The 1GE systems predominate , but 10GE systems are beginning to show up as prices of optical components begin to decline . <p> While quality of service ( QoS ) and compatibility with WANs and other MANs are issues , these are being overcome with new technologies and standards like resilient packet ring ( RPR ) , which promises to improve the linkage of Ethernet and Sonet systems . With suitable changes and additions to the existing standards , the 1GE and 10GE systems may have won this space permanently over more complex and expensive Sonet systems . <p> LANs Local-area networks continue to use the traditional 10/100-Mbit/s Ethernet over CAT5. 1GE over copper ( CAT5E or CAT6 ) is @ @ @ @ @ @ @ @ @ @ network interfaces in PCs become standard and as 1GE switches decline in price . The 1GE connections are still mainly backbones for larger LANs , but 1GE to the desktop is increasing with the availability of 1GE over copper . All of this is a very mature business with only marginal growth expected . <p> One hot area , though , is power over Ethernet . This upcoming IEEE Ethernet standard ( 802.3af ) defines how to supply dc power over Ethernet twisted pair to power voice-over-IP phones and wireless-LAN hot spots . The IEEE has established a working group to transmit 10 Gbits/s over copper by extending the XAUI interface over coax cable . A 10GBaseT study group has also been set up to investigate 10-Gbit/s Ethernet over twisted pair or other copper lines . <p> The major growth sector is wireless . Many organizations are adopting wireless LANs ( IEEE 802.11b ) to expand their networks and to provide mobile capability within the organization . While security is still an issue , that problem is being solved in the newer versions of the equipment . The current 11-Mbit/s @ @ @ @ @ @ @ @ @ @ systems that run to 54 Mbits/s . As the new 802.11g products become available , look for them to become the primary WLAN products in the enterprise . ( For more on WLANs , see " Wireless LANs And Cell Phones Lead The Way , " this issue , p. 65 . ) <p> PANs Personal-area networks are a tiny niche in the overall networking world . They use wireless technology . Infrared ( IR ) systems started the trend with interfaces in laptops and PDAs . But they never became popular . The current PANs are mostly Bluetooth . While Bluetooth chips are now much lower in price , they have not been widely employed in PANs . Some laptops and PDAs have them , but the biggest use of Bluetooth so far has been in cell phones for cordless headsets . Currently , PANs seem to be a networking segment that is going nowhere . It is the classical technology looking for an application . There may never be a killer app beyond the cordless headset . PANs are expected to get a major boost in speed as @ @ @ @ @ @ @ @ @ @ is a forthcoming bright spot in PANs : the ZigBee standard for short-range , low-speed ad hoc networks for monitoring and control operations . ZigBee may eat into the Bluetooth space , but in reality it is in a niche of its own . Silicon from several vendors is expected later this year . <p> The biggest boost in PANs , however , may come from the ultra-wideband ( UWB ) products that should become available later this year . Speeds of greater than 100 Mbits/s will be available for short ranges ( up to 10 m ) . But again , what is the application ? UWB PANs will no doubt find their greatest potential in the home for interconnecting video equipment . <p> SANs Perhaps the brightest spot in networking is storage-area networks . These interconnections link large disk arrays to servers and other systems . The reigning technology is Fibre Channel ( FC ) , an optical ring configuration that has become the de facto standard . FC continues to get faster as the newer versions of the standard have increased rates to 1.0625 Mbits/s and 2.125 @ @ @ @ @ @ @ @ @ @ Faster 4G and 10G systems are in the works . <p> FC manufacturers have also felt increasing competition from a serial version of the popular SCSI parallel interface used for years to connect disk arrays . Known as Internet SCSI or iSCSI , this networking standard encapsulates SCSI commands into TCP and then transmits them over IP . This makes Ethernet a viable connection to the disk arrays . Both 1GE and 10GE systems are becoming available , and they are generally less expensive than FC systems because they use standard Ethernet hardware . But the FC vendors have joined the quest for lower costs and they will no doubt continue to dominate this field despite the rise of iSCSI . <p> In addition , there are efforts to transmit FC over IP . FCIP is Fibre Channel over TCP/IP that tunnels FC over existing IP networks . Another effort , iFCP , supports FC in Layer 4 TCP/IP transactions . <p> NETWORKED FUTURE The general movement to network everything will continue . Manufacturing plants and factories are adopting Ethernet for monitoring and control . Most of the electronic functions @ @ @ @ @ @ @ @ @ @ home networks are growing in popularity . Further , work is being accomplished remotely more and more with Internet connections . 
@@21004591 @1004591/ <p> Light-emitting diodes ( LEDs ) are semiconductor devices that emit light when an electrical current passes through semiconductor materials . But for LEDs to perform at their best they need the assistance of LED drivers to provide better efficiency , reliability , and longevity . <p> LED drivers are electrical devices that prevent damage to LEDs by regulating the forward voltage ( VF ) of the LED that changes with temperature , avoiding thermal runaway while delivering a constant current to the LED . LED drivers also aid efforts to meet new energy requirements ( e.g. , Energy Star ) . <p> The steady growth of LED lighting technology has generated a wide range of LED-driver IC options in the semiconductor market . An appropriate driver generates a successful application . Some of the major developments in LED applications that have occurred and continue to evolve are as follows : dimming LED lamps , automotive lighting , LED signage , smartphone backlighting , and TV backlighting . <p> Here we present five different LED driver products for the major developments in LED applications mentioned earlier : <h> 1 @ @ @ @ @ @ @ @ @ @ use the ON and OFF setting , as dimming helps to reduce energy consumption . There are two popular methods for dimming LEDs in switch-mode driver circuits : analog and Pulse-Width Modulation ( PWM ) dimming . <p> Analog Dimming refers to the adjustment of the nominal LED current . The analog voltage is adjusted and the LED current is changed to achieve dimming . This approach is not acceptable in many applications because there is a color shift with current variation . In contrast , pulse width modulation ( PWM ) dimming is accomplished by adjusting the nominal LED current by switching ON and OFF at a sufficiently high frequency to avoid a flickering effect . <p> 1 . This is a schematic of LED driver configured as a low-side buck utilizing the LYT7503D from the LYTSwitch-7 family of ICs . This dimmable LED driver is designed to power a 60 V LED voltage string at 125 mA output current from an input voltage of 90 V ac to 300 V ac . ( Figure courtesy of Power Electronics ) <p> - <p> One of the challenges of dimming @ @ @ @ @ @ @ @ @ @ were never designed for LEDs . However , an array of products exist that can be used in this application . For example , Power Integrations offers the LYTSwitch-7 ( Fig. 1 ) . This buck LED driver IC has a buck topology with a power factor higher than 0.9 . It is compatible with TRIAC dimmers capable of delivering up to 22 watts . The 735V integrated MOSFET ensures sufficient overvoltage protection during line surge occurrence . Its design offers a wide input ( 90 VAC " 308 VAC ) and output voltage range operation . An EMI pi filter blocks differential and common mode noise . Bleeders are not included in the design ; passive damping and a single winding inductor are used for TRIAC management . <h> 2 . Automotive lighting . <p> The LED automotive lighting market is actively growing . Every automotive lighting solution includes a distinctive LED driver ; they are used for energy saving solutions , visibility , etc . Depending on the application , sometimes it 's better to use linear drivers instead of switching drivers . This also applies to automotive @ @ @ @ @ @ @ @ @ @ on the back or on the front of the car . They will dissipate heat at different levels , depending on the environment and placement . <p> LED lighting can improve the safety of drivers and pedestrians by enhancing the range of visibility when the headlights are turned ON , OFF , or dimmed to efficiently perform at any stage of the journey . LED headlights present several challenges because the input voltage can vary depending on the condition . Therefore , step down ( buck ) and step up ( boost ) topologies are demanded for better performance . <p> 2 . Its synchronous operation eliminates unstable dimming that can occur when the input voltage is low . ( Figure courtesy of Cypress Semiconductor ) <p> - <p> The S6BL112A ( Fig. 2 ) single-output synchronous Buck LED driver from Cypress , for example , supports both analog and PWM dimming functions . It includes a frequency adjust pin that allows the user to adjust the frequency from 205 kHz to 2.1 MHz . The switching frequency ( FOSC ) is programmed by using an external resistor ( RRT @ @ @ @ @ @ @ @ @ @ S6BL112A Automotive LED driver features an input voltage range of 4.5-42 V that allows it to handle extreme operating conditions such as cold-cranking . Cold cranking occurs when the automobile engine starter draws an excessive amount of current due to starting the engine in cold temperatures . It also can function during load dump , which is a power surge that occurs when an automobile battery is disconnected while the alternator is supplying current during engine operation . <h> 3. 16 + 16 LED displays . <p> 16 + 16 displays are becoming more common , as they are great for outdoor use like storage signs , billboards , public transport signs , etc . Most of LED displays today are 8 + 8 and can not communicate many international alpha-numeric characters . With a 16 + 16 display , however , it is possible to create signs in multiple languages that require more LEDs . <p> 3 . In the MAXREFDES99# block diagram , four MAX7219 ICs are daisy-chained to drive a full 256-LED array , which can display any international alpha numeric symbol . ( Figure courtesy of @ @ @ @ @ @ @ @ @ @ a reference design ( MAXREFDES99# ) ( Fig. 3 ) that integrates four of its MAX7219 LED drivers to create a 16 + 16 display with 256 LEDs . The MAXREFDES99# can be powered from a wall-wart which provides a minimum of 7W of power and an output voltage in the range of 7.5 V dc to 12 V dc . The reference design works with both Arduino and ARM mbed platforms . <p> The MAX7219 is a compact , serial input/output common-cathode display driver that interfaces microprocessors ( -Ps ) to seven-segment numeric LED displays of up to eight digits , bar-graph displays , or 64 individual LEDs . Here is a short video of the display in action that I took while visiting Maxim 's demo room in San Jose . <h> 4 . Smartphone backlighting . <p> LEDs enable thinner backlight designs and support advanced backlight architectures that reduce PCB area and lower cost . The amount of LEDs changes depending on the size of the smartphone display . Bigger displays require more LEDs for backlighting applications . <p> Inductive drivers ( inductive DC-DC converters ) are @ @ @ @ @ @ @ @ @ @ . Because they operate more efficiently than single strings of LEDS at lower output voltages , they result in longer battery run-time . <p> 4 . AS3492 Typical Operating circuit . The ON13 and ON45 can be used as PWM inputs to accurately control the LED brightness . ( Figure courtesy of AMS ) <p> - <p> AMS ' AS3492 ( Fig. 4 ) - is an inductive DC-DC converter that can drive up to five strings with two LEDs each in series with a system efficiency of 86% ( DC-DC and current sources combined ) . The DC-DC converter operates at a fixed frequency of 2 MHz and includes soft startup to allow easy integration into noise-sensitive RF systems . <p> The output of the DC-DC converter is used for five current sources connected to up to 10 LEDs . The AS3496 has the following built-in protection mechanisms : Short LED protection ( SLP ) , Open LED Protection ( OLP ) and Over Voltage Protection ( OVP ) . This display backlight driver has been designed specifically for mobile phones , digital cameras , PND and PMPs. <h> @ @ @ @ @ @ @ @ @ @ BLU ) in a TV or monitor is a major source of power consumption . LED drivers can offer significant power reduction through different backlight architectures : direct and edge backlight . In the edge backlight architecture , the LEDs surround the edge of the display . This approach offers the advantage of cost reduction by using fewer LEDs . For its part , direct backlight architecture puts the LEDs directly behind the display . In doing so , it provides better contrast but at a higher cost . <p> Two major dimming modes are used for LED backlight applications : global dimming ( all LED strings are dimmed together ) and local dimming ( LED strings are dimmed independently ) . <p> 5 . The MC34844 is a solution for backlighting small and medium size LCD panels , on low power portable and high definition devices ( Figure courtesy of NXP Semiconductors ) <p> Among the products targeting this market is NXP Semiconductor 's MC34844 ( Fig. 5 ) , an LED driver for backlighting small- and medium-size LCD panels . It specifically serves low-power portable and high-definition devices @ @ @ @ @ @ @ @ @ @ personal computer notebooks , GPS screens , small-screen televisions , etc . ) . Operating from supplies of 7 to 28 V , the MC34844 is capable of driving up to 160 LEDs in 10 parallel strings . The integrated boost converter generates the minimum output voltage required to keep all LEDs illuminated with the selected current , providing 90% efficiency ( dc-dc ) . The MC34844 also includes a Pulse Width Modulation ( PWM ) generator for LED dimming . The LEDs can be dimmed to one of 256 levels , programmed through the I2C/SM-bus interface . Therefore dimming ratios up to 65,000:1 ( 256:1 PWM , 256:1 Current DAC ) can be supported . External PWM inputs may also be used . <p> The MC34844 features LED over temperature protection , LED short protection , and LED open-circuit protection . The IC includes overvoltage protection , overcurrent protection , and undervoltage lockout . To achieve enough voltage to drive a number of LEDs in series , a boost converter is implemented to produce a higher voltage from a smaller one , which is typically used by the logical @ @ @ @ @ @ @ @ @ @ approaches for controlling LED lighting ; every application is different , and LED drivers can provide efficiency and reliability by selecting the appropriate parameters . As technology advances we will see better LED driver applications capable of minimizing power consumption without trading-off in terms of efficiency , switching frequency , component counts , etc . We will see more LED drivers and sensors working together within the Internet of Things ( IoT ) , where smart building and smart city markets are fast growing . 
@@21004592 @1004592/ <h> Consider All The Factors When Selecting The Proper Inductive Proximity Sensor <p> When an application calls for detecting a metallic target that falls within an inch of the sensing surface , inductive proximity sensors are apt for the task . First introduced in the early 1960s , these durable components have proven their mettle in the sensing arena . In fact , they 're the best-selling sensing technology in the world . Their immunity to dust and dirt buildup suits them well for harsh industrial environments . Additionally , the standardized physical and electrical characteristics of the general-purpose , cylindrical types of these sensors simplify their use . <p> Naturally , designers make some common mistakes when applying these devices . Knowledge in several key areas , though , can help careful users avoid these pitfalls . Successful object detection requires an understanding of the fundamentals of sensor design . The criteria for choosing between the various styles of inductive proximity sensors also must be kept in mind . And , the significance of key sensor specifications and the effect of mounting restrictions on sensor implementation should be @ @ @ @ @ @ @ @ @ @ : the coil , oscillator , detection circuit , and output circuit . The target material , environment , and mounting restrictions all have an influence on these items and on the senor 's operation , magnetic nature , and shielding . The oscillator generates a fluctuating , doughnut-shaped magnetic field around the winding of the coil , which is located in the device 's sensing face . <p> When a metal object moves into the sensor 's field of detection , Eddy currents build up in the object , magnetically push back , and finally dampen the sensor 's own oscillation field . The sensor 's detection circuit monitors the amplitude of the oscillation and , when it becomes sufficiently damped , triggers the output circuitry ( Fig. 1 ) . <p> Inductive proximity sensors come in shielded and unshielded versions . Without any shielding , the doughnut-shaped magnetic field generated by the sensor 's coil is unrestricted . As a result , the sensor will be triggered when any metal object comes from behind , along side , or in front of the device . In a shielded @ @ @ @ @ @ @ @ @ @ field to radiate only from the sensor 's detection face . Even unshielded inductive proximity sensors have peeled-back ferrite-core shielding , which gives them a longer sensing distance than the shielded versions . At the same time , this feature prevents false readings caused by objects behind the detection face . <p> There are five categories of inductive proximity sensors : cylindrical , rectangular , miniature , harsh environment , and special purpose . Cylindrical threaded-barrel sensors account for 70% of all inductive proximity sensor purchases . Years ago , this style 's behavior was standardized by the CENELEC organization , which determined characteristics such as body size , sensing distances , and output levels . It 's easy to understand why a designer would automatically select this general-purpose sensor , since it would be the right choice 70% of the time . <p> Yet experience has shown that there are many proximity-sensing applications where one of the other , specialized sensors can provide a better solution . Designers who automatically specify a general-purpose sensor may encounter problems that would vanish if another style were selected . Target material , @ @ @ @ @ @ @ @ @ @ sensor style . <p> In the world of inductive proximity sensors , not all metals are created equally . The familiar specification in technical data sheets refers to a " standard detectable object " made of an iron ( ferrous ) material . Other metallic materials , such as stainless steel , brass , aluminum , and copper , have different influences over the inductive effect . They 're usually less detectable than iron , too . <p> Designers should determine two things . First , is the target material made out of iron or another metal ? Second , is it possible for the target material to change in the application 's future runs ? To calculate the sensing distance of nonferrous metals , multiply the standard sensing distance by a reduction factor . Typically , this value is 0.8 for stainless steel , 0.5 for brass , 0.4 for aluminum , and 0.3 for copper . <p> A full-line sensor supplier will have a sensor solution for the detection of troublesome metallic materials . These special inductive proximity sensors are known as " nonferrous sensing " or " @ @ @ @ @ @ @ @ @ @ as aluminum better than they sense iron , while all-metal sensors will pick up on all kinds of metal at the same sensing distance . <p> What separates the nonferrous and all-metal sensors from general-purpose inductive proximity sensors is the number of separate inductive coils included in the proximity-sensor head . The nonferrous and all-metal types contain two or three separate coils in the sensor head , while the general-purpose sensor has only one . Consequently , the nonferrous and all-metal sensing styles tend to be larger and more expensive than their general-purpose counterparts . <p> Environmental conditions can significantly affect the sensor . Extreme temperatures will reduce its operating life , causing premature failure . Hot temperatures will make it more sensitive , while cold temperatures will lower its resistance to shock . Nevertheless , a full-line sensor supplier can offer solutions to specific environmental conditions . <p> In certain applications , metallic " chips " or filings accumulate on the sensor 's side or face . To account for this , some modern inductive proximity sensors contain embedded microprocessors that detect the slow buildup of these chips over @ @ @ @ @ @ @ @ @ @ These sensors are " chip immune . " The flat-pack proximity sensor also resists the effects of chip buildup . With its slim profile , it 's virtually unaffected by chip buildup when its sensing face is vertically exposed . <p> Sensors may be exposed to cutting fluids or chemicals for prolonged periods of time as well . This can cause traditional inductive proximity sensors to become brittle and crack , shortening their lifetimes . In such cases , designers must again turn to a specialized model . Proximity sensors dipped , coated , or shot from Teflon suffer no i 'll effects from the material in terms of performance or reliability . Teflon 's added cost can be justified by the material 's stability in the presence of cutting oils and corrosive chemicals . It also prevents weld slag buildup . <p> High-temperature environments pose another challenge . Inductive proximity sensors generally are self-contained devices that include their silicon amplifiers and detection circuitry inside the sensor-head housing . Self-contained proximity sensors are practical for most applications until environmental conditions begin to exceed the standard operating parameters for a silicon-based circuit @ @ @ @ @ @ @ @ @ @ . <p> Separate Amplifiers May Be Needed Under any temperature conditions beyond this range , the circuitry becomes prone to operating failure . Designers should then look for inductive proximity sensors that use separate amplifiers . Their sensor head contains the inductive coil and little else . The amplifier and detection circuitry can be located safely away in a remote , environmentally controlled area . Such sensors can resist temperatures as high as 200-C . <p> Inductive proximity sensors are strong representatives of the last decade 's microelectronics revolution . Today , it 's possible to manufacture a rectangular proximity sensor as small as 5.5 by 5.5 by 19 mm with an extended sensing range of 1.6 mm ( Fig. 2 ) . Advances in sensor miniaturization also result from the development of the separate in-line amplifier types . These sensors come with sensing heads as small as 3 mm in diameter and robotic cabling that enables the sensor head to move if necessary . <p> In some instances , space constraints prohibit the use of an inductive proximity sensor with a traditional cylindrical body . Fortunately , a wide @ @ @ @ @ @ @ @ @ @ the subminiature ( 5.5 by 5.5 by 19 mm ) to the flat-pack style ( 25 by 10 by 50 mm ) , all the way up to the limit-switch housing size ( 40 by 40 by 115 mm ) . A sensor in a limit-switch housing will vastly outlive a typical limit switch , which has mechanical contacts . A limit switch has a life expectancy of about 300,000 cycles , while a similarly shaped sensor in limit-switch housing can last up to 100,000 hours . <p> If a specialized sensor is n't required , designers can reliably fall back on the proven success of the traditional cylindrical type . But before a particular device is specified , it 's important to investigate several areas to ensure a long-lasting and well-manufactured sensor . <p> A strong enclosure is crucial . The thicker the barrel housing in a cylindrical proximity sensor , the less likely it is to break because of overzealous installation techniques or incidental object collision . Keep in mind , however , that housing thickness varies from manufacturer to manufacturer . <p> Also , check the sensor @ @ @ @ @ @ @ @ @ @ sensors are potted , but poor potting is almost worse than no potting at all . Air bubbles can be trapped inside poorly potted sensors . These bubbles cause undue stressing , which may lead to pc-board cracking and failure . <p> The cable must have proper strain relief , too . An inductive proximity sensor with a cable that protrudes directly out of the potting material is susceptible to breakage at the junction between the potting material and the cable . A proximity-sensor cable with this design also has a much weaker pull force . Strong , flexible strain relief can provide a sensor with a long life . <p> Even though they 're used outside the sensing industry , certain terms have unique definitions when they 're applied to inductive proximity sensors . Designers should understand what these terms mean before specifying a particular device . <p> When an inductive proximity sensor 's data sheet refers to a standard detectable object , it describes the specified shape , size , and material that 's used as the standard for examining the sensor 's performance . This definition is @ @ @ @ @ @ @ @ @ @ the shape and material of the object being detected . Generally , the standard detectable object will be an iron plate with a thickness of 1 mm and a height and width equal to the inductive sensor 's diameter . <p> Detection distance is the position at which the inductive proximity sensor is triggered when a standard detectable object is moved in front of it in a defined manner . To determine this distance for a sensor with an end ( or " front " ) detection surface , the sensor 's center line is aligned with the standard detectable object 's center line . Then , the object is moved toward the sensor 's face until the sensor changes output states . <p> Detection distance is influenced both by the conductivity and the thickness of the target material . Highly conductive materials make poor targets for traditional inductive proximity sensors . Thick materials are harder to detect than thin ones . Both factors relate to the generation of Eddy currents in the target . A conductive material disperses Eddy currents , so the target becomes harder to detect . @ @ @ @ @ @ @ @ @ @ move current , causes a buildup of Eddy currents . This makes it detectable at greater distances . <p> The reset distance is the distance at which the inductive proximity sensor releases its output when the standard detectable object is removed from its field of detection . The difference between the detection distance and the reset distance is called the distance differential . Typically 3% to 10% of the overall detection distance , the distance differential is incorporated into the sensor 's design to prevent its output from " chattering " ( switching on and off erratically ) due to noisy environments or detectable object vibrations ( Fig. 3 ) . <p> Today 's quality inductive proximity sensors can have trigger points that are repeatable to 0.0001 in . To obtain such precision , though , the detectable object must be moved the reset distance away from the sensor after each time the sensor is triggered . <p> The setting distance describes the distance at which the inductive proximity sensor will trigger an output with the standard detection object , even if the detection distance has decreased due to temperature @ @ @ @ @ @ @ @ @ @ will have the luxury of sensing the standard detection object described in the sensor data sheet . <p> The detection distance for an irregular object can not be estimated from the manufacturer 's data . Instead , it must be measured with a sample object . To do so , take the object in question and move it toward the sensor until the output changes state . The result is the detection distance for that particular combination of target object and inductive proximity sensor . <p> The setting distance for the target object can then be calculated by the following formula : new setting distance = ( detection distance obtained by test with target object ) + ( setting distance of the standard detectable object ) / ( standard detection distance of the standard detectable object ) . <p> Mounting requirements must be considered when the inductive proximity sensor is implemented into the design . Otherwise , there may be a reduced sensing distance , false triggering , or target nondetection . It 's important to consider the effects of the mounting hardware itself as well as other metallic objects @ @ @ @ @ @ @ @ @ @ embedded into a metallic mounting fixture up to the point where the shielded sensor 's face is flush with the mounting surface . This embedded mount protects the sensor from mechanical damage due to incidental contact with the target object . Even so , shielded sensors should n't be recessed into a metal mounting surface . Objects , materials , or opposing surfaces that are n't supposed to be detection objects should remain clear of the inductive sensor 's face by a factor of three times the sensor 's standard detection distance . <p> Unshielded sensors can not be completely embedded into a metallic-mounting fixture . Because of their extended sensing distance , they 're susceptible to the influences of surrounding metals . Designers , then , have to obey the factor-of-three rule for shielded types . The sensor must be surrounded by a metal-free area . This area must be equal to the sensor 's size ( or diameter , in the case of a cylindrical proximity sensor ) . It also must stretch in every direction , with a depth clearance of two times the sensor 's standard @ @ @ @ @ @ @ @ @ @ clearance requirements can lead to false detection or reduced sensing distances . <p> When multiple inductive proximity sensors are mounted in close proximity to one another , either side by side or in opposing directions , the sensors can be subject to an effect called mutual interference . If one proximity sensor 's field couples with the detection coil field of another , an inductance may generate a beat frequency in one or both of the sensors . This , in turn , causes the output of the proximity sensor to chatter . <p> Mutual interference problems can be insidious , due to their erratic nature . When inductive sensors are mounted side by side at distances closer than the sensor manufacturer 's mutual-interference specifications , they may perform seamlessly . Then , they may suddenly display signs of chattering and false detection . <p> Separation distance specifications for sensors mounted side by side can vary according to sensor body type and from manufacturer to manufacturer . Always examine and adhere to the manufacturer 's specification distances for mounting inductive proximity sensors to avoid potential mutual-interference . <p> Several options @ @ @ @ @ @ @ @ @ @ inductive proximity sensors to be mounted close together . Shielded types allow for closer mounting . So do miniature inductive sensors , whose smaller size means decreased sensing distances and a smaller likelihood of mutual interference . <p> Finally , if close sensor mounting can not be avoided , the sensors can be multiplexed . Switching alternate sensors on and off and taking alternate reads can be a quick solution to a mutual-interference problem , provided that the application accounts for the corresponding reduction in sensor response time . <p> Equipped with an understanding of sensor operation , available sensor options , and the application 's environmental conditions , designers can select the inductive proximity sensor that best fits their needs while delivering optimum performance . 
@@21004593 @1004593/ <h> Get The MOST Out Of Your Automotive Communications <p> The MOST network protocol for cars offers support for music , video , telecom , and anything else engineers can imagine . <p> Wolfgang Bott Oct 08 , 2008 <p> T he clamor for more digital connectivity in vehicles has car designers scrambling to implement systems that efficiently distribute audio , video , and other content . These requirements have led to the design of a future-proof system and networking architecture that can cope with the different development time frames in the consumer and the automotive worlds . <p> MOST offers more than the physical connection between devices . It also provides the software infrastructure to manage the complexity of multiple devices communicating with each other . As telephones , navigation systems , portable media devices , and infotainment systems are integrated to provide a rich entertainment experience , they need to communicate so they do n't overwhelm the user with the details of moving audio and video to multiple stations in the car . <p> Via MOST , designers can tame this complexity by moving all audio , @ @ @ @ @ @ @ @ @ @ , using either plastic optical fiber ( POF ) or unshielded twisted-pair ( UTP ) wires . <p> MOST Technology is the result of the collaboration among members of the MOST Cooperation , which consists of 16 carmakers and more than 75 suppliers working to establish and refine a common standard for the evolving requirements of automotive multimedia networking . Through this work , MOST has become the de facto standard in the automotive industry for transporting high-bandwidth audio , video , and control information between various vehicle subsystems . <p> Its quality of service ( QoS ) makes it a prime transport for applications that stream content to provide consumers with high-quality information , video , and sound . MOST is used in over 58 vehicle models from more than 16 vehicle brands from around the world . The technology started in Europe but has now expanded into Asia , with Toyota , Hyundai , Kia , and SsangYong recently introducing several models . <p> The traditional way of connecting analog signals between various components and using controllerarea networking ( CAN ) to control communications is n't viable in @ @ @ @ @ @ @ @ @ @ would have to be connected with each other . If several of the connections involved surroundsound , for example , each link between devices would need six or more wires just for the audio signals alone . <p> Car designers can significantly reduce the complexity of the wiring harness by using MOST , which uses a ring structure ( Fig. 1 ) . Figure 2 shows an actual example of one vehicle manufacturer going from a traditional analog-based system to using MOST . <p> CONSUMER , AUTO ELECTRONICS CONVERGE MOST helps car companies connect to the consumer world . It allows the network backbone in the car to comply with the robustness and reliability requirements of the automotive industry and provides a pipeline for moving audio and video . The long design cycles of a car make it difficult to quickly adapt to the latest consumer trends , though . <p> With the standardized interfaces of MOST , car companies can maintain their infotainment backbone on their own time schedules and only need to develop a single customized gateway device to connect to the latest consumer electronics . It would @ @ @ @ @ @ @ @ @ @ that could be upgraded over time . Other consumer- and computer- oriented technologies , such as Ethernet and USB , are relevant to the car . <p> Ethernet 's wide proliferation , high bandwidth , and the optimized communication of bursts or packets of information make it an excellent connectivity solution between the outside world and the automobile . The protocol can connect an external Ethernet-based infrastructure to a vehicle and move large amounts of diagnostic information between the two , such as downloading software into the vehicle when the car is in a repair bay . <p> Many vehicles rely on embedded Ethernet products . The non-PCI architecture is well suited for the automobile since it obviates the need for a full personal- computer infrastructure . Instead , it provides simple interfaces to the typical microcontrollers used inside the car while taking advantage of the vast computing power that exists outside of the vehicle . <p> Continue on Page 2 <p> While Ethernet is an efficient data-transport technology that relies on packet switching , MOST provides for efficient audio and video streaming by using a circuit switched architecture . @ @ @ @ @ @ @ @ @ @ data and one or more users of that data . By combining Ethernet and MOST , vehicle makers can use the best functionality that each technology has to offer . <p> USB has become the interface of choice for many consumer electronics devices . When a consumer brings an MP3 or video player , memory card , digital camera , or even a cell phone into the car , its connection is likely to be over USB . Within the automobile , USB provides the connection to the consumer world . However , standard consumer USB cables introduce significant electromagnetic emissions to the vehicle . <p> Instead of using cables to a central location , USB ports can be located where consumers will connect their devices while sending content from those devices over the MOST network backbone . MOST enhances the single host/multiple device architecture of USB by providing the distributed control architecture ( multiple controllers and slaves ) and simple mechanisms for allocating the entertainment content that 's stored in various consumer products . <p> Here again , the connection to the external world is through a ubiquitous consumer @ @ @ @ @ @ @ @ @ @ and control within the vehicles is over the stable MOST infotainment backbone . <p> Wireless technologies such as Bluetooth and Wi-Fi are also used to connect nomadic devices to MOST . They ca n't completely replace wired solutions due to the need to charge the batteries of these portable components , but they 're complementary to the systems in the car . These technologies allow for seamless transfer of information without having to be tethered to the car . <p> Many nomadic devices use a standard mini-USB connector . Cell phones , media players , GPS receivers , and other devices are adopting it , even if they do n't need to communicate data , because it provides a common way to charge the batteries in these devices . MOST , Ethernet , and USB provide the next generation of automotive interfaces that enable feature-rich and easy-to-use information and entertainment systems . Ethernet and USB are well understood in the market . <p> MULTIMEDIA UNLIMITED A MOST network is very easy to use due to simple connections . Plug-and-play functionality permits the network to identify the characteristics and features of @ @ @ @ @ @ @ @ @ @ management functions include channel allocation , system monitoring , addressing , and power management . The synergy with the consumer and PC industries is possible with consistent PC streaming and because it operates with or without a PC . <p> The most efficient and cost-effective way to continue automotive innovations in all of these areas is to develop the devices independently and then connect them together via a MOST gateway using standard hardware and software interfaces . <p> The clear trend is to enable the automotive system to attach the required features instead of providing every possible upcoming interface . With the gateway , MOST will offer a way to successfully decouple the automotive development cycles from the consumer electronics cycles . <p> The latest MOST Specification is at Rev. 3.0 . It 's a complete overhaul of the specification structure , offering several new features . While the specification is independent of speed grade , it can already work with the newly defined MOST150 physical layer . Designers now can use a higher bandwidth of 150 Mbits/s , an isochronous transport mechanism to support extensive video applications , and @ @ @ @ @ @ @ @ @ @ . <p> MOST provides the specification for audio and video signals to be transported with high bandwidth efficiency and without any overhead for addressing , collision detection/recovery , or broadcast . This way , it offers capacity that packet-switched networks can only achieve with much higher gross bandwidth . Consequently , multiple HD video streams and multichannel surroundsound with premium QoS can be transmitted while simultaneously moving high loads of packet data around . <p> The latest version adds Ethernet and isochronous channels to the well-known synchronous , packet , and control data channels of previous specification versions . The Ethernet channel can transport unmodified Ethernet . This permits software stacks and applications from the consumer and IT domain , where innovation is much quicker , to be seamlessly migrated into the car . TCP/IP stacks or protocols utilizing TCP/IP can communicate via MOST without any modification . <p> Continue on Page 3 <p> As a result , the new generation of MOST provides the automotive-ready physical layer for Ethernet in the car . In addition , MOST Specification Rev. 3.0 offers an isochronous channel to support streams that are @ @ @ @ @ @ @ @ @ @ usecase is the transport of MPEG streams over a MOST network , since MPEG streams generally use variable bit rates . This new MOST feature enables extensive video applications . <p> MOST Specification Rev. 3.0 also adds significant enhancements to the control channel . By doubling the bandwidth of that available with MOST25 , the channel can control devices in real time . <p> With the integration of DVD audio and DVD video into digital networks , content protection becomes a requirement . DVD content on a digital network must be DTCP-protected ( Fig. 3 ) . HD DVD and Blu-ray content over MOST is also supported . That 's because Advanced Access Content System ( AACS ) specifications allow for DTCP-protected digital outputs . <p> DTCP requires source and sink devices to authenticate each other , and there 's a need to encrypt multimedia streaming data before sending it over a digital network . A sink device , then , must be able to decrypt protected digital content . DTCP on MOST also supports point-to-multipoint connections . The single phases consist of authentication ( 32-bit public device key ) @ @ @ @ @ @ @ @ @ @ encryption and decryption ( M6-56Bit , AES-128Bit ) . 
@@21004594 @1004594/ <h> Basics of Design : Circuit Breakers <p> Circuit breakers are everywhere . If a technology , product , or piece of equipment runs on electricity , chances are it contains at least one circuit breaker to keep users and internal components safe . Download this paper from Carling Technologies covers circuit-breaker types , advanced circuit-breaker applications and choosing the right circuit breaker . <p> May 04 , 2017 <p> Brought to you by <p> A circuit breaker is any device that automatically opens a circuit to stop current flow when a predetermined overload current is detected . It does this without damage to itself so that it can be reset once current returns to normal. - Overload current can occur for many reasons , but it is potentially dangerous to personnel and equipment . <p> Download this resource from Carling Technologies to learn about circuit-breaker types , advanced circuit-breaker applications and choosing the right circuit breaker . 
@@21004600 @1004600/ <h> The Impact of File Systems on the Life Expectancy of Solid State Storage <p> Sponsored by Datalight <p> Dec 05 , 2016 <p> Brought to you by <p> The endurance of solid state storage is a major factor in many embedded designs . Flash media wears out over time , and while that may be okay for some consumer products , it is unacceptable for devices used in industries such as medical , industrial or mil/aero . Download this whitepaper for a detailed comparison of flash media performance , when using Linux file systems , compared to- Datalight 's Reliance Nitro. 
@@21004601 @1004601/ <p> Wearable technology for personal health monitoring is the wave of the future and potentially very big business . Every day , there 's a new wrist band or smart watch capable of monitoring heartbeat , workout activity ( stand , move , and exercise ) , calories , - heart- rate , sleep patterns , and more . In this article , we will look at the technology behind heart-rate monitoring ( Fig. 1 ) , its challenges , and ways to reduce power consumption , thereby extending the useful life of the wearable device between recharges . <p> Every Microampere Counts <p> A 200-mAh smartwatch battery must typically support one day of usage or two weeks of standby- time between recharges , with daily usage roughly defined as four hours of active operation in a 24-hour cycle . The corresponding daily allowance for the smartwatch 's electronics ( microprocessor , memory , sensors , display , and power management ) is 50 mA . Accordingly , a typical operational amplifier absorbing 1.5 mA will claim a full 3% of the available current , corresponding to seven minutes @ @ @ @ @ @ @ @ @ @ <p> Heart-Rate Monitoring <p> Sensing your heartbeat by touching your pulse is pretty easy . The blood is pumped impulsively by the heart at the rate of roughly once per second ( 1 Hz ) . A contraction of the heart muscle corresponds to a flow " a volume of blood pushed through your arteries " and a relaxation of the muscle corresponds to an ebb . <p> As your heart beats , arteries expand in response to the incoming blood flow and contract between heartbeats . Your pulse is thus sensed and verifies that you are alive . What is more difficult to determine , though , is your heart rate . This is where wearables , in the form of wrist bands and smartwatches , come into play . <p> PPG <p> Reflective photoplethysmography ( PPG ) is a technique that uses light pulses to measure heart rate by sensing volume variations in the blood flow resulting from the heart 's pumping action ( Fig. 2 ) . Green light produces the largest modulation depth in flowing blood , with maximum absorption at flows and minimum at ebbs @ @ @ @ @ @ @ @ @ @ PPG green LED emits a short light pulse that penetrates the skin and is reflected back . The portion of the light reflected by the blood is modulated by its ebbs and flows , and detected by a photodetector as an ac signal at the frequency of the heartbeat . Static portions of the targeted area reflect light as well , detected as a dc signal that will be subsequently discarded by the signal processing . <p> Signal Amplification <p> The current signal produced by the photodiode in response to light from the green LED is typically processed by the heart-rate monitor 's analog-front-end ( AFE ) circuit . At the core of the AFE is a low-power operational amplifier . The op-amp transimpedance configuration ( Fig. 3 ) amplifies the photodiode ( PD ) current I by a factor R , yielding an output voltage VOUT = I*R. - The capacitor C implements a lowpass filter of time constant RC that let 's the low-frequency heart-rate signal pass , but filters out any higher-frequency noise . <p> 3 . The op-amp transimpedance configuration amplifies the photodiode ( PD ) current @ @ @ @ @ @ @ @ @ @ VOUT = I*R . <p> - <p> The Ideal Amplifier for Heart Monitoring <p> The ideal amplifier for this application would combine high speed , low power , precision , and low-input current noise . The MAX44260 , developed by Maxim Integrated , combines features to fit this need . Delivering 15-MHz bandwidth with only 750--A supply current , the MAX44260 offers high efficiency in terms of megahertz per microamp while consuming little power ( 50% less than comparable devices , according to Maxim ) . Its 1.2-fA/GHz current noise density helps minimize current-to-voltage conversion error . <p> Thanks to its shutdown pin , it 's possible to keep the device alive only when needed , which adds to the power savings . Operation down to 1.8 V also saves power , and becomes an important feature as more portable and low-power systems move to lower voltage rails . <p> Signal-Processing Advantages <p> The MAX44260 's design inherently boosts immunity from RF signals present in wearable devices . Its low input bias current ( 0.01 pA typical at ambient temperature ) becomes critical when measuring high-impedance sensors or photodiodes in @ @ @ @ @ @ @ @ @ @ the sensor reading . In addition , the combination of low voltage offset and low noise can be beneficial when driving either a standalone analog-to-digital converter ( ADC ) or one that 's integrated inside a microcontroller ( Fig 4 ) . <p> 4 . The combination of low voltage offset and low noise lends itself well to driving either a standalone analog-to-digital converter ( ADC ) or one that+ ? ? s integrated inside a microcontroller . <p> - <p> Conclusion <p> It 's clear how important it is to minimize power dissipation , input bias current , and input noise while maximizing bandwidth and RF immunity for the op amp in a heart-rate monitor 's AFE circuit . To that end , the MAX44260 1.8-V , 15-MHz , rail-to-rail op amp can help meet those goals for today 's wearable healthcare monitoring applications . <p> Nazzareno ( Reno ) Rossetti is a seasoned analog and power-management professional , a published author , and holds several patents in this field . He holds a doctorate in electrical engineering from Politecnico di Torino , Italy . <p> Steve Logan is @ @ @ @ @ @ @ @ @ @ . Steve joined Maxim in 2013 and has over 15 years of industry experience , both in business management and applications roles . Steve graduated from San Jose State University with a Bachelor of Science in electrical engineering . 
@@21004603 @1004603/ <h> Wireless Communications : The Lure Of Wireless Is Irresistible <p> Numerous wireless technologies abound to tackle virtually any chore . <p> Louis E. Frenzel Sep 29 , 2002 <p> Connectivity . Staying in touch . That 's what it 's all about , and it 's addictive . Today , the cell-phone business is a giant , driven by the security-blanket need to always have a phone available , coupled with that instant gratification from contacting someone immediately . Wireless technology makes it possible to conduct business on the road or reach someone in an emergency . <p> But cell phones are only one piece of the wireless connection revolution . Today , it also covers e-mail and the Internet . Even though we still talk endlessly on the phone , we also e-mail our brains out . In only one decade , e-mail has gone from a tiny niche to the primary way that we communicate in business . E-mail is mostly a wired kind of connectivity , but thanks to wireless technology , you can now e-mail to your heart 's content from your laptop , @ @ @ @ @ @ @ @ @ @ communicating society or what ? <p> But there 's more . Wireless is working its way into virtually every aspect of our business and home life . Wireless PC and peripheral connections , wireless headsets , and wireless local-area network ( LAN ) connections are the norm . Home networking is no longer just for the wealthy . It 's becoming a necessity for us all as we share our PC resources , connect our entertainment equipment , and monitor and control our home functions " with no wires at all . <p> Wireless clearly dominates electronics today unlike any other killer app . More is going on in wireless than in any other electronic segment , and it 's affecting virtually all markets , including enterprise , consumer , and industrial . <p> Cell Phones Rule Wireless : While cell-phone sales have been down during the past two years , the volume still hovers around 400 million handsets per year , and projections for the future are very positive ( Fig. 1 ) . Driving this recovery is the industry 's goal of 3G systems that will bring high-speed @ @ @ @ @ @ @ @ @ @ to our handsets . But high costs , lack of viable applications , technological issues , and lack of spectrum have slowed this development . Real 3G systems using ITU 's IMT-2000 UMTS W-CDMA are n't expected in any volume until 2004 , if then . <p> Meanwhile , the industry is focusing on interim 2.5G systems that add digital data capability to present-day TDMA/GSM and CDMA digital systems . Carriers like AT&amp;T Wireless and Cingular are rolling out GSM systems that include the flexible data transmission capability called GPRS with data rates of up to about 56 kbits/s . <p> Sprint has announced its next-generation system using Qualcomm 's cdma2000 technology . Sprint calls it 3G , thanks to the ITU 's rather loose definition of 3G . The cdma2000 1XRTT version 's speed potential is up to 144 kbits/s . GSM/GPRS systems are expected to achieve rates as high as 384 kbits/s by adopting EDGE via the GSM/GPRS framework with 8PSK modulation . Qualcomm 's EV-DO technology gets you real 3G with cdma2000 up to 2.4 Gbits/s . <p> One expensive complication for 2.5G and 3G phones is @ @ @ @ @ @ @ @ @ @ systems that will accurately tell where every cell-phone user is located within 100 yards of accuracy . EOTD triangulation systems or GPS-based systems should solve the problem . <p> Finally , the growing complexity of the baseband chips in 2.5G and 3G phones has put more than average pressure on designers to reduce power consumption . Innovative power-management chips and battery technology like the new , small fuel cells are helping to achieve the long standby and talk times demanded by users . <p> When will we implement UMTS W-CDMA 3G ? It 's anyone 's guess , as carriers try to find data applications and services to support such a massive build-out . With all the 3G delays and 2.5G successes , you must wonder if we should n't just skip 3G and go directly to the proposed OFDM-based 4G systems with full software-defined radios . <p> Wireless LANs ... And PANs : Wireless local area networks ( WLANs ) are by far the fastest growing wireless segment . While the triple-digit percentage increases of the past two years have quickly gone away , WLANs have been a bright @ @ @ @ @ @ @ @ @ @ and flexibility in a LAN is well known . But it took a widely accepted Ethernet standard ( IEEE 802.11b ) and a tough interoperability certification program ( Wi-Fi ) to make it successful . Now 802.11b WLAN connections , which are common in enterprise offices , dominate home networking and implement wireless Internet access points . <p> The 802.11b standard specifies DSSS in the 2.4-GHz ISM band to achieve a data rate of up to 11 Mbits/s at distances up to about 100 meters , indoors and out . The newer 802.11a radio modems giving up to 54 Mbits/s in the 5-GHz band use OFDM , so they are very robust in noisy and multipath environments . But the range is limited to about 100 feet . <p> Earlier this year , the IEEE standards committee approved the 802.11g standard , which provides a speed upgrade path to 54 Mbits/s for the 802.11b modems in the 2.4-GHz band . Numerous vendors have already announced multiband , multimode chips combining 802.11a/b and 802.11a/b/g . <p> Right now , the main issue in wireless Ethernet is security . The 802.11b standard @ @ @ @ @ @ @ @ @ @ many who use WLANs either do n't know that it 's available or fail to enable it . The IEEE standards groups and some vendors have been working on increased security measures for both wired and wireless Ethernet . <p> An unexpected application of 802.11b has been the establishment of wireless access points for e-mail and the Internet . These so-called " hot spots " are being installed in airports , hotels , restaurants , and other places where laptops are most likely to be deployed . Even cell-phone carriers are looking at 802.11b as an alternative or complement to 2.5G and 3G cell-phone data access . <p> In another unexpected effort , some enterprising companies are even building mesh networks of 802.11b transceivers as a way to supply high-speed broadband access to rural communities with no DSL or cable-TV modem service . Internet service is being provided to subscribers within a 12-mile radius . <p> Wireless Potpourri : Four other wireless technologies are making great progress : Bluetooth , ZigBee , UWB , and RFID . Even short-range infrared ( IrDA ) still exists . With a stable standard @ @ @ @ @ @ @ @ @ @ arrived . The most popular applications are wireless cell-phone headsets ; links between cell phones , PDAs , and laptops ; and wireless PC peripheral connections . The rumored 3-Mbit/s Bluetooth is expected to even further broaden its reach . <p> ZigBee is a newer technology that like Bluetooth uses the 2.4-GHz ISM band . Designed for greater simplicity , lower power , and lower speed over longer distances than Bluetooth , ZigBee is finding its way into toys , home control , and industrial telemetry and control . <p> UWB is the esoteric wireless microwave technology that transmits data without a carrier in the form of very short pulses , which produce an extremely wideband signal . A spread-spectrum-like signal results , which is very secure and robust in multipath and noisy environments . Thanks to advances in semiconductor technology and the FCC 's recent approval of low-power UWB in the 3.1- to 10.6-GHz band , considerable effort is under way to develop fast ( over 100-Mbit/s ) WLAN chips and high-resolution , short-range radar for collision avoidance . <p> Figure 2 positions all the wireless technologies relative to @ @ @ @ @ @ @ @ @ @ 's something for everyone . <p> Looking Ahead : What 's next in wireless connectivity ? As always , higher speed is the ultimate goal . But new services are in the works too . Cell phones are going to see the location services activated to our benefit . E-mail and instant messaging will grow more popular with PDA/cell-phone combos . No doubt we will enjoy sending and receiving still digital photos , but not video . <p> At home , get ready for the wireless blitz . Soon we will have satellite as well as terrestrial digital radio broadcasts . HDTV is on the horizon . The problem of trying to connect multiple TV sets to a single set-top box and cable connection will be solved as UWB wireless links allow us to freely stream video . Wireless connections between DVDs , PVRs , MP3 players , and even speakers will become commonplace . <p> In WLANs , we will see more enterprise wireless at increasing speeds . Bluetooth connections , from laptops and PDA to PCs , will be standard as will wireless mice and keyboards . <p> @ @ @ @ @ @ @ @ @ @ the freedom of wireless , you can never go back . 
@@21004604 @1004604/ <p> Sensors have made serious inroads into automotive , medical , industrial , and aerospace applications . But you ai n't seen nothin ' yet . Rising concerns for safety , convenience , entertainment , and efficiency factors , coupled with worldwide government mandates , will see sensor usage swell to unprecedented levels . <p> Add to that the predicted explosion in wireless and consumer applications , and one can see why sensor manufacturers anticipate quickly developing huge markets and applications through the end of this decade . Most of these sensors will be of the **29;27;TOOLONG ( MEMS ) and microsystem-technology ( MST ) type , with nanosensors showing great promise . <p> Mention automotive systems , and sensor manufacturers can easily see a host of sensing possibilities for measuring not only pressure , but also inertia , position , proximity , temperature , flow rate , force , strain , torque , vibration , and tilt . And the sensing technologies used to measure these parameters are just as varied ( see " The Business Of Sensors , " Drill Deeper 8325 at www.elecdesign.com ) . According @ @ @ @ @ @ @ @ @ @ Motors Technology Center ( www.gm.com ) , " sensing needs for automobiles are growing by leaps and bounds . " He cited several growth areas for chassis controls , vehicle positioning/location , object detection , vision enhancement , auto environment heating , ventilation , and air conditioning , as well as engine and transmission controls . Vehicle stability enhancement was just one of the many examples he cited . <p> A recent U.S. National Highway Transportation Administration ( NHTSA ) proposal for side-impact airbags would add two to six sensors to every automobile . Even though the proposal does n't mandate their use , U.S. , European , and Japanese auto manufacturers indicated that they would supply side-impact airbags in all of their vehicles by the end of this decade for safety reasons . Some automotive suppliers like TRW ( www.trw.com ) and Delphi ( www.delphi.com ) use a combination of accelerometer and pressure sensors ( the latter having a faster response than accelerometers ) in side-impact airbags . <p> Inertial sensing in cars has become another hot topic . In fact , Motorola ( www.motorola.com ) and Analog Devices @ @ @ @ @ @ @ @ @ @ clusters to manage the vast number of sensing functions that will be required for vehicle dynamics , navigation , safety , and steer-by-wire applications ( Fig. 1 ) . <p> " The interaction between anti-lock braking , electronic brake-force distribution , traction control , and active yaw control systems allows the achievement of dynamic stability in an automobile , " says Harvey Weinberg , a senior applications engineer for Analog Devices . Motorola 's John P. Schuster adds that " the modular approach allows multiple applications to be supported by using a core platform . It builds on aerospace gyro applications that can be adapted for automotive applications at a lower cost and smaller size . " <p> OPTICAL SENSING IS IN One novel approach developed by Optrand ( www.optrand.com ) to measure engine pressure involves a multifunctional device that combines a fiber-optic-based pressure sensor with the glow plug used in passenger diesel engines . The PressureSense glow plug , comprising a sensing head , a fiber-optic cable , and signal-conditioning electronics , offers a total accuracy of 62% against a water-cooled reference transducer at pressures above 5 bar and @ @ @ @ @ @ @ @ @ @ . The company foresees the first use of this device by 2007 . <p> Honeywell ( www.honeywell.com ) proposes the use of optical sensing for a low-cost passive keyless entry system , parts of which can be embedded within a car 's door handle . The sensor would consist of a key-like optical enclosure that houses a transceiver . To gain entry , the vehicle owner places the key-like enclosure between the door handle and the car 's body . <p> Hall effect sensors will find homes in a vast range of automotive functions , including sensing throttle and brake pedal position , camshaft position and speed , barometric air pressure , and manifold absolute pressure ( MAP ) . According to Infineon Technologies AG ( www.infineon.com ) applications engineer Werner Roessler , active Hall effect sensors can be put to use in power-train control and cam and crankshaft applications . " This provides more accuracy , better startup strategies , and the ability to detect a crankshaft 's starting point position , versus a passive sensor approach , " he says . Another advocate of the Hall effect sensor @ @ @ @ @ @ @ @ @ @ this technology for contactless position sensing . <p> A NEW SENSING PARADIGM Electric field or E-field sensing uses electrodes and the electric field between them . It 's another option for sensors in airbags and other applications , according to Freescale Semiconductor . <p> " This method of sensing makes for a smarter airbag , in which the bag will not deploy prematurely , by taking into consideration not only the passenger 's head position ( i.e. , has it moved or not ? ) , but also the passenger 's size and weight , " says Don Laybourn , applications engineer for Freescale . <p> Such sensors can be set up on steering wheels with electrodes around the rim and other points , allowing them to determine when a wheel is released ( such as when a driver falls asleep or suffers a disabling medical condition ) , which will then produce a warning signal . This method can also be used to gently bring the vehicle to a halt . <p> Seat electrodes in a vehicle could also apply the brakes through the anti-lock braking system if it @ @ @ @ @ @ @ @ @ @ seat if a vehicle is moving . This would prevent runaway conditions , such as when a car is parked on a slope . Car-window rain and frost sensing is yet another application . <p> Another huge arena for sensors is the wireless sector . Wireless sensors grab a $500 million share of the current $40 billion sensor market , says MEMS pioneer Janusz Bryzek ( email protected ) , who is also managing partner of BN Ventures , a venture capital firm . By the end of the decade , that number should climb to over $10 billion . <p> Bryzek notes that only a small fraction of these wireless sensors operates from a battery . Yet given present wireless standards activities , there 's a growing need for wireless sensors that can operate from battery voltages of 2 to 3.6 V. On the other hand , power consumption must be minimized , which is not an easy task for wireless sensing systems . <p> One of the hottest areas in the world of wireless sensors is automotive tire-pressure monitoring systems ( TPMSs ) , with government mandates in @ @ @ @ @ @ @ @ @ @ monitoring systems are indirect yet low in cost . but the more expensive direct tire-pressure monitoring method " where every tire has a sensor and transceiver " is favored by many sensor and automotive subsystem OEMs . Of course , such systems require batteries to operate . Battery-less direct systems have been developed , but they 've yet to be proven in the field . <p> According to Dirk Leman , TPMS product manager for Melexis , the direct method will likely prevail , being phased in over the next few years . He notes that " battery-based technology is here to stay for some more years , and passive technologies are mature enough to penetrate niche applications in the near future . However , for a Tier 1 supplier implementing passive technologies , the road map , business model , and leveraging of existing competencies are at least as important as the individual product cost when selecting a single technology . " <p> In the long run , he cautions that intelligent indirect technologies may generate a bigger growth potential for MEMS sensors than direct TPMSs . That 's @ @ @ @ @ @ @ @ @ @ to pressure monitoring . <p> Medical applications are numerous . The potential for wireless sensing also extends to the medical field , where wearable electronics will make a huge impact on remote patient bio-monitoring and bio-chemical detection . For instance , wireless strain gauge sensors can be used to measure in-vivo total knee-replacement joint loads in humans . According to Steven Arms , president of Microstrain Inc. ( www.microstrain.com ) , " We 've shown that this can be done in a collaborative project with the Scripps Institute ( www.scripps.edu ) and Johnson &amp; Johnson ( www.jnj.com ) . " <p> In another development , Microstrain and the Department of Veterinary Medicine at the University of Wisconsin in Madison ( www.wisconsin.edu ) measured bone plate growth in-vivo in lambs . The company also performed in-vivo vertebral spine bone strains in humans in collaboration with the Department of Orthopedics at the University of Arizona ( www.arizona.edu ) and re-animated paralyzed human limbs in a cooperative project with the Bioengineering Deptartment of Case Western University ( www.cwru.edu ) using control systems based on strain gauges . <p> The plain magnet is still @ @ @ @ @ @ @ @ @ @ , to hold together large broken bones more accurately and safely in humans . Present methods use X-rays and a surgeon 's skill to do this , but it 's more costly , less safe , and less accurate and takes a longer time . So in a joint project with Virginia Tech ( www.vt.edu ) , the University of Virginia ( www.virginia.edu ) , the Carilion Biomedical Institute ( **27;58;TOOLONG ) , and Carilion Health Systems ( www.carilion.com ) , Triad Semiconductor ( www.triadsemi.com ) developed intramed-ullary nails ( IMNs ) that allow orthopedic surgeons to safely , quickly , and accurately hold broken bones together . The group 's prototype magnetic targeter system uses a target magnet on a wand within the IMN and an LED display ( Fig. 2 ) . <p> Sensors of all types will also find uses in many industrial applications for monitoring the health of rotating machines and motors and to track the health of our nation 's infrastructure . Radatec ( www.radatec.com ) reports on a microwave-based proximity/displacement sensor that allows the monitoring of machinery in extremely harsh environments at high rotating @ @ @ @ @ @ @ @ @ @ applications from Microstrain are also being used to keep track of the structural integrity of bridges , tunnels , highway overpasses , buildings , and other civil structures . Their EmbedSense strain-gauge-based wireless-transmission modules provide low-power , battery-operated sensing nodes at high data-acquisition rates required by civil authorities . Scalable arrays of passive strain gauge sensors can be interrogated remotely . Switched-reactance methods eliminate many components such as the RF oscillator , crystals , and feed-through antennas . <p> USHERING IN NANO Nanotechnology will no doubt play an important role in sensing . At last month 's Sensors Expo , held in Detroit , Mich. , Dean Aslam , associate director at Michigan State University ( www.egr.msu.edu ) , presented " multi-walled carbon nanotubes " ( CNTs ) , which were grown to form a preconcentrator section of a micro gas chromatograph for sensing chemicals . Featuring wall layers ranging from 5 to 30 -m and lengths up to 500 -m , the CNTs offer an ultra-high surface area and low energy consumption , as well as superior adsorption/desorption characteristics compared to other known materials . The work was supported @ @ @ @ @ @ @ @ @ @ Foundation ( NSF ) and is part of the research work being performed at the University of Michigan 's Center for Wireless Integrated Microsystems ( WIMS ) . <p> No matter what type of nano-device emerges , nanotechnology itself needs lots more research and must be mastered before it can be realized . Professor Ahmed Busnaina , a leading nanotechnology researcher at Northeastern University ( www.northeastern.edu ) and a keynote speaker at Sensors Expo , holds this opinion . He says the industry needs to develop nanotemplates as nanomanufacturing tools for nanodevices and sensors as a bare minimum before the technology can flourish . 
@@21004606 @1004606/ <p> Simply put , 3D printing is poised to radically change the world you live in . While the technology has been around since the 80s , only in the last few years , with technology advances and dropping prices , has it caught the attention of most people . Today , 3D printing is rapidly evolving with new players entering the field , more patents expiring , new technologies ( e.g. , CLIP and Multi-Jet Fusion ) being developed , and supporting software catching up . It 's estimated that the market will grow to $20 billion by 2025 . <p> Over 30 years ago , two major companies invented the major technological components of 3D printing , and they 're still the dominant technologies currently in the market. - In terms of 3D printing of object , three processes have become popular . <p> The first is called fused deposition modeling ( FDM ) . It uses a thermoplastic filament , which is heated to its melting point and then extruded , layer by layer , to create a three-dimensional object . This rather slow process supports @ @ @ @ @ @ @ @ @ @ PLA ) types of materials . <p> The second process is called selective laser sintering ( SLS ) . With this method , tiny particles of plastic , ceramic , glass , and metals are fused together by heat from a high-power laser to form a solid , three-dimensional object . SLS is a faster process than FDM and supports a larger variety of materials , such as polymers ( commonly known as nylon ) , and polystyrene ( a steel , titanium , and alloy mix ) . <p> The third process is called stereolithography ( SLA ) . Here , excess plastic liquid is cured and hardened to form a solid , three-dimensional object . A faster process than FDM , SLA supports photopolymer materials that differ in how the layers are built . <p> All of these technologies are quite mature . However , the speed issue has been a barrier for companies ranging from consumer goods to big machinery manufacturers and large industrial players looking to adopt 3D printing in their processes . For instance , with FDM technology , 3D-printing speed is between 50 to @ @ @ @ @ @ @ @ @ @ up to 48 mm per hour , and SLA reaches 14 mm/h . A study was conducted regarding the printing of a 51-mm-diameter complex object , and results showed that the printing took 11 hours with SLA and three hours with SLS . Such speeds can not live up to the expectation of replacing the assembly line in a factory . <p> Beyond the Big Three <p> However , the landscape for 3D printing is quickly changing . For instance , companies are beginning to invest in the continuous liquid interface process ( CLIP ) - that uses- photo polymerization- to create smooth-sided solid objects of a wide variety of shapes to increase speed and accuracy of the 3D-printing process . And while 3D printing has been widely adopted in product prototyping , with just a CAD file , it 's much faster and less costly to put design ideas into tangible product. - With 3D printing , there 's no need to have different molds or tooling for each revision of the design , enabling much faster iterations during the design phase . <p> Take a look at how @ @ @ @ @ @ @ @ @ @ been utilizing this technology to advance their competitive edge . <p> Remote and on-demand manufacturing feature of 3D printing helps to digitalize and disrupt the supply chain . With the easy setup of 3D printers and stored digital print , businesses that have to operate in remote locations , where it may take a very long time to deliver the broken parts , may significantly benefit from the ability to manufacture the spare parts with 3D printing . This approach eliminates the inventory cost for storing expensive spare parts and avoids revenue loss when the machinery goes down. - <p> Businesses that are required to store up spare parts for their machines and appliances for many years can instead print the spare parts , which helps minimize production and warehouse cost . Manufacturers also eliminate the shipping cost by localizing the production . With 3D printing , manufacturers can lean-produce according to demand , as needed , and despite a higher per-part cost , the supply chain is highly simplified . <p> Complex geometry also is possible with 3D printing , which is n't the case with traditional injection molding @ @ @ @ @ @ @ @ @ @ Companies developing design software have been working to provide automatic design optimization for 3D printing to achieve design advantages made only feasible by additive manufacturing . With this great feature , aerospace and automotive has been exploring how to combine parts to reduce the cost and complexity of assembly , reduce the weight , and further lower energy costs by using lighter materials and increasing the heat dissipation . <p> Expanding Applications <p> Perhaps the greatest advances in 3D printing have been delivered in the important role of mass customization and production in the medical field . Products such as Invisalign would be absolutely impossible without the help of 3D printing . <p> We have already seen 3D-printed human organs in study environments and medical instruments such as personalized prosthetics for amputees . Customized auditory implants are also great candidates for 3D printing . <p> On top of that , 3D-printed miniaturized bio-robots have shown the ability to find their way through a human body to carry out repair jobs on a target organ or deposit medicinal drugs . At Harvard , nano-robots containing DNA strands have been printed . @ @ @ @ @ @ @ @ @ @ cancer cells , releasing specially calibrated antibodies to destroy these target cells . We expect the biology and life sciences industry to experience radical transformation through all of these findings . <p> There are still some obvious limitations or obstacles of 3D printing . With its price and speed , it 's still hard to justify it replacing traditional manufacturing in terms of mass production. - With the additive manufacturing 's layer-by-layer feature , post-processes are required to achieve the same mechanical properties and product quality . Legally , ambiguity still exists in regards to who will take the legal responsibility of a malfunctioned product . The intellectual-property protection also raises certain concerns . Even with these setbacks , technically , the possibilities of 3D printing are infinite and will no doubt keep opening the door to new products in a variety of applications . <p> Ping Guo is an R&amp;D Associate Manager at Accenture Technology Labs on the Digital Experience Team . Ping holds a B.S. and M.S. in computer science from Rensselaer Polytechnic Institute . Her research area is digital operations , with a focus on 3D printing and wearables. 
@@21004608 @1004608/ <p> A high-frequency matrix converter built by researchers from the University of Arkansas can simultaneously accept energy from several different sources , including solar panels , and convert it for use in the electrical grid . ( Image courtesy of Martin Abegglen , Flickr ) . <p> As the energy industry shifts toward- renewables , engineers are looking to improve systems that feed- energy from- solar and wind farms to the electric- grid . Researchers- at the University of Arkansas have made some progress , inventing- a high-frequency matrix converter to simplify- the process of turning renewable energy- into electricity . <p> The main feature of the system is the ability to simultaneously accept energy from a variety of sources , including solar panels and wind turbines , and convert it for use in the electrical grid . This sets it apart from current technologies , which are only able to convert electrical input from a single source without sacrificing efficiency . <p> Because different harvesting methods produce varying levels of direct current , researchers Joseph Carr and Juan Balda invented a system that could consolidate these inputs into @ @ @ @ @ @ @ @ @ @ , the system converts energy from different sources without the use of specialized transformers . <p> The system could be used- to replace the large transformers currently used in renewable energy networks . Furthermore , it could- provide a simplified alternative to the current multiphase system , reducing the costs of development and maintenance. - The U.S. Department of Energy pursued and was granted a patent- for the technology at the end of March . It is now seeking licensing opportunities for the new power converter . 
@@21004609 @1004609/ <p> The Donald Trump administration is mulling over a broad review of the H-1B visa program that let 's thousands of foreign engineers and computer scientists work in the United States , according to a draft of an executive order leaked to several news organizations . <p> This year , around 85,000 foreign nationals were granted H-1B visas , which enable them to temporarily live and work in the United States at the company that applied for the visa . Technology and semiconductor companies use H-1B visas to fill entry-level jobs and hire international college graduates . <p> But critics , including some electrical engineers and small businesses , say the program has a dark underbelly . They say that aspects of the H-1B program choke off jobs for American engineers and that the visas allow large corporations to save money by outsourcing jobs to imported workers . The random lottery drawing for H-1B visas is also contentious . <p> If signed , the draft order would launch an investigation into " the extent of any injury to U.S. workers caused by the employment in the United States of foreign @ @ @ @ @ @ @ @ @ @ the H-1B and the L-1 visa for employees that have worked in a foreign branch of a company and request transfer to the U.S. <p> A final report would be due 18 months after the order is signed . <p> The draft lacks specific alterations to the H-1B program , but the Department of Labor review would seek ways to make the application process more efficient and benefit only " the best and brightest , " a phrase that H-1B critics have used for years to highlight the workers that the program is ignoring . <p> The status of the executive order is unclear . Written by Andrew Bremberg , the director of the Domestic Policy Council , the leaked document could be anything from a rough draft to the final version . A future version could be vastly different . <p> Trump criticized the H-1B program during his presidential campaign and has folded opponents of the program into its cabinet . At one point that he invited former Disney workers who lost their jobs to H-1B replacements to speak at a Florida rally . Jeff Sessions , Trumps nominee @ @ @ @ @ @ @ @ @ @ visas for years . <p> But the fact that the draft wants to start with a review of the visa program could mean that Trump intends to keep the program running . If signed , the executive order would follow Trumps immigration ban on countries including Iran and Syria . Google and Microsoft , which both hire H-1B workers from those countries , were two of the highest profile companies to speak out against that ban . <p> In electrical engineering , the H-1B program has a spotted history . In a 2013 Electronic Design survey , 19% of respondents said their companies used the H-1B visa program , but many were concerned about the visa 's negative impact . Though only 9% felt personally threatened by the program , over 40% said that it cut into American engineering jobs . <p> That has been the refrain among the programs critics . Many proposed changes targets how outsourcing companies , which exploit H-1B visas to import workers for entry-level technology jobs , operate . <p> The IEEE-USA , a leading American trade group for electrical engineers , has urged giving @ @ @ @ @ @ @ @ @ @ experienced engineers . Zoe Lofgren , a California Democratic representative , proposed a bill last month that would favor visas for higher paying jobs . Under her bill , a fifth of the H-1B slots would be reserved for small businesses . <p> " My legislation refocuses the H-1B program to its original intent to seek out and find the best and brightest from around the world , and to supplement the U.S. workforce with talented , highly-paid , and highly-skilled workers who help create jobs here in America , not replace them , " said Lofgren in a statement . <p> Lawmakers have also presented H-1B bills in Congress . Last month , Chuck Grassley , a Republication Senator from Iowa , and Dick Durbin , a Democratic Senator from Illinois , reintroduced a bill to prioritize H-1B applicants with advanced degrees and high-paying job offers . They first proposed the legislation in 2007 . <p> " Congress created these programs to complement Americas high-skilled workforce , not replace it , " Grassley said in a statement . The law would also require companies to make a " good faith " effort to hire American workers first . 
@@21004614 @1004614/ <p> U.S. technology companies often design products in the United States and then manufacture and sell those products overseas . In the semiconductor and integrated-circuits arena , in particular , companies frequently design chips and components in technology hubs like Silicon Valley , and then manufacture and sell them overseas to end-product manufacturers who incorporate them into consumer products like phones , tablets , and computers . <p> One area in which this business model can clash with U.S. law is in the field of patents . As explained in this article , chief technology officers and others on the design and product documentation side can play a key role in mitigating the risk of patent infringement should some of those consumer end products eventually be imported into the United States . <p> Justin A. Hendrix , Associate , Finnegan , Henderson , Farabow , Garrett <p> Whether a company may be liable for patent infringement based on products manufactured overseas hinges on what happens post-manufacture . If the company imports the product into the U.S. , it could be liable for direct infringement . On the other hand @ @ @ @ @ @ @ @ @ @ remains there , there 's no infringement . That 's because , under U.S. patent law , infringement occurs only when someone , without permission from the patent owner , makes , uses , offers to sell , sells , or imports the patented invention within the United States.1 <p> A more difficult scenario arises when , as is frequently the case with ICs and components , the product is sold to an end-product manufacturer overseas and it 's incorporated into a consumer product that 's then imported into the United States . The design company may not be liable for direct infringement because sale of the IC or component occurred overseas . But it could be liable for indirect infringement , namely , inducing the end-product manufacturer to infringe . <p> Induced Infringement <p> Under a theory of induced infringement , a tech company that sells products overseas could be liable for U.S. patent infringement where , for example , an end-product manufacturer imports the company 's product into the United States and directly infringes a U.S. patent . To be liable for the end-product manufacturer 's infringement under @ @ @ @ @ @ @ @ @ @ of the patent , known that its actions would result in infringement , and have intended to cause the infringement.2 <p> When litigated in court , the dispute often centers on the intent requirement ; namely , whether the tech company intended for the infringement to occur . Rarely will one find a smoking gun that shows a company 's intent to infringe . <p> Patent owners asserting infringement , therefore , often look to circumstantial evidence of intent that might exist in items such as datasheets , user manuals , and product guides . Even if a tech company believes it did not intend to infringe , if the product documentation suggests otherwise , there may still be a finding of induced infringement . By considering recent examples in which tech companies faced this situation , CTOs and others responsible for product design and documentation can be mindful of ways to mitigate the risk of liability for induced infringement if third parties import the company 's overseas products into the United States . <p> Technical Documents/Support as Proof of Intent to Induce Infringement <p> In a case involving LED @ @ @ @ @ @ @ @ @ @ documentation for the products showed intent to induce infringement in the United States.3 The drivers provided functionality for , among other things , LED backlighting in devices such as phones . According to the patent owner , the supplier for the LED drivers , Kinetic Technologies , induced Samsung to infringe by providing Samsung with the LED drivers that were incorporated into phones manufactured overseas and then later sold in the United States . <p> In evaluating whether Kinetic Technologies intended Samsung to infringe , and was therefore liable for the infringement , the court looked to product datasheets and the technical support Kinetic offered Samsung . The court found that the datasheets did not show intent to induce infringement because , first , they did not show any encouragement or desire for Samsung to import its phones into the United States . Second , the court explained that the datasheets did not contain instructions on how to use the accused products in an infringing manner . <p> Regarding the technical support that Kinetic had provided to Samsung , the court found that the support was not specifically directed to @ @ @ @ @ @ @ @ @ @ the datasheets nor the technical support provided a sufficient link between the LED drivers and Samsung 's alleged infringement to conclude that Kinetic intended for Samsung to infringe. - - <p> In a case involving cache management , the court similarly found that product manuals , datasheets , and product instructions did not show intent to induce infringement.4 There , the patent owner had accused Intel of inducing its customers to infringe by selling them processors that were designed with mechanisms for cache coherence . When a product can be used both in an infringing way and a non-infringing way , the court explained , the evidence showing that the accused party teaches the infringing use would show intent . <p> Although the technical documents described how Intel 's processors worked , the court found those documents did not teach customers how to use the processors in an infringing manner . Further , the court explained , the documents did not recommend , encourage , or promote using the processors in an infringing manner . Simply describing the processor 's functionality , the court concluded , is not enough to @ @ @ @ @ @ @ @ @ @ Supply Chain as Proof of Intent to Induce Infringement <p> Whether a company intends to induce infringement may also hinge on whether it knew products that it initially sold overseas were later imported into the United States . At issue in one recent case was a global supply chain involving lenses made by Genius Electronic Optical for use in digital cameras in smartphones and tablets.5 <p> As part of the supply chain , Genius sold lenses to module integrators overseas who incorporated the lenses into cameras . The module integrators then sold the cameras to system integrators overseas , who subsequently incorporated the cameras into phones and tablets . Apple and Motorola then sold the final products , including some in the United States . <p> Genius did not dispute that its lenses infringed the patents at issue , but argued that it had no insight into Apple 's and Motorola 's supply chains , and had no idea whether its lenses were incorporated into products that were later sold in the United States . Because the phones and tablets had more than one supplier for the lenses , for @ @ @ @ @ @ @ @ @ @ the United States . The court agreed . <p> As the court explained , because it was plausible that none of Genius ' lenses entered the United States , Genius could not have knowledge of infringement by any Apple and Motorola products in the United States , and thus could not have induced infringement . Further , the court explained , Genius was not willfully blind to whether its lenses entered the U.S. , which might have supported a finding of intent . <p> To show willful blindness , the court explained , Genius must have subjectively believed a high probability existed that its lenses entered the United States and must have taken deliberate actions to avoid learning the truth . But Genius was at best deliberately indifferent to whether its lenses entered the U.S. , the court concluded , and such indifference does not rise to the level of intent needed to induce infringement . <p> Takeaways <p> These cases provide examples of how to mitigate the risk of liability for induced infringement if you manufacture and sell your products overseas , but third parties eventually import some of @ @ @ @ @ @ @ @ @ @ reveal , merely describing the functionality of a product might not show intent to induce infringement . But if the companies had recommended or encouraged others to use the products in a certain way , or had promoted using the products in a certain way by touting the benefits and results of such use , a different result might have occurred . <p> If you do not need to recommend or promote using your products in a certain way , describing only the functionality of your product in the datasheets and product guides can help mitigate the risk of liability for induced infringement . In addition , as with the company in the last example , putting products into a supply chain overseas without knowledge of where those products are eventually sold might buffer you from liability for induced infringement . 
@@21004616 @1004616/ <h> Learn The Ins And Outs Of Probing Those Tricky Differential Signals <p> Differential signals are the wave of the future for high-speed , high-volume data transmissions . There 's no doubt about it . The prime focus of the convergence industries " television , personal computers , and communications " is not only to transmit more data at faster speeds , but to do it more accurately and more economically . As transmission speeds have increased , digital signal transition levels have correspondingly decreased , making signal integrity and clarity critical concerns . Also , in accordance with Moore 's Law , as computer microprocessor speeds continue to double every 18 months , the maximum rate at which ground-referenced signals can reliably transmit data is quickly approaching . <p> In order to limit the disturbance of signals and reduce power dissipation , more and more designs are turning to differential circuitry . This move to improved differential-signal technology for signal transmission , though , faces challenges " not only at the basic measurement levels , but at the **26;87;TOOLONG level as well . Designers of personal-computer architectures are @ @ @ @ @ @ @ @ @ @ . Rambus memory is a prime example , due to its differential clock and data lines . Digital signals are n't just " 1s " and " 0s " any longer . They behave like analog signals at RF and higher frequencies and require high-frequency analog measurement techniques . <p> Circuit designers and **27;115;TOOLONG designers both must invent and improve differential design and measurement techniques to allow technology to jump to the next performance level . The need to understand and use technology-breakthrough measurement tools and proper measurement techniques is of key importance . Many designers still use a pair of probes ( single-ended passive or active probes ) to measure differential signals . But this technique can be full of hazards , including rapid signal degradation , producing unreliable measurements . <p> So what 's the right way to measure differential signals ? We will examine a few key elements that , hopefully , will provide the insight and information required to help define or refine the type of differential measurements required by today 's circuitry . We 'll also try to identify the pitfalls as well as some @ @ @ @ @ @ @ @ @ @ from this differential world . <p> All voltage measurements are two-point measurements " therefore , they are inherently differential . The measurement is made between two nodes in the circuit . One node is at a potential while the other may be at ground reference or at an elevated voltage level . Single-ended signals are referenced to ground , while differential signals are the difference between two signal lines or test points , neither of which are at ground potential . Many of today 's signals fall into the category of true differential or pseudodifferential . These include common telephone lines ( balanced nongrounded ) , battery-powered communication equipment , battery-powered computational devices , disk-drive read-write channel signals , and RF communication ICs . <p> While today 's signals are becoming more differential in nature , the signal levels themselves are decreasing . Driven by applications that need to draw lower power , such as battery-powered products , this decrease in signal level can result in lower signal-to-noise ratios . And with a lower signal-to-noise ratio , there is a greater need for a measurement technique that can reject the @ @ @ @ @ @ @ @ @ @ amplifies the difference signal between its two inputs , rejecting signals common to both inputs . Having a high impedance from these two inputs to a common ground helps to eliminate ground loops and their associated problems . The measure of a differential amplifier 's ability to eliminate the undesirable common-mode signal is referred to as the common-mode rejection ratio , or CMRR . <p> CMRR can be degraded by a multitude of factors : amplifier mismatches , poor input connections , long lead lengths , incorrect ground connections , attenuation mismatches , changing source-impedance levels , and increases in signal frequency . The presence of one or more of these factors will degrade the performance of any differential-amplifier design to some extent . It also will determine the amount of common-mode signal that it will be able to reject . Figure 1 shows the effect of unequal source impedance on CMRR , while Figure 2 shows the common-mode error from a differential amplifier with a 10,000:1 CMRR . <p> So how do you limit the number of errors ? Here are a few methods for decreasing the amount of @ @ @ @ @ @ @ @ @ @ the measurement tool 's bandwidth is sufficient to capture the signal and the noise components , and that it has sufficient CMRR for the signals targeted for capture . Next , keep all signal interconnects to the device under test as short as possible to avoid parasitic inductance and capacitance . If you need to use extended leads , twist them several times to reduce the line pickup . Be careful , though , because this increases the capacitance and inductance to the probe 's input . For high-frequency measurements , make ground connections as short as possible ( yes , differential probes still have a ground connector ) . Remember , you may need to connect the differential probes to ground to prevent damage to the device under test . Finally , measure at test points where source-impedance changes are minimal . <p> Here 's a tip for estimating the CMRR error of nonsinusoidal signals : Connect both inputs to the measurement source . The scope will display the common-mode error . Unfortunately , though , this does n't catch any changes in source impedance at the two measurement @ @ @ @ @ @ @ @ @ @ requires one test point to be connected to the circuit ground or the circuit common . Using this technique can lead to ground loops , which increase signal degradation . The use of this technique also may increase device-under-test loading to the point of nonoperation . <p> But , there are situations where single-ended probing solutions may have to be considered . For instance , it may be the only solution available because of bandwidth requirements , or if the measurement solution must be cost-effective . Yet these needs are quickly disappearing with today 's improved differential solutions . <p> Many differential applications , such as disk-drive read-channel signals , Rambus clock signals , and RF amplifiers , are sometimes measured through single-ended techniques . Using a pair of passive or active single-ended probes that have been matched for attenuation , propagation delay , and input/output impedance can produce a certain level of measurement performance . <p> Sometimes designers do n't appreciate or understand the value of differential probes and prefer to integrate single-ended probing solutions into their test regimen . A single-ended probe measurement carries with it a certain @ @ @ @ @ @ @ @ @ @ adjustments required by a differential measurement . Disturbances that contribute to measurement errors with single-ended probes are : lower common-mode rejection ; the insertion of ground-loop paths ; lead inductance imbalances ; and additional capacitive loads . All of these factors affect the device under test , allowing measurement errors to creep into the design . <p> The best results that single-ended , quasi-differential techniques can provide are CMRRs of 40 dB ( 100:1 ) , as compared to a true differential-measurement tool that provides CMRRs of greater than 80 dB ( 10,000:1 ) at high bandwidths . Figure 3 shows how single-ended and differential probes can measure differential signals . <p> Probing Differential Signals A variety of tools exist for acquiring differential signals . As mentioned above , however , the use of some of these tools may create as many measurement errors as they solve . Some of the tools for acquiring differential signals include : <p> Quasi-differential solutions : These include single-ended probes that are used with oscilloscopes employing algebraic addition . <p> Built-in high-performance differential amplifiers : These devices usually are built right into the instrument @ @ @ @ @ @ @ @ @ @ : These are generally external accessories and require probes or leads . <p> Passive differential-voltage pairs : These sets are designed for specific amplifier systems . <p> Keep in mind that the probe is an extension of the instrument . To reduce the errors inherent to single-ended solutions , the amplifier needs to be placed closer to the DUT . This is accomplished by setting the differential amplifier at the tip of the probe . Placing the amplifier in the probe head as close to the probe 's measurement tips as possible greatly improves the measurement accuracy and CMRR components of the measurement solution . Of course , this also minimizes the number of differences introduced into the measurement . At the same time , the probe head is made as small as possible to reduce mechanical stress to the circuit under test . <p> High-bandwidth active differential probes can be used in place of single-ended probing in most applications , except where the increased cost of this probing solution prohibits its use , or where higher bandwidths provided by single-ended solutions are absolutely required . The main reason the @ @ @ @ @ @ @ @ @ @ the reduction of the low-impedance ground path . The ground-lead side of a single-ended probing solution , when placed on the circuit under test , creates a series resonant tank circuit . This may lower the measurement system bandwidth . True differential measurements eliminate the low-impedance ground loops created by single-ended probing solutions . <p> The DUT attachment is a major concern in not only the differential-measurement area , but in all other measurement areas as well . Many of today 's differential probing solutions overcome the challenges of DUT attachment by providing a variety of adapters specifically designed for the probe . Many ICs and circuit boards today do not readily allow measurement access to crucial signals . The designer must develop an adapter or include a testing capability right into the circuit design . This is best done in the early stages of the design to ensure that all circuit-design parameters are taken into account . <p> What seems to be ground may not behave like ground for fast signals where the rise time is less than 2 ns . Ground-distribution problems can not be isolated with a @ @ @ @ @ @ @ @ @ @ the ground , as seen by the IC , is n't always the ground where the probe is attached . What 's more , once the probe ground is attached to the circuit , the ground distribution to the IC has been altered . <p> Many differential-measurement techniques are the same as those mentioned earlier for decreasing the amount of common-mode error . Still , here are a few more procedures to add to your arsenal . <p> Use interconnects , cables , and adapters designed for the measurement tool you are using . For high-frequency measurements , wind the leads through a ferrite toroid to reduce excessive common mode pickup . Connect the ( + ) lead to the higher potential level . If measurement errors seem to be apparent , then reverse the leads to check for the level of difference . <p> When making timing ( propagation delay ) measurements , ensure that the positive input and negative input of the first test point are in the same direction on the second test point . <p> Also , remember that measurement-system bandwidth includes scope , probe , @ @ @ @ @ @ @ @ @ @ and output devices as a " system . " To improve measurement accuracy , system bandwidth should be three to five times the signal to be measured . Knowing your application helps in selecting your probe type . Consider these factors : <p> Signal type being measured " voltage , current , logic , other <p> Signal frequency content " dc , Hz , kHz , MHz , GHz <p> Signal source impedance " resistive , capacitive , inductive <p> Physical connection considerations " DUT and instrument <p> Instrument input " 50 + , 1 M+ , other <p> Instrument bandwidth or rise time <p> Measurement tools have limitations , so there is a need to reduce the amount of known error when making crucial design and engineering measurements . The errors are either electrical ( amplitude errors , phase-angle shifts , propagation delays , changing source impedance ) or mechanical ( physical geometries , attachment degradation , attachment capability ) . Figure 4 provides an indication of the amount of error involved when the measurement tool is n't fast enough . <p> Timing measurements are always a concern . @ @ @ @ @ @ @ @ @ @ timing measurements will become more and more crucial . For example , when using a differential probe on a processor or bus structure using Rambus , deskew resolution requires timing alignment of the differential signal to the corresponding bus signals . These nanosecond and subnanosecond signals will require additional bandpass from the measurement tool in order to avoid adding errors to the measurement in question . <p> With any new technology comes new probe-to-DUT interface requirements . The ability to probe the IC will provide the most accurate and reliable signal measurements . Many of today 's surface-mount ICs , however , will need to be accessed by probing close proximity pins that require unique probe-tip attachments . Compliance at the probe tips is necessary so probes can be positioned at any angle , and so sufficient force can be applied to assure excellent contact . <p> Today 's computer speeds are limited by the bus structures used by the microprocessor , memory-management chipsets , and peripheral device chipsets . The present architecture used in memory management limits the bus speeds to less than 200 MHz . <p> Differential-technology applications @ @ @ @ @ @ @ @ @ @ memory buses . Rambus technology , with edge speeds from 600 ps down to 200 ps ( 600 MHz to 1.6 GHz ) , represents one of the technology directions for microprocessor memory , displays , and transmission architectures . Rambus technology employs a differential clock as opposed to relying on the present ground-based processor clocking systems . Considering that the clock signal is at the heart of the processor , and that the Rambus clock is differential , it 's a fairly safe bet that differential probing technology will be necessary to meet measurement requirements . <p> Local-area networks with a greater dependence on data transmission have placed increased demands on standard Ethernet connections . Gigabit Ethernet has been developed to alleviate the increased data-transmission demands . <p> For all of these fast technologies , the low differential-IC 's voltage swings ( 0.8 V to 1.2 V , in some cases ) for logic levels increase the susceptibility to noise and signal degradation . Thus , high signal-to-noise ratio is of significant importance . Differential-measurement solutions can provide this level of integrity and performance where a signal-ended system will @ @ @ @ @ @ @ @ @ @ through all kinds of techniques : single-ended passive probes , single-ended active probes , differential-amplifier systems , battery-powered instruments , and differential probes . The trend is " faster is better . " One needs only to look at high-performance technology products and watch how new technology trickles down into consumer products to see this . <p> As the speeds of devices increase and move into the next generation , the nature of probing will become more complex . Differential probing techniques will continue to evolve and improve . Measured signals will require more direct-connection techniques to provide the reliable and accurate measurement speeds needed to design , verify , and manufacture future products . Today 's differential solutions are expanding to meet these and future needs . <p> Despite all of these voltage-measurement techniques , other measurement styles and approaches may be needed to produce the accurate and reliable measurements required by tomorrow 's products . The differential current measurement approach may help improve the speed and accuracy of these measurements , though it 's a little harder to use . Higher-frequency current probing solutions are now available for @ @ @ @ @ @ @ @ @ @ direction quickly , also may lead the way in meeting future measurement needs . <p> We may not know what the exact structure of future technology will be , but we do know that tomorrow 's designs will be faster and smaller . So the measurement tools will have to be faster , more accurate , and easier to use , too . <p> Recommended Reading : <p> " ABC 's of Probes , " Tektronix Inc. , Literature number 60W-6053-7 , July 1998. 
@@21004617 @1004617/ <h> Networking : WANs , MANs , LANs , And PANs Connect Everyone <p> Wired , wireless , and optical technologies make any communication possible . <p> Louis E. Frenzel Apr 28 , 2002 <p> Slowly but surely , networking is linking together everything electronic in some way . Whether or not you agree with that , there are benefits to enjoy and money to make . Killer technologies like Ethernet , wireless , and optical are making it happen . <p> Networking 's future appears to stay focused on achieving higher speeds , even though our data rates already do everything we want . The real goal is to get that speed to everyone , and do it in a secure environment . <p> WANs : After years of build-out in the long-haul telephone and Internet backbone networks , there 's more than enough capacity to accommodate needs for the immediate future . The economic downturn has slowed the provisioning of all this capacity . Lots of dark fiber is available to light the future when necessary . <p> MANs : This is the hot spot in the @ @ @ @ @ @ @ @ @ @ current speed and capacity needs or do n't exist at all , so there are plenty of growth opportunities ( see " Optical : Undisputed King Of High-Speed Data Transmission , " p. 57 ) . <p> LANs : Virtually all medium and large enterprises have been fully networked for years . However , there will be an ongoing need for upgrades in service to higher speeds and gradual replacement of older systems . More and more enterprises are adopting wireless networking as well because its declining cost allows them to take advantage of the flexibility it offers . <p> PANs : We 're just now starting to see the effects of personal area networks . Most are wireless , with the Bluetooth star showing the way . It took years for Bluetooth to come into its own , but today it 's poised for major growth , so you 'll be seeing more of it and such spinoffs as ZigBee . IrDA is n't dead , and the newer inductive wireless networks have great potential in some applications . <p> Ethernet Everywhere : Clearly , Ethernet is the networking @ @ @ @ @ @ @ @ @ @ been around for decades , it has considerable life left ( Fig. 1 ) . The original 10-Mbit/s coax systems have mostly been replaced by 100-Mbit/s twisted-pair Fast Ethernet . A newer version handles 1 Gbit/s on CAT5 ( Category 5 ) wiring as a LAN backbone or to the desktop . <p> The 1- and 10-Gbit/s optical fiber versions of Ethernet will ensure a continuation of this flexible and endurable technology . The 1-Gbit Ethernet ( 1 GE ) configuration is being widely adopted in large LAN backbones and storage-area networks ( SANs ) . Already , 1-GE systems are showing up in new metro networks . No 10-Gigabit Ethernet ( 10 GE ) systems are yet in operation , but these will find applications in large fast LANs and SANs , metro networks , and even WANs replacing Sonet systems . Ethernet has also been blessed as the de facto industrial networking standard too . <p> What 's next for Ethernet , 100 Gbits/s ? Not right away , as the technology is n't there yet . Most likely , a 40-Gbit/s version will take advantage of available @ @ @ @ @ @ @ @ @ @ in the metro and long-haul networks . <p> Additionally , Ethernet has come to dominate wireless networking . Wireless is increasingly becoming the physical layer of choice in many LANs , and the IEEE 802.11b Ethernet has become the de facto standard . The latter has flourished because the Wi-Fi consortium ensures interoperability between many vendors ' equipment . Prices have dropped due to competition and more widespread adoption . <p> Wireless Ethernet also has a life . The recently approved 802.11g standard offers a speed upgrade path for 802.11b to 22 Mbits/s , and even 54 Mbits/s . And , 5-GHz 802.11a standard products are slowly rolling out . <p> Frontiers For Growth : Aside from opportunities for expansion in the metro network arena , several major sectors will experience growth : mesh networks , home networks , cell-phone networking , broadband , UWB , and security . <p> The classical network topology is the mesh , where all nodes are connected to each other ( Fig. 2 ) . Even though they 're very expensive to implement , there 's a growing interest in mesh networks because they @ @ @ @ @ @ @ @ @ @ networks scale more easily than other topologies , so many local carriers and metro network vendors are seriously considering them . <p> Mesh networks also are proposed as the wireless broadband solution in locations where cable and DSL are n't available . Every home wireless node acts as a router , creating a mesh network with each of its neighbors . Such mesh networks provide excellent Internet access and could be a solution for the wireless local loop . <p> Another trend is the growth in home networks . Wireless dominates with Ethernet 802.11b in the lead , but viable phone-line and power-line network products have finally become available . Affordable access gateways now make it fast and easy to network several PCs at home . <p> Plus , the new 2.5G cell phones have become nodes in a huge wireless data network , providing e-mail and Internet access . But the 2.5G data services , like GPRS and 1xRTT , are n't selling well . This is not good for forthcoming faster 3G phones . Many believe consumers will prefer a wireless LAN access port to a cell phone @ @ @ @ @ @ @ @ @ @ consensus that high-speed data access is n't what most cell-phone subscribers need , as the killer application for cell phones remains voice . <p> Perhaps the networking opportunity of greatest importance and benefit is broadband . Data applications like e-mail and Internet access will continue to dominate the Internet . But as the world moves closer to being a totally networked group , it will bring interactive gaming , more online education , and voice , movies , and music on demand " but only when everyone has an affordable broadband connection . <p> Currently , less than 10% of U.S. homes have a broadband connection . Statistics say that out of the approximate 10 million current broadband connections , roughly 7% are cable modems and 2.8% are DSL . Less than 2% use some form of wireless/satellite broadband link . <p> Cable TV 's hybrid fiber-cable ( HFC ) networks are almost everywhere now . This very reliable and affordable technology will keep dominating broadband . Most project cable as the continuing leader in broadband growth . <p> As for DSL , most of us are impressed , even @ @ @ @ @ @ @ @ @ @ to 1.5 Mbits/s on the POTS ( plain-old telephone system ) local loop . But speed is typically much less over longer distances and with more noise . Let 's face it , DSL is a dead-end technology . Billions of dollars are being spent to roll out a technology that has no room to grow . We should move on to the better killer technology , optical fiber . <p> Wireless networking will also benefit from forthcoming ultra-wideband products . In February , the Federal Communications Commission ( FCC ) approved the use of UWB for networking and in short-range radar applications . UWB wireless LANs should produce data rates of over 100 Mbits/s and at very low power . This will enable inexpensive video links in home networks and even wireless versions of IEEE 1394 and USB 2.0 . <p> Finally , and maybe of greater importance , is the resolution of security issues in Internet and wireless applications . While there are some software and hardware solutions in the form of firewalls , encryption , and more recently biotechnology , we 're still waiting for " the @ @ @ @ @ @ @ @ @ @ deployment of some applications will continue to be slowed by the technical complexities of the problem , the lackadaisical attitude about security in industry despite terrorist and hacker threats , and the widespread disagreement over which approaches to take . Indeed , security is one of the better opportunities in networking today . 
@@21004624 @1004624/ <h> Harry Nyquist : A Founding Father Of Digital Communications <p> When electrical engineers hear the name " Nyquist , " they think of what Harry Nyquist is best known for : his Sampling Theorem . Evidence of its importance is everywhere . Products like cell phones , audio CDs , and iPods are all based on the broad-shouldered foundation of the theorem , and that alone is enough to place Nyquist among the industry 's greats . But Harry Nyquist had many other , lesser known accomplishments , a number of which resonate strongly today . <p> Harry Nyquist was born in 1889 in Sweden . Impressed by Nyquist 's intelligence , a teacher encouraged him to go to America , where there was greater opportunity . Nyquist arrived in the U.S. in 1907 and subsequently earned BSEE and MSEE degrees from the University of North Dakota in 1912 and 1915 , respectively , and a PhD in physics from Yale University in 1917 . <p> In 1917 , Nyquist joined the American Telephone and Telegraph Company , delving into the work of improving telegraph picture and voice @ @ @ @ @ @ @ @ @ @ in 1934 , which allowed him to continue his work in transmission engineering until his retirement in 1954 . He built an impressive body of work during his 37 years with the communications giant , represented by his 138 U.S. patents and a dozen published technical articles . <p> As early as 1918 , Nyquist had begun attempts to adapt telephone circuits for transmission of images . By 1924 , AT&amp;T had something it termed " telephotography , " or what we 'd call a facsimile machine . Despite a cruder method of execution , it used the same principles as today . <p> A photographic transparency was mounted on a spinning drum and scanned . The data was then transformed into electrical signals that were proportional to the shades and tones of the image . Next , the data was transmitted over phone lines and deposited onto a similarly spinning sheet of photographic negative file , which was developed in a darkroom . Incidentally , the first faxed images were 5- by 7-in. photos sent from New York City to Cleveland . Each photo took seven minutes to transmit @ @ @ @ @ @ @ @ @ @ in solving the communications issues of the day . In 1927 he extended the work of J.B. Johnson and developed a mathematical explanation for thermal noise , now known variously as Johnson or Nyquist noise . <p> The beginnings of modern information theory are found in the body of his work . In a 1924 paper in the Bell System Technical Journal , Nyquist first referred to what was transmitted by telegraphers as " information . " He suggested that two factors determined the " maximum speed of transmission of intelligence . " <p> Those factors were the signal 's shape ( a square wave was deemed superior to a sine wave ) and the choice of code used to represent the intelligence . Using maximum Morse-code telegraphy speed as a starting point , Nyquist eventually determined that the maximum speed of intelligence transmission is proportional to the logarithm of the number of symbols that need to be represented . <p> Nyquist 's most significant work was his 1928 paper , " Certain Topics In Telegraph Transmission Theory . " It refined his earlier work on improving transmission speed . @ @ @ @ @ @ @ @ @ @ 's theoretical work on the bandwidth requirements for data transmission and the basics of sampling continuous analog signals and converting them to digital form , now better known as the Nyquist Sampling Theorem . <p> Sampling Theorem <p> According to the Sampling Theorem , an analog signal must be sampled at regular intervals over time and at twice the frequency of its highest-frequency component to be converted into an adequate representation of the signal in digital form . Thus , the " Nyquist frequency " is the highest frequency that can be accurately sampled . It represents one-half of the sampling frequency . Adhering to the Nyquist Sampling Theorem ensures no lost data upon reconstruction in the analog domain . <p> Once again , Nyquist drew upon Morse code as a model to establish a way to digitally encode an analog signal using ones and zeros . A side benefit of this work was his invention of the codec circuit used to perform the coding and decoding of the analog signal . <p> Nyquist 's work was enormously influential to the communication engineers that followed him . This was especially @ @ @ @ @ @ @ @ @ @ considered by many to be the father of information theory . Nyquist 's 1924 and 1928 papers were cited in the first paragraph of Shannon 's own claim to greatness , the 1948 paper titled " The Mathematical Theory of Communications . " <p> Numerous experts say that Nyquist stated the Sampling Theorem , and Shannon later mathematically proved it . Moreover , many believe that Nyquist and Shannon are responsible for virtually all theoretical advances in modern communications . <p> In the early 1930s , Nyquist began looking into negative-feedback amplifiers and how to determine when they become stable . His findings resulted in the development of the Nyquist Stability Theorem . During World War II , the theorem helped control artillery that used electromechanical feedback systems . An outgrowth of Nyquist 's work in feedback loops was the " Nyquist plot , " which plots the magnitude and phase of a frequency response on orthogonal axes . <p> After his retirement , Nyquist became a part-time consultant , providing communications expertise to the Department of Defense and private defense electronics firms . He received many honors for his @ @ @ @ @ @ @ @ @ @ recipient of the National Academy of Engineers ' Founder 's Medal . <p> Yet Nyquist never saw the full fruits of his labor . He died in 1976 , years before the debut of the technology needed to make digital audio recording and playback a reality , and ultimately an enormous commercial success . 
@@21004627 @1004627/ <h> Optical : Undisputed King Of High-Speed Data Transmission <p> As telephone and computer networking have evolved over the years , they have steadily moved toward an all-fiber optical physical layer . Today , virtually all long-distance telephone service is by fiber . The Internet 's development and growth have boosted optical transport into the stratosphere . Optical dominates simply because nothing else provides the speed and overall data capacity at a reasonable cost . <p> But there 's a downside to too much of a good thing . With the past decade 's over-building in the long-haul backbone , we now have a bandwidth glut . <p> Due to this overcapacity and the recent economic downturn , the optical industry has been one of the hardest hit financially . But it also has experienced threefold revenue growth over the past five years . Thousands of startups have emerged during this period , each seeking venture funding and a position in the market . Thanks to consolidation through mergers and acquisitions during this downturn , most of their new optical-transport killer technologies will survive in some form . <p> @ @ @ @ @ @ @ @ @ @ the LAN and MAN space previously occupied only by twisted pair and coax . Projections for market growth in North American optical transport equipment show how optical is progressing even during bad times ( Fig. 1 ) . <p> Legacy Systems Still Rule And Benefit : Synchronous optical network ( Sonet ) and asynchronous transfer mode ( ATM ) are the traditional legacy architectures still carrying the bulk of the data load worldwide . The most significant change in these systems has been their steadily increasing speed , thanks to new lasers and digital chips . Newer 2.5-Gbit/s ( OC-48 ) systems have replaced older 155- and 622-Mbit/s ( OC-3 and OC-12 ) systems . Today , carriers are gradually upgrading to OC-192 10-Gbit/s systems . <p> Semiconductor manufacturers are finally ready to release OC-768 systems that run at 40 Gbits/s . Figure 2 shows how the upgrading of the Sonet long-haul networks finally converges with the steady upgrading of Ethernet networks at the 10-Gbit/s level . The rate of speed increase for Ethernet and Sonet has been significantly faster than Moore 's Law , forcing semiconductor makers to find @ @ @ @ @ @ @ @ @ @ 's potential . We 're finally there ! <p> For years , many expected fully packetized Internet Protocol ( IP ) systems to eventually replace existing long-distance and Internet backbone systems . But that just has n't happened , de-spite the existence of the new IPv6 protocol and killer technologies to facilitate it . One reason is be-cause the massive investment in the entrenched telecom infrastructure wo n't be re-placed overnight . <p> Carriers will move in that direction , but meanwhile , they 'll rely on upgrades to keep their systems viable as they attempt to expand their services and make a profit . In a flash , designers will adopt any new technology that helps squeeze costs out of the system while improving performance . <p> Currently , we have more than enough long-haul and backbone fiber for the immediate future , but there are bottlenecks in the metropolitan and local access networks . Information can travel very fast over long distances , but locally it 's restricted to slow or nonexistent metropolitan-area networks . This is gradually being solved because the metro network remains the hottest , @ @ @ @ @ @ @ @ @ @ the downturn . Slowly but surely , new metro networks are being put into place , again thanks to the new optical technologies that make high speeds available at reasonable costs . <p> Although many metro networks are being built with Sonet to maintain compatibility with long-haul networks , newer technologies are being adopted . Optical versions of 1-Gbit Ethernet ( 1 GE ) are already finding their place in the metro space . The forthcoming 10 GE will find application in the metro regions and even in new long-haul WANs . Fresh technologies like mesh metro networks and resilient packet-ring architectures promise faster and more flexible packet MANs with quality-of-service ( QoS ) guarantees . <p> To completely benefit from the present awesome long-haul capacity and forthcoming metro capabilities , the first/last mile of access must soon be replaced or upgraded . Full convergence of voice , data , and multimedia with all hot new applications wo n't happen until everyone can access a broadband connection . <p> Recently , the telecom industry lobbied the U.S. Congress and the President for regulations to facilitate and expedite a broadband rollout @ @ @ @ @ @ @ @ @ @ fiber to the home ( FTTH ) " already exists . For example , 1 GE is the near-perfect technology for home Internet access . Even fiber to the curb and twisted pair to the house will give us a bandwidth far beyond DSL or even cable . <p> DWDM Shines Brightly : The impressive speed increases over the years have greatly expanded the capacity of fiber optical networks . Coupled with that is a technology that further multiplies existing fiber 's data capacity . Known as dense wavelength-division multiplexing ( DWDM ) , this technique has already lit an enormous amount of dark fiber with a rainbow of IR light , each wavelength representing a separate channel of high-speed data . <p> DWDM has given new life to older fiber and enabled significant increases in total bandwidth and transmission capacity . Today , it 's possible to transmit over 160 wavelengths of light on a single fiber , each carrying a data rate of 10 Gbits/s . That 's terabits per fiber . Plus , 40-Gbit/s OC-768 systems are coming . With OC-3072 next on the horizon , can @ @ @ @ @ @ @ @ @ @ <p> Tunable lasers give DWDM systems more flexibility and lower cost . They also enable the design of new network architectures that incorporate dynamic wavelength provisioning , addressing , and routing . And , new vertical-cavity surface-emitting lasers ( VCSELs ) are making short-haul LAN or metro systems cheaper and faster . <p> DWDM also offers a potential solution to the multiprotocol management problem , especially in the metro space . By isolating each protocol to a different wavelength and employing wavelength switching , this mix of protocols can be managed quite readily . <p> In addition to tunable lasers and VCSELs , there are hundreds of new , improved optical parts like isolators , power dividers , attenuators , filters , dispersion compensators , and modulators . Ad-vances in Raman amplifiers and erbium-doped fiber amplifiers ( EDFAs ) are be-ginning to eliminate the need for costly optical-to-electrical-to optical ( OEO ) conversions . New optical switches , including microelectromechanical system ( MEMS ) devices , provide speed as well as protocol-independent switching to make networks more flexible . <p> All of these new and affordable parts are gradually bringing @ @ @ @ @ @ @ @ @ @ all-optical network ( AON ) . Companies are finding ways to fabricate optical components using standard silicon wafers and processing technology . This has led to large-scale integration of optical components . One recent example is a full-optical add-drop multiplexer on a chip . <p> Soon we 'll see the AON and passive optical networks ( PONs ) , which both eschew electronics and lower costs , eventually leading to new optical networking applications . Metro networks are a target for AONs , whereas PONs are aimed at the first/last-mile access with FFTH or fiber to the curb ( FTTC ) . 
@@21004628 @1004628/ <h> Taking The Liability Out Of Reliability <p> Designers who evaluate COTS products must take into account the intended application and the likely demands on the system . <p> Bryan Rogers Jul 31 , 2004 <p> Increasing use of COTS components and subsystems has allowed designers of high-reliability ( hi-rel ) applications to benefit from the short lead-times , extensive choice , rapid product evolution and lower cost of commercial electronic technologies where the demands of the application and environment will allow . By exploiting these opportunities , designers of space , military and civil aviation applications can configure systems for hi-rel applications under the functionality , performance cost and time-to-market pressures that prevail in the commercial sector . <p> Commercial power supply design , for example , has advanced rapidly in recent times , particularly in relation to the design of distributed power architectures . COTS offers designers the opportunity to use the latest converters , regulators and power semiconductors to achieve lighter , more efficient , lower-cost power supplies within tighter timescales . <p> However , COTS products can not simply be designed-in on the designer 's @ @ @ @ @ @ @ @ @ @ a given COTS product may be little or no wider than its standard commercial counterpart . The package may not be hermetically sealed , in which case the system can not be exposed to moisture or particle ingress . Also , a COTS product may not be qualified for exposure to high or low levels of radiation , which may prevent its use in space or certain nuclear applications . For these reasons the engineers who evaluate and select COTS products must take into account the intended application and the likely demands on the system before sanctioning their use . <p> To expand the choices available to designers , companies are now offering products that are designed for hi-rel applications built using lower cost technologies , as well as dedicated , hermetically sealed hi-rel components . These include standard plastic packaged devices built on qualified manufacturing lines , with guaranteed performance over a wider temperature range than standard commercial products . Also , products designed for other severe-environment applications , such as automotive under-bonnet or cellular base station electronics , are now reaching a performance level that makes them a @ @ @ @ @ @ @ @ @ @ today 's automotive power supplies are expected to operate under temperature extremes , moisture conditions and mechanical stress that are similar to those that some hi-rel systems are required to endure . <p> The result is that designers of power systems for hi-rel applications can now choose from a range of COTS and dedicated power semiconductor technologies that includes discrete devices such as power MOSFETs , voltage regulators , IGBTs and Schottky diodes , and integrated modular solutions such as DC-DC converters and motor control circuits . <p> DISCRETES FOR HI-REL DESIGN Consider a power switching application that requires a through-hole N-channel power MOSFET rated at 30W and capable of withstanding up to 100V drain-to-source breakdown voltage ( BVDSS ) , and capable of continuous operation at up to 8.0A at 25-C or 5A at 100-C . <p> Choosing , for example , from the IR product family , either the IRL1520N HEXFET power MOSFET in standard TO-220 FULLPAK plastic package , or the IRHF7130 HEXFET in a TO-39 package are viable options . Both of these devices have the same HEXFET integrated transistor/diode equivalent circuit and achieve fast switching @ @ @ @ @ @ @ @ @ @ , and will operate with a junction temperature between -55-C and +175-C . Therefore , despite the fact that this device is not supplied in a hermetically sealed package , it is still suitable for hi-rel applications where temperature extremes are among the prime design constraints . The IRHF7130 , on the other hand , has a lower operating junction temperature range of -55-C to +150-C , but is supplied in a hermetically sealed package and is a radiation-hardened device compliant with MIL-STD and characterised for both Total Dose and Single Event Effects ( SEE ) radiation . As a result , the IRHF7130 is a natural choice for applications such as satellites or other spacecraft , or weapon systems designed to operate in environments subject to high levels of radiation . Figure 1 shows the two devices side by side : the same electrical parameters , with different environmental properties . <p> CONVERTER CHOICES Designers of hi-rel systems are as dependent as any other group on lightweight , efficient DC-DC converters as part of distributed or conventional power architectures . To increase the choices for designers , IR has @ @ @ @ @ @ @ @ @ @ with the latest topologies . These are specifically targeted at military , aerospace and ruggedised industrial applications . <p> As an example , the AA28XX series offers products with a wide input voltage range from 15V to 50V , allowing the designer to optimise the primary bus voltage for overall power efficiency . Converters are available rated up to 25W output power , and there are single- and dual-output models with voltages of 3.3V , 5.0V , 5.2V , 12V , 15V , -5V , -12V and -15V . The AA28XX converters are not delivered in hermetically sealed packages , but are designed to operate under extremes of temperature , mechanical shock , and vibration , making them suitable for military vehicle and flight applications where the increased ingress resistance of hermetic sealing is not required . <p> Radiation-hardened and radiation-tolerant converters are also available for space and weapon applications , such as IR 's Z-series single output DC-DC converters ( Figure 2 ) . Outputs of 1.5V , 2.5V and 3.3V are available , to provide the very low supply voltages required by the electronics onboard space vehicles and @ @ @ @ @ @ @ @ @ @ as that encountered by geo-synchronous and low earth orbit satellites . Low voltage design is one of the techniques used by satellite systems designers to minimise the vehicle power budget and avoid heavy , bulky power supplies that would otherwise impose far-reaching design constraints and also add to the launch costs . The Z-series converters use a combination of surface mount technology for the larger passive and power components and hybrid construction for control circuits , to simplify assembly and achieve a small footprint . <p> Another series of standard hi-rel DC-DC converters offers radiation tolerance for extended operation in moderate radiation environments . The AMA-series ( 5W ) , AMF-series ( 12W ) and AMR-series ( 30W ) converters are built using high-density chip and wire hybrid technology that complies with the class H requirements of MIL-PRF-38534 . They are fabricated in a facility fully qualified to MIL-PRF-38534 . The converters can be mounted directly to a heat conduction surface without signal leads penetrating the heat sink surface , allowing greater independence in mounting and greater mechanical security than traditional packages . The package , which is shown in @ @ @ @ @ @ @ @ @ @ long-term hermetic seal . <p> The radiation performance of the AMA/F/R series supplements the higher radiation performance available in the ART2815T converter series , and is suitable for space vehicles operating in low earth orbits , including launch boosters or orbiting space stations . <p> HI-REL MOTOR CONTROL In hi-rel applications , just as in any other market , electronic control of fans , pumps , actuators and other motor-driven subsystems deliver efficiency , noise , space , weight and cost benefits over mechanical solutions . But until recently , hi-rel designers have had to develop custom motion control designs because available off-the-shelf solutions have not been suitable for harsh environments . This is now changing as power electronic vendors continue to increase their expertise in applying COTS technologies in hi-rel applications . Highly integrated motion control modules that incorporate all of the electronics needed to accurately drive and control a motor are now entering the market . <p> The OM9375 3-phase brushless DC ( BLDC ) motor control subsystem is one example . As shown in the block diagram of Figure 4 , the power stage , non-isolated driver @ @ @ @ @ @ @ @ @ @ integrated on-chip . Ideal for fans , pumps and actuator systems , the OM9375 is rated for 25A average phase current and a 160V maximum bus voltage , and can accurately control motor speed and direction . A soft start facility ensures safe motor starting . <p> Designers creating specialist solutions for hi-rel applications now have a wider choice of power electronic components and modules that will meet their requirements . COTS has been pivotal in encouraging this ; in addition to streamlining design and development , it has also allowed vendors to gain a clearer understanding of the wide variety of environmental conditions under which hi-rel systems are required to operate . 
@@21004631 @1004631/ <h> Wireless Mesh Expands The Boundaries Of Networking <p> Greater range and reliability , plus much lower costs , have businesses scrambling for wireless mesh to implement into their short-range wireless setups . <p> Louis E. Frenzel Sep 14 , 2005 <p> Most computers are on a network nowadays . Consumer electrical , electronics , and communications products are next . Industrial sensors and controls , machine tools , and other devices in process control and manufacturing are under way . And do n't forget about machine-to-machine ( M2M ) , which will let any machine talk to any other machine via several layers of networking . <p> One day , everything will be networked . That day may be closer than we think thanks to wireless mesh networking . With it , designers can interconnect any device with an inexpensive short-range wireless chip to everything else . This really opens the door to all sorts of new applications that simply were n't possible before . <p> MESH CONCEPTS In a mesh network , the nodes are all connected to one another . This is called a full mesh @ @ @ @ @ @ @ @ @ @ link to all other nodes , making for a very useful arrangement . But as the number of nodes increases , the number of links becomes impractical . The number of links ( L ) is defined by the number of nodes ( N ) with the expression : <p> L = N ( N - 1 ) /2 <p> Connecting 20 PCs would require 190 links " a hardware and wiring nightmare . So , practical networks use a bus , ring , star , or other network topology plus some access method to reduce the number of interconnections . The only widely utilized wired mesh network is the Internet . <p> Going wireless makes the mesh usable and affordable . Furthermore , a partial mesh like the mesh in Figure 2 achieves the primary benefits of the full mesh . Here , not every node is connected to every other node . But if there are enough links , designers can realize some amazing advantages . <p> Mesh networks are primarily used for monitoring and control operations . As a result , the mesh usually carries sensor readings @ @ @ @ @ @ @ @ @ @ involved , though some advanced mesh networks make that possible . Because monitor and control operations involve relatively short and simple packets , data rates can be very low . A few kilobits per second is often fast enough , and higher speeds can be implemented if needed . Typical data rates range from 20 to 250 kbits/s . <p> Perhaps the key benefit of the partial mesh is that the range of each node is greatly multiplied . Most short-range wireless technologies have a typical maximum range of 10 m or less . But this need n't be the maximum communications distance , since all other nodes are used as repeaters or routers . <p> A signal can be passed from node to node , extending the range indefinitely . In Figure 2 , node A can get a message to node L by passing the signal through nodes A-B-E-M-I-L . An alternate path is A-C-D-F-L . There are several other multiple redundant paths , too . The data to be transmitted is put into a packet , and the packet is " hopped " from node to node @ @ @ @ @ @ @ @ @ @ , the nodes attempt to get data to a collection point or access point such as M in Figure 2 . The data then is aggregated and sent on to a local-area network ( LAN ) , metro-area network ( MAN ) , or wide-area network ( WAN ) for further transmission ( such as the LAN in a manufacturing plant or the Internet ) . <p> A popular variation of the mesh topology is a hybrid consisting of several point-to-multipoint ( PMP ) star networks , where multiple nodes talk directly to a central coordinating node or access point ( AP ) . Then , the multiple APs are connected in a mesh configuration . <p> The fact that there 's more than one path through a mesh introduces the other major benefit " reliability . If one path fails because of obstructions in the signal path , a defective node , or multipath attenuation , the signal can find one or more alternative routes . If the battery in a node fails , it drops out of the network , but other nodes relay the data via alternative @ @ @ @ @ @ @ @ @ @ equipment occasionally may block a previously good wireless path . Furthermore , temporary interference from another source or a sudden noise burst may prevent transmission . Again , a mesh automatically finds another path . <p> The total number of nodes is an important consideration in a mesh network . To benefit from multiple hop paths , many nodes are required . The absolute minimum mesh configuration is three nodes . Yet adding more nodes will significantly increase the reliability and robustness of the mesh . <p> Mesh networks also scale well . Initially , they may consist of only a dozen or so nodes . But that can scale to hundreds or even thousands of nodes without difficulties . <p> In addition , mesh networks are self-forming . The nodes automatically discover one another and establish a link if they 're within range . This is called an ad hoc network . If the nodes are mobile , the network constantly and automatically reforms itself to the participating nodes . <p> A new node can be added at any time . If that node is too far away to @ @ @ @ @ @ @ @ @ @ added in between to establish a link . With small , inexpensive nodes , this approach is still cheaper than wiring in most applications . <p> POWER SAVINGS Mesh uses very little power , too . Because the distance between nodes is kept short , the transmit power needed to establish reliable communications is very low . In fact , some nodes may be battery operated . <p> Since nodes transmit packets in bursts , the node may go to sleep and draw only microamps , waking up only when called upon to relay a message or when it has one to send . Duty cycle may be only 0.1% to 1.0 % , greatly reducing power consumption . Battery life can last from many months to many years , reducing the need for frequent maintenance . <p> While self-organizing , self-healing mesh networks offer massive benefits , they also have a downside , namely security . Mesh networks can be hacked and compromised if they are n't protected . Yet protection is available with encryption methods like the Advance Encryption System ( AES ) . <p> Another disadvantage for @ @ @ @ @ @ @ @ @ @ of time to wake up and transmit data . Also , each hop requires a finite time . Total latency between nodes can be 5 to 30 ms . In some deterministic industrial control applications , this may not be fast enough . But in many instances , that latency is n't an issue . <p> THE RADIO INTERFACE Given so many available single-chip wireless transceivers today , which one is best for a mesh ? The answer lies with the application . For instance , there 's no reason why designers ca n't use the inexpensive ISM-band ( industrial , scientific , medical ) ICs operating at 315 , 433 , and 915 MHz . Bluetooth is another possibility . <p> When more inexpensive Ultra-Wideband ( UWB ) transceivers become available next year , the door will open for very highspeed , short-range mesh networking . Consumer electronics can use it to connect all of the various video and audio components together around the house . Maximum data rates for UWB , in the form of wireless USB or direct-sequence UWB , are 480 Mbits/s and 1 Gbit/s , @ @ @ @ @ @ @ @ @ @ data rate over a longer range . Artimi and other companies are beginning to provide the software in an external embedded controller to create a mesh solution . One good possibility for a radio interface for mesh is the ubiquitous 802.11 Wi-Fi transceiver . The cost is very low and the data rate is high , from 11 to 54 Mbits/s . On the other hand , power consumption is high , and this standard implements a point-topoint ( P2P ) or point-to-multipoint ( PMP ) star topology . <p> Yet with the proper software and sufficient power , Wi-Fi is a good option if high data rates are needed . Several companies make software that converts a Wi-Fi radio into a mesh node . The IEEE is working on the 802.11s mesh-networking standard . A full standard is n't expected for several more years , though . In the meantime , several proprietary mesh systems are available . <p> Perhaps the best option is the newer wireless standard , IEEE 802.15.4 . Also known as ZigBee , this standard was created from scratch to work in a mesh configuration @ @ @ @ @ @ @ @ @ @ ) layers as well as the basic topology and interoperability between nodes ( Fig. 3 ) . The ZigBee Alliance has created the network and security upper layers , and it may develop application profile layers . <p> IMPLEMENTING MESH NETWORKS Many 802.15.4 chips are available if you 're the do-it-yourself type . ZigBee uses the unlicensed ISM bands of 915 MHz and 2.4 GHz in the U.S. and 868 MHz in Europe . All of the chips use direct-sequence spread spectrum ( DSSS ) for robustness and minimization of multipath . Maximum data rate is 20 kbits/s for the 868-MHz version , 40 kbits/s for the 915-MHz version , and 250 kbits/s for the 2.4-GHz version . Most vendors opt for the 2.4-GHz configuration . <p> A good example of a typical ZigBee RF chip is Freescale 's MC1319x series . The MC13191 is a 2.4-GHz transceiver using DSSS and offset-QPSK ( quadrature phase-shift keying ) modulation . It 's set up so designers can use their own or another proprietary protocol . The MC13192 is similar , but it has a built-in MAC layer that 's 802.15.4-compliant . @ @ @ @ @ @ @ @ @ @ . The third member of the series , the MC13193 , fully complies with ZigBee . <p> A newer line of Freescale chips , the MC1320x family , puts the transmit/receiver antenna switch on chip . It fully integrates one of Freescale 's HCS08 processors on-chip to create a single-chip Zig-Bee solution . <p> Freescale also has partnered with Millennial Net , which offers mesh networking software and solutions . Millennial Net 's Mesh-Scape wireless sensor networking system can run on Freescale 's RF transceiver chips , creating a proprietary mesh solution . <p> MeshScape includes the full mesh networking software as well as a line of node modules . Its 916-MHz nodes and 2.4-GHz nodes work with the software . A MeshGate module aggregates data from the network and sends it on . An End node module captures data in a hybrid star-mesh network , while a Mesh node module is used with sensors and actuators . <p> The mesh system developed by Ember is a good choice for a full standardized ZigBee implementation . It consists of Ember 's EM250 single-chip transceiver/controller " a complete ZigBee system-on-a-chip " @ @ @ @ @ @ @ @ @ @ sophisticated mesh . The EM250 has an 802.15.4-compliant , 2.4-GHz transceiver , plus an on-chip 16-bit RISC processor to handle the ZigBee and higher networking layers . Ember 's EM260 RF transceiver has the same features as the EM250 . It works with Atmel 's AVR , TI 's MSP430 , and other embedded controllers . <p> The software component of the Ember system , EmberZNet 2.0 , is a fully ZigBee-compliant networking stack that can handle a wide range of end applications . Ember 's developer kit just about hands your design to you on a platter ( Fig. 4 ) . In addition to a developer board , the kit supplies 12 complete node boards that offer designers a chance to test the mesh concept themselves . There 's also a Power-over-Ethernet ( PoE ) injector . On the software side , the kit 's full set includes the Ember Studio Network-Management Software , Ember Studio Debug Tools , the EmberNet Stack and API and library , and full documentation . <p> Lots of other companies produce chips , modules , and software for ZigBee and similar proprietary @ @ @ @ @ @ @ @ @ @ single-chip-solution CS2420 RF ZigBee transceiver with an integral processor called the CS2430 . <p> Helicomm 's IP-Link 1200 modules are ready to use in ZigBee nets . The company also has a 900-MHz module for longer range . Software and developer kits are available as well . Cirronet , another RF modem company , offers a wide range of ZigBee modules , software , and development boards . <p> WI-FI MESH While ZigBee leads the industry in short-range mesh networking , plain old 802.11 or Wi-Fi can be used in a mesh configuration with the right software . As mentioned earlier , the IEEE 802.11s mesh standard for Wi-Fi is still a few years away . Meanwhile , lots of proprietary systems are available using 802.11 or similar technology . Wi-Fi makes sense for a mesh air interface that needs higher speeds and longer ranges and where power consumption is less of an issue . <p> Wi-Fi mesh provides low-cost broadband connections to consumers in rural and suburban areas that are n't served by cable TV or DSL lines . By establishing each subscriber as a repeater/router node , Internet @ @ @ @ @ @ @ @ @ @ area . Lots of small towns use such a system . Now the industry is looking at bigger fish , though , with one major system already being proposed to offer connectivity all over Philadelphia . <p> An 802.11 mesh , the Wireless Intelligent Transport Network ( WITnet ) system from Accton Technology , is a variation of the hybrid star-mesh topology . It provides a way to mesh the APs of existing or new star/P2P 802.11 networks . <p> Today , each AP needs a connection back to the infrastructure via a T1 line or other link . The Accton system eliminates this expensive link from most of the APs in the mesh . The APs relay data to and from a single wired AP via mesh techniques . <p> WITnet has all of the properties of a mesh , as it is self-organizing and self-healing . Designers can add new nodes ( APs ) quickly and simply . It has built-in AES encryption and authentication for security . There 's probably no faster or easier way to expand an existing hot-spot network at minimum cost . One additional @ @ @ @ @ @ @ @ @ @ On top of that , the system will be compatible with the forthcoming 802.11s mesh standard . <p> The MEA and Motomesh systems devised by Motorola represent a fast high-end mesh network . Motorola got into the mesh fray when it bought Mesh Networks a few years ago . MEA is the basic Mesh Enabled Architecture that allows 802.11-like nodes and APs in the 2.4-GHz unlicensed band to be meshed . It offers all of the essential features of a mesh and 802.11b systems , and it can be used in mobile applications where 802.11b fails . <p> MEA uses the patented quadrature-division multiple-access ( QDMA ) method . Originally developed under a Defense Advanced Research Projects Agency ( DARPA ) contract for military mesh networking , QDMA is a version of CDMA that does n't require a basestation like CDMA cell-phone networks . Instead , each node can serve as a repeater/router , and the nodes may be mobile at speeds up to 250 mph . Maximum burst data rate is 6 Mbits/s . Typical sustained rates range from 1 to 2 Mbits/s . <p> The Motomesh product line @ @ @ @ @ @ @ @ @ @ mesh networks for public safety organizations . It 's a good fit with fire and EMS , police , disasterresponse , and homeland-security organizations . It provides data services as well as streaming video , photos , Geographic Information System data , and access to databases or other information needed in the field by police , construction workers , and others . <p> At Motomesh 's heart lies an access point that combines two standard 2.4-GHz , 802.11b-like radios and two 4.9-GHz , publicservice-band radios that incorporate MEA . One set operates in the standard 2.4-GHz band , the other in the 4.9-GHz band . <p> These meshed access points can communicate with laptops and other nodes in cars and other vehicles at speeds up to 200 mph ( Fig. 5 ) . Its location-based system allows any vehicle to pinpoint itself or any other user within a -10-m range " without GPS . Even nodes operating inside buildings , tunnels , or downtown " canyons " of tall buildings or traveling at high speeds can be located in about a second . 
@@21004633 @1004633/ <h> The Business Of Homeland Security May Top $100 Billion <p> Demand for new technologies and system upgrades due to heightened homeland-security concerns may create a $100 billion industry over the next several years . With more than 170,000 employees and several very large agencies now under its umbrella ( including the Customs Service , Secret Service , Coast Guard , and Border Patrol ) , the Department of Homeland Security expects to receive more than $41 billion in FY2004 , or about 64% more than it got just two years ago . Only about $8 billion of that is earmarked for science and technology . But add in spending from local , state , and private corporations , and the amount of spending almost triples that of the federal budget . <p> Several independent market research organizations tally the market for U.S. technology products and services at more than $98 billion . The Homeland Security Research Corp . predicts that overall spending on domestic security will climb to $180 billion in 2008 . <p> One problem , says intelligence and analysis firm Provizio ( www.provizio.com ) , is @ @ @ @ @ @ @ @ @ @ out how to sell their products or services to a specific agency . Despite the huge market projections , the market is fragmented with no centralized procurement for homeland-security technologies . Provizio believes this can actually be a good thing : " With the fragmented market , vendors are able to target multiple customers within various agencies and levels of government , " it says . Yet long sales cycles within multiple potential clients will increase vendors ' costs of sales . <p> The federal government has already signaled where it might spend millions on big-ticket items and programs related to homeland security . One is a high-frequency surfacewave radar to detect small maritime vessels and low-flying aircraft . **26;144;TOOLONG is leading its development . While it 's under the Department of Defense 's ( DoD 's ) Counterdrug Technology Development Program Office , it 's being considered as a homeland-security tool . The idea is to provide low-cost , all-weather , accurate , and reliable surveillance of surface vessels and small aircraft well beyond the visible horizon . <p> Similarly , Silicon Graphics Inc. ( www.sgi.com ) and General @ @ @ @ @ @ @ @ @ @ to produce the U.S. Navy 's Area Air Defense Commander Capability System , powered by SGI 's computing and visualization technology , for forward-deployed operations and homeland defense . The system provides military commanders with information from radar and data links into a graphic representation . <p> With the highly publicized success of unmanned aerial vehicles ( UAVs ) in Iraq , homeland-security officials are now seriously considering using them domestically for round-the-clock surveillance . In fact , the DoD is already working with industry and the Federal Aviation Administration ( FAA ) to integrate UAVs into U.S. airspace . <p> " We see this as a multiyear effort , " says Air Force Major Jim McCormick , co-manager of the newly established UAV Interoperability Working Group , which is addressing this issue . The objective , he says , is to establish a common set of rules for the use of UAVs across the U.S. within five years . Boeing ( www.boeing.com ) and the Defense Advanced Research Projects Agency ( DARPA ) have already demonstrated that a UAV controlled from the ground could be integrated into air-traffic-controlled airspace @ @ @ @ @ @ @ @ @ @ opportunities for the industry may come from within the Department of Homeland Security , which is concerned about the threat of missile attacks on passenger airlines . The threat is taken so seriously , the government is considering paying for the installation of antimissile devices on commercial aircraft in the U.S. , which could cost billions of dollars . <p> Analogic Corp . ( www.analogic.com ) has already partnered with Sanders Design International ( www.sandersdesign.com ) to develop and produce an aircraft infrared countermeasures system for commercial airliners against shoulder-fired , heat-seeking missiles . Analogic is also working with Lockheed Martin to market a range of detection products , starting with a device that identifies threat materials to prevent them from being carried onto aircraft in carry-on luggage . <p> Another technology bound to gain from homeland-security concerns is RF identification . Four U.S. companies " NaviTag Technologies ( www.navitag.com ) , Hewlett-Packard ( www. hp.com ) , toy maker Hasbro ( www.hasbro.com ) , and trucking firm Anderson Cargo ( www.andersoncargo.com ) " along with Swiss firm Jungbunzlauer ( www.jungbunzlauer.com ) are already testing a small RF I 'd tracking @ @ @ @ @ @ @ @ @ @ then trucked over U.S. highways . As part of an experiment supported by the U.S. Transportation Department , agents acting as terrorists will attempt to break into the containers . <p> Then , there 's biometrics . A study last year by the U.S. General Accounting Office ( GAO ) identified seven " leading " biometric technologies that could potentially secure the nation 's borders " facial recognition , fingerprinting , hand geometry , iris recognition , retina recognition , signature recognition , and voice recognition . The report concludes that , in addition to privacy and policy implications for increasing security , " the cost of biometric border control would not be trivial . " <p> The DoD 's Biometrics Management Office selected BearingPoint ( www.bearingpoint.com ) to develop technologies that could greatly enhance security at the department 's facilities . A BearingPoint priority is a DoD Common Access Card , which is a computer-chip-based smart card . Distribution of these contactless cards ( meaning they do n't have to be inserted into a card reader ) for certain military units is expected to exceed 4 million this year @ @ @ @ @ @ @ @ @ @ officials , and an area that continues to be studied , is incompatibility in communications . One lesson that came out of the 1993 World Trade Center terrorist bombing is that federal agencies , local law enforcement and fire departments , ambulance services , and the military could not communicate . They each operated with the frequencies assigned to their agencies , unable to talk directly to one another . <p> This resulted in the formation of the Public Safety Wireless Advisory Committee , which spent a year looking at interoperability from every angle , from technology and spectrum allocation to funding . The committee produced a 600-page report . But 10 years later , even after the events of Sept. 11 , 2001 , little has changed . <p> Several organizations and companies are finally on the case . The Telecom-munications Industry Association ( TIA ) has been working with the public safety community to develop standards for public safety wireless communications interoperability . New systems under one of these programs , known as Project 25 , were established to develop voice and data standards for digital public safety @ @ @ @ @ @ @ @ @ @ U.S. , with more being developed . Under Federal Communications Commission ( FCC ) rules , every 700-MHz radio must include Project 25 compatibility . The Pentagon also requires Project 25 for new land mobile radios . According to the Public Safety Wireless Network , a joint effort of the U.S. Departments of Justice and Treasury , 14 states have implemented interoperable emergency communications systems , mostly as a result of post-Sept. 11 pressures . <p> Meanwhile , a guide for public officials titled " Why Ca n't We Talk " Working Together To Bridge The Communications Gap To Save Lives , " was released by the National Task Force on Interoperability ( NTFI ) . The NFTI has called on Congress to create a national Spectrum Trust Fund that would set aside funds from revenue from the sale of radio frequencies to the private sector to help state and local governments coordinate their communications . NFTI is also promoting the passage of the Homeland Emergency Response Operations Act . It would give public agencies the broadcast frequencies Congress set aside for them in 1997 ( from 764 to 775 @ @ @ @ @ @ @ @ @ @ being used by TV channels 63 , 64 , 68 , and 69 . <p> In addition , several industry OEMs have developed and are marketing hardware they claim meets communications interoperability requirements . Transcrypt International 's ( www.transcryptsecure.com ) portable Tactical Interoperability Kit ( TIK ) can link portable and mobile radios operating in three frequencies . M/A-Com ( www.macom.com ) is promoting a scalable , network-based system called NetworkFirst that converts audio signals into IP digital data packets for transmission to regional operating centers . The center would send the messages over a private intranet connecting multiple radio systems . Eventually , says Jay Herther , M/A-Com 's federal market manager , this could be expanded into a nationwide network linking existing systems of all makes , modes , and frequencies . <p> Further progress came in early March when the National Communications System ( NCS ) , responsible for ensuring emergency preparedness communications , formally joined the Department of Homeland Security . The NCS has been a function of the DoD for 40 years . It currently works with U.S. wireless carriers to deploy a Wireless Priority @ @ @ @ @ @ @ @ @ @ services by year 's end . Help may also be on the way from Congress . Legislation recently introduced by Sen. Diane Feinstein ( D-CA ) proposes to set aside $109 million to ensure that fire , police , and other emergency-management services can communicate among themselves . <p> CYBER SECURITY A raging debate at the federal level on cyber security continues . Is it adequate ? Most experts think it 's insufficient , pointing out that the Department of Homeland Security lacks the resources and expertise to secure the nation 's information systems . Government officials insist that 's changing , with information security receiving the highest priority , but they admit that much more work must be done . 
@@21004642 @1004642/ <p> After careful consideration , the latest digital temperature-measurement system from Linear Technology Corp . ( LTC ) , the LTC2986/LTC2986-1 ( see figure ) , stood out as the best in analog for 2016 . The LTC2986 temperature sensor is built on the LTC2983 and LTC2984 " two successful temperature-measurement systems that had won awards in the past . The chip just keeps getting better with the addition of more features , including three new operating modes . <p> The LTC2986-1 is the EEPROM version of the LTC2986 . On-chip EEPROM stores user-configuration data and custom sensor coefficients , eliminating IC or sensor programming by a host processor . <p> LTC claims the 10-channel LTC2986 IC can measure temperatures with 0.1-C accuracy and 0.001-C resolution . To ensure resistive measurements are accurate , current reversal eliminates thermocouple effects in the resistive sensor . <p> The LTC2986 can interface with different types of temperature sensors , including type B , E , J , K , N , S , R , and T thermocouples ; 2- , 3- , or 4-wire resistance temperature detectors ( RTDs ) ; @ @ @ @ @ @ @ @ @ @ . The IC includes all active circuitry , switches , measurement algorithms , and mathematical conversions to determine the temperature for each sensor type . For example , in the case of thermocouples , the IC has high-order polynomial equations built in for all types of thermocouples to convert the voltage output from the sensors into a temperature result . <p> The LTC2986 Multi-Sensor Digital Temperature Measurement System features 10 flexible inputs that make it possible to interchange sensors . <p> - <p> The new operating modes provide better support for external overvoltage-protection resistors that are shared between multiple sensor types , powered temperature sensors with analog outputs , and non-temperature-related sensors like pressure and other voltage-output sensors . <p> The company offers several tools to design engineers who would like to start new projects using the new **30;172;TOOLONG IC . For instance , the DC2531 demo manual is a starter kit for demonstrating the LTC2986 's performance . Also sensor demonstration boards are available for universal temperature measurement , thermocouple , dedicated RTD , and dedicated thermistors . <p> The SPI interface works with multiple digital systems . In @ @ @ @ @ @ @ @ @ @ makes it possible to customize the LTC2986 . Overall , the demo software can help program and run the LTC2986 : It 's able to configure the LTC2986 , check and save the configuration , run the device , output the results into a file , and even create Linduino One-ready C code based on the configuration . <p> The LTC2986 supports operating temperature ranges from 0- to 70-C , " 40- to 85-C , and " 40- to 125-C . The RoHS-compliant device comes in a 7- x 7-mm LQFP-48 package . Pricing starts at $16.56 each in 1,000-piece quantities . 
@@21004644 @1004644/ <h> Fundamentals of Transient Low-Current Measurement <p> The measurement of fast transient voltages is a relatively well-understood and documented procedure . However , the measurement of fast transient currents presents a number of measurement challenges that make them much more difficult than measuring voltage transients . <p> Sep 28 , 2016 Type <p> On-Demand Webinar <h> Speakers <p> Alan Wadsworthpplication EngineerKeysight Technologies <h> Description <p> Why this webcast is important:The measurement of fast transient voltages is a relatively well-understood and documented procedure. - However , the measurement of fast transient currents presents a number of measurement challenges that make them much more difficult than measuring voltage transients. - Digital multi-meters ( DMMs ) and oscilloscopes using either shunt resistors or a current probe are the most common methods for measuring AC current , but they all have drawbacks : <p> 1 . DMMs have limited bandwidth and can not reveal any details about dynamic current behavior <p> 3 . Oscilloscope current probes require degaussing @ @ @ @ @ @ @ @ @ @ a few microamps of current . <p> This webcast will review the above solutions and then explain new techniques and equipment that can support the measurement of transient currents into the nanoamp and picoamp range at 1 Ghz sampling rates and up to 200 MHz of bandwidth . While the primary focus of this webcast is on the characterization of devices and materials , many of the techniques to be discussed are general and can also be applied to other situations ( such as component and module testing ) . <p> Who should view this webcast : Engineers , scientists and researchers that need to make low-level transient current measurements would benefit from attending this webcast. 
@@21004647 @1004647/ <h> Get The Most Out Of ATM Networks With Multicasting <p> Asynchronous Transfer Mode ( ATM ) has evolved from limited field trials to early volume deployment since the introduction of the first commercial product in 1993 . There is a growing recognition in the industry that ATM connections to individual desktop computers will provide significant benefits to users including : <p> * A single network access point for all services <p> * Improved access to multimedia and video conferencing services <p> * Quality and simplified management of services <p> To increase the pace of ATM deployment , perceived barriers such as high cost and the lack of stable specifications for ATM services need to be overcome . The ATM Forum is moving rapidly to finalize key specifications that will make ATM the best option for multimedia applications . The specifications already finalized or soon-to-be finalized are : <p> * LAN Emulation <p> * Private Network Interfaces <p> * Multiprotocol Over ATM <p> * Traffic Management <p> * Switched Virtual Circuit <p> * Voice Over ATM <p> One common service that has become a business driver for the deployment @ @ @ @ @ @ @ @ @ @ increases in Internet access and usage have pushed up bandwidth demand and produced delays and congestion . ATM is an ideal solution for these applications , because it is inherently capable of providing the right quality of service ( QoS ) depending on the requirements . <p> An approach that will enable ATM networks to be the most efficient and cost-effective solution is to use the switching capability of the network more efficiently . Such a scheme , multicasting , is discussed in this article . <p> The major advantage of an ATM network is its ability to transport different types of signals through a single network using a standard cell format . Different classes of service imply various levels of cell priority , such as constant bit rate ( CBR ) , for the transport of delay-sensitive traffic such as voice and interactive video ; variable bit rate ( VBR ) , for delay-insensitive traffic such as data ; available bit rate ( ABR ) , for non-time-critical traffic ; and unknown bit rate ( UBR ) traffic . <p> Different modes of transmission demand support for unicast ( @ @ @ @ @ @ @ @ @ @ can be implemented as a series of multiple unicast links if the network is substantially under-used . But the recent dramatic increases in Internet usage will most likely overwhelm networks using the the unicast approach . It is more economical to use true multicasting than to add more bandwidth and use unicasting . Therefore , the ATM switching nodes will need to provide both priority queueing and multicasting features . <p> Multicasting is an efficient way of reducing the demand on the ATM network and switching bandwidth , thereby reducing the cost per connection . For example , if the ATM nodes do not have multicasting , a user sending an e-mail to coworkers 1 , 2 , 3 , 4 , and 5 must transmit five unicast copies of the same e-mail to five different destinations ( Fig. 1a ) . <p> With multicast functionality , there are different ways the e-mails can be sent . One way is to send a copy to node B , from which it is multicasted to nodes C and E ( Fig. 1b ) . Node C delivers the e-mail to coworker @ @ @ @ @ @ @ @ @ @ where it is delivered to coworker 4 , and passed down to node G , which delivers it to coworkers 1 , 2 , and 3 . <p> Comparing Figures 1a and 1b , the unicast method uses 13 segments of the network while the multicast method uses only five ( Table 1 ) . Therefore , using multicasting in the above example results in a 62% savings on network bandwidth usage . Different amounts of network bandwidth would be saved if other paths are used . The trade-offs would be in the amount of delay and the probability of congestion . <p> Delay in a network is defined as the time it takes for the message to go from the sender to the receiver . The minimum delay is the sum of the time it takes for the message to travel across the links and the queueing time in the nodes . If any of the links in the path become congested , additional delay will be added until the link becomes available , assuming the message is not discarded due to congestion . <p> In normal operation , @ @ @ @ @ @ @ @ @ @ is the absolute time it takes to traverse a path . In the e-mail example above , the use of multicasting sends the e-mail to coworker 1 through a four-node path versus a two-node path using unicast . As a result , the multicasting incurs more node and link delays . If L is the average delay through one node and one link , the average delay using multicast would be 4L . This is the minimum possible delay assuming congestion-free transmission . <p> The total delay is dependent on how many times the e-mail stalls in a node , and the length of the congestion . Today , there is not enough experience with ATM traffic patterns , especially in the Internet service area , to give a definitive figure . However , a first-order estimate is given here to show the potential impact of multicasting . <p> If PCM is the average probability of congestion for any node in multicast mode , and PCU is the average probability of congestion for any node in unicast mode , the probability of congestion-free transmission through the four-node path ( P4F @ @ @ @ @ @ @ @ @ @ ) 4 ( 1 ) <p> The probability of congestion-free transmission through the two-node path ( P2F ) using unicast is : <p> P2F = ( 1-PCU ) 2 ( 2 ) <p> The probability of congestion in a network with multicast capability is smaller than with unicast only--in this example 62% lower . Therefore : <p> For any given probability of congestion PCU , the chance of having a congestion-free transmission is always higher using multicast than unicast , even though with multicast , the path is twice as long . <p> Therefore , using multicasting increases the probability of congestion-free transmission . Alternatively , the network can support more users for a given desired probability of congestion . The trade-off is longer absolute minimum delay . <p> Within an ATM switching node , the cell processing is usually partitioned between the switching fabric and the interfacing line cards . Cells received on an incoming link are either stored in input buffers waiting to be routed to outbound links , or routed directly to output buffers . There are several types of ATM switch architectures which deliver various levels @ @ @ @ @ @ @ @ @ @ concerns in switch node design is how effectively multicast and broadcast functions are supported . <p> Two options are : to queue up the cell in the input or output buffers within the switch fabric , or forward the cell to the queues in the interfacing line card . Although the first method results in very simple line cards , the disadvantages are an added memory requirement in the switch buffers , or an increase in blocking probability . <p> The advantages of the second method are lower memory requirement and less blocking probability in the switch fabric . On the other side , the disadvantage is the higher degree of complexity in an interface card design , such as the requirement for multiple virtual-circuit ( VC ) address translation before sending the cell to the multicasted terminals . The implementation of VC address translation requires a large amount of memory in the form of either a hashing function or content addressable memory ( CAM ) . <p> Unfortunately , the current ATM physical layer standard ( UTOPIA ) favors a simple interface card design that does not support either @ @ @ @ @ @ @ @ @ @ to provide support for multicasting in both single- and multi-PHY UTOPIA . The key is to transmit the data with the multicast information , i.e. which channels will receive the cell . Two methods are presented here . The direct method uses an inband multiport indicator ( Fig. 2 ) . Each bit location is associated with a port . For example , the presence of a 1 in any bit of the 6-bit multiport indicator indicates that the corresponding port is selected . The inband multicast indicator can be carried anywhere in the ATM cell header . Figure 3 shows an example of using the HEC byte to carry the multicast indicator . <p> To ensure that cells containing voice or video information are not delayed by less urgent messages , priority queueing is necessary . Usually four queues per port are enough to support CBR , VBR , ABR , and UBR traffic . <p> One way of providing priority in UTOPIA is to encode the priority inband . Priority can be carried in any two bits within user-selectable locations in the ATM header . For these two @ @ @ @ @ @ @ @ @ @ while 11 represents the lowest priority . Cells in the highest priority queue are sent as output first until the queue is empty , before a cell from the second priority queue is sent , and so on for all four queues . <p> A major challenge in communications system design is accommodating continuous changes in customer needs . One such need is the 25 Mbit/s ATM interface to the desktop . To add a 25 Mbit/s interface capability to an ATM switch node , the engineer must decide how many lines terminate in an interface card , which functions are necessary , and what level of loading is required for the switch fabric . <p> One of the most popular transport signals today is the OC-3 SONET/SDH signal . The OC-3 signal uses a 155.52 Mbit/s line rate that can carry a maximum ATM cell payload rate of 149.76 Mbits/s . The maximum ATM cell rate that can be carried in a 25 Mbit/s ATM signal is 25.126 Mbits/s . Six channels of 25 Mbit/s ATM signals would have a maximum cell rate of 150.75 Mbits/s , just 0.66% @ @ @ @ @ @ @ @ @ @ six channel 25 Mbit/s ATM concentrator with some buffering is a logical and economical way to supply ATM to a community of users ( Fig.5 ) . This design uses simple line physical layer devices that provide the basic transmission-convergence ( TC ) sublayer and physical-media-dependent ( PMD ) sublayer functions . <p> Figure 6 shows another example of an ATM concentrator where the multicasting and priority capabilities are added to the physical-layer device . TranSwitch has successfully implemented a 208 pin PQFP VLSI device , SALI-25C , to provide the transmission convergence sublayer function , with up to 4000-cell buffering , multicasting , and multipriority for use in this type of concentrator . <p> Due to its built-in QoS capabilities , ATM is an ideal technology for multimedia applications . The cost effectiveness of ATM can be improved further by using newer technology , integrating more functions in a single VLSI device , and adding features such as multicasting and priority queueing in the ATM network . The implementation of the multicasting and priority functions in an ATM switch node requires careful consideration of the switch node 's internal @ @ @ @ @ @ @ @ @ @ desired probability of congestion in the transmission link . <p> Even though the current ATM physical-layer standard , UTOPIA , lacks support for multicasting and priority , there are ways to supplement the UTOPIA standard to provide these two functions in the physical layer . This allows the system designer the freedom to place these functions in the physical layer , the ATM layer , or in the switch fabric . 
@@21004652 @1004652/ <h> Flash-Based Microcontrollers Are Rapidly Taking Charge <p> Flash memory-based microcontrollers have changed the landscape for embedded applications . Programming speeds and access times have improved . Flash reliability is no longer a concern in all but the most demanding environments . Flash memory-based microcontrollers have effectively knocked off one-time programming ( OTP ) technology and are even beating out ROM-based solutions in some security-conscious environments . <p> Mark Buccini , MSP430 product line marketing manager for Texas Instruments , indicates that while ROM-based microcontrollers account for about half the current shipments , flash-based microcontrollers have garnered more than three quarters of new design wins . <p> Flash memory technology has proven especially cost-effective for designs that require smaller quantities . David Lamar , senior marketing manager for microcontroller products at NEC Electronics , says flash-based microcontrollers are often used in an initial production run where ROM may eventually be used for cost savings . This gets products to market quickly and provides flexibility in terms of updates while products gain the benefit of field testing . <p> Flash memory technology 's nonvolatile nature makes it the perfect complement @ @ @ @ @ @ @ @ @ @ enables field updates and storage of relatively static information , like configuration settings . <p> Flash-based microcontrollers are expected to dominate the world of embedded applications for at least a few years to come . While contenders are under development , like Motorola 's MRAM , they 're only in the experimental and testing stages ( see " MRAM : A Replacement For Flash ? " p. 54 ) . <p> Because microcontroller environments are very demanding in terms of reliability , price , performance , and power consumption , general adoption of these new technologies will take years . Flash-based microcontrollers are typically available in the same form factor with the same pinouts as OTP- and ROM-based solutions . This has allowed flash-based microcontrollers to be used interchangeably . If new technology is implemented in the same fashion and does n't have special power or pinout requirements , then the speed of acceptance will be improved significantly . <p> If employing flash memory were simply a matter of including a block of silicon , there would not be such a variety of products . The figure shows how flash-based @ @ @ @ @ @ @ @ @ @ performance , reliability , and programming time , among other things . Flash-based microcontrollers usually include at least one of these techniques . A number of these are typically found on high-performance or very low-power microcontroller products . <p> Low Power : ROMs consume very little power and are nonvolatile to boot . But flash-microcontroller designers keep pushing down the power re-quirements , making power less of an issue when choosing a microcontroller . Geoff Lees , director of marketing for Philips Semiconductor , says the LPC900 microcontroller draws as little as 1 -A in power-down mode and just 2 to 10 mA at full speed , depending on the peripherals used and the processor clock speed . This low-power operation is based upon a design that minimizes flash power requirements without resorting to additional hardware , such as instruction caches . <p> Microchip 's nanowatt technology addresses lower-power operation by applying multiple design techniques . These range from multiple power-management modes to support for a number of selectable clock sources . Slowing down the processor reduces system power consumption , including power necessary for flash-memory access . <p> Microchip @ @ @ @ @ @ @ @ @ @ provides low-power operation and long- term data retention ( on the order of 40 years ) . To improve manufacturability , the PEEC cell utilizes a merged cell with a Fowler Nordheim tunneling region instead of a defined tunnel dielectric window . The single transistor architecture performs more like a two-transistor flash architecture in terms of reliability . <p> Cyan Technology takes a different approach to minimizing overall system power requirements . Cyan 's eCog employs an SRAM instruction-caching system . SRAM consumes less power than flash and has a faster access time . The cache reduces the number of flash memory accesses with its associated increase in power consumption . Typically , there 's a charge pump drain of a few milliamps when flash memory is accessed . Caching is employed by a number of systems , usually to increase processor execution speed . <p> The eCog 's cache allows programmers to lock code in the SRAM cache . Normally , a cache will toss out old code to make space for new code . This can be a problem for interrupt response . If the main application prevents @ @ @ @ @ @ @ @ @ @ time and power consumption will increase . Locking the interrupt code in the SRAM makes power and speed usage predictable . <p> Combine this with a downshift to a lower clock speed , and the eCog consumes only 10 -A . This approach works very well for battery-operated , radio-based mobile devices where a device is typically waiting for a message . When the eCog detects incoming information , it can switch to high-speed mode , unlock the cache , and receive and process the data . This let 's the eCog support even high-powered devices that idle the 802.11 interface for long periods . <p> High Performance : Flash memory provides the nonvolatality and reprogrammability that designers demand , but fast access and cycle times are not a big selling point . Flash memory designers continue to wring out as much performance as possible , although it 's unlikely that flash memory will ever challenge SRAM , the other memory found in every microcontroller , in terms of speed . <p> One way to deliver code to the processor core faster is to use a flash memory that is wider @ @ @ @ @ @ @ @ @ @ 16 , and 32 bits are standard for flash memory arrays in microcontrollers . But Philips Semiconductor 's new 32/16-bit microcontroller family , based on the 32-bit RISC ARM processors , uses a two-transistor cell because it 's more rugged and requires a lower voltage than a single-transistor approach . Additionally , it has a minimum retention time of 10 years and memory cells that are protected from such disturbances as programming adjacent cells . The microcontrollers will employ a 128-bit wide flash memory bus that 's four times wider than the RISC instructions . <p> Cygnal Integrated Products also gives its 25-MHz flash memory a boost of four times , enabling the 8051 processor core to run at 100 MHz . The company uses a 32-bit wide flash memory to supply the 8-bit instruction stream to the processor , but this is only a start . A 4-byte prefetch buffer provides sufficient buffering to allow sequential access to the flash memory at the 100-MHz rate . <p> Moreover , Cygnal includes a 64-entry instruction cache to keep things moving when the application execution varies from a sequential flow . @ @ @ @ @ @ @ @ @ @ processor to run at full speed as long as code is accessed sequentially , or the code is contained in the instruction cache . <p> Ubicom 's 120-MIPS ( millions of instructions/s ) IP2202 needs to run at top speed in many communications environments , which is why it packs two banks of SRAM . One bank can be used for program memory if an application explicitly moves code from flash memory to SRAM . Applications can run directly from flash memory , but only with corresponding hits in performance and power . The trick for programmers is to keep frequently executed code in SRAM . This is n't too difficult given the availability of 16 kbytes of SRAM for the task . The split between code and data in this SRAM was arbitrarily decided upon to allow developers to trade off faster execution speed for more data space . <p> Making It Secure : While lower power and high speed are the usual considerations associated with flash-based microcontroller designs , security is an often overlooked feature . A number of different security issues come into play with flash microcontrollers @ @ @ @ @ @ @ @ @ @ many whose intellectual property is frequently the main distinguishing factor in many products based on flash microcontrollers . Another issue is the prevention of improper read or write accesses . Restriction of read access enables data to be hidden or encrypted while the prevention of accidental writes protects an application from overwriting itself . <p> With regard to securing application code , Eugene Feng , business director of application specific product group for Silicon Storage Technology ( SST ) , says that flash memory is more sensitive to physical dissection than ROM . So while a determined pirate could crack open a chip and access a ROM directly , accessing a flash memory in this way will usually corrupt its contents . <p> SST 's FlashFlex51 family of 8051-compatible microcontrollers uses the company 's SuperFlash CMOS technology . Its SoftLock feature prevents flash memory updates . The feature is en-abled by setting an address in flash memory for the routine allowed to perform the updates . Knowing the address for this routine , how it works , and where it 's located will be necessary to update the flash memory @ @ @ @ @ @ @ @ @ @ 's in-application programming ( IAP ) . IAP has a deterministic write time and can employ a dual- block configuration , which allows writes to occur in one block while another block accesses program code . <p> Switching blocks could be a problem for interrupts that implement an interrupt vector in flash memory . SST addresses this possibility by allowing interrupts to be redirected to a different flash-memory block . <p> Because SST 's sector size is just 64 bytes , it requires fine-grain control . But the small sector size also eliminates the need to update much larger blocks ( 64 kbytes for many other systems ) . <p> Another feature of the SuperFlash technology , soft partition support , let 's data be stored in flash memory that 's not used for program memory . A DMA engine and mailbox register interface enables the use of flash memory as data storage without significantly affecting program execution . The interface moves data in the background instead of requiring an application to wait for the completion of flash memory writes . <p> Whatever the embedded-system design needs " low power , @ @ @ @ @ @ @ @ @ @ to deliver the features . As a result , flash memory-based microcontrollers will be the primary choice for embedded-system designs for many years to come . 
@@21004653 @1004653/ <p> In power electronics , design engineers strive to deliver more power in a more efficient manner , and in smaller footprints at all stages of the power-delivery chain , from the smart grid to the end application . When it comes to the dc-dc link , several factors in particular are driving designs toward increased power density . <p> The move to portables and wearables in multiple fields is one such driver . Medical equipment that once had its own room now arrives at the patient 's bedside on a cart . Desktop PCs are now tablets . And , of course , every generation of fitness band seems to cram more features into a smaller , thinner space . <p> In fixed-base installations , big data and the growth of the cloud has driven a massive expansion in server capacity ; Amazon alone is estimated to have over 1.4 million servers , and Google uses over 260 MW of power yearly . Denser , more efficient power conversion is a key component for reducing server energy costs , and that includes cooling " one of the largest @ @ @ @ @ @ @ @ @ @ there 's a drive toward ever-smaller devices operating at higher speeds following the curve predicted by Moore 's Law , now more than 50 years old . In 1971 , Intel 's 4004 , the first commercially available microprocessor , had a circuit density of 192 transistors/mm2 , compared to 8.4 million transistors/mm2 in the current-generation Xeon Haswell-EP . <p> Smaller devices operate at lower voltages and higher speeds . Although the current consumption per transistor decreases , overall consumption tends to increase since each device has so many more transistors . In response , power-supply converter designs are moving toward lower voltage , higher current , and quicker response to transient load variations . To cut resistive power losses , the trend in large-scale server and telecom applications is to employ an intermediate voltage " say , 12 or 24 V " combined with multiple point-of-load ( POL ) dc-dc converters . <p> - <p> Many systems require multiple voltages and power levels . For example , the PMP11399 is a complete PMBus power system for three ASIC/FPGA cores , DDR3 core memory , VTT termination , and auxiliary @ @ @ @ @ @ @ @ @ @ a 12-V/300-W power supply with nine POL buck converters supplying six different voltages : 5 , 3.3 , 1.5 , 1.2 , 1 , and 0.85 V. Power levels range from 260 mW to 60 W. <p> Developments in three areas are allowing designers to boost dc-dc performance while simultaneously increasing power density : more efficient control topologies ; more efficient power transistors ; and high-density three-dimensional packaging . <p> More Efficient Topologies <p> From the design standpoint , there are a couple of ways to get more power out of a smaller package. - One is to use fewer conversion stages . To achieve this , though , the converters must offer a large ratio of input voltage to output voltage ( VIN-to-VOUT ) . For example , a 10-to-1 ratio permits stepping down a 12-V input to as low as a 1.2-V output , while a 5-to-1 ratio only allows step-down to 2.4 V. If a device requires power at 1.2 V , then a 10-to-1 converter is needed for a single-stage solution . <p> Another way to reduce size is by increasing the converter 's switching frequency @ @ @ @ @ @ @ @ @ @ However , a tradeoff must be considered : A higher switching frequency can result in a more compact design , but it also causes extra switching losses that decrease efficiency and affect thermal performance . <p> The series-capacitor buck-converter topology meets these conflicting demands by blending high-frequency operation with a high VIN-to-VOUT ratio and high output current ( Fig. 1 ) . Without compromising operating efficiency , the capacitive conversion topology drastically reduces size , allowing the design of more compact applications , or the option to pack more features into the same space . The new topology also reduces the bill of materials , which can lower the overall system cost . <p> 1 . A standard synchronous buck topology uses two FETs Q1 and Q2 and a single inductor L ( a ) . A capacitive conversion topology ( b ) is a two-phase design with four power FETs , two inductors ( La and Lb ) , and a series capacitor Ct current flow alternates between the two inductors . ( Source : Texas Instruments ) <p> - <p> The capacitive conversion topology merges a switched-capacitor circuit @ @ @ @ @ @ @ @ @ @ requires one extra capacitor ( the series capacitor Ct ) compared to a conventional two-phase buck converter topology , but offers several advantages such as automatic current balancing between the inductors and lower switching losses . <p> The series capacitor Ct functions in a similar manner to the energy transfer capacitor in a SEPIC converter . As Ct alternately charges and discharges , and the FET power switches ( Q2a and Q2b ) open and close , the current flows alternately through the two inductors in four time intervals to establish a steady-state output at the appropriate stepped-down voltage level . <p> The voltage across the capacitor is nominally 50% of VIN , minimizing switching power losses , since a lower voltage swing results in less power loss per cycle . This enables higher-frequency switching with smaller inductors and capacitors , saving system space and weight . <p> The two-phase operation means that the on-time of both high-side switches is double that of a regular buck converter . This is particularly helpful in high-frequency , high-conversion ratio applications , because it allows for more precise control and minimizes the effect @ @ @ @ @ @ @ @ @ @ . The TPS54A20 two-phase converter features a selectable per-phase switching frequency of up to 5 MHz and efficiency &gt;90% . The value of Ct is a function of desired voltage ripple and switching frequency ; multilayer ceramic capacitors are a good choice as they have low ESR , low ESL , and an extended temperature range . ( Source : Texas Instruments ) <p> - <p> As an example , the TPS54A20 ( Fig. 2 ) is a two-phase , synchronous series capacitor buck converter optimized for low-voltage applications from a 12-V supply . Small , low-profile inductors significantly reduce PCB area and height . An adaptive control architecture provides fast transient response and accurate voltage regulation at up to 10-MHz operating frequency ( 5 MHz per phase ) . A phase-locked loop ( PLL ) locks switching signals to a reference oscillator to maintain fixed frequency operation during steady-state conditions . <p> New Power FETs Ease Transition to Higher Frequencies <p> Since power MOSFETs first made their appearance , performance levels have improved in each succeeding generation by concentrating on reducing the major power losses " switching , conduction @ @ @ @ @ @ @ @ @ @ , the most common technology , offers drastically lower switch resistance ( RDS(ON) ) than earlier DMOS devices . This reduces the conduction loss but at the cost of increasing the other three losses , which are due to internal capacitances . Consequently , designers must choose between a low operating frequency to optimize the efficiency or a high frequency to increase power density . <p> NexFET , a third-generation macrocell power MOSFET technology developed by Texas Instruments , offers an RDS(ON) comparable to TrenchFET , but reduces the parasitic capacitances by about 50% ( Fig. 3 ) . Low capacitances mean low input gate charge and short voltage transients during switching , allowing for an increase in operating frequency . <p> The NexFET improvement is most advantageous at 30 V and below , which is well suited for the distributed POL bus architectures popular in server and telecom applications . <p> 3D Packaging Boosts Power Density <p> Increasing converter power density requires improving some key power packaging metrics . For example , reducing the parasitic capacitance and inductance is key to increasing switching frequency . And , of course @ @ @ @ @ @ @ @ @ @ <p> For higher power levels , each component must be optimized ; a multichip module ( MCM ) combines a controller and power FETs into a single package for the most power-efficient overall solution . Originally , MCM designers were restricted to two dimensions , but new packages are placing components on top of each other in a three-dimensional arrangement ( Fig. 4 ) . <p> 4 . Combining the controller and power FETs into a single three-dimensional package can significantly save on board space , 60% in this example ( Image Source : Texas Instruments ) <p> - <p> Three-dimensional packaging has several electrical and thermal performance benefits , as long as the individual components lend themselves to the arrangement . In a synchronous buck converter , the NexFET 's vertical current flow makes it ideal for stacking . The high-side FET source terminal is then located directly above the low-side FET drain terminal , virtually eliminating resistance and parasitic inductance between the devices and enabling faster switching . In addition , the low-side source terminal is at ground potential and can be soldered directly to the exposed pad @ @ @ @ @ @ @ @ @ @ 5 . The PowerStack 3D package includes both high- and low-side power FETs and a control module . The stacked arrangement is smaller and has superior parasitic and thermal performance than a side-by-side MCM solution . ( Source : Texas Instruments ) <p> The CSD87381P , for example , is a NexFET half-bridge power block optimized for synchronous buck applications with 5-V gate drive . This device can deliver up to 25 A with appropriate airflow and heat sinking . It is available in a 3- + 2.5-mm package , and has excellent thermal performance with a measured thermal resistance junction-to-case ( ++JC ) of 1.65-C/W and thermal resistance junction-to-air ( ++JA ) as low as 84-C/W . <p> The TPS548D22 is a 40-A synchronous buck converter in a PowerStack package suitable for storage , telecom , or similar digital high-density POL applications . The converter input-voltage range is from 1.5 up to 16 V , and VDD input-voltage range extends from 4.5 to 22 V. Output voltage ranges from 0.6 to 5.5 V. <p> Figure 6 shows a simplified application schematic . The switching frequency can range from 424 @ @ @ @ @ @ @ @ @ @ a switching frequency of 650 kHz achieves a good balance between small solution size and high efficiency . <p> With low voltages and high currents dominating in large-scale server and telecom applications , it 's critical to make the most of limited board space by increasing the power density of POL synchronous buck converters . <p> The optimum solution draws on multiple fields : new converter topologies , new MOSFET technology , and new packaging designs . After careful consideration of the tradeoffs , engineers can then determine the best combination of features for their applications . 
@@21004656 @1004656/ <p> Because most of today 's digital logic , mixed-signal , and analog circuits include a voltage reference , designers must understand how references operate and how to choose from among the available types . From the many specifications that characterize a voltage reference , it 's important to know which are necessary for a given application , and why they fill the need . <p> The 1s and 0s of digital circuits , for example , are distinguished by thresholds that correspond to a logic high or logic low . Such applications do n't require discrete-component zener or band-gap references . Instead , the 1s and 0s are determined by a " reference " consisting of the internal base-emitter voltage drop ( VBE ) of a bipolar transistor in TTL circuits , or by the gate-source voltage drop ( VGS ) of a MOSFET in CMOS circuits . <p> In a mixed-signal device , like the ubiquitous analog-to-digital converter ( ADC ) or digital-to-analog converter ( DAC ) , the voltage reference can be included on the chip or provided externally . For purely analog circuits , such @ @ @ @ @ @ @ @ @ @ at the desired level by comparing the known value of a built-in reference to the feedback or error signal . <p> A simple voltage detector can be made from a comparator and two inputs : one for the signal to be monitored , and the other for a voltage representing the trip point . This trip level can be set by a pair of resistors or by an internal/external voltage reference . A pair of resistors makes a simple reference , but the resulting voltage is at the mercy of the source driving the divider and of the stability of current drawn from the resistor-divider node . By contrast , a Maxim MAX917 voltage detector contains a comparator and an internal voltage reference . <p> The main types of voltage references are based on the zener diode , the buried-zener diode , and the bandgap device ( Table 1 ) . Each type can be configured as either a two-terminal shunt topology or as a three-terminal series topology . Zener diodes , or those diodes intended to operate in the reverse-bias region , require a series current-limiting resistor . Zeners @ @ @ @ @ @ @ @ @ @ . The BZX84C2V7LT1 zener , for ex-ample , has a nominal VOUT of 2.7 V , but it varies from unit to unit , from 2.5 to 2.9 V , a tolerance of about -7.5% . <p> The MAX6330 , a shunt device with power-on-reset output , avoids some of the drawbacks of zeners ( Fig. 1 ) . It has a tight initial accuracy ( within 1.5% or better ) over the full IOUT range of 100 -A to 50 mA . As with all shunt devices , designers should consider the following factors when selecting a proper shunt resistor , RS : <p> Designers should choose the highest nominal resistor value for RS that yields the lowest current consumption . The design safety has to accommodate the worst-case tolerance of the resistor used : <p> The following general power equation ensures an adequate power rating for the resistor : <p> A shunt topology always draws ILOADMAX + ISHUNT , whether or not a load is present . On the other hand , shunt references have an advantage . By properly sizing RS , the same shunt can operate @ @ @ @ @ @ @ @ @ @ in the range of 10 to 60 -A . <p> The principle behind bandgap references is the summing of two VBE voltages . Because one voltage has a positive temperature coefficient ( TC ) and the other a negative TC , their sum at the output has a zero TC ( Fig. 2 ) . Of course , actual output TCs never equal exactly zero . IC design , packaging , and manufacturing-test capabilities all affect the output TC . With care , though , it 's possible to attain reasonably low VOUT TCs between 5 and 100 ppm/-C . <p> The absence of an external resistor in a three-terminal bandgap or other series-mode voltage reference simplifies the design and minimizes power consumption . But it is n't possible to simply insert the reference on a board and forget about it . The surrounding circuitry might require special performance from the reference . A -5% power supply and an 8-bit data-acquisition system , for instance , place much looser demands on the reference as opposed to a micropower system where current consumption must be as low as possible for each @ @ @ @ @ @ @ @ @ @ the MAX6025 or MAX-6192 draws a supply current of only 35 -A maximum , which is virtually independent of IOUT . <p> A digital system with 16-bit resolution , for example , has an LSB size of one in 65,536 ( 15.26 + 10G6 or 15.26 ppm ) . If the ADC is a 16-bit device with a full-scale input of 0 to 5 V , it can resolve inputs down to 1 LSB , approximately 76.3 -V . <p> To cope with noncorrectable errors like noise , the reference should contribute very low noise so that every bit of ADC resolution counts . Good choices for this purpose are the MAX6150 ( 35 -V p-p ) , MAX6250 ( 3 -V p-p ) , and MAX6350 ( also 3 -V p-p ) . Each contributes less than 1 LSB of noise in a 16-bit measurement . One alternative is to oversample and average the measurements , but that approach has its own limitations . Plus , it consumes processor power and increases system cost . <p> Output-voltage temperature hysteresis ( THYS ) is another noncorrectable error . THYS is @ @ @ @ @ @ @ @ @ @ due to sequential but opposite temperature excursions ( from hot to cold and then cold to hot ) . <p> With its amplitude directly proportional to the temperature excursion , THYS can be very troublesome . In many situations , circuit design and packaging of the voltage-reference IC make this error nonrepeatable . One such situation appears in a MAX6001 reference where the three-pin SOT23 package has a typical THYS of 130 ppm . But a similar IC reference ( MAX6190 ) in the larger , more stable SO-8 package exhibits only 75 ppm of THYS . <p> Temperature drift can usually be accommodated because it 's generally a very repeatable error . High-resolution systems typically require compensation anyway . In order to keep a 5-V , 16-bit system within -1 LSB over the commercial temperature range ( 0- to 70-C , with a 25-C reference point ) , the reference drift must be better than 1 ppm/-C . For instance : <p> + " V = 1 ppm/-C + 5 V + 45-C = 255 -V <p> This performance is acceptable for a 14-bit system operating over the commercial @ @ @ @ @ @ @ @ @ @ requirements of a 16-bit system ( Table 2 ) . <p> Long-term stability ( LTS ) provides an indication of the extent to which latent die stress or ion migration exists in a package or family of devices . Furthermore , circuit-board cleanliness over the extremes of temperature and humidity can strongly impact this parameter . LTS is valid only at the reference temperature of 25-C . <p> Another troublesome parameter is one that specifies the ability of a voltage reference to source and sink current . Most applications require the reference to source current to the load . Yet , many references ca n't sink current . Consequently , the output voltage can drift due to IBIAS and leakage currents if they exceed the current-sink capability of the reference . <p> The challenge of system design lies in balancing the tradeoffs of cost , size , precision , power consumption , and the like . Although they entail a larger bill of materials , the more expensive component-based systems , when implemented properly , require less compensation and calibration after the design is in production . 
@@21004659 @1004659/ <h> Planar Transformers Make Maximum Use Of Precious Board Space <p> Power supplies have limited the minimum size that electronic systems can attain , relying as they do on large transformers with large ferrite cores and magnet wire windings . By their very design , planar transformers ease this limitation and allow designers to achieve the low profiles required for pc-board mounting in space-constrained applications . In addition , their construction endows them with more unit-to-unit repeatability , high power-density capability , higher-frequency operation , and high efficiency . While the disadvantages are few , it is important to understand the device 's basic construction to fully appreciate its capabilities and potential drawbacks . <p> Wire-Free Design Planar transformers are so compact because they are made from copper leadframes and flat , continuous copper spirals instead of copper magnet wire wound around conventional ferrite cores . The spirals are etched on thin sheets of dielectric material and stacked on flat , high-frequency ferrite cores to form the transformer 's magnetic circuit ( Fig. 1 ) . Next , the core material is bonded with a low-grain-diameter epoxy to minimize @ @ @ @ @ @ @ @ @ @ as Kapton , within the stack of spirals ensure high isolation between windings . While the leadframes are used to mechanically secure the transformer in place ( because it is of low mass ) , for high-shock/vibration applications , the flat ferrite cores can be bonded to the pc-board using double-sided polyester tape . Connections to the outside circuit , such as the power semiconductors , are made by standard pc-board pins . <p> Mechanical Features It is this construction that gives the planar transformer its characteristically low profile , which usually ranges from between 0.325 to 0.750 in . This makes them especially attractive to power-supply manufacturers working within tight space restrictions . <p> The planar transformer 's pc-board construction means that once the circuit-board components are designed and stamped for a planar device , the windings of subsequent transformers in a production run will be spaced exactly the same distance from each other ( Fig. 2 ) . This design allows planar transformers to be manufactured with automated assembly equipment , greatly improving device unit-to-unit repeatability and yield in production runs with tight specifications . Conventional transformers are @ @ @ @ @ @ @ @ @ @ in the spacing of the windings , along with the vagaries of manual assembly , can contrive to produce wide variations in device performance . <p> The uniformity and predictability of planar transformers has the added advantage of making them simpler to model than conventional transformers . This especially applies when using **26;204;TOOLONG ( CAE ) tools such as SPICE modeling . <p> With excess weight an on-going problem in the typical power-supply design , the planar 's ability to reach weights as low as 0.6 oz. per 100 W has made it a key component in many lightweight designs . <p> While the planar transformer has many advantages , its development was initially hampered by the need for custom cores , pc-board windings , and isolators . However , this attitude is changing as the devices gain acceptance . <p> Electrical Characteristics Planar transformers offer efficient operation at high switching frequencies , typically reaching 97% efficiency at switching frequencies through 500 kHz . Their maximum operating frequency can reach as high as 1 MHz ( with low flux density ) . The flat windings are the key to their @ @ @ @ @ @ @ @ @ @ improve the device 's power-density capabilities . <p> Because conventional transformers generally rely on round-wire windings around a ferrite core , the copper conductor is not efficiently used . This is due to a phenomenon known as skin effect . Skin effect occurs when induced currents and magnetic fields cause current in a round conductor to concentrate near the thin outer surface " or skin " of the wire , especially at higher frequencies . As a result , the total current-carrying area is less than the full wire area , making the ac resistance greater than the dc resistance by an amount determined by the skin thickness . <p> In a planar transformer , however , the " windings " are actually flat conductive traces formed on copper-clad pc-boards . As a result , the current tends to concentrate toward the outer edges , but it still flows through the entire conductor , with improved overall current density compared to a cylindrical ( wire ) conductor . The end result is that a planar transformer , with its flat windings , can achieve higher efficiency in much smaller sizes @ @ @ @ @ @ @ @ @ @ parasitic reactances , such as interwinding capacitance and leakage inductance ( typically under 0.5% ) . The low leakage inductance is achieved by splitting , which puts part of the primary winding in one place , such as the top , part of the winding at the bottom of the stack , and then evenly sandwiching the secondary windings on both sides of the stack . <p> In wound designs , leakage inductance is difficult to control . The low stray capacitances and leakage inductances go a long way toward reducing high-frequency ringing in a planar transformer 's output voltage . This construction " with conductive circuits stacked on dielectric sheets " also allows a planar transformer to achieve good primary-to-secondary and secondary-to-secondary dielectric isolation . The devices can accommodate a wide range of input voltages , and can be specified with one , two , or three outputs . They also meet or exceed the performance requirements of offline converters <p> Designing With Planars Because current-carrying capability is a concern in an SMPS , planar transformers typically employ 4-oz. copper-clad circuit boards for their internal winding forms . The @ @ @ @ @ @ @ @ @ @ other sections of an SMPS . The copper used in a 4-oz. copper circuit board is 5.6 mils thick , or 2.8 mils from the center to the surface . In a circular conductor , the current skin depth for copper at 70-C can be obtained from the equation : <p> where S is the skin depth in centimeters , and f is the operating frequency . This works out to be a little over 5 mils at an operating frequency of 250 kHz . It appears to leave little room for error with 4-oz. copper boards . <p> However , the planar cross section of 4-oz. copper must be converted to circular mils ( as with wire tables ) to make for a more meaningful examination of skin depth and current density for a given operating frequency . A circular mil is the area occupied by a circle with the diameter of 0.001 in . Just divide the area in square inches by 0.785 x 10-6 . <p> At higher current densities ( and output power levels ) , 4-oz. copper may not be robust enough . Most circuit-board @ @ @ @ @ @ @ @ @ @ order . Pc-boards can also be paralleled to double the wire size . 
@@21004660 @1004660/ <h> Take Advantage Of Fast Ethernet PHY Testing <p> Today 's increase in computing power , coupled with the ability to share applications and data , has driven the modern networking infrastructure to new levels of speed and sophistication . Having emerged as the leader in desktop networking , Fast Ethernet is able to bring much needed bandwidth to users , while maintaining the integrity of Ethernet . <p> Adopting physical-layer conventions from the fiber distributed data interface ( FDDI ) , Fast Ethernet has leveraged existing technology into the framework of a carrier-sense **35;232;TOOLONG ( CSMA/CD ) network , preserving users ' and administrators ' knowledge of network operation . Coexisting with installed network devices , Fast Ethernet has become both legacy-compatible and capable of providing future migration to 100-Mbit/s connections as users upgrade their interconnect systems . Consequently , it 's brought about a slew of testing and interoperability concerns . <p> The IEEE has provided the standards by which the physical-layer and physical-medium devices must perform . Mixing this with interoperability testing of existing devices provides a robust environment for determining the overall fitness of the @ @ @ @ @ @ @ @ @ @ backwards interoperability , shows that the network is evolving as a tool that maintains data integrity without compromise . <p> In addition to the IEEE standards , the University of New Hampshire Interoperability Lab , Durham , N.H. , has formed a Fast Ethernet consortium . Members may have their products tested in a series of both IEEE and interoperability scenarios " testing that has become a necessity for any company developing Fast Ethernet systems . Let 's review the basics of Fast Ethernet testing . Covering methodologies to real examples will provide an understanding of the challenges faced in meeting IEEE conformance . <p> The logical place to begin physical-layer testing is with the individual system , i.e. , the network host or adapter . Testing is then done in a contained environment . Typical vehicles for testing Fast Ethernet physical-layer ( PHY ) and transceiver devices are media-access units ( MAUs ) or network interface circuits ( NICs ) . The MAU is useful , because network test equipment frequently comes ready to test devices via a media-independent interface ( MII ) connection . Board-level testing should allow @ @ @ @ @ @ @ @ @ @ to the magnetic devices and RJ-45 connector . At the board level , other non-connection related issues may be addressed , such as power consumption , footprint , and external component count . <p> The basic equipment required for performing tests on Fast Ethernet physical layers includes an MII-based test platform , such as the Netcom Systems ' X-1000 or Smartbits system . Testing also demands accurate voltage and current generators , as well as an oscilloscope , multimeter , and various types of cables and terminations . <p> The mechanism through which these multispeed devices configure the appropriate speed is auto-negotiation . It 's actually a process through which the part signals the far-end station . Using 10-Mbit/s fast link pulses ( FLPs ) , it then configures to a predetermined speed option or the highest common denominator . Auto-negotiation also let 's devices distinguish between FLPs and normal link pulses ( NLPs ) , so there 's no confusing 10-Mbit/s data with the auto-negotiation process . <p> In addition , the part can sense " idles " in 100-Mbit/s systems . It therefore does not miss a **28;269;TOOLONG 100-Mbit/s-only @ @ @ @ @ @ @ @ @ @ that a 10-Mbit/100-Mbit system with auto-negotiation should be capable of communicating with any other 10-Mbit/100-Mbit Ethernet device . <p> Robust physical-layer devices need to be able to operate with non-standard-compliant , as well as compliant , auto-negotiation devices . Early implementers of non-standard 10-Mbit/100-Mbit devices used a technique known as speed sensing to configure to the appropriate speed . With that technique , the host device first sends out 10-Mbit/s data and then 100-Mbit/s data alternately . That way , it can see how the far end responds . If available " many speed-sensing systems are still in place " testing should include the use of these devices . They definitely provide an added dimension of test data . <p> By default , it 's become commonplace to perform certain tests on Fast Ethernet devices . Few people , however , understand the purpose of these tests and their relevance to the network . An example of this is the cable-length test . <p> It 's normal to run PHY devices up to 130 m of cable . After all , the IEEE specification calls for 90 m of cable @ @ @ @ @ @ @ @ @ @ And first-generation Fast Ethernet devices worked up to this distance , so people have been conditioned to test to that limit . <p> The EIA/TIA specification requires that all PHYs be able to receive a compliant signal through 90 m of CAT-5 cable , plus an additional 10 m of CAT-5 patch cable through at least four jacks in the setup . That test alone does not ensure that the part will function correctly at any other distance or temperature variations . <p> Every physical-layer evaluation should include tests from 0 m through at least 130 m of CAT-5 cable in 10-m increments . Some devices have deficiencies in the midrange cables . Unfortunately , these distances are common in many smaller offices . At any distance , the result should be correct auto-negotiation , a link , and an extremely low bit error rate . By understanding the test better , as well as what it exercises in the design , you will see it as a more powerful tool " not just a checklist requirement . <p> More often than not , there 's some combination of improper @ @ @ @ @ @ @ @ @ @ which a signal is somehow deficient has a negative effect on network performance . In the best case , that part of the network segment is n't capable of talking with the rest of the network , but does n't interfere with its operation . If the situation is that non-standard format signals are sent across the network , other problems arise . <p> Say the entity is a node connected to a workgroup-level repeater . Then , the entire workgroup sees the " garbage " the node is transmitting . Most likely , this garbage is propagated up to a more intelligent repeater or switch capable of partitioning the node . Or , if the repeaters are configured in a stack arrangement without a management unit , quite a few workgroups would be exposed to the bad data . The net result would be a loss of bandwidth . <p> Looking into the network from a system perspective , there are other limitations that must be tested to ensure proper operation . A transceiver sending out a signal that 's been compromised " by return loss , VOD , @ @ @ @ @ @ @ @ @ @ the burden of receiving that signal on the far end . <p> Remember , a sound **26;299;TOOLONG device should be able to work with all other devices currently on the network " IEEE compliant or not . This is where the interoperability testing mentioned previously plays a large part . If the host system is a multiport device such as a repeater , it places itself in a position to " repeat " bad information , as well as non-standard information . <p> Every designer should have a basic battery of tests that can be run on PHY devices prior to beginning a design . That way , he or she can judge the fitness of the part . The tests below should help to construct this test suite . <p> Test 1 : Return Loss . Transmit return loss is calculated using a network analyzer measuring the reflections from the transmit drivers of the PHY ( Fig. 1 ) . This results in a combination of both the front-end transformer and the physical-layer device . The reflection combines with the attenuated signal , crosstalk , flat-channel loss , and @ @ @ @ @ @ @ @ @ @ far-end receiving physical-layer device . <p> Test 2 : Rise Time/Fall Time . Measuring the rise and fall times of the transitions is vital . The standard " ANSI specification X3.363 TP-PMD 9.1.6 Rise/Fall Times Symmetry " calls for parts with 3- to 5-ns rise/fall times . A sharp rise time will help with cable distances and give you a margin if you need to slow it down to help with emissions . The difference between all measured rise/fall times must be less than 0.5 ns . Most likely , a part that exceeds this symmetry specification will help with EMI compliance . <p> The DUT should be set to transmit scrambled MLT-3 idle signals . Now , measure the 10% to 90% rise and fall times of the differential signal . All measured times should be between 3 and 5 ns . Rise/fall symmetry should be less than 0.45 ns . If the rise and fall of the differential signals are added together , they should equal a constant voltage . Any delta from that constant becomes a common-mode spike . In the EMI realm , that 's a @ @ @ @ @ @ @ @ @ @ designer to be FCC-compliant . The more symmetrical the rise and fall time , the smaller the common-mode spike . <p> Test 3 : BER Testing For 10/100 Mbits/s . BER testing is one of the main tests for both 10-Mbit and 100-Mbit systems . It ensures packet reception under the environments in the test . That 's the basis for the cable-length test employed by most people ( Fig. 3 ) . <p> BER testing should be performed for both 10-Mbit and 100-Mbit rates . During this test , it would help if the DUTs were subjected to worst-case environments . This includes -20 to +90-C , as well as 10% above and below voltage levels . <p> An MII cable allows the DUT to be placed in a temperature chamber . Two DUTs should always be used . Using only one with a loopback cable does n't take ppm variations of the clock into account . The clock ppm difference of the two DUTs should be at worst 100 ppm . Test every distance between 0 and 130 m of cable . Many physical-layer devices have holes in @ @ @ @ @ @ @ @ @ @ not surprising to see an area of several meters " 40 to 45 m , for example " where the part does not function at all . <p> The part also may be exercised over both voltage and temperature by means of a power-supply and temperature chamber . Over temperature , the cable changes attenuation , causing a part that may work one day to fail the next at the same cable length . Although the specification calls for a total of 90 m plus a 10-m patch , cable , jack , and connector , variations over temperature should call for extra margin . <p> When checking error rates , use the largest legal size ( 1514 bytes ) and minimum gap ( 9.6 -s for 10 Mbit , 960 ns for 100 Mbit ) . This has data on the wire for the longest period of time . Also , utilize incremental and F0F0 byte patterns . The F0F0 pattern causes the worst-case transitions on the part 's MII bus . <p> Test 4 : Power-Supply Sensitivity . Through this test , the designer can see what may @ @ @ @ @ @ @ @ @ @ a more complicated/noisy environment than the MII MAU . When included with power-supply and temperature variation , it also may be used in combination with the previously mentioned tests ( Fig. 4 ) . <p> Most physical-layer-device MII MAUs have power split into separate VCC planes . A signal generator coupled with a slew-rate-controlled buffer can inject noise into a system . All frequencies should be injected into each and every isolated plane . Some physical-layer devices need a clean or regulated power supply to function properly . Test cable length and BER with a noisy system . It 's likely that cable length will decrease as noise to the system increases . <p> Test 5 : Receive Equalization/Jitter . This one 's more complicated than the previous tests , but very useful in exercising the physical-layer device in worst-case scenarios . The key to most of these devices is their ability to properly receive and decode a signal , however distorted it may become , from the network . This test is becoming more widespread as users start to understand the importance of exercising the receive equalizer , as @ @ @ @ @ @ @ @ @ @ be able to meet the worst-case TP-PMD specification ( Fig. 5 ) . <p> Starting with basic ideal binary data , it 's then modified to reflect a certain set of parameters . For a worst-case scenario , those parameters would include ppm drift , rise/fall time , jitter , cable loss/phase delay , transformer effects , crosstalk , etc . The end result is a waveform representing a packet that has been modified with the above parameters . <p> For converting the data , it 's typical to use a tool like Mathcad . The modified data is sampled and converted to a series of analog voltages " hence an analog waveform . This waveform is supplied to the analog waveform generator , and sent to the DUT via BNC cables connected to the Receive differential signals . The ability of the DUT to properly receive the packet is then analyzed using the network analyzer , in this case a SmartBits type of tester . An external power supply tests the DUT 's performance over different voltage ranges . <p> When evaluating a 10/100 physical layer , the first @ @ @ @ @ @ @ @ @ @ subset of TP-PMD testing . This will allow you to test , in part , the transmitter of the device . First , get a look at the transmit waveforms of the device while it 's transmitting 100-Mbit idles . Optimally , all measurements should be done at the RJ-45 . With a BNC-to-RJ45 cable , this is easily done . If using simple oscilloscope probes , the next best option is hooking to the transmit out pins on the cable side . <p> Other system-level tests can be run by routing the signal through intermediate devices , such as repeaters and switches . Multiple nodes can connect through a hub . A generic view of the system performance can be gathered by monitoring each node 's ability to transmit and receive with that hub . Then , interoperability can be tested by attaching nodes from various vendors to the hub and alternating cable distances , etc . This type of system-level testing can be quite extensive and time-consuming . Unfortunately , it 's usually not done thoroughly until user problems arise . <p> While 10-Mbit and 100-Mbit physical-layer and @ @ @ @ @ @ @ @ @ @ test labs like that of the University of New Hampshire can provide much-needed help . The results are stable , interoperable networks that operate with the same degree of reliability as existing 10-Mbit/s environments . And they provide for future operation at 100 Mbits/s . <p> By applying the above tests , the designer can quickly evaluate the performance of a physical-layer device , as well as understand how much work will be required to implement that solution in a system-level design . Having passed the above tests , the Enable Semiconductor 5VSingle , 3VSingle , and 3VCardbus devices ( now available from Lucent Technologies ' Microelectronics group ) each reflect successful IEEE and UNH testing . They may be used as a benchmark for testing similar physical-layer devices . <p> The tests outlined in this article serve as a beginning to understanding and testing physical-layer devices . Once that basis is understood , the designer can appropriately grasp , in conjunction with other IEEE and interoperability testing , the limits of the physical-layer device and design networking systems . <p> University of New Hampshire : UNH provides system-level testing @ @ @ @ @ @ @ @ @ @ growing and includes a very adequate section on auto-negotiation at this time . It also has a variety of vendors ' products that it can use to do interoperability testing . 
@@21004661 @1004661/ <h> Learn about the Fundamentals of Clocks <p> Join us on Thursday , March 23rd , for Fundamentals of Clocks , an introduction to clocks and frequency synthesis , clock terminology , timing and common applications . We will discuss Phase-locked loops ( PLL ) , Analog PLLs , Digital PLLs and Direct Digital Synthesis and there will be live Q&amp;A . <p> Mar 14 , 2017 <p> Join us on Thursday , March 23rd , for Fundamentals of Clocks , an introduction to clocks and frequency synthesis , clock terminology , timing and common applications . We will discuss Phase-locked loops ( PLL ) , Analog PLLs , Digital PLLs and Direct Digital Synthesis and there will be live Q&amp;A. 
@@21004663 @1004663/ <h> Burn-In Issues <p> Just how important in terms of power-supply product reliability is the quality and repeatability of the assembly process ? Don Gerstle explains . <p> Don Gerstle Jun 30 , 2005 <p> Users of power-supply products demand increasingly high levels of reliability and performance . Although the suppliers of individual components can confidently provide impressive life and reliability data , the compound effect on overall reliability can be significant when a large number of individual components are combined in a module such as a power supply . <p> Perhaps more important in terms of product reliability is the quality and repeatability of the assembly process . Solder joints , connectors , and mechanical fixings are all potential origins for product failure . In use , operating temperature and other environmental factors also affect the longevity and reliability of a power supply . <p> Burn-in and various other forms of life and stress testing help provide the data to enable power-supply manufacturers to continually improve the reliability of their products . Indeed , when analysed correctly and fed back into the design and assembly process , the @ @ @ @ @ @ @ @ @ @ burn-in process and can even demonstrate that burn-in is not necessary to achieve the target reliability for a particular product . <p> THE BURN-IN PROCESS The purpose of the burn-in process for power supplies is to weed out " infant mortalities " " as seen in the first portion of the well known " bathtub curve " of failure rate versus operational time ( Fig. 1 ) . These latent , early life failures are attributable to intrinsic gross faults within the bought-in components , assembly errors , and faults induced in components by inappropriate handling ( e.g. , ESD damage ) . It should be noted that there are certainly no absolutes in the world of reliability testing , only probability and confidence levels for large populations . <p> Hence , there is never a guarantee that the burn-in process catches all infant mortalities . In fact , some problems need to be seen in functional testing <p> The conventional approach to power-supply burn-in over many years has involved running the supplies at an elevated temperature , often the maximum rated operating temperature listed in the product data specifications @ @ @ @ @ @ @ @ @ @ latent defects is accelerated . <p> The supplies are run under full load with power cycling , and the input voltage run at either the maximum or minimum voltage to provide either maximum voltage stress or maximum current stress , depending on the design topology . Care in the choice of conditions is necessary as , for example , some components in some topologies can see more stress at light loads , such as snubber networks in variable frequency converters . Some ingenuity can also be applied . For example , if a product is intended to operate normally with forced air , it could be run in still air at light load and continue to achieve comparable temperature stress levels . <p> Data logging and analysis of the units under test is important to determine whether a failure has occurred , and if so , when . If all failures actually occur within minutes of a 48-hour burn-in sequence , there would be very good reason to know about it , shorten the time , and increase throughput while saving energy . It is normal for companies such as @ @ @ @ @ @ @ @ @ @ to ensure that any changes in performance are identified . <p> This can also show whether there are any intermittent problems . Understanding and using burn-in data to modify product design and manufacturing processes can result in improved reliability and yield that will be reflected in future data collected from burn-in . <p> Experience in burn-in testing has shown that thermal cycling precipitates more infant mortalities than a constant elevated ambient , although the sets of failures do n't completely overlap . Thermal cycling with a dwell time at each thermal extreme is , therefore , the preferred process . Increasing the thermal rate of change precipitates more failures in fewer cycles ( Fig. 2 ) . Generally , care must be taken to ensure that the products are not stressed outside of their ratings in the often untypical environment of burn-in . If overstressed , some useful life of a good product could be " used up " and at worst , hard or latent failures could actually be induced in otherwise good product . <p> At C&amp;D Technologies , the burn-in process normally starts with a duration of @ @ @ @ @ @ @ @ @ @ time of burn-in when no failures occur after a set number of hours . Depending on the product 's complexity and topology , a decision is made to reduce the future burn-in hours by half after 200 to 500 units have gone through the process with no failures occurring in a quarter of the current burn-in time . This process is continued until the burn-in time is reduced to two hours , where it is held for the remainder of production . Some argue that burn-in can be eliminated when no failures occur after multiple production builds . However , it could be argued that this removes the insurance against a group of defective components being used and/or a process anomaly occurring . <p> In volume production of parts that are known to have a significant infant mortality rate , perhaps because of the degree of manual assembly , a regime of variable burn-in can be used . In this case , failures are expected , but when a pre-calculated period of failure-free operation of a batch has elapsed , burn-in is terminated . <p> HASS AND HALT Some manufacturers @ @ @ @ @ @ @ @ @ @ types of burn-in described do n't eliminate , within a reasonable time , all of the failures seen to occur in the early life of a power supply . Also , conventional burn-in does n't provoke early failures that could be a result of the shock and vibration of shipping and handling . <p> To combat this , a more aggressive HASS ( Highly Accelerated Stress Screen ) can be used that applies mechanical , thermal , and electrical stress typically beyond product ratings but within design margins . Acceleration factors of more than 40 over conventional burn-in have been claimed for this method , giving correspondingly shorter test times . A problem , however , is that the stress levels are so extreme that there is a risk of damaging good product with hard or latent failures . <p> In answer to this , the HALT ( Highly Accelerated Life Test ) process was designed to identify the real damage limits in a product by stressing the product to failure with temperature extremes , thermal cycling , progressively higher levels of vibration , and then a combination of thermal @ @ @ @ @ @ @ @ @ @ limits of the power supply are identified . These operating limits are then used to set the lower HASS test levels . <p> HALT is also used extensively during product development to identify potential weaknesses in the design . The test equipment required to do HALT must typically ramp temperature between " 55 to +125C while applying six-axis linear and rotational random vibration . This requires a major capital investment and is often subcontracted to specialist test houses . <p> THE NO BURN-IN PRODUCTION MODEL As described earlier in the article , once burn-in failures have reduced to a certain level , some manufacturers feel that the process can be dropped completely . This can be considered only if the manufacturing process is entirely predictable and the quality of bought-in material is such that it has no gross latent intrinsic defects . Although commodity components approach this quality level and modern manufacturing quality control can minimise process variations , there is still a real risk that a customer may see some early life failures . The cost of this in terms of goodwill has to be weighed against the costs @ @ @ @ @ @ @ @ @ @ tests may be employed on small numbers of units to gauge whether all infant-mortality failures has been identified , on-going life tests are run for up to six months on 25 to 50 units at a moderately elevated temperature . These tests are normally only utilised when there are large quantities of units built on a continuing basis , and can give an estimate of the intrinsic reliability of a product in service " that is , MTBF . It should be emphasised that real field failure rate is the most accurate measure of the reliability of a product . <p> A calculated MTBF can be compared with the demonstrated figure obtained through burn-in to check for consistency . <p> The important point to note is that quality and reliability can not be tested in or inspected in . Burn-in testing is ultimately another inspection process but serves as a mechanism for process control and feedback . Failures in burn-in along with field failures prompt failure analysis and corrective action , to ensure that the product design and process have been centred and optimised to provide the best product possible @ @ @ @ @ @ @ @ @ @ yields give higher product reliability , happier customers , and lower warranty return costs . 
@@21004664 @1004664/ <h> Design Engineers Battle The Dark Side Of Electromagnetism <p> Today 's higher population densities on pc boards , faster switching speeds , and greater switched power contribute to the increased probability of interference between circuits , modules , and systems . This means emissions requirements are much tighter . Design engineers now recognize the need for more rational and effective bypass and decoupling strategies as they combat the dark side of electromagnetism . <p> The old " rabbit 's foot " approach of sprinkling capacitors around the board proves much less effective under the new conditions , possibly even aggravating an existing problem . All capacitors , leads , and board traces have associated series inductance which , at the higher switching rates , is neglected at one 's peril . These formerly negligible reactances can interact with the capacitance to produce not only zeroes , but also poles that could yield unpleasant or mystifying results . <p> We approached this issue in a previous article ( " Tuned Decoupling Tames Noise In Switching Circuits , " Electronic Design , July 6 , 1998 , p. 42 ) @ @ @ @ @ @ @ @ @ @ pc-board trace inductance to specific frequencies that we desired to suppress . The article detailed the advantages of the technique as well as the caveats of employing it . Here , we revisit tuned decouplers and look at the use of discrete inductors to improve and extend the decouplers ' effectiveness . <p> Effective decoupling requires that the decoupler provide the ac content of the switched current while the main power source supplies the average current , and therefore , all of the energy . In this way , high-frequency currents stay off of the power and ground buses and remain confined to small ( decoupling ) loops near the target , thereby minimizing emissions . Therefore , the primary analytical tool is a model based on an ac-current-source representation of the switching component , or network ( Fig. 1 ) . In this model , iO is the ac current through the switched unit , iS is the part of iO that flows through the inductance LS of the power-bus trace , and Z is the impedance of the decoupling network . The response iS(f)/iO(f) is obtained from this @ @ @ @ @ @ @ @ @ @ was possible with a hardware implementation ( Fig. 2 ) . Top-side ( component ) traces were sized for desired inductance value , according to the formulas of Rostek ( " Avoid Wiring-Inductance Problems , " electronic design , Dec. 6 , 1974 , p. 62 ) . The entire bottom side of the board was used for the ground plane . <p> The power bus was connected to a 10-V dc power source and was bulk-decoupled by two 47--F tantalum capacitors at the connection point . The 2N7000 FET switch was driven by a 5-V square wave at a 1-MHz rate with a 50% duty cycle . A magnetic field probe monitored radiation off of the power-bus trace , and the obtained information was displayed on a Hewlett-Packard spectrum analyzer . <p> For additional insight , a Spice model of the hardware was used to study the various decoupling configurations . In all Spice runs , 100 cycles of the driving signal were sufficient to attain steady-state values . Three circuit representations were studied , and in general , the three stood in agreement . <p> The three basic @ @ @ @ @ @ @ @ @ @ branches ( Fig. 3 ) ; a pi filter with series discrete inductor and trace-tuned , capacitor-based parallel branches ( Fig. 4 ) ; and an LC filter with discrete series inductor and trace-tuned , capacitor-based parallel branches ( Fig. 5 ) . <p> The capacitors C1 and C2 , shown schematically in these figures , were MuRata Erie radial-leaded ceramic devices , made with X7R dielectric . The reactances represented by L1 and L2 are trace and/or lead inductances . The reactance represented by LX was implemented with Coilcraft 90-13 axial-leaded inductors . <p> Any 1--F ceramic capacitor has an inherent antiresonance ( i.e. , minimum impedance ) at 5 MHz , indicating an intrinsic inductance of about 1 nH . Adding 24 nH of series trace/lead inductance yields the antiresonance at about 1 MHz . Similar considerations hold for a 0.033--F capacitor , which has an inherent antiresonance at 27.5 MHz . <p> For convenience , the investigation assumed that the spectral region of concern extended from the fundamental ( 1 MHz ) to the fifth harmonic ( 5 MHz ) . You can find the empirical results @ @ @ @ @ @ @ @ @ @ 6 , 7 , 8 , 9 and 10 . The pole frequencies were computed from the ac model . Additional plots of hardware results can be accessed on the Web at www.elecdesign.com . <p> Tuned decoupling networks can very effectively suppress emissions produced by switching circuits . A single-branch tuned decoupler acts to quench emissions by producing a zero at the frequency to which it 's tuned . Additionally , it can reduce emissions at higher frequencies . Compare Figure 7 and Figure 11 with Figure 6 ( the no-decoupling case ) . When a single frequency dominates the emission pattern , a single-branch decoupler tuned to the offending frequency obtains a good quench . <p> Reacting With Trace Inductances The designer must realize that the single-branch decoupler will interact with power-bus trace inductance and ground-return trace inductance ( if the latter is n't negligible ) to produce a resonance ( pole ) at a frequency less than that of the decoupler 's zero . So , sufficient energy at frequencies in the neighborhood of this newly created pole could result in a new emissions issue . <p> A @ @ @ @ @ @ @ @ @ @ separate frequency , quenches emissions at both tuned frequencies by producing zeroes at these frequencies . It can also reduce emissions at frequencies that are greater than the higher of the two tuned frequencies . For examples , see Figure 8 and Figure 12 . <p> Like the single-branch de-coupler , the dual-branch version produces a pole at a frequency below that of the lower of the two zeroes . Plus , it produces a pole at a frequency that 's intermediate between the frequencies of the two zeroes . Energy at frequencies in the neighborhood of either new pole could then become a complicating factor in the EMC picture . These same statements can be generalized for n-branch decouplers ( n &gt; 2 ) for situations in which it 's desired to quench emissions at n number of different frequencies . <p> A series inductor placed between the two branches of a dual-branch decoupler creates a pi filter . Depending on the value of the series inductance and/or juxtaposition of the parallel branches , this filter can either move the pole out of the frequency range of concern ( @ @ @ @ @ @ @ @ @ @ low-frequency zero ) , or move the pole to a different frequency within the range of concern . If the L1-C1 branch in Figure 4 is the decoupler 's low-frequency-zero branch , the pole will be moved out of the range of concern ( assuming a sufficiently large series inductance ) . For an illustration of this , check out Figures 9 and 13 . Also , compare Figure 8 and Figure 12 . <p> On the other hand , if the L1-C1 branch is that of the high-frequency-zero , the pole will move to a different frequency within the range of concern ( see item #8 in the table ) . In either case , the pi filter also suppresses emissions at frequencies greater than that of the decoupler 's high-frequency-zero . <p> The LC filter in Figure 5 can be a very good multifrequency decoupler ( Fig. 10 , again ) . For complete effectiveness , the tuned parallel branch ( the " C " part of the filter ) should be tuned to a frequency that 's less than or equal to the lowest frequency in the @ @ @ @ @ @ @ @ @ @ failing to meet this criterion is shown in Figure 15 . <p> Both the pi filter and the LC filter efficiently suppress multiple frequencies . In each case , the price is the insertion of a discrete inductor in series with the power trace . This inductor must be physically large enough to carry the average current and some of the ac current without going into magnetic saturation . <p> The decouplers might interact with parasitic reactances or among themselves ( as we have seen in the dual-branch case ) to produce new resonances and potentially complicate the suppression effort . For instance , a single-branch decoupler may interact with parasitic reactances , or with the decouplers of nearby switching circuits to produce poles at intermediate frequencies . <p> The response equations , derived from the ac model , have proven themselves as good predictors of decoupler performance ( see the table ) . They can be used to analyze the effectiveness of a given decoupler configuration . Furthermore , they have the capability to serve as a decoupler design tool . <p> Let 's pause for a brief review @ @ @ @ @ @ @ @ @ @ configurations . For a single-branch decoupler ( Fig. 3a , again ) , we have : <p> where : <p> is a zero of the response and : <p> is a pole . In our specific example , the decoupler 's f1 is equal to 1.0066 MHz , which is slightly off antiresonance at f = 1 MHz . <p> For the dual-branch decoupler ( Fig. 3b , again ) in which the branches are tuned to different frequencies , f1 and f2 , we have Equation 4 . The f1 is given by Equation 2 , where : <p> and : <p> is the frequency at which iS/iO = 1 , and the pole frequencies fP1 and fP2 are obtained from the roots of the denominator of Equation 4 . <p> For the pi filter shown in Figure 4 , we use Equation 7 . The f1 and f2 are given by Equations 2 and 5 , respectively , and fS is given by Equation 6 . The pole frequencies are the roots of the denominator of Equation 7 . <p> Here 's an instructive example of the progressive @ @ @ @ @ @ @ @ @ @ . For convenience , we assumed the frequency range of concern extended from the fundamental ( 1 MHz ) to the fifth harmonic ( 5 MHz ) . Because the switching signal has a 50% duty cycle , the spectrum of interest is concentrated at 1 , 3 , and 5 MHz . Any content at 2 or 4 MHz would be attributable to the nonzero rise and/or fall times of the switching signal . <p> The table summarizes the response results and pole frequency results for 10 of the 13 decoupler configurations . Response ratios and pole frequencies for the model prediction were obtained directly from the appropriate equation . The response ratio for the test results were computed from the test data , as shown in the following example for item #4 . The computation is based on the following relationship : <p> Note the generally good agreement in results between the circuit representations for a given decoupler ( see the table , again ) . Only for items #2 ( 1 MHz ) and #11 ( 3 MHz ) do the responses differ by a factor of @ @ @ @ @ @ @ @ @ @ isolated power source from the current switch than is the case for item #2 ( heavier filtering at 1 MHz ) , the hardware circuit more nearly approaches the circuit of the ideal current source used in the ac model . Agreement between analytical and empirical results is close in these cases of greater isolation . <p> It is n't clear why the result is very different for the third harmonic in item #11 . Interestingly , the Spice result is close to the test result for Item #2 ( as expected ) , and the Spice result is close to the model prediction for item #11 . Evidently , in the case of item #11 , the resonance in the hardware located near 1 MHz is considerably narrower than the models predict . <p> No Decoupling : The results of operating the circuit without decoupling are shown in Figure 6 . For convenience , we designated the response at each frequency of interest equal to zero dB . <p> Single-Branch Decoupling : The results of decoupling the circuit with a single branch , tuned to 1.0066 MHz , are @ @ @ @ @ @ @ @ @ @ The degree of filtering increases as one moves from item #2 to item #3 , as does the portion of iO provided by the decoupler . <p> Ideally , a single branch decoupler , tuned to a specific frequency , will supply all of the current for that particular frequency with minimal filtering . In reality , the decoupler in this example is tuned somewhat off 1 MHz . Hence , the theoretical impedance of the decoupler is nonzero at 1 MHz . In addition , even at antiresonance , there 's a residual impedance in the decoupler , making for a nonzero component of iS at the target frequency . For these reasons , the heavier the filtering , the greater the amount of iO provided by the decoupler . <p> With the exception of its overly optimistic result for the fundamental of item #2 , the ac model offers an accurate prediction of the actual hardware outcome for single-branch decoupling . <p> Dual-Branch Decoupling : The results of dual-branch decoupling the switching circuit appear in items #4 and #5 of the table . One of the duals is @ @ @ @ @ @ @ @ @ @ . Comparing the test results of #4 to those of #2 , we find two things . <p> First , the decoupler of item #4 provides much greater suppression of the fundamental than does #2 . It also provides greater suppression of the fifth harmonic than do either of the item #2 or #3 circuits . This is as expected , because its second parallel branch is tuned to 5.06 MHz . But a resonance is now created at about 4 MHz , and this resonance is broad enough to cause the third harmonic to spike . The ac model helps us to see that this should be expected . <p> Second , the heavier filtering of the decoupler of item #5 suppresses the response at all three of the odd frequencies , compared to the item #4 decoupler . It matches the best results of items #2 and #3 decouplers at 1 MHz and 3 MHz , and it significantly improves on those results at 5 MHz . The resonance still exists at about 4 MHz , as predicted by the ac model and corroborated by Spice . This @ @ @ @ @ @ @ @ @ @ the current increases ( via a change in rise/fall time or in duty cycle ) . <p> Pi Filter : One means of moving the resonance caused by the dual-branch decoupler out of the frequency range of concern is by constructing a pi filter , obtained by separating the dual branches of Figure 3b with an appropriate-size inductor . This construction can be seen in the circuit of Figure 4 . In addition to being of at least a certain minimum inductance value , the inductor must be chosen so that it wo n't saturate at the expected current levels . <p> With L1 = 25 nH , C1 = 1 -F , L2 = 30 nH , C2 = 0.033 -F , and LX = 1 -H , the item #6 decoupler shifts the 4-MHz resonance of the item #4 circuit into the 800- to 900-kHz range . The responses at 3 MHz and at 5 MHz are almost quenched . But , the response at 1 MHz undergoes a substantial increase , compared to the item #4 results , because it then resides in the neighborhood of the @ @ @ @ @ @ @ @ @ @ at least directionally , from the ac model . <p> The heavier filtering of the item #7 decoupler virtually quenches the responses at all three odd frequencies . It moves the resonances to still lower regions of the kilohertz range . <p> The decoupler of item #8 exchanges the parallel branches of the item #6 decoupler about LX . This results in the 1-MHz and 5-MHz responses being quenched while the 3-MHz response increases slightly from its item #6 value . Consider the resonance that appears for the circuit of item #8 . This frequency was found by figuring out the roots of the denominator in Equation 7 . We obtain a resonance at around 3.7575 MHz . <p> This range-of-concern resonance is quite narrow . Its influence appears in the slight increase in the response at 3 MHz for item #8 compared to that of item #6 at 3 MHz . Given the suppression advantage that the lightly filtered item #8 configuration enjoys over the lightly filtered item #6 configuration , it may be worth the risk of accepting a weak resonance in the frequency range of concern by @ @ @ @ @ @ @ @ @ @ #6 circuit , but also over the heavily filtered item #7 decoupler . This would achieve a lower component count/cost . Keep in mind , though , that when the higher-frequency branch is placed first to the voltage source , a resonance , however weak , remains in the frequency range of concern . <p> As a final consideration for the pi decoupler , we investigated the question of a minimum value for LX , which would be the smallest inductance capable of moving the resonance out of the frequency range of concern . Using the decoupler from Figure 4 ( with L1 = 25 nH , C1 = 1 -F , L2 = 30 nH , and C2 = 0.033 -F ) , the ac model found the minimum LX value , 368 nH , which is the LX value that zeroes the denominator of Equation 7 at f = 1 MHz . The Spice method found 340 nH for minimum LX . Furthermore , inserting LX = 333 nH into our hardware model yielded the result of Figure 14 . <p> LC Filter : The generic LC filter @ @ @ @ @ @ @ @ @ @ ( item #9 ) and the heavily filtered ( item #10 ) versions provide good suppression . Also , both produce resonances well below the frequency range of concern . In fact , the lightly filtered item #9 decoupler results in suppression matched only by the higher-parts-counts configurations of items #7 , #8 , and #10 . On a cost-effective basis , the configuration of item #9 is the decoupler of choice for multifrequency suppression . <p> The results obtained with the decoupler of item #11 illustrate the importance of careful tuning ( in this case , tuning the parallel branch to a frequency equal to or less than the lowest frequency value of concern ) . The resonance at 864 kHz is sufficiently strong and wide to cause a spike , rather than a suppression , in the response for the 1-MHz component of iS . <p> One may legitimately ask why we spent so much time studying the pi configuration if the simple LC filter is so effective and cost-effective as a multifrequency decouple . Well , several reasons come immediately to mind . First , the pi @ @ @ @ @ @ @ @ @ @ So , it 's essential to know its strengths and its weaknesses . <p> Consider the case of a single-branch tuned decoupler too , as in Figure 3a . If a parasitic reactive branch occurs in parallel with that decoupler , and that parasitic branch is antiresonant at a frequency other than where the decoupler produces a zero , a situation like the one in Figure 3b would result . A pole would develop at an intermediate frequency . Plus , increased emissions could occur if the new resonance multiplies one of the harmonics of iO . <p> A similar situation would result if the second parallel branch , rather than being parasitic , was the tuned decoupler of a nearby circuit that was switching at a rate other than that of the first circuit . In such instances , one might want to consider introducing a series inductance ( LX ) , observing all of the points required to make the introduction effective . <p> Another potential cause of those " unintended consequences " so familiar to EMC workers is an LC decoupler on a nearby circuit . This @ @ @ @ @ @ @ @ @ @ like that shown in Figure 4 , with the possibility of the various undesirable outcomes described in the Pi Filter section . <p> Whether it 's with or without discrete inductors , tuned decoupling can be a useful way to suppress electromagnetic emissions from switched circuits . It 's important , though , to carefully choose and design decouplers in order to obtain the optimum effect in a given situation . 
@@21004665 @1004665/ <h> Wireless LANs Explode With A Kaleidoscope Of Options <p> From IEEE Standards , to HomeRF , to personal-area networks like Bluetooth , users will be unthethered like never before . <p> Patrick Mannion May 28 , 2000 <p> Since the FCC opened up the spectrum in the 2.4-GHz band for unlicensed use , companies such as Proxim , Lucent , and Symbol Technologies have led the charge of proprietary wireless connectivity solutions into vertical markets . These include **25;327;TOOLONG , government , and educational institutions . Only recently have solutions started to leak into the enterprise and consumer markets . From all indications , however , the trickle is about to become a flood as companies rally around wireless local-area-network ( WLAN ) standards such as 802.11b and HomeRF , and personal-area networks ( PANs ) like Bluetooth . <p> Devices based on each of these standards are in various stages of rollout . Each has its own demons to overcome in terms of cost , performance , interoperability , security , and overall implementation . In addition , as these devices proliferate , there 's much concern @ @ @ @ @ @ @ @ @ @ only heightened by proposals to widen the instantaneous bandwidth of frequency-hopping ( FH ) systems to allow for higher data rates . It could be argued that widening the FH bandwidth is a good thing . The sooner the 2.4-GHz band gets overcrowded , then the sooner the jump will be made to the much-anticipated 5-GHz band , which still remains tantalizingly at bay . <p> Though the various WLANs face many complicated problems , the possible solutions are a welcoming match of variety and elegance . All of these solutions are designed to improve the performance , lower the cost , and shrink the size of upcoming designs , while making the devices more user-friendly . <p> At the forefront of chip development for 802.11b is Intersil . With its Prism II chip set , the company has been one of the leading suppliers of chip solutions to OEMs such as Symbol Technologies . Symbol has incorporated the Prism II into its Spectrum24 11-Mbit/s line ( see opening photo ) . <p> Originally introduced as a five-chip set , the Prism II takes advantage of higher integration and Intersil @ @ @ @ @ @ @ @ @ @ the baseband processor and the media-access controller ( MAC ) ( Fig. 1 ) . Dubbed the Prism 2.5 , the solution brings the chip count for a complete solution down to four . Available this summer , the Prism 2.5 weighs in with a bill-of-materials ( BOM ) cost of roughly $50 for a reference design . <p> Why DSSS ? Both Intersil and Symbol have myriad reasons for focusing on the direct-sequence , spread-spectrum ( DSSS ) -based standard of 802.11b . But both agree that the high data-rate capability of DS , plus the fact that it 's an approved , ratified standard at this point , is a really strong selling point . At this stage , no high-rate standard exists for frequency-hopping spread-spectrum ( FHSS ) , which remains at the original 802.11 specification of 1 to 2 Mbits/s . That goes along with FCC regulations specifying that an FH radio has to hop 79 channels and have an instantaneous bandwidth of 1 MHz . <p> This has been a thorn in the side of FH developers . The laws of physics and communications theory @ @ @ @ @ @ @ @ @ @ neighborhood of around 2 Mbits/s . While it 's possible to encode more bits per symbol , the energy per bit increases , thereby violating the FCC 's output-power limitation . Spread spectrum is limited to an output power of 1 W , though most radios use lower-power outputs , in the 100-mW range . <p> The DS modulation scheme specifies three , non-overlapping channels , with a 22-MHz bandwidth . This wide bandwidth per channel allows up to 8 bits per symbol , to give an aggregate throughput of up to 11 Mbits/s . But in reality , much like 10Base-T Ethernet , this may only reach 4 to 7 Mbits/s . <p> DS itself refers to taking a pseudo-random-noise ( PN ) code , and using it to directly spread the waveform . The 802.11 standard specifies Barker , or 11-bit , codes for 1 and 2 Mbits . For higher data rates , complementary code keying ( CCK ) is used " six bits in the code , then two more bits by rotating the waveform 90- , using quadrature phase-shift keying ( QPSK ) . <p> @ @ @ @ @ @ @ @ @ @ of Ethernet , MIS departments are taking a closer look at WLANs as a viable augmentation to their networks . According to John Hughes , director of product management for wireless products at Symbol , this raises the interesting question , " Which users will drive the WLAN market " those who buy the LAN for home and bring it to work , or those who use it at work and bring it home ? " <p> The issue revolves around the enterprise buying large amounts of 802.11b high-rate products . The circle will then begin whereby prices will fall and volumes will go up . " So , while there 's a hodgepodge in the home now , you still want something easy and standard to implement " that someone in the office knows how to work so you can call them , " says Hughes . " I believe 802.11b will win at home . The products are all interoperable . " <p> Interoperability is a major issue with any WLAN , and 802.11b is no different . Because of this , devices developed under 802.11b are submitted @ @ @ @ @ @ @ @ @ @ Lab . According to Michael Froning of the wireless lab , the devices are very close to full interoperability . But they tend to fall down in the areas of the Wired Equivalent Privacy ( WEP ) protocol and power save . WEP refers to how the data frames are encrypted and offers a security option . To date , failures have been restricted to select pairs , with the problem residing in the MAC . <p> " Another issue , " says Froning , " and one that 's not defined in the standard , is the handling of roaming , in terms of how an access point ( AP ) notifies another AP as a cell roams . " There is n't a way within the 802.11 standard to define how the AP actually does that , so each vendor has their own solution . As a result , it behooves MIS departments to avoid mixing and matching APs in a network until the issue is resolved . Security and roaming will be enhanced through firmware upgrades . <p> Riding the 802.11b Wave Though some outstanding issues remain @ @ @ @ @ @ @ @ @ @ difficulties will be overcome in short order . Only in the past few weeks , Lucent , 3Com , and Zoom Telephonics , have each announced .11b products " Orinoco , AirConnect , and ZoomAir , respectively . <p> Along with Symbol , Zoom uses the Prism II chip set as well . But according to Zoom 's president , Dana Whitney , implementing an 802.11b device requires more than just sticking a standard chip set on a pc board . " We 've found that good control of the manufacturing process is essential , " says Whitney . " The carrier frequency is at 2.4 GHz , so controlling impedances is important . " Other items , such as component specifying , need to be monitored closely . If this is n't done , production models wo n't reflect the prototype in terms of range , throughput , and mobile characteristics . <p> While 802.11b devices dominate on the enterprise , they 're far from the only game in town on the home front . As proponents of 802.11b take the tack that wireless home networking will trickle down @ @ @ @ @ @ @ @ @ @ bottom-up approach . <p> HomeRF uses FHSS modulation , with a maximum throughput of 1.6 Mbits/s . The HomeRF Working Group opted for this radio to minimize cost , as the 1-MHz bandwidth places minimal requirements on the radio amplifier . Highly linear and , hence , expensive amplifiers are required by the 22-MHz bandwidth of DS implementations . <p> Another reason the group selected FH is because it possesses the ability to operate in high-density situations . With DS , it 's possible to have up to three basestations operating in a given space on different channels . If a fourth station is introduced , though , it will pick one of the channels currently in use by one of the other three stations . As a result , DS has to be located carefully to minimize interference . Good vendors of DS solutions will provide placement software for office and home spaces for the basestations . <p> SWAP For Basestations To get up and running quickly , the HomeRF Working Group chose Proxim 's Shared Wireless Access Protocol ( SWAP ) . To date , devices based on @ @ @ @ @ @ @ @ @ @ , raising questions regarding the standard 's potential for success . Cayman Systems and Intel recently laid those fears to rest by announcing their respective introductions into the home market . <p> Cayman offers the 3220HW , an ADSL gateway that 's fully integrated with Proxim 's Symphony HomeRF solution . The 3220HW is designed to help service providers rapidly accelerate the deployment of integrated wireless solutions in small offices and homes . There , portable , high-speed Internet access is a burgeoning market . The inclusion of a four-port Ethernet hub adds extra value by linking mobile wireless devices with existing stationary PCs , printers , and other network resources . The gateway is available now for $998 . Intel 's offering is the Any-Point Wireless Home Network PC Card or USB connection . <p> Key to the HomeRF standard is the provision for both data connections and high-quality voice connections . This provision was enhanced by Siemens , working closely within the group to integrate 802.11 data into its DECT voice expertise , with the former being a packet-based protocol and the latter based on time-division multiple access @ @ @ @ @ @ @ @ @ @ systems . The currently used digitized voice-over Internet Protocol ( VoIP ) packets can suffer from latency problems and a plethora of other issues as a result of not having built-in telephony support . <p> According to Ben Manny , chair of the HomeRF Working Group , " these early HomeRF products will be asynchronous nodes . " Manny explains , " The specification calls out three different types of devices you can build . One is just an asynchronous data node , for peer-to-peer networking and native TCP/IP wireless communication . Another type is an isochronous node ( I-node ) , like a cordless phone . The third device is a basestation , or control point . " <p> There are two basestation classes " data-only and a voice/data control point . The basestation is a data node with the ability to cache messages . So , it 's a centralized controller for the home network . This allows a couple of a-nodes to talk to each other , while the other goes to sleep . The centralized controller will cache for that device . A power-management scheme allows @ @ @ @ @ @ @ @ @ @ network by having this control point manage the network . <p> On behalf of the Working Group , the most recent act was the approval of a certification test . Two types of testing are required . The first , parametric or self testing , is a list of basic measurements on the radio to make sure it conforms with the specification . The second is a series of defined interoperability tests done by a third party , in this case PlugLabs and Purdue University ( the same group that does the tests for HomePNA ) . <p> FCC To Rule On FH Bandwidth While these tests take place , the debate rages on concerning the proposal before the FCC to widen the instantaneous bandwidth of FH systems to 3 and 5 MHz . The proposal will allow increased data throughput up to 10 Mbits/s , thereby allowing HomeRF devices to compete fairly with DS systems . Kevin Negus , director of business development at Proxim , says , " We want a convergence of the FH regulations on a global basis . Today we can build 10-Mbit/s FH products @ @ @ @ @ @ @ @ @ @ But in the U.S. , the way the rules were written artificially constricts the bandwidth on FH in a way different than elsewhere . The FCC is simply in the process of making a rule to allow FH devices to use bandwidth in a flexible manner , like DS . " <p> Not everyone , though , views it as simply as Negus . The proponents of both DS and Bluetooth claim that widening the bandwidth would create insurmountable interference issues . In addition , " they wo n't get the performance they think , because they want to reduce the dwell time , and increase the frequency and overlap channels , " remarks Dana Whitney of Zoom . " If you look at this closely , it wo n't yield them 10 Mbits/s . It will be dramatically lower " 4 or 5 Mbits/s . " The interference stems from the fact that as the band is widened , the signals occupy bigger slots . <p> Cost Comparison Echoing this feeling is Bob Pearson , wireless marketing manager at Intersil . He also tackled the cost angle , which @ @ @ @ @ @ @ @ @ @ " We have done extensive analysis , and DS radios are pretty much on cost parity with FH radios , so the FH approach wo n't have any cost benefit . The other thing is that , as you go up in data rate , the receiver complexity goes up in order to demodulate the waveform . " <p> He goes on to point out , " Our analysis has shown that any benefit from going to higher data rates using FH will be offset by the higher cost of an increased-complexity receiver . " Of course , any cost analysis has to be taken with a pinch of salt , as it 's extremely dependent on quantities and the OEM 's relationship with the supplier . <p> One could argue , however , that the proponents of FH have largely ignored the higher-data-rate waveform complications of demodulation . " They 're on a learning curve there , as it 's necessary to add an equalizer on the baseband processor to demodulate the waveform because it 's so much more susceptible to multipath interference , " says Pearson . " @ @ @ @ @ @ @ @ @ @ <p> While HomeRF might counter that DS radios are capable of transmitting at up to 1 W in the 2.4-GHz band to overcome interference issues , most 11-Mbit radios transmit at about 40 mW to conserve power . Overall , many believe the ruling will decimate the band , and the arguments continue . <p> Despite the objections of DS proponents , it appears , at this juncture anyway , that the FCC is well on its way to allowing the ruling . If it goes ahead , Ben Manny predicts that the next thing to happen after this first launch of products will be a line of products that take advantage of the ruling . Those will allow for things such as multiple MP3 streams . Although SWAP can perform MP3 streams right now , it can handle only two streams with its payload of 500 kbits/s . MP3 is about 150 kbits/s . Manny envisions , " It would be nice if everyone in the house could have their own private MP3 streams . " Other plans exist for full AC-3 , bridges to HomePNA , improved voice @ @ @ @ @ @ @ @ @ @ <p> None of these modifications overshadow the basic affinity HomeRF has for telephony , and that shall remain a strong selling point . As broadband enters the home , the battle for dial-tone dollars escalates . AT&amp;T wants to go around the local-exchange carrier ( LEC ) . The LEC wishes to sell multiple dialtones without having to lay more copper and , therefore , would like to prepare its DSL lines for VoDSL . <p> Explaining the situation , Manny points out , " That 's great , but how do you get these multiple dialtones to the handsets in your house ? Consumers like the flexibility of cordless phones . So , do you bring these to a box and buy four different cordless phones and four different basestations , or do you use HRF DECT which allows you to have distinct handsets and allows you to deliver four separate dial tones to each handset ? " Manny continues , " That same radio also can connect to your PC or Web tablet , and deliver the Internet connection wirelessly . " The argument is only validated by @ @ @ @ @ @ @ @ @ @ 900-MHz band gets crowded out . <p> Bluetooth Stumbles While 802.11b and HomeRF duke it out , Bluetooth has hit a stumbling block of its own . Now hailed as complementary to WLANs , it stands to form the basis of the IEEE 's 802.15 standards work on personal-area networks ( PANs ) . Bluetooth , however , is proving to be long on promise , but short on delivery . With limited silicon availability , no one even nearly ready for production , and no fully qualified devices at all , projections for a Bluetooth solution with a BOM of under $5 may have to be pushed out until at least the year 2003 . Some think it might even have to wait until 2005 . <p> Right now though , a slew of companies are conducting " show and tell . " One of the many is Philsar , with its very-low-power solution , the PH2401 ( Fig. 2 . ) In fact , its ultra-low-current draw at 1.8 V of under 20 mA was one of the main reasons Conexant chose to snap up Philsar recently . @ @ @ @ @ @ @ @ @ @ potentially explosive Bluetooth market . <p> The radio is fully compliant with the Bluetooth specification in v1.0 , and is designed for Class 2 and Class 3 operation of 1 to 10 meters . The transmitter , which offers programmable power output levels of between -10 and 2 dBm and an RF sensitivity of -84 dBm , comes in a BCC48++ package . Operating off 1.8 V , with the option of 1.2 V , the device is a fully integrated solution . It contains an on-chip voltage-controlled oscillator ( VCO ) , a synthesizer , a power amplifier , a low-noise amplifier ( LNA ) , IF filters , a signal-strength indicator , and a bit slicer . <p> Philsar also recently teamed up with Mitel , which is developing a Bluetooth baseband hardware and software solution for standalone , low-power applications . Mitel 's solution , the MT1020A , contains an on-board ARM-7 processor to reduce the amount of processing power required . <p> This approach will raise the gate count . Still , according to Martin Huckle , product line manager for Bluetooth at Mitel , analysis @ @ @ @ @ @ @ @ @ @ less , partly due to its migration to a 0.18--m process . Huckle claims that there 's a possible savings in power of up to 50% over competing devices . Plus , the processor includes a fully functional codec as part of the baseband . Mitel is the only company that provides such a feature . " We see voice as being essential to Bluetooth , so we 're offering the full data/voice solution , " Huckle clarifies . While the first iterations will be done at 0.35 -m , Mitel will move to 0.18 -m by the third quarter of 2001 . <p> Other companies touting product availability include Atmel , with its T2901 . Developed by Temic , the T2901 includes the transceiver , synthesizer , and a VCO , too . Fully Bluetooth compliant , the device has a noise floor of 23 dB , a linearity , in terms of spurious-free dynamic range ( SFDR ) , of 50 dB , an in-band image of 20 dBc/Hz , and a VCO phase noise of G89 dBc/Hz at 500 kHz . Atmel 's chip features a closed-loop @ @ @ @ @ @ @ @ @ @ to component tolerance and noise effects . <p> While the above reflects increasing levels of integration , the ultimate goal is to bring everything on board . Alcatel is far along on the road to this with its latest Bluetooth offering . Introduced at CeBIT 2000 , the company is offering the device as the world 's most integrated solution , and they might be right . <p> Into a 15- by 15-mm package , the company managed to include the complete radio ; baseband controller ; an ARM7 processor ; the Bluetooth 1.0 software stack on flash ROM with optional application-layer software ; the baseband interfaces of SPI-bus , UART , and PCM , with USB optional ; and the antenna . All external components , such as the RF input filter and decoupling components , are embedded in the BGA package . <p> Hardware sampling at the moment is plentiful . Still , the actual deployment of low-cost devices stands a long way down the road . While some say the Bluetooth originators set too low a goal at $5 , other factors delay the rollout . <p> @ @ @ @ @ @ @ @ @ @ Bluetooth has fired the imagination of everyone concerned . Now it 's being groomed for roles in everything from personal digital assistants ( PDAs ) , cell phones , and printers , to voice-activated computers and control systems and mobile communications . The Special Interest Group ( SIG ) , claiming newcomers everyday , now consists of around 1700 members . But it must be stated that membership is free and there are no obligations upon joining . Many of those members , therefore , could be developers of other , competing , short-range wireless technologies , just trying to keep tabs on what 's happening . <p> Software Skills Needed Interest has brought constant revisions to the specification . It started out at 500 pages , but has since grown to over 1500 pages . With the added profiles and dynamic nature of the specification , one requires much more than hardware finesse to achieve a successful Bluetooth . " You need somebody with extremely good software skills . The hardware is n't a problem , it 's a straightforward interconnect , straightforward operation . " according to Mike @ @ @ @ @ @ @ @ @ @ hardest part is understanding the specification and how to use the software that exists . The 1500-page specification is like going through very heavy mud . " <p> The other difficult part is the antenna , with its many different designs and approaches . Bender suggests buying this piece . His sentiment was echoed by Kjell Westerlund , an applications engineer at Ericsson . " The antenna is key , " says Westerlund . " If that does n't work , then the software is moot . It 's important because you never know the shape and size of the device your Bluetooth solution is going into , so it 's a unique design every time . " <p> Ericsson is taking the path of providing complete , proven designs to customers . The company has kicked off its Solution Providers program , which is an attempt to enlist antenna manufacturers and software companies to do it all for a third-party customer " mostly out of Europe . <p> A Call For Development Tools The dearth of available software is only exacerbated by the lack of available development tools . @ @ @ @ @ @ @ @ @ @ operating system . When Motorola got a leg up in the Bluetooth market by purchasing DigiAnswer , it arrived on the fast track to fully enabled devices . According to Buddy Broecker , operations manager for wireless emerging markets , those devices should see the light of day by the end of June . Broeker projects that by that point , they will be fully qualified and in production . <p> Motorola opted to make the enabling and development tools in house . " The pervasiveness of Bluetooth will be tied to the tools available to write applications , " says Broeker . " Multiple layers must be laid down before it can proliferate . " <p> For Ericsson , Motorola , or anyone in this arena , the key to proliferation is interoperability testing . With these concerns in mind , the SIG is working with Rohde &amp; Schwarz , the Munich , Germany-based manufacturer of high-end test equipment , to install such equipment in various parts of the world in order to test upcoming Bluetooth solutions . Plus , there are many more " unplugfests " yet to @ @ @ @ @ @ @ @ @ @ year 's end they should be ironed out . <p> While the interoperability issue gets resolved , the Bluetooth SIG is working on service discovery . This aspect of Bluetooth keeps expanding in scope as more applications are defined . The core of an ongoing debate is the level at which the protocol stack service discovery should be implemented " down low or up high , just below the application layer . <p> In the opinion of Robert Pascoe , president of Salutation Consortium , it should be implemented right up at layer six or seven . " We are independent of the underlying protocol . The problem is if you 're an applications provider trying to port to these Bluetooth devices , then you need to deal not only with the lower-level protocol , but also service discovery . " Pascoe adds that " We allow any device to work anywhere using a transport manager which manages the transport at the lower levels , not down at the protocol stack . " Salutation is a nonprofit group providing an **34;354;TOOLONG ( API ) set , thereby ensuring that the @ @ @ @ @ @ @ @ @ @ . <p> The Bluetooth Working Group asked the consortium , along with Microsoft ( UPnP ) and Sun ( Jini ) , to come up with a service-discovery protocol for Bluetooth . According to Pascoe , that was the wrong approach . He explained that " One protocol is what we need . If you have a high-level protocol on one end , and a low-level protocol on the other , you may not be able to communicate . " Further , he said that " The goal is consistency across platforms " consistency of the information to eliminate data loss . " <p> Shrinking Size " And Cost For any of the thousands of OEMs presently designing solutions for the 2.4-GHz market , once the technicalities of hardware design , standards compliance , and interoperability are met , the next stage is to lower the overall size and cost of the implementation . There are many ways to do this . The two most successful paths involve architecture refinement and packaging innovation . These are the specialties of ParkerVision and Intarsia , respectively . <p> ParkerVision recently announced a @ @ @ @ @ @ @ @ @ @ 40% . In the words of Al Petrick , director of marketing and business development at ParkerVision , " Direct conversion is the way of the future . " He admits though , " It has been tough to do because of dc offsets , but our technology has taken care of this . " Using its proprietary D2D technology , ParkerVision 's chip converts 2.4 GHz to baseband analog in one step ( Fig. 3 . ) <p> This allows the company to take the radios and implement them in CMOS , along with the MAC and baseband processor . Embedding the radio and reducing overall chip count is the key to lowering transceiver costs . <p> Embedding the radio and reducing overall chip count is the key to lowering transceiver costs . ParkerVision 's patented technology uses no mixers or multipliers . It 's a way of using a subharmonic clock to convert the RF carrier down to baseband analog . Says Petrick , " We say RF matched filter because the way you convert the PLL clock down from the RF carrier is related to matched-filter theory @ @ @ @ @ @ @ @ @ @ filters and multiple IF down-conversion stages , reduces cost and power consumption , and improves performance . The performance matches that of cellular radio technology , with a second-intercept point ( IP2 ) close to +30dB and IP3 to +15 dB . <p> The company has spun its technology into product in the form of the PV-1000 , an RF vector modem that will be available by the fourth quarter of this year . It supports all data rates up to 22-Mbits/s radios and features an I/O interface that 's virtually glueless to almost every baseband processor on the market . Intersil has already licensed ParkerVision 's technology . <p> Intarsia , for its part , is a 2.5-year-old company funded by Dow and Flextronics , that provides technology to integrate passive components associated with RF designs . It specializes in integrating as much as possible by using its thin-film-on-glass process . Steve Whelan , vice president of sales and marketing addresses this . " We 've seen a lot of focus on trying to integrate as much as possible onto the silicon , " he says . " But @ @ @ @ @ @ @ @ @ @ found is that a lot of the high-Q components , such as inductors and capacitors , ca n't be as easily integrated onto the chip . Our process allows you to integrate these components onto a substrate . And then , in turn , add an RF IC to provide a fully functional module . " The method of attachment , usually a direct module attach ( DMA ) , is one that uses solder balls around the device periphery . <p> Competing with such technologies as low-temperature , co-fired ceramics ( LTCC ) , Intarsia claims that this process will bring a 50% savings in space over LTCC . It 's very similar to a semiconductor process , whereby all of the films are sputtered onto a glass substrate measuring 400 by 350 mm ( Fig. 4 . ) The fine lines allow for a very high number of components , while the large glass size can result in up to 10,000 Bluetooth devices per panel . In Whelan 's own words , " We can get tolerances with resistors and capacitors of between 5 and 10% " before @ @ @ @ @ @ @ @ @ @ The Next Step : 5 GHz While 802.11b , HomeRF , and Bluetooth-based 802.15 are at the cutting edge of wireless networking today , deployment of the mentioned products in the coming year or two is overshadowed by speculation over interference and band crowding . Research has shown that if an 802.11 and Bluetooth radio try to grab a channel independently , there will be interference . Because 802.11 is at a much higher power level , Bluetooth will suffer . <p> Any interference issues that occur will only grow worse as the band gets more crowded . Notwithstanding , help may be on its way . The IEEE 802.11a and the European ETSI HiperLAN II Committees are both on the path to a 5-GHz OFDM standard with a very similar physical layer . The differences lie only in the MAC . <p> Their similarities could lead to more coalescence , which could just be a question of firmware . " The idea of a global radio with a WLAN adaptor that can recognize what country it 's in , and reconfigure itself to meet that country 's regulatory requirements @ @ @ @ @ @ @ @ @ @ Farpoint Group , " I think that will appear over the next few years . It 's mostly a case of power levels and firmware " easy stuff . " <p> For more on the issues and conflicts facing wireless designers , join us at Electronic Design 's Communications Workshop in Chicago , June 26 and 27 . There , all the above topics will be addressed " and much more . 
@@21004666 @1004666/ <p> FDMA is the process of dividing one channel or bandwidth into multiple individual bands , each for use by a single user ( Fig. 1 ) . Each individual band or channel is wide enough to accommodate the signal spectra of the transmissions to be propagated . The data to be transmitted is modulated on to each subcarrier , and all of them are linearly mixed together . <p> 1 . FDMA divides the shared medium bandwidth into individual channels . Subcarriers modulated by the information to be transmitted occupy each subchannel . <p> The best example of this is the cable television system . The medium is a single coax cable that is used to broadcast hundreds of channels of video/audio programming to homes . The coax cable has a useful bandwidth from about 4 MHz to 1 GHz . This bandwidth is divided up into 6-MHz wide channels . Initially , one TV station or channel used a single 6-MHz band . But with digital techniques , multiple TV channels may share a single band today thanks to compression and multiplexing techniques used in each channel @ @ @ @ @ @ @ @ @ @ communications systems . A single fiber optic cable has enormous bandwidth that can be subdivided to provide FDMA . Different data or information sources are each assigned a different light frequency for transmission . Light generally is n't referred to by frequency but by its wavelength ( ++ ) . As a result , fiber optic FDMA is called wavelength division multiple access ( WDMA ) or just wavelength division multiplexing ( WDM ) . <p> One of the older FDMA systems is the original analog telephone system , which used a hierarchy of frequency multiplex techniques to put multiple telephone calls on single line . The analog 300-Hz to 3400-Hz voice signals were used to modulate subcarriers in 12 channels from 60 kHz to 108 kHz . Modulator/mixers created single sideband ( SSB ) signals , both upper and lower sidebands . These subcarriers were then further frequency multiplexed on subcarriers in the 312-kHz to 552-kHz range using the same modulation methods . At the receiving end of the system , the signals were sorted out and recovered with filters and demodulators . <p> Original aerospace telemetry systems used @ @ @ @ @ @ @ @ @ @ single radio channel . Early satellite systems shared individual 36-MHz bandwidth transponders in the 4-GHz to 6-GHz range with multiple voice , video , or data signals via FDMA . Today , all of these applications use TDMA digital techniques . <p> TDMA <p> TDMA is a digital technique that divides a single channel or band into time slots . Each time slot is used to transmit one byte or another digital segment of each signal in sequential serial data format . This technique works well with slow voice data signals , but it 's also useful for compressed video and other high-speed data . <p> A good example is the widely used T1 transmission system , which has been used for years in the telecom industry . T1 lines carry up to 24 individual voice telephone calls on a single line ( Fig. 2 ) . Each voice signal usually covers 300 Hz to 3000 Hz and is digitized at an 8-kHz rate , which is just a bit more than the minimal Nyquist rate of two times the highest-frequency component needed to retain all the analog content . @ @ @ @ @ @ @ @ @ @ illustrates TDM and TDMA . Each time slot is allocated to one user . The high data rate makes the user unaware of the lack of simultaneity . <p> The digitized voice appears as individual serial bytes that occur at a 64-kHz rate , and 24 of these bytes are interleaved , producing one T1 frame of data . The frame occurs at a 1.536-MHz rate ( 24 by 64 kHz ) for a total of 192 bits . A single synchronizing bit is added for timing purposes for an overall data rate of 1.544 Mbits/s . At the receiving end , the individual voice bytes are recovered at the 64-kHz rate and passed through a digital-to-analog converter ( DAC ) that reproduces the analog voice . <p> The basic GSM ( Global System of Mobile Communications ) cellular phone system is TDMA-based . It divides up the radio spectrum into 200-kHz bands and then uses time division techniques to put eight voice calls into one channel . Figure 3 shows one frame of a GSM TDMA signal . The eight time slots can be voice signals or data such @ @ @ @ @ @ @ @ @ @ a 270-kbit/s rate using Gaussian minimum shift keying ( GMSK ) , which is a form of frequency shift keying ( FSK ) modulation . <p> - <p> 3 . This GSM digital cellular method shows how up to eight users can share a 200-kHz channel in different time slots within a frame of 1248 bits . <p> CDMA <p> CDMA is another pure digital technique . It is also known as spread spectrum because it takes the digitized version of an analog signal and spreads it out over a wider bandwidth at a lower power level . This method is called direct sequence spread spectrum ( DSSS ) as well ( Fig. 4 ) . The digitized and compressed voice signal in serial data form is spread by processing it in an XOR circuit along with a chipping signal at a much higher frequency . In the cdma IS-95 standard , a 1.2288-Mbit/s chipping signal spreads the digitized compressed voice at 13 kbits/s . <p> - <p> 4 . Spread spectrum is the technique of CDMA . The compressed and digitized voice signal is processed in an XOR logic @ @ @ @ @ @ @ @ @ @ result is that the digital voice is spread over a much wider bandwidth that can be shared with other users using different codes . <p> The chipping signal is derived from a pseudorandom code generator that assigns a unique code to each user of the channel . This code spreads the voice signal over a bandwidth of 1.25 MHz . The resulting signal is at a low power level and appears more like noise . Many such signals can occupy the same channel simultaneously . For example , using 64 unique chipping codes allows up to 64 users to occupy the same 1.25-MHz channel at the same time . At the receiver , a correlating circuit finds and identifies a specific caller 's code and recovers it . <p> The third generation ( 3G ) cell-phone technology called wideband CDMA ( WCDMA ) uses a similar method with compressed voice and 3.84-Mbit/s chipping codes in a 5-MHz channel to allow multiple users to share the same band . <p> OFDMA <p> OFDMA is the access technique used in Long-Term Evolution ( LTE ) cellular systems to accommodate multiple users in @ @ @ @ @ @ @ @ @ @ ) is a modulation method that divides a channel into multiple narrow orthogonal bands that are spaced so they do n't interfere with one another . Each band is divided into hundreds or even thousands of 15-kHz wide subcarriers . <p> The data to be transmitted is divided into many lower-speed bit streams and modulated onto the subcarriers . Time slots within each subchannel data stream are used to package the data to be transmitted ( Fig. 5 ) . This technique is very spectrally efficient , so it provides very high data rates . It also is less affected by multipath propagation effects . <p> - <p> 5 . OFDMA assigns a group of subcarriers to each user . The subcarriers are part of the large number of subcarriers used to implement OFDM for LTE . The data may be voice , video , or something else , and it 's assembled into time segments that are then transmitted over some of the assigned subcarriers . <p> To implement OFDMA , each user is assigned a group of subchannels and related time slots . The smallest group of subchannels @ @ @ @ @ @ @ @ @ @ ) . The system assigns the number of RBs to each user as needed . <p> SDMA <p> SDMA uses physical separation methods that permit the sharing of wireless channels . For instance , a single channel may be used simultaneously if the users are spaced far enough from one another to avoid interference . Known as frequency reuse , the method is widely used in cellular radio systems . Cell sites are spaced from one another to minimize interference . <p> In addition to spacing , directional antennas are used to avoid interference . Most cell sites use three antennas to create 120- sectors that allow frequency sharing ( Fig. 6a ) . New technologies like smart antennas or adaptive arrays use dynamic beamforming to shrink signals into narrow beams that can be focused on specific users , excluding all others ( Fig. 6b ) . <p> 6 . SDMA separates users on shared frequencies by isolating them with directional antennas . Most cell sites have three antenna arrays to separate their coverage into isolated 120- sectors ( a ) . Adaptive arrays use beamforming to pinpoint desired users @ @ @ @ @ @ @ @ @ @ ) . <p> One unique variation of SDMA , polarization division multiple access ( PDMA ) , separates signals by using different polarizations of the antennas . Two different signals then can use the same frequency , one transmitting a vertically polarized signal and the other transmitting a horizontally polarized signal . <p> The signals wo n't interfere with one another even if they 're on the same frequency because they 're orthogonal and the antennas wo n't respond to the oppositely polarized signal . Separate vertical and horizontal receiver antennas are used to recover the two orthogonal signals . This technique is widely used in satellite systems . <p> Polarization is also used for multiplexing in fiber optic systems . The new 100-Gbit/s systems use dual polarization quadrature phase shift keying ( DP-QPSK ) to achieve high speeds on a single fiber . The high-speed data is divided into two slower data streams , one using vertical light polarization and the other horizontal light polarization . Polarization filters separate the two signals at the transmitter and receiver and merge them back into the high-speed stream . <p> Other Methods @ @ @ @ @ @ @ @ @ @ is carrier sense multiple access with collision detection ( CSMA-CD ) . This is the classical access method used in Ethernet local-area networks ( LANs ) . It allows multiple users of the network to access the single cable for transmission . All network nodes listen continuously . When they want to send data , they listen first and then transmit if no other signals are on the line . For instance , the transmission will be one packet or frame . Then the process repeats . If two or more transmissions occur simultaneously , a collision occurs . The network interface circuitry can detect a collision , and then the nodes will wait a random time before retransmitting . <p> A variation of this method is called carrier sense multiple access with collision avoidance ( CSMA-CA ) . This method is similar to CSMA-CD . However , a special scheduling algorithm is used to determine the appropriate time to transmit over the shared channel . While the CSMA-CD technique is most used in wired networks , CSMA-CA is the preferred method in wireless networks . 
@@21004668 @1004668/ <h> White Paper : Basics of Ball Grid Arrays ( BGAs ) <p> While there are entire textbooks that cover the topic of BGAs , their use and fanout techniques , the quick overview provided here offers an engineer a good starting point for improving BGA designs . <p> Apr 26 , 2017 <p> Brought to you by <p> BGA 's are the boon and bane of engineers and printed circuit board designers . Their unparalleled pin density and low lead inductance are essential in today 's high-pin count , high-frequency integrated circuits . However , that same pin density and unique interface create a challenge unique unto themselves . These challenges need to be faced head on since the ball grid array ( BGA ) is prevalent in modern PCBs . The quick overview provided here offers engineers a good starting point for improving BGA designs . 
@@21004669 @1004669/ <h> An Out-Of-Box Experience : Development Kits <p> Inexpensive development kits can realistically open the door to a world of options . In the past , designers would stick with a chip family or vendor due to the high cost of changing platforms and the difficulty in evaluating new systems outside their normal realm . Vendor loyalty is still valuable , but the ability to quickly evaluate new hardware platforms let 's designers check out alternatives for their favored vendors or other vendors . <p> Cost is n't the only reason for the flood of new evaluation or development kits ( although their inclusion of low-cost hardware and software tools certainly helps ) . For instance , there 's the availability of powerful microcontrollers that can be programmed with familiar high-level languages like C and C++ . Also , flash memory permits simple programming and standalone operation of user-programmed applications . <p> Open-source software ( OSS ) has made a serious dent in software tool cost . Many kits come with OSS packaged for that platform . Vendors like Green Hills Software , IAR , and Keil typically bundle their @ @ @ @ @ @ @ @ @ @ or complement the collection of software included with a kit . <p> Support hardware prices and footprints have dropped significantly , too . Macraigor includes its JTAG technology on some evaluation boards so that developers need not contend with separate JTAG modules . Of course , the tradeoff is that the latter can be used with another board . <p> Not to be overlooked is the Universal Serial Bus ( USB ) . Kits that use USB as an interface bring a number of features to the fore . It can provide power , eliminating the otherwise ubiquitous and costly power brick . It also brings a flexible interface often used with advanced debugging tools like JTAG . Moreover , it 's the interface of choice , given today 's laptop and desktop migration to USB-only interfaces . <p> As a result , many of today 's kits come with extremely low pricetags . Even more expensive solutions offer significantly more functionality than in the past . So in a nutshell , designers can now reach various plateaus with such a broad range of solutions . <p> DEVELOPMENT PLATEAUS Not @ @ @ @ @ @ @ @ @ @ handy to have a way to gauge kits ( see " Reaching A Plateau , " below ) . I 've used a four-level system for grading kits in my EiED Online column . These range from initial kit-functionality demonstrations to full-blown development work . Kits can be divided into three general categories : demonstration , evaluation , and development . <p> Demonstration kits like those from Texas Instruments ( Fig. 1 ) and Atmel ( Fig. 2 ) are interesting because they 're designed to reach Plateau 1 , but they actually are good fits on the next two levels . But reaching these levels requires further work from the user " downloading the tools from the Internet and adding some hardware to the mix . Then again , what would you expect from something that costs $20 ? <p> Evaluation kits , the next step up , typically include a board , software , and documentation . They also may have additional diagnostic hardware . They 're designed to cost as little as possible while providing tools suitable for application development . The software tools often are limited @ @ @ @ @ @ @ @ @ @ with the board provided , with the microcontrolleron the board , or with a matching diagnostic-tool . Code size and time limits are common-as well . Stay away from the latter if possible , -because the kit becomes useless if the software is no longer usable . <p> Development kits are usually designed to provide a platform that 's as unrestricted as possible . Timeouts may be associated with a matching subscription support service , but even these services guarantee operation for at least a year . The tools are generally restricted to a particular vendor 's target hardware , but this varies depending on the supplier and the kit . <p> Unfortunately , there 's no standard naming convention for either the kind of kit or the level it 's designed to reach . Likewise , a wide range of quality affects how well and how quickly a designer can reach a particular plateau . <p> Why should you check out a kit ? Well , for one , it can help you to get a head start on product development . Also , it can become like a @ @ @ @ @ @ @ @ @ @ that an actual product . It can further assist you in learning about a new platform for educational purposes or for a comparative evaluation . <p> Kits are a great way to keep abreast of the latest technology . They 're used in schools and universities as part of **25;390;TOOLONG curricula . Companies also have their reasons for offering kits . For instance , they might be showing the capabilities of a new technology like ZigBee . Or they may be trying to garner new developers and convince them to migrate to their platform . Overall , they 're attempting to boost demand for the underlying product . <p> Keep in mind a number of issues while looking for a kit . There 's usually a major difference in functionality between kits that use serial/USB software monitors versus JTAG for debugging and flash programming . Also , make sure you understand any limitations on the support software , such as time limits , code-size limits , and debugging limitations . <p> OPEN SOURCE GNU tools are the foundation of OSS . Richard M. Stallman , president of the Free Software @ @ @ @ @ @ @ @ @ @ its tools and developed GPL ( General Public License ) . GNU tools like the gcc compiler form the basis for many software tool suites found in development kits . <p> Another key addition to OSS is the Eclipse integrated development environment ( IDE ) ( see " Anatomy Of An IDE " at www.elecdesign.com , ED Online 3376 ) . This has moved the sometimeslimited OSS graphical development tools to the premiere platform in use by a range of real-time operating-system ( RTOS ) and developmenttool vendors as the basis for their own products ( e.g. Accelerated Technology , LynuxWorks , Monta Vista , QNX , and TimeSys ) . <p> The CrossCore package features more on-board peripherals . It also includes significantly more internal and third-party support . Plus , it comes bundled with a copy of Analog Devices ' VisualDSP++ development tools , versus the GNU tools for the Stamp . Which is better ? It depends on a variety of factors , from the pocketbook to the developer 's experience to the long-range use of the kit . As with most kits , no one kit @ @ @ @ @ @ @ @ @ @ or more kits available from the vendor or third parties . Thus , hundreds of kits are available . Renesas , Samsung , and STMicroelectronics produce dozens of chip families with a wide range of third-party kit support , and they represent just three of the many vendors out there . <p> Specialized applications further inflate the number of options . Take for example Microchip 's Mechatronix board , which targets motor control ( Fig. 4 ) . It highlights Microchip 's PIC product line and includes two different types of small motors . The board also can be connected to external motors . Then there 's Zilog 's motor-control solution , which targets brushless dc ( BLDC ) motors ( see " Smart Motion Makes For A Smarter Design , " ELECTRONIC DESIGN , p. 41 , Oct. 27 , 2005 , ED Online 11294 ) . It can provide sensorless speed control . <p> Low-cost solutions do n't necessarily translate into lowquality tools . In fact , even complex areas like motor control are leading to bundled tools that simplify the design and evaluation process . Zilog has @ @ @ @ @ @ @ @ @ @ the developer , such as the type of motor . <p> With ZigBee being such a hot topic , the large amount of available kits should come as no surprise ( Fig. 5 ) . Ember , Freescale , and Silicon Labs kits illustrate the range of solutions that developers will have to contend with . <p> Ember 's kit includes half a dozen boards . ( Hey , a single Zig-Bee module is pretty useless . ) The boards include an Ethernet connection , so units can serve as gateways . It also enables Ember to provide a very sophisticated wireless management and monitoring system . It 's one of the most expensive kits , designed as a highend development solution for companies looking to commit to ZigBee . <p> The Freescale evaluation kit resides at the other end of the spectrum . Designed to highlight the capabilities of Freescale 's offering , it can be used simply as a demo kit with a pair of boards or as a midrange development tool . An on-board antenna keeps costs down . Meanwhile , Silicon Labs ' solution sits in @ @ @ @ @ @ @ @ @ @ . <p> MODULE KITS Some of the ZigBee kits use plug-in modules . They offer a way to incorporate development hardware into a final solution . Of course , many companies simply target modules as a solution , while chip vendors often target custom hardware . <p> Rabbit Semiconductor has had success selling modules ( Fig. 6 ) . Designers can buy the 8-bit Rabbit processors , but most developers simply use the modules . The plug-in approach serves up a number of benefits , including the ability to easily change the module used in a product from a less expensive , less functional unit to a more expensive , more functional unit . <p> FPGA KITS Microcontroller-based kits are the most numerous , but analog and FPGA solutions are available , too . They tend to have a more limited audience and are often more expensive . Likewise , the learning curve usually is steeper . Getting to Plateau 3 may take days to weeks instead of hours . <p> Altium along with FPGA vendors Altera and Xilinx have some interesting solutions , though they are not exclusive . @ @ @ @ @ @ @ @ @ @ evaluation in addition to simpler and less expensive tools . One sample response is Xilinx 's Spartan-3 Starter Kit , which costs $99 . At the other end of the spectrum is Altium 's Nanoboard-NB1 . It contains plug-in modules for FPGAs and complex programmable logic devices from a number of vendors . <p> REFERENCE DESIGNS Looking for a product out-of-the-box ? You may be looking for a reference design . They tend to be different from conventional kits , but their end purpose is usually the same " to get developers to use the vendor 's product . <p> Be it a reference design , demo kit , or evaluation kit , developers have a wide range of choices to get hands-on experience at a reasonable cost . 
@@21004674 @1004674/ <h> MEMS Raise Testing Issues From The Beginning To The End Of The Design Cycle <p> Microelectromechanical systems ( MEMS ) can be realized in many fashions . To date , however , pressure sensors and accelerometers have been the majority of high-volume applications . In fact , a number of these devices are currently produced in quantities greater than a million devices per month . As time goes on , other MEMS devices , including rate sensors/gyros , optical switches , RF MEMS , and chem/bio MEMS , will experience widespread application . <p> The early focus on the development of MEMS has been on device design . Now that MEMS are being commercialized at an ever increasing rate , the focus is on delivering a robust and cost-sensitive product . Packaging and testing have become major ways to differentiate between products . Furthermore , the cost of undertaking these activities is receiving great attention by manufacturers . Typically , the cost of testing can be as much as 33% , with packaging from 33% to 45% , of the solution 's total cost . <p> Any company @ @ @ @ @ @ @ @ @ @ to this fact . No longer will it be acceptable to design the test strategy after the design of the device and package . Testing issues must instead be included in the overall design of the device/package in the early phase of development . <p> Testing of MEMS devices can occur at various stages during the development of a MEMS solution . Figure 1 is a flow chart illustrating a standard MEMS development cycle . From early on in the determination of material properties by real life testing to final acceptance testing , MEMS are a major candidate for extensive testing . This article will focus on front end , or materials testing , and the back end , the reliability and acceptance testing . <p> The current rapid pace of materials development for MEMS rivals the similar development experienced by the steel industry about a century ago . New MEMS materials are continually developed to exploit specific material properties and process compatibilities . A decade from now , the structural material of choice for MEMS might not be any of the materials utilized in today 's devices . A @ @ @ @ @ @ @ @ @ @ in Table 1 . The exciting pace of material development in the MEMS industry requires the development of material testing techniques that can provide the properties of these materials as they evolve . <p> The unknown reliability of many MEMS devices limits their incorporation into commercial products . The long-term stability of these devices can only be ensured with greater knowledge of the basic material properties and failure mechanisms of the materials employed in MEMS designs . The motivation for this knowledge arises for numerous reasons . <p> Some " new " materials actually are n't new but rather just being employed for the first time in MEMS . These materials include thin films for actuation , such as shape-memory alloys and multilayers for optical reflectance . Other materials are truly new " alloys " like the new class of silicon-germanium ( SiGe ) materials . Those provide special processing advantages over the more mature polysilicon comprising the majority of MEMS devices . The obvious advantages provided by SiGe materials , including CMOS compatibility , ensures their continued development and incorporation into commercial products . <p> Still , there 's @ @ @ @ @ @ @ @ @ @ of these SiGe alloys , including elastic stiffness , corrosion resistance , fracture toughness , and creep resistance . But , opportunities for developing additional " alloys " have n't ended with SiGe . There 's no question that more MEMS materials will arise , and their properties will need to be quantified . <p> There are substantial challenges in measuring the properties of MEMS materials " whether those materials are new or old . The materials making up MEMS are deposited as thin films . Although the electrical characterization of thin films is well established , the mechanical characterization of the same films is difficult . There are numerous properties that need to be measured for each material , including elastic modules , yield strength , fracture toughness , fatigue resistance , corrosion resistance , creep behavior , and residual stress . No single standard of testing for any of these properties exists . Numerous tests have been proposed and are being carried out by different manufacturers and institutions . But , the rigorous comparison and benchmarking of these test techniques have yet to be performed . <p> The @ @ @ @ @ @ @ @ @ @ material between manufacturing sites and even between manufacturing batches . Material properties of a common MEMS material , polysilicon for example , deposited by one manufacturer can vary substantially from that deposited by another . Manufacturers even see variations in film properties between wafer batches . Furthermore , Exponent has documented variations in properties across single wafers . A map of the variation in residual stress , measured by Exponent , in a silicon nitride film across a single silicon wafer is shown in Figure 2 . The variation is sufficiently large to change device performance if the design depends on a given value of residual stress . <p> Therefore , the question of appropriate , validated testing remains an open issue . An important effort to coordinate MEMS testing is currently taking place within the American Society of Testing and Materials Task Group ( ASTM ) on Structural Films and Electronic Materials , E.08.05.03 . This task group is meeting to compare the various test techniques used to evaluate MEMS materials with the final objective of setting qualified , tested standards through which MEMS designers , manufacturers , and @ @ @ @ @ @ @ @ @ @ task group is at the Fall ASTM meeting in Orlando , Florida ( Nov. 10-12 ) . <p> MEMS material testing also is essential because numerous MEMS devices operate under conditions unknown in the macro world . Certain characteristics of two classes of devices , RF and optical MEMS switches , can be examined in Table 2 . <p> The actuation frequencies provided in the table result in a number of total accumulated actuation cycles that extends far beyond what has been required in " macro " applications . Both of these classes of devices can experience fatigue and wear from contacting surfaces during individual actuation cycles . There 's little or no information about fatigue or wear for virtually any engineering material under these conditions " for neither macro nor MEMS devices . As a result , lifetime predictions are device specific . Plus , given the lack of fundamental material testing , predictions are n't always largely validated by statistics . <p> Therefore , the MEMS industry is employing new materials under conditions that macroscopically have never been characterized . New sets of material data will have to @ @ @ @ @ @ @ @ @ @ <p> One example of MEMS testing that showed an unexpected reliability issue was crack growth in silicon . Exponent has developed a MEMS fatigue and crack-growth test specimen . The specimen is a perforated , triangular plate that 's both suspended above and connected to a substrate by a single beam with a stress concentration ( Fig. 3 ) . The specimen oscillates in the plane , applying bending loads to the connecting beam . The specimen is resonated until failure , and multiple specimens can be tested to evaluate the fatigue resistance and crack growth under different levels of stress . Stress versus time and the number of cycles to failure for a set of tests on single-crystal silicon is provided ( Fig. 4 ) . <p> These tests showed that silicon MEMS could fail under conditions of relative humidity . This was unanticipated by the MEMS community and has promoted changes in packaging techniques to prevent failure of MEMS due to absorbed moisture . <p> The challenges of MEMS material testing and reliability permeate all stages of MEMS commercial development . The initial concept of a MEMS product @ @ @ @ @ @ @ @ @ @ and the intended application . For instance , silicon has demonstrated a sensitivity to moisture . A sensor based on silicon may need to be isolated from a moist environment , or alternative materials might have to be considered . For the last decade , Exponent employees have worked within MEMS reliability testing and have provided reliability assistance throughout the MEMS product development cycle . <p> The good news about MEMS material and reliability testing is that MEMS devices are operating successfully in numerous applications where the stresses and demands exceed those frequently imposed on " macro " devices . The challenge in MEMS material testing is to understand how to measure the performance of those materials so that future devices can exploit those material properties and operate at comparable levels of reliability . <p> There are distinct differences in the test requirements for MEMS devices as a function of the MEMS product life cycle . In each phase , the meaning of test performance also is different . <p> The R&amp;D phase requires that the test system perform comprehensive laboratory functions . The test system must have the flexibility @ @ @ @ @ @ @ @ @ @ range of operating parameters . The typical users are either device designers or highly skilled people with the technical background to devise their own measurement requirements . The user also needs to employ the equipment in an interactive mode . System accuracy , flexibility , and the ability to transition the current test and measurement methodology to the pilot phase determine test performance . <p> The pilot phase requires that the test system perform the same tests that eventually will be implemented during full production . This system will provide the dual function of establishing product validation as well as production test validation . In addition to providing low-volume production capability , the test system provides data that will more closely indicate the costs of testing for the production phase . Test performance is determined by measurement throughput . It 's advantageous to replicate some of the features of the R&amp;D phase system . <p> The production-phase test system represents a scaled-up version of the pilot-phase test system . It usually must handle more devices at one time . Typically , it includes an automated material handling system to load @ @ @ @ @ @ @ @ @ @ may either be highly skilled production engineers or unskilled equipment operators . Test performance is determined by device throughput . Reliability and maintenance are important issues too . <p> Regardless of the MEMS product life-cycle stage , there 's a generalized definition of a MEMS test system by functional categories . One , the computer , controls the entire system and provides communication interfaces to the outside world . Another , the instrumentation , includes all of the source and measurement electronics used during the testing process . <p> The stimulus is a separate assembly that actuates the MEMS device in the domain of its sensitivity . The fixturing category is an electromechanical assembly that provides a controlled path from the stimulus to the device undergoing testing while maintaining electrical contact to that same device . <p> The environmental control typically controls the ambient temperature of the device during testing . The **28;417;TOOLONG functional category is a robotic system that loads devices to and from the fixture assembly . It 's only required during the full-production phase . <p> Yet another category , the application software , is a device-specific @ @ @ @ @ @ @ @ @ @ of the nonapplication software modules which support the development of test programs and their operational use . <p> The Need For High Volume The first consideration is to justify the need for high-volume equipment . Although there 's some latitude in the definition of high-volume equipment , we will assume that the definition includes the ability to operate the production test process with minimal operator intervention . Furthermore , it 's assumed that minimizing the skill level of the operator is desirable . Lastly , and obviously , the raw throughput rate must satisfy operational and financial objectives . <p> In order to define the detailed requirements , we must begin with a top-level view of the major components that comprise the high-volume test system . These are the electronic measurement system , the MEMS stimulus system , the device fixture mechanism , the environmental control system , and the material handling system . <p> The capabilities of each of these must be matched to the overall objectives of the MEMS device manufacturer . A typical list of objectives categories includes production test and calibration ; test development ; calibration @ @ @ @ @ @ @ @ @ @ integration ; and product engineering . These lists provide a starting point from where priorities can be analyzed and rationalized according to budget and schedule goals . <p> With respect to the electronics contained in a MEMS device , there 's a clear trend toward a common structure . The purpose of the electronics is to apply a calibration correction function , perform analog signal conditioning , and transmit the output signal . Therefore , the structure of each MEMS device can then be separated into three parts . <p> The first , the MEMS element , is the raw transducer or actuator . The next is the signal conditioning circuit , which may include amplifiers and filters . These circuits must be adjusted , or trimmed , on a per-device basis . The third part is memory , which is used to store the calibration constants determined during the trimming process . <p> Early versions of signal-conditioning circuits were laser trimmed . That gives only simple correction capability . Next came custom fixed-function circuits with memory registers . The trend has continued to include fixed-state machines with multiple register @ @ @ @ @ @ @ @ @ @ Eventually there will be full microprocessors . All of this is geared toward providing better performance . It 's this performance advantage at a low price that determines which MEMS manufacturers will be successful . When all of these parameters are taken into consideration , the determination of requirements can commence . <p> Given the intense competition in any of the high-volume MEMS applications , manufacturers are faced with compressed development schedules . This means that production capability must be flexible to accommodate changing specifications and production rates . <p> Therefore , test requirements must be clearly defined for the life of the MEMS product and some consideration must be made for future requirements . Typical functional requirements categories for sensors include sensitivity correction , offset correction , and temperature-coefficient compensation . The electronic requirements categories for typical electronically trimmed sensors include the number of device pins , power supply , dc source and measure , ac source and measure , and digital I/O communication . <p> By providing the essential data for each of these requirements categories , the specification of the high-volume test system can be extracted . @ @ @ @ @ @ @ @ @ @ capability to support the production effort throughout the entire production life of the MEMS device . <p> One of the challenges to MEMS manufacturers is determining how much testing is required . In order to minimize cost , it 's desirable to minimize the amount of testing as long as yield , performance , and quality levels can be maintained . <p> There are certain parameters that can be guaranteed by design and others that can be determined by sample-based testing . These generally apply to situations where statistical analysis reveals an acceptable level for the standard deviation in the production process . <p> If the degree of repeatability is too low , then each device must be tested explicitly on an individual basis . It 's the nature of many MEMS devices to fall into this category . There 's usually a high degree of variability that 's an intrinsic characteristic of the MEMS element and its sensitivity to the mechanics of the production process . <p> One role of the production test equipment is to provide a mechanism to collect data for analysis . This is to determine @ @ @ @ @ @ @ @ @ @ <p> It 's important to understand variability of the MEMS product on a continual basis . So , the capability must fully characterize devices and be able to change tests and measurements on an ongoing basis . <p> Although many solutions exist for testing standard semiconductor devices , which are strictly electronic , MEMS devices have both an electronic instrumentation element as well as a mechanical , optical , or chemical instrumentation element . This introduces a whole new perspective on physical instrumentation . Much of the existing physical instrumentation is geared for laboratory use and may not be easily scaled for high-volume use . These might exist as individual instruments , but may not be easily integrated into production machinery . <p> For example , as mentioned earlier , accelerometers and pressure sensors are well established high-volume MEMS devices . They can each be discussed to highlight how their differences affect the implementation of high-volume production test equipment . <p> Automated material handling systems for MEMS device production are a significant and costly element of any production system due to their high level of customization . The key consideration @ @ @ @ @ @ @ @ @ @ . <p> For pressure devices , the tendency is to manipulate as large a batch as possible , partly because of the dynamics of controlling the pressure stimulus . It also is due to the need to have robust pneumatic connections . Furthermore , it 's quite possible to connect many pressure devices in parallel . <p> This is a sharp contrast to accelerometer devices . Because the effective area of the accelerometer stimulus is limited , only a small number of devices can typically be processed at one time . <p> The device I/O pins include all electrical contacts to the device . Both the pressure devices and the accelerometer devices share similar requirements . Each has power , ground , and , typically , a digital communication function and an output pin . <p> One important difference relates to the output pin . The accelerometer is a device whose operational signal bandwidth is high in comparison to that of a pressure device . How sophisticated the pin electronics and signal processing electronics must be is dictated by these differences . <p> Most calibration compensation circuits have provisions to @ @ @ @ @ @ @ @ @ @ temperature effects behave in a linear pattern determines how many temperature set points are required in the calibration process . <p> Temperature behavior is primarily determined by the intrinsic method of sensing " namely , resistive or capacitive . Normally , piezoresistive devices require more temperature compensation . Basically , because the typical pressure sensor is piezoresistive and the typical accelerometer is capacitive , that pressure sensor requires more complicated temperature compensation techniques . <p> The role of the device fixture is to provide electrical and mechanical connections to the device . The major concern for pressure fixtures is pressure leaks , while the major concern for accelerometer fixtures is mechanical resonance . <p> Another important yet subtle aspect of the fixture design is that the fixture itself becomes part of the signal measurement path . As a result , a wider range of technical disciplines is required to develop a robust production solution . <p> We have focused our attention on the testing of the currently popular MEMS devices , specifically pressure sensors and accelerometers . Major challenges still exist in the development of high-performance and cost-effective testing of @ @ @ @ @ @ @ @ @ @ input-stimulus devices becomes a reality , much-more-complex testing system and reliability analysis will be required . <p> The level of complexity of this problem will be reduced on one hand by the wealth of knowledge gained to date regarding the testing of physical sensors . Complexity will be dramatically increased by the difficulties in creating and calibrating systems associated with RF , chemical , and photonic input . Success for MEMS device manufacturers will depend on the ability to specify and procure the specialized equipment that meets their detailed requirements . <p> MEMS testing and reliability will be addressed at Commercialization of Microsystems 2000 , to be held in Santa Fe , N.M. , Sept. 5-9 . Information on the conference is available at **37;447;TOOLONG 
@@21004676 @1004676/ <h> Electronic Design 's Internet of Things Products of the Week ( 4/30-5/6 ) <p> Searching for that gateway or USB bridge chip to round out your latest design ? Our editors have collected seven IoT products that have caught our eye in recent weeks . Maybe one is just what you 've been looking for . <p> Searching for that gateway or USB bridge chip to round out your latest design ? Our editors have collected seven IoT products that have caught our eye in recent weeks . Maybe one is just what you 've been looking for . 
@@21004678 @1004678/ <h> Power-Supply Considerations For Servo Amplifiers <p> The " linear " power supply is simple : just a transformer , rectifier , and capacitor . But , selecting one to power a servo amplifier and motor can be anything but simple . What follows is a short tutorial outlining some of the problems motion-control engineers encounter and the solutions available for them . <p> While a control-system engineer thinks in terms of **28;486;TOOLONG , it 's common for the motor to be chosen by a mechanical engineer ( ME ) who is more in touch with the actual pieces of an automatic machine . The ME makes choices based on mechanical units such as torque needed for acceleration , maximum rpm , and continuous power needed at a shaft , and so forth . These considerations yield a motor , rating , case size , and rotor inertia . <p> What 's missing from this picture is the copper . Magnetic fields produce torque in the motor , and these are produced by ampere-turns of copper in the motor . It is this magnetic-field strength in the motor that @ @ @ @ @ @ @ @ @ @ The field strength is a function of the number of turns of wire multiplied by the current in the wire . This produces the motor constant ( Km ) , which can be expressed in units of torque per ampere of winding current ( Kt ) , or as volts per rotational velocity units ( Ke ) . In the English system , one sees Kt as lb-in. /A , or oz-in. /A , and in the SI system , these become Nm/A . The rotational units ( Ke ) are V/krpm ( volts per thousand rpm ) in English , or V/rad/second in SI . <p> Now , ampere-turns as a product , is governed by two factors : the current in the wire , and the number of turns . Look in a motor catalog , and you 'll see the real-world embodiment of this fact as a choice of windings for a particular case size and power rating . You wo n't see the number of turns listed , it 's hidden in the motor constant . Ordinarily , there will be from two to four windings @ @ @ @ @ @ @ @ @ @ each . Since torque = torque constant * current ( Kt * I ) , for a constant shaft torque rating , it will take more or less current to do the job . Or , high current multiplied by few turns produces the same strength field in the motor as low current in a lot of turns . So which winding is the right one ? <p> Enter the electrical engineer ( EE ) , who is informed by the ME which motor must be used for the latest and greatest machine , and who must produce a control and drive system for it . How do you choose between the different windings available ? <p> Choosing The Windings Begin with the maximum expected speed of the motor , then add a fudge factor for possible variations , to produce your design-maximum revolutions per minute . Divide this number by 1000 to get " krpm , " run your finger across the columns in the motor chart where you find Ke ( back-EMF constant in V/krpm ) , and do some quick multiplications . The result is a range @ @ @ @ @ @ @ @ @ @ ) at your design-maximum rpm . <p> Next , have your ME give you the maximum torque expected during acceleration to the maximum rpm . Divide this ( do n't lose track of units ) by the torque constant , and the result should be the peak current in amperes . Multiply this by the motor resistance to get the IR drop across the motor windings . <p> If you 're going to be thorough , do n't forget that the motor will heat up if you 're driving it hard . Without extending this tutorial into all of the calculations needed to compute the motor rms ( root-mean-square ) current , let 's just assume that you heat it up to the motor 's design TMAX , frequently 150-C . If you start at room temperature , 25-C , this is a change of 125-C , with the result that the armature resistance can increase by as much as 49% ! So now you have the " worst-case " terminal voltage for the system , which is the voltage required to accelerate the motor at the maximum rate up @ @ @ @ @ @ @ @ @ @ give you maximum accelerating torque , TX , and the top speed , UX . From these , calculate the maximum motor terminal voltage that must be delivered by the power supply and amplifier combination ( VTX ) ( Fig. 1 ) : <p> VTX = <p> VAX + IX ( RA + RTH ) + LA(dIX/dt) <p> where VAX = maximum BEMF , or UX * Ke , and IX = TX/Kt . <p> For the power-supply selection , ignore the armature inductance , because the voltage across this will depend on the modulation type . It can be assumed to have an average value of zero under steady-state conditions . <p> Choosing a power supply is like most other decisions made in pursuit of a goal . All of this motor talk is about defining that goal . Congratulations , you just did that . Now you know the terminal voltage that must be delivered to the motor by the amplifier/power-supply combination if your machine is going to work . Next stop--the servo amplifier . <p> The Servo Amplifier Commonly a pulse-width-modulated ( PWM ) type servo amplifier @ @ @ @ @ @ @ @ @ @ in the winding . This current , produces torque , which divided by inertia , produces acceleration . When the acceleration is integrated with respect to time , it produces velocity , and then position , and so on . <p> Suppose that we calculated our design-maximum motor terminal voltage to be 90 V dc . Do you choose an amplifier with a 24- to 90-V dc operating voltage range ? You could , but it would be cutting it close to use an amplifier that is about to go into overvoltage shutdown just as it outputs the voltage that the motor needs . The problem is , the amplifier is not just a piece of wire connecting the power supply and the motor . <p> In a PWM amplifier , MOSFET or IGBT devices are switching away , but rarely get to turn on all of the time ( achieve a 100% duty cycle ) . So , our maximum design voltage might occur at , say , 97% duty cycle , therefore add 3% to the input voltage to the amplifier . <p> Working backward from the motor @ @ @ @ @ @ @ @ @ @ , what you get is the minimum voltage required from the power supply . This is the voltage needed at the amplifier 's input power terminals to run the motor in the way the ME intended . <p> But , before you pick up the phone to order that 99-V power supply , check the datasheet for something called " regulation . " This is the no-load voltage minus the full-load voltage , divided by the full-load voltage . Multiply this by 100 and you can express it in a percentage . Obviously , if the voltage did n't change as the load changed , the answer would be 0% . <p> You will not find this number on a linear power-supply datasheet . What you will find is a number more likely to be from 5 to 15% . This is caused by the internal resistance of the power supply . As long as you select your power supply based on the full-load output voltage , your system will have enough voltage to drive the motor . The effects of non-zero regulation will , however , affect the choice @ @ @ @ @ @ @ @ @ @ power company ? Read the fine print and you 'll find that the 120 V ( or 115 V , 100 V , 200 V , 230 V , or 240 V , depending on your country and locale ) that is the nameplate voltage on your power delivery system is n't always accurate . It might vary as much as -10% . Result : all of that stuff about minimum voltage needed at the amplifier terminals , and at the output of the power supply at full load had better be happening at low-line mains voltage , or your control system will be offline when the power dips . In fact , if you examine closely the operating range of equipment made for the U.S. , you will commonly see a range of 105 to 132 V ac . This means that for a nominal 120-V supply , the output might dip ( 120 - 105 ) /120 , or 12.5% from nominal during those brown-outs , and rise 10% , too . <p> In order to guarantee the minimum power-supply output voltage under the load calculated previously , @ @ @ @ @ @ @ @ @ @ be prepared for a low-line situation . This will handle the motor needs nicely . <p> All that 's left now is to consider is the amplifier . From 120 V , the voltage can rise 10% to 132 V. We must be sure that the amplifier will be OK with this high-line , no-load voltage before we wrap and bag this design . <p> This is a key point of linear power-supply selection : when the power line sags , and the load is at a maximum , there must be enough voltage to drive the motor and amplifier . And , when the motor is idle , amplifier disabled , and the power line at its maximum possible voltage , the output will rise to a maximum that can not damage or disable the amplifier . From a design point of view , pick the power-supply voltage based on expected line excursions and your minimum amplifier input voltage . Then , check the maximum voltage to see if it 's OK for your amplifier 's operating voltage range . <p> Back at the amplifier terminals , two things @ @ @ @ @ @ @ @ @ @ is converted to watts at the motor terminals , but some of it just makes the amplifier hot . There we go again , those darn amplifiers just are n't perfect . But , they are pretty good , typically 90% or better . That is , 90% of the power going into the amplifier zips right out the other end , into the motor . Furthermore , the PWM action at the amplifier outputs acts like a dc transformer . The constant bus voltage is modulated to appear as a variable voltage from 0 to -HV . So , the real wattage needed at the amplifier input becomes motor power plus amplifier losses . Divide this actual power by the needed bus voltage , and you 'll get the dc current needed from the power supply . <p> Power-Supply Definition Elbow room is great . A good design does n't need to be more tightly defined than necessary , because tight tolerances cost money and narrow the range of operation . If motors had no internal resistance , amplifiers no losses , and power supplies perfectly regulated , none @ @ @ @ @ @ @ @ @ @ wait for this to happen , but offer instead the step-by-step procedure for doing by the numbers what we have described above . We will not delve into the origins of the maximum revolutions per minute and accelerating torque at this time , but will assume that the mechanical types have dutifully left these data on your desk , along with a datasheet of the motor model of choice . <p> Current RatingNow that you know the key voltages for your motion system , it 's time to find the current-rating of the power supply . The easy way is to make this the same as the amplifier 's peak current . But , in incremental motion systems , this will typically occur only a portion of the overall time , so using this figure will usually result in an oversized ( and overpriced ) power supply . <p> Linear supplies are designed to tolerate short-term overloads of 200% to 300% of their continuous ratings . You can use this figure to find a rating closer to your actual needs . The real mechanical watts in your system are determined @ @ @ @ @ @ @ @ @ @ : torque ) , and duty cycle . Try to find a value for the average motor speed and current , multiply these , and get an average power . Take this number and divide it by the power-supply voltage , and you will have an estimate of the supply-current rating . This will generally be somewhat less than the peak amplifier 's current value . <p> Now you have completed the first pass through the process . There were three windings for this motor , were n't there ? Did this iteration result in a power-supply voltage range that fits with any servo amplifier you have seen lately ? Yes ? Jot down the model number , and proceed . If not , do it again ! Fact : You are a techno-juggler with at least three pieces to keep in the air at a time . You must pick your parts so that the motor , amplifier , and power supply not only work , but work together simultaneously . But , if it was that easy , everyone would be doing it . <p> Suppose that you @ @ @ @ @ @ @ @ @ @ motor winding , amplifier , and power-supply choice in hand . Are we there yet ? For one motor , sure , but most real systems have multiple axes . Do we repeat this process for each axis , and then add up the watts and buy a power supply to handle all of these at once ? Unless your loads are all pumps that run continuously at the design maximum load , the answer is " no . " It 's time for a major engineering fudge-factor . <p> Duty-Cycle Fudge FactorIt 's called duty cycle ( not the PWM type this time ) . In incremental-motion systems , those factory-automation engineers most frequently encounter , not all axes run all of the time . If your process is very deterministic , you might succeed in calculating the watts per axis , and adding these successfully . But , it 's more likely that your machine runs different motion programs depending on a process that changes over time . The best way to sort this out is not on paper , but on the floor ( of the R&amp;D @ @ @ @ @ @ @ @ @ @ a power supply sized for , say , one axis of a three-axis machine . Run your machine as it was intended . Come back in one hour , and place your hand on the power transformer . The copper in its windings is an excellent rms detector of current . We gave it an hour to run because of the long thermal time-constant of the transformer itself . If the transformer is hot , increase the power rating of the supply and try again . If it is cold , you oversized . Downsize the power rating of the supply and try again . <p> If the transformer does n't get noticeably warm , you 're probably not getting your money 's worth . So , you can buy the confidence of over-specing , or play roulette with the winding temperature rating of the transformer . It 's up to you . But , the final decision based on multi-axis , duty-cycle demands is tough to make on paper , so allow some lab or floor time to sort this out in the design cycle . The reward will @ @ @ @ @ @ @ @ @ @ reliably delivers the power you need . <p> First , cabling . How do we connect all these parts together ? Size the wire first . Use the charts in the wire catalogs , and any local electrical codes and wiring practices , if needed . Teflon-insulated wire is best for power wiring due to its very high-temperature and voltage ratings . Next best is cross-linked or irradiated PVC ( polyvinyl chloride ) . Less common , and much cheaper than Teflon , it will withstand solder-iron temperatures without melting . And it 's more flexible and easier to strip than the Teflon . The last choice is regular PVC . It 's OK for lower voltage , in cooler-running or lower-powered equipment , but not a good choice for anything connected to the mains , or above , say 75 V dc , or so . <p> Next , PWM amplifiers put fast ripple currents into power supplies , in addition to the average currents they draw ( the ones we have been discussing ) . To keep these currents from " talking " to adjacent cables , twist @ @ @ @ @ @ @ @ @ @ For newer CE-compliant applications , consider using shielded cables to reduce EMI emissions from these wires . Typically , these are going to be bigger wires ( AWG 18 to 12 ) , so it 's best not to try soldering them , but use crimp-on connectors to mate with screw-lugs , or Euro-style compression connectors instead . <p> Fusing Most people think that the fuse is meant to protect their equipment . In fact , the prime function of the fuse is to protect the world from your equipment when it fails . The survival of your machine is secondary . At the minimum , you will want a fuse between the mains and your final choice of power supply . Given the inrush currents associated with capacitor-input supplies , this will be a time-delay fuse . <p> Choose the current rating based on the power-supply nameplate rating , and add 25% . Remember , a fuse should only carry 80% of its rated current continuously . If you have a 500-W power supply operating from 120-V ac mains , the rated line current would be 500/120 or 4.17 @ @ @ @ @ @ @ @ @ @ the choice between a 5- or 6-A fuse based on how much of that power-supply rating you 're likely to use in practice . <p> The choice of a second tier of fuses to protect each individual amplifier is up to you . Depending on the cost or value you assign to an individual amplifier , you can let the pc-board etch be the fuse of final resort . And , you only need to put a single fuse in the mains wiring to the power supply , or fuse each amplifier individually . Given that the amplifiers usually shut down with internal ( or external ) short circuits , and that total , catastrophic failure is rare , most users decline the individual fuse per amplifier . It 's your call . <p> Wiring And Grounding Do n't daisy-chain wires from power supply , to amplifier 1 , and then onto amplifier 2 , etc . Instead , use a star system , with one twisted pair from each amplifier connecting to the terminals of the power-supply filter capacitor . <p> Also , ground your system properly . Remember @ @ @ @ @ @ @ @ @ @ amplifiers and the power supply : slow currents , or the average currents that drive the motor , and fast currents , the ones you ca n't see , but exist due to the switching of the transistors in the amplifiers . The slow currents make measurable IR drops between the ends of the cables . The fast currents produce even bigger voltage spikes in the inductance of the wires . <p> Enter relativity . The voltage between the ends of the power wires are relative to those ends . Ground the negative terminal of the power-supply capacitor , and these voltages will appear between the amplifier ground terminals , and chassis ( general electrical system ) ground . <p> From the viewpoint of the amplifier circuits ( remember relativity ) , the world just got very noisy . From where the control system sits , the amplifier looks really noisy . You can eliminate this noise by disconnecting the power-supply capacitor from ground , instead grounding each amplifier with its own short grounding conductor to a local star ground terminal . This way , the wiring noise will be @ @ @ @ @ @ @ @ @ @ there it wo n't matter to the amplifiers , or to the control system . <p> Regeneration Finally , because this is a motion-control system with stored mechanical energy , there 's regeneration to consider . Your servo amplifier is a two-way street when it comes to power . Most of the time you deliver power to the load . But , once you accelerate a load to a given speed , or elevate it to some height against the pull of gravity , you have stored mechanical energy that must now dissipate to bring the load to rest . This energy flows from the load back into your system . <p> The motor handles this two-way power delivery easily , as does your four-quadrant PWM servo amplifier . But , when you get to the power supply , you 're looking into the business end of a rectifier that only passes power in one direction--from the power line into the filter capacitor . In the case of regeneration energy , it 's a brick wall . The solution is a " dumper , " or regenerative energy dissipater . @ @ @ @ @ @ @ @ @ @ and rapidly switch a high-power resistor across the terminals to dissipate the energy as heat . As more energy comes back from the load , the dumper switches with an ever-increasing duty cycle to mimic a resistor with a lower and lower resistance . The effect is to have a rheostat across the cap that is electrically variable to satisfy the Ohm 's law solution R = E/I ; where E is the bus voltage during regeneration , and I is the current coming from the motor during deceleration . As soon as the load is brought to rest , the " pump-up " of the power supply stops , the voltage drops , and the dumper turns off . <p> These devices are common accessories from amplifier makers , and found as part of the amplifier , or as external accessories . They are usually adjusted to a voltage that is below the amplifier 's shut-down voltage , but above any steady-state , high-line , and no-load voltages . The peak power dissipated by these devices is very high , and they are intended to operate only during deceleration @ @ @ @ @ @ @ @ @ @ By now , you should know enough to pick your motor winding , select and size a power supply , roughly spec a servo amplifier , and wire the whole thing together . You 're now ready for your next assignment--making it all work ! But that 's another story . <h> Linear Power-Supply Regulation And Internal Resistance <p> The full load current , in terms of the voltage across the load resistance , is found through the equation : <p> IL= VFL/RL <p> The load current , in terms of the load current and internal , or no-load voltage is given as : <p> IL= VNL/ ( RI + RL ) <p> Combine the above two equations to get : <p> VFL/RL = VNL/ ( RI + RL ) <p> Solve for RI when load resistance , no-load , and full-load voltages are known to get : <p> RI= RL x ( VNL - VFL ) /VFL <p> However , these data are not usually shown on a datasheet . It 's more likely you 'll find the output ( full-load ) voltage , current , and percent regulation @ @ @ @ @ @ @ @ @ @ see that VFL is actually the internal no-load voltage minus the drop across the internal resistance : <p> VFL = VNL - ( IL x RI ) <p> Rearrange to solve for RI : <p> RI= ( VNL - VFL ) /IL <p> Now , remember that percent regulation was defined as : <p> Percent regulation = ( ( VNL - VFL ) /VFL ) x 100 <p> Insert the above term into the equation for RI and reduce it to give : <p> RI = ( percent regulation/100 ) x ( VFL/IL ) <p> The result is a handy equation to model the effective internal resistance of a power supply based on specification-sheet data--namely , full-load voltage and current , and percent regulation . ( Fig. 3 ) <h> Worst-Case , Power-Supply Output Voltage <p> Lowest Output Voltage ( VLO(DC) ) = <p> ( VLOWLINE/VNOM ) x VFULLLOAD <p> Highest Output Voltage ( VHI(DC) ) = <p> ( VHILINE/VNOM ) x VFULLLOAD x ( 1 + %R/100 ) <p> where : <p> VLOWLINE = low-line mains voltage <p> VNOM = nominal mains voltage <p> VHILINE = high-line mains voltage @ @ @ @ @ @ @ @ @ @ power-supply regulation in percent <p> Example : <p> A power supply has these specs : 65 V dc , 8 A , and 5% regulation . <p> VLOWLINE = 105 V ac <p> VNOM = 120 V ac <p> VHILINE = 132 V ac <p> Lowest Output Voltage = 56.9 V dc <p> Highest Output Voltage = 75.1 V dc <p> Compare the minimum required voltage at the amplifier input terminals with the Lowest Output Voltage to check adequacy . <p> Compare the Highest Output Voltage with the amplifier 's operating voltage range to ensure that the amplifier will not shut down due to an overvoltage condition . <h> - <h> Power-Supply Definition Procedure <p> 1 . Find the maximum motor armature voltage : <p> VAM = VDM x Ke <p> where : <p> VAM = maximum armature voltage <p> VDM = design-maximum rpm ( in krpm ) <p> Ke = V/krpm ( volts per rpm/1000 ) <p> Add at least 10% to compensate for manufacturing tolerances , and to include a little operating headroom for the control system . <p> 2 . Find maximum IR drop ( VRM ) @ @ @ @ @ @ @ @ @ @ : <p> IDM = design-maximum current <p> TDM = design-maximum torque <p> Kt = torque constant <p> TDM and Kt should use same units for torque <p> VRM x 1.5 x IDM x RA <p> where : <p> VRM = maximum IR drop <p> RA= armature resistance <p> 1.5 = addition of 50% to VRM to cover hot-motor scenario . <p> 3 . Find design-maximum motor terminal voltage : <p> VTM = VAM + VRM <p> where : <p> VTM = design-maximum motor terminal voltage <p> Multiply this by maximum current to get armature wattage . Now you know the maximum power input to the motor terminals in watts . <p> 4 . Find minimum power-supply voltage at amplifier input terminals : <p> HVMIN = ( VTM/DM ) + ( IDM x RO ) <p> where : <p> HVMIN = minimum power-supply voltage at amplifier input terminals <p> DM= maximum duty cycle ( e.g. 0.97 for 97% ) <p> RO= amplifier " on " resistance <p> 5 . Find full-load , power-supply output voltage : <p> VFL = HVMIN x ( VNOM/VLOWLINE ) <p> where : <p> VFL = full-load @ @ @ @ @ @ @ @ @ @ VLOWLINE = low-limit mains voltage <p> In the power-supply catalog find a device with a full-load output voltage near to this . Take this number , and calculate the high-line , no-load voltage ( VHI ( DC ) ) according to the procedure already outlined ( see " Worst-Case Power-Supply Output Voltage , " ) . This is the high-line voltage that the amplifier must tolerate without going into shutdown . 
@@21004679 @1004679/ <h> Basics of Energy Efficiency and Low-Power Design <p> Sponsored by Newark element14 <p> Jul 11 , 2016 <p> Brought to you by <p> As the demand for energy grows worldwide , manufacturers of electronic equipment are continually looking for ways to improve the energy efficiency of their designs . One of the primary goals of the Internet of Things ( IoT ) is to help consumers become better users of energy " on the factory floor , at home , at work , on the road , while exercising , or at the doctor 's office . In this Basics Of Design , we will discuss energy efficiency and the IoT , and spotlight technologies and devices that are helping engineers design products that use less power while still boosting performance . 
@@21004681 @1004681/ <h> Oscilloscopes Meet Demands Of Biomedical Apps <p> Specifying low front-end noise figures to allow the analysis of extremely small signals with high signal fidelity , the RTO Series digital oscilloscopes use a single core ADC to ensure an accurate representation of signals when debugging biomedical sensors and equipment . The instruments provide a gain range of 1 mV/division and consistent overdrive recovery to eliminate distortion and ensure signal fidelity . They employ a real-time digital trigger as opposed to analog triggers that typically have a long re-arm cycle . Since the digital trigger does not need to re-arm , every sample can trigger data acquisition to avoid missing events . ROHDE &amp; SCHWARZ INC. , Columbia , MD. ( 888 ) 837-8772. 
@@21004683 @1004683/ <h> Guarantee The Success Of Future 3G Handsets <p> Interactive content could lead companies out of the current UMTS predicament . According to research conducted by Forrester Research , consumers in Europe spent some 101 billion Euros on communication via fixed network , mobile phone , and post in 1999 . The research also uncovered an interesting fact : New interactively assisted content could produce a host of successful services . Frost &amp; Sullivan ascribe a further lion 's share of the revenue to mobile gaming . By 2008 , it predicts that 178.8 million mobile gamesters will exist . <p> Interactive content places highly complex requirements on mobile systems . It involves a combination of flexibility and wide-ranging functionality with minimal memory size , processor , and battery power . Memory protection also is part of the mix . Hardware restrictions have to be offset by means of intelligent software . As a result , the profitable development of mobile communications systems calls for fundamental importance to be assigned to six main requirements . <p> Before delving into the six requirements , it 's important to note that @ @ @ @ @ @ @ @ @ @ term , however , it does safeguard investments in development . The use of a common basic platform for differing handset models presents an ideal solution ( FIG. 1 ) . In the 3G handset , for example , the hardware and software platform will become like the chassis of a car . The same chassis can be used for several types of car models . <p> In this way , 3G-handset applications can be compared to the features of a car , such as air conditioning , electric moon roof , dual air bags , etc . The 3G mobile phones that are built on one general platform will host different and varying applications . The handset manufacturer will differentiate the devices so that they range from low-end to high-end . That manufacturer will also design handsets for different user profiles . <p> A 3G platform can not be exactly the same for all types of terminals . For example , the memory configurations and possibly the CPU extensions are different when comparing a voice-only mobile telephone and a multimedia terminal . For various applications , however , the @ @ @ @ @ @ @ @ @ @ once . A significant potential for savings can be gained by reusing the system software in the various hardware configurations . Such software includes telephone protocols , baseband software , a call control system , and voice coding and decoding . <p> In general , six requirements exist that must be met in order to obtain successful GPRS/UMTS terminals . These requirements assume the use of a common basic platform . They comprise the following : <p> Dynamic Program Loading In Real Time A key feature of 3G is the ability to update the software inside the telephone at any time . This aspect gives manufacturers and end users higher flexibility . The hardware and operating-system platform must therefore support the dynamic loading and unloading of programs in run time ( FIG. 2 ) . In addition , the handset must be upgradable at any type of usage by equipping it with different applications . The manufacturer can then update software with new versions at a very late stage in the production cycle " or even after the unit is shipped . For the user , this translates into the @ @ @ @ @ @ @ @ @ @ applications to add to the existing factory-installed capabilities . Subsequently , the user 's handset can be turned into anything : a phone , a PDA , or perhaps even something not yet imagined . Business-to-business applications also are sure to appear on the market . <p> Cost Efficient Use Of Memory Saving memory is probably the most significant cost-saving factor for a 3G handset . To compensate for limited memory , more demand is placed on the handset software . This is particularly true for the platform software . As a result , the operating system itself must be compact , modular , and highly configurable . It should consist of several modules that can be included or excluded , depending on the required functionality . <p> For example , in the OSE for Wireless Devices operating system , each component 's footprint ( code only , no data ) ranges from 60 to 150 kB . An extensive choice of modules usually results in a system of approximately 700 kB . Each component should offer several configuration options that can scale the component up or down in both @ @ @ @ @ @ @ @ @ @ as little RAM as possible when executing . It can achieve this goal by limiting the use of buffering and advanced memory management , including efficient methods of preventing memory fragmentation . If all operating-system components are able to execute out of either RAM or Flash , costly RAM is saved . <p> Another mechanism that saves space is shared libraries . This approach allows several applications to run the same code with different data . When implementing shared libraries , keeping the real-time characteristics of an RTOS can become a somewhat complicated process . But in OSE for Wireless Devices , shared libraries can be used without the typical traditional shortcomings , such as longer interrupt latency . <p> Transparency In Distributed Systems A 3G terminal is a good example of a typical multiprocessor design in which application programs can run more efficiently . To attain this efficiency , the processor operations are distributed over CPUs and DSPs . With one standardized RTOS that supports both general-purpose CPUs and DSPs , the software can be used repeatedly in different hardware configurations . The same system software , like telephone @ @ @ @ @ @ @ @ @ @ both the CPU and DSP at the same time . Or , it works on one DSP . If the RTOS offers a common application programming interface ( API ) and transparent communication over CPUs , the CPU boundaries become invisible . Applications can then be easily moved from one CPU to another with little to no changes required ( FIG. 3 ) . <p> Reliable And Robust Service What is the " killer application " for 3G handsets ? As with 2G mobile phones , voice communication will most likely take top billing . In order for it to succeed , however , the reliability of the phone call must be outstanding . It must rarely fail to connect . It also has to connect quickly . In addition , it must almost never disconnect spontaneously . <p> Several ways exist to ensure a robust system . Error handling in the RTOS kernel , for example , enables the isolation of errors and their handling . In OSE , calls do not return error codes . Instead , whenever returning from a system call , the application understands that @ @ @ @ @ @ @ @ @ @ , control is transferred to an error handler with an error code for identification . The error handler can then take appropriate action . It might , for example , perform another system call , inform another application of the problem , or restart an application ( FIG. 4 ) . <p> On a single CPU , the OSE mechanism 's supervision of tasks , programs , applications , and entire units is very useful . In a distributed environment , however , it is essential . Application A can request supervision from any other application B. If the supervised application B is for some reason not available , A will get an automatic notification . Then , A can take an appropriate action . It may , for instance , redirect its communication to C. The OSE for Wireless Devices OS provides a mechanism called hunting for an application . Issuing a hunt request causes the kernel to send the identification number ( task I 'd ) of the application 's name as soon as the application is available . <p> Memory protection shields the system from crashes due to @ @ @ @ @ @ @ @ @ @ such as telephony protocols , that simply must not crash . Because a 3G handset will have many more applications than today 's phones , it is inherently more vulnerable . It is simply unacceptable for faulty applications to crash other applications or even the system itself . <p> In the next-generation handsets , system software will put very high demands on reliability . It will be forced to co-exist with less critical software , such as games . Applications downloaded in run time also can be memory protected . Perhaps more importantly , the system can be protected from downloaded applications . For these reasons , products like the OSE operating system integrate a memory manager and protection software with run-time loading functionality . <p> Combined Memory Model Great care has to be taken when selecting the memory-management facility for a mobile terminal . The combination of three different memory-addressing methods provides an efficient solution . These methods include Single Address Space Equal ( SASE ) , Single Address Space ( SAS ) , and Multiple Address Space ( MAS ) . <p> Of the three methods specified , @ @ @ @ @ @ @ @ @ @ used for virtual memory systems in most desktop OSs , such as Solaris , Linux , and NT . But in a real-time system that requires high processor performance with the minimum amount of space , MAS presents a number of disadvantages . Consequently , combining SASE , SAS , and MAS invites a host of advantages . Each memory-addressing method presents advantages for different code and data types . MAS is only used in areas that actually require it . This approach accelerates execution while offering real-time behavior . <p> Minimum Power Consumption A long standby and operating time rank among the main factors that will ensure the success of mobile terminals . In spite of their minimum power demand , CPUs and DSPs should be operated at the lowest possible frequency whenever possible . The mobile applications also should reduce power usage . When possible , savings should permit applications to be powered down . In addition , the power of all modules should be reduced whenever they are not directly required . <p> I/O modules could , for example , be powered down . The processor could @ @ @ @ @ @ @ @ @ @ , however , a power down entails using up further time and power . Accordingly , powering down a module does not always present the best solution . Consequently , the user program should be capable of determining the modules for which this activity makes sense . Subsequently , it should be able to figure out the time for which each module must be powered down in order to achieve effective power savings . <p> The power-management facility of OSE for Wireless Devices permits this type of intelligent decision with the aid of an additional halt feature . If specific conditions have been met , the module switches to a power-saving mode . <p> Following the six criteria that are described in detail above will allow 3G handset manufacturers to obtain successful GPRS/UMTS terminals . Com-bining the criteria with advanced applications gives a profitable and compelling handset product . OSE Systems ' collaborations with Synergenix for mobile gaming and with 3GLAB for mobile branding are examples of this . OSE Systems and Synergenix recently introduced the Mophun game engine for OSE for Wireless Devices . <p> Manufacturers can now build @ @ @ @ @ @ @ @ @ @ the end user , that means access to enjoyable mobile gaming that is similar in quality to gaming consoles . The graphics-rich , real-time interactive games can be downloaded directly from the Internet or over the air . The Mophun gaming platform , for example , runs on extremely limited hardware resources . It boasts a minimum requirement of an 8-b processor running on 12 MHz ( FIG. 5 ) . <p> Consumers are increasingly demanding mobile phones with advanced multimedia capabilities . At the same time , network operators are looking to bring to market high-quality , own-branded devices that enable the delivery of advanced services . The pre-integration of 3GLAB 's Trigenix mobile interface software and OSE 's real-time operating system provides engineers with a pre-validated dynamic software solution . This solution is based on the core ARM architecture . OSE 's run-time program loading provides the dynamic functional updates . Meanwhile , Trigenix 's over-the-air customizable user interface provides ease of use . It enables the rapid development of mobile phones with user interfaces that can be fully branded and " themed " to meet operator market @ @ @ @ @ @ @ @ @ @ on the topic discussed , please refer to the references listed here : <p> www.ose-systems.de <p> Here you will find a white paper on the OSE wireless platform , as well as detailed information on the development of third-generation handsets. 
@@21004686 @1004686/ <h> Embedded Memories Are The Key To Unleashing The Power Of SoC Designs <p> The semiconductor industry continues to validate Gordon Moore 's original prediction that device densities and speeds will double every 18 months . With process technologies pushing well into the deep-submicron arena , they have finally reached a point where IC designers can integrate significant densities of memory and logic together on the same chip . In doing so , they have ushered in the system-on-a-chip ( SoC ) era . <p> Integrating memory on-chip is n't a new concept , of course . Microcontroller designers have done it for years . But the emergence of multimillion-gate ASIC designs has increased the demand for a wide range of embedded memory options and applications . Over the past few years , the prospects for embedding DRAM and flash memory on-chip have received a great deal of attention . But developing a single process to maximize the performance of both memory and logic circuits has been an ongoing struggle . <p> In the highly anticipated embedded DRAM arena , for instance , developers have faced an inherent contradiction @ @ @ @ @ @ @ @ @ @ logic circuits , and the need to maximize retention time and reduce cost for DRAM circuits . Integrating the two technologies into a single process capable of eliminating the expensive additional mask layers has proven more difficult than expected . <p> IC designers have n't faced the same process constraints with embedded SRAM . Used for many years to accelerate performance in high-end network routers and switches , embedded SRAM does n't require extra masking steps . This is because it 's based on the same process used in logic designs . Moreover , while embedded SRAM employs a larger cell size than DRAM , new technologies are emerging to help boost embedded SRAM density . So , despite recent advances in the development of embedded DRAM and flash memory processes , embedded SRAM remains the workhorse of ASIC memory designs . <p> The key to embedded SRAM performance is memory compiler design . As process technologies have matured from one generation to the next , though , compiler designers have faced unprecedented challenges . A memory compiler works on the basic principle that memory has a regular structure . @ @ @ @ @ @ @ @ @ @ memory array , predecoder , decoder , and the column select and I/O section . The memory array is constructed by using the same memory core cell ( Fig. 1 ) . The other three building blocks are also erected from a basic leaf cell . A compiler creates a memory design by using instances of the different leaf-cell types to make up the desired memory width and depth . <p> To address the ever-increasing demands of ASIC designs , memory compiler developers must constantly strive to improve density , performance , and power as technology moves from one generation to the next . Top performance in all of these areas is achieved when the leaf cell and memory core cell are optimized for both process technology and memory-size range . For example , LSI Logic Corp . has developed SRAM compilers optimized for different memory-size ranges and memory core cells that combine the highest driving capability and the smallest size for G12 0.18--m technology . <p> Over time , new challenges have also forced compiler architects to adapt . Compiler designs are now optimized to meet the demands for @ @ @ @ @ @ @ @ @ @ are deployed to improve performance and power consumption . SoC cores are designed with tightly coupled memories to overcome the processor-to-memory bottleneck . <p> As more complex system functions were integrated onto a single chip , the memory compiler had to evolve to embrace more memory subsystem features as well . Today 's embedded memory designs often feature multiport , synchronous or asynchronous operation , and stringent power control ( Fig. 2 ) . <p> Perhaps , though , the greatest challenge facing the embedded SRAM developer is how to satisfy the growing demand to embed ever-larger memories on-chip . Over the past few years , the amount of embedded memory available to ASIC designers has rapidly grown from 1 Mbit in a 0.35--m process technology to 2.5 Mbits in 0.25--m processes , and more recently , to 6- to 8-Mbits in 0.18--m technology . That , in turn , has dramatically complicated the test process . To fulfill those requirements , current embedded memories typically feature built-in scan latches and a scan path , as well as a built-in self-test ( BIST ) logic wrapper to perform self test @ @ @ @ @ @ @ @ @ @ of cost-effective embedded memory designs . Accordingly , many ASIC manufacturers have gone a step beyond and integrated redundant rows and columns into their memory structures . <p> Some employ soft built-in self-repair ( BISR ) schemes in which the device identifies a bad row in a self-diagnostic routine and uses address mapping logic to automatically translate it to a good address space . While soft BISR strategies can improve yield and reduce cost , they present some significant limitations . <p> Usually , a soft BISR solution can add up to 1.5 ns to address setup time , posing a significant liability for high-performance designs . Developers must be aware of this liability and restrict soft BISR use to applications that can tolerate this additional time penalty . Plus , repair in soft BISR is a function of the power-on condition . Repeatability also is an issue . Finally , designers must compensate for power-on time . A soft BISR solution takes approximately 2 ms to run BIST , identify faulty rows , and repair them before the memory can be used . <p> Recently , some ASIC vendors @ @ @ @ @ @ @ @ @ @ is similar to those employed in standard DRAM parts using a fuse link and laser system to implement repair in manufacturing . In these schemes , an algorithm automatically burns in a field that directs the fuse box to connect to a good row address as soon as the bad address arrives ( Fig. 3 ) . In a hard BISR scheme , the fuse register output is linked to the scan output of a faulty location analysis and repair execution ( FLARE ) unit . The only time enable is high is when the fuse data is read into the FLARE at power-up . A BISR operation mode loads information directly from the fuse bank into the FLARE register , so remapping can take place without rerunning the BIST . <p> Hard BISR promises to eliminate the performance penalty and repeatability issues that designers must grapple with in a soft BISR approach . But , it requires more design and engineering resources than a soft BISR solution . Furthermore , it demands that designers pay a slightly higher silicon area overhead due to employment of the fuse bank . @ @ @ @ @ @ @ @ @ @ on-chip , they become increasingly susceptible to soft error rate ( SER ) , which is caused by exposure to alpha particles and cosmic rays . That , in turn , has driven the integration of error correction circuity ( ECC ) into memory designs . <p> Another way to mitigate some of the SoC embedded memory demands is to embed system functions into memories , rather than embedding memories into system functions . An excellent example is the content addressable memory ( CAM ) , a proven technology that 's historically been implemented in ASIC/custom design . Today , it 's economically feasible as a standard product . <p> Used extensively to handle packet-classification and policy-enforcement tasks in data networking applications , CAMs utilize a search-table concept to provide a higher-performance alternative to software-based searching algorithms . The architecture is based on the idea of associating a mask word with each CAM word , allowing the user to mask entries on a per-bit basis . To add an auto lookup function into memory , a CAM builds an exclusive-or ( EOR ) function into a standard SRAM ( Fig. @ @ @ @ @ @ @ @ @ @ in a random fashion . It can be stored at a specific address similar to RAM , in the next empty location , or written over a location with invalid information . Each location has an Empty flag bit and a valid bit to facilitate storing information into those locations . Once the CAM is loaded with application information , data can be found by comparing every memory bit with every data bit in the Comparand Register . This is made possible by the built-in EOR function of the memory cell . All bits in a stored location are connected to a Match line . If every bit is a match , then the Match line wo n't be pulled down . A Match flag bit is set to indicate that the information is found in the device . The search time is deterministic because a CAM searches all locations in one cycle . <p> To maximize an ASIC designer 's flexibility and support the use of product-specific features and configurations , custom CAM compiler technology is currently available in today 's market . That same technology also helps reduce @ @ @ @ @ @ @ @ @ @ CAM cores , the HSTLB , supports applications requiring smaller CAM densities of less than 256 entries and 72-bit word widths , while a second , the HDCAM , addresses networking applications that need larger CAMs in the 4-kword by 68-bit range . <p> Because custom compiler technology offers more flexibility , a number of unique features and functions can be added to support high-speed data search applications . For instance , these cores can be partitioned into CAM and SRAM , or associative and associated data fields . The intrinsic lookup capability of the CAM provides the address pointer to the SRAM . The associative data in the SRAM is accessible on the next instruction cycle for read or modify . This matches the requirements of networking system address attributes ( associative data ) stored with the network address . <p> Attributes may include protocol identifiers , port identifiers , or static/dynamic entry marker bits , among others . This quick lookup and subsequent translation capability enables the ASIC designer to use the CAM for protocol translation and header processing applications . In a typical application the designer could @ @ @ @ @ @ @ @ @ @ , or to make the conversion the other way around . <p> A unique Format Control CAM field ( Format CAM ) let 's the device simultaneously store different CAM word types in the CAM . A CAM with four 1-kword quadrants and a 4-bit-wide Format CAM can simultaneously store 64 different CAM word types in the 4-kword CAM . This flexible search capability allows the designer to mix many different search data in the CAM . Some common examples include the ability to store double-wide words along with single-wide words , store and search various address header subfields like source and destination address or ports , and mix protocols such as ATM and IP . <p> Another key capability in networking applications is multiple-match prioritization . In this situation , the CAM automatically prioritizes the entire 1-kword quadrant search space and returns the highest priority matching entry . A parallel search of all quadrant locations identifies priority with a binary-coded output called ENCA . The CAM assigns an internal status bit or " valid bit " for each of the words to determine which entries are valid . But the @ @ @ @ @ @ @ @ @ @ . The set operation is automatically registered on a load command and may be reset through the reset command or the unload command . <p> To accelerate processing of multiple matches , a NextMatch mode resets the current highest priority matching entry , completes a reprioritization , and returns the next highest matching entry within a single cycle . This mode efficiently identifies the multiple matches without the need for successive compare , unload , and re-compare operations . <p> A next available output ( AVAL ) feature helps facilitate the management of data storage within the CAM . By prioritizing and encoding all valid bits , AVAL always provides the highest priority unused address location that 's available for data storage . <p> To minimize power consumption in large CAMs , the HDCAM architecture also is partitioned into quadrants , and a pipelined data flow is imposed on one quadrant . This enables ASIC designers to use internal circuitry to automatically stop the clock for inactive quadrants . <p> These unique capabilities can play a major role in the successful development of an SoC product . Recently , one @ @ @ @ @ @ @ @ @ @ by 68-bit CAM with special purpose hardware to control the associative search process in a network router application . The customer chose to integrate the hdcm4k68 HDCAM memory block into a device fabricated in LSI 's G10 0.35--m process . <p> The ASIC combined 180 kgates of logic , two single-port memories ( one 512 words by 32 bits and the other 1 kword by 32 bits ) and a 64-way by 24-word by 30-bit HSTLB block . The hdcmkx68 HDCAM occupied 5.8 million of the device 's total 7.1 million transistors . The customer opted for a VG56 PBGA+ high-performance , low-inductance package to handle the thermal and power effects generated by the hdcm4k68 's 550-mA average current requirements . <p> The real benefit of using custom CAM compiler technology comes when a designer needs to meet unique data search requirements . In this case , the customer was able to take advantage of bit- and column-masking , a double-wide search mode , and the successive processing of multiple matching entries to boost performance . Moreover , the HDCAM 's quadrant architecture gave the customer the opportunity to implement @ @ @ @ @ @ @ @ @ @ into 1-kword quadrants , the designers were able to power down three-fourths of the CAM space in each clock cycle , significantly reducing power consumption . <p> More Logic Functions To Come The next step is to extend the CAM concept by adding more logic ( system ) functions to memories . A typical example is adding a logic function , such as compare , to a CAM . That type of device would support a fully associative search on user-defined fields over logic functions . <p> A more radical extension of the embedded-memory concept is to integrate the processor function into memory . This type of architecture promises to dramatically alter traditional concepts of memory as a passive element . Instead of reading out only what has been written into it , memory with a processor function ( or collaborative memory ) will be able to modify data when it 's accessed through a process . An excellent example of a potential collaborative memory function is data compression and decompression . Many mechanical storage devices , like tape or disk drives , now compress or decompress stored data on-the-fly @ @ @ @ @ @ @ @ @ @ to embed even more complex system functions . One of the hottest topics in memory research is the development of intelligent devices capable of memory-assisted computation . Researchers are already laying the groundwork for devices that will essentially eliminate the processor-to-memory bottleneck in today 's systems by merging both functions on-chip in a much more fundamental manner than today 's embedded memory devices . These new devices should eliminate the processor-to-memory performance gap , provide a better building block for parallel processing , and more efficiently utilize the tremendous number of transistors available on a single chip . <p> Enabling this new generation of intelligent memories will be continual gains in device density as process technology tracks Moore 's Law . Some researchers predict devices capable of offering 1 Gbit of on-chip memory , which will support internal bandwidths approaching 100 Gbits/s . This dramatic improvement in memory/system bandwidth promises to not only revolutionize system performance , but also to open the door to the rapid development of truly reconfigurable systems . 
@@21004687 @1004687/ <h> Built-In Self-Test Streamlines Testing Of Mixed-Signal SoCs <p> As the integration between digital and analog circuitry in-creases in system-on-a-chip ( SoC ) designs , the challenge of testing these mixed-signal functions be-comes increasingly complex in terms of test development time , automatic-test-equipment ( ATE ) complexity and cost , and production test times . There are some built-in self-test ( BIST ) methodologies available today that enable the analog portions of an SoC design to effectively test themselves . They also can report results in digital format , minimizing the impact of this increased integration . <p> This reduced impact is particularly true for analog-to-digital converters ( ADCs ) , digital-to-analog converters ( DACs ) , and voltage-controlled oscillators ( VCOs ) . Employing a technique called histogram-based analog BIST ( HABIST ) , the results of analog circuit tests can be converted to digital test results . The resulting digital data can then be analyzed for such parameters as integral and differential nonlinearity , gain and offset errors , effective least-significant bit ( LSB ) , and clipping and modulation distortion . <p> During an HABIST implementation @ @ @ @ @ @ @ @ @ @ to a histogram , from which characteristics can be studied to gain valuable information about circuit performance . The sample-and-hold circuit and the ADC perform the conversion from the analog domain to the digital domain ( Fig. 1 ) . Once the data from the ADC is fed to the histogram generator , the results can be downloaded and read by a digital ATE system . <p> The technique uses undersampling of the analog signal(s) under test to quantify how long the signal remains at each amplitude level , placing the values in various bins in a histogram ( Fig. 2 ) . The histogram characterizes the waveform of the signal under test , capturing its essential elements . <p> Using software simulation tools , an ideal histogram for each signal under test can be created , as can histograms for signals due to certain defects , like stuck bits and various types of nonlinearity and distortion . These signatures for various types of faulty circuit behavior can be stored for use in determining the pass/fail status of analog circuits under test during production testing . <p> Should the signal @ @ @ @ @ @ @ @ @ @ normally undergoes significant changes ( Fig. 3 ) . The clipped sinewave shown does n't spend nearly as much time at the high and low boundaries . Therefore , the resulting histogram has fewer entries in the outside bins and many more entries in the bins adjacent to them . Subtracting the acquired histogram from the ideal histogram creates a difference histogram that can be analyzed to determine which defects are present in the circuit under test . <p> In addition , the histogram-based method can be deployed to test the ADC that 's part of the circuit itself when a proper stimulus signal , usually a ramp , is applied to its input . The ramp signal can be supplied either by an external signal generator or by a DAC that might already be present in the design ( Fig. 4 ) . Multiplexers at the DAC inputs and output allow it to be employed not only for on-chip functional purposes , but also as the stimulus generator for ADC testing . <p> The results from the histogram-based BIST circuitry can be accessed by a digital-only ATE , offering @ @ @ @ @ @ @ @ @ @ IEEE-1149.1 ( standard protocol from JTAG for Joint Test Action Group ) testability bus interface , normally included in the design to provide access to the on-chip boundary-scan circuitry , can be used to access the HABIST results . ( Boundary-scan circuitry enables interconnect testing during board assembly . ) These are placed in a user-defined test data register and accessed by the standard 1149.1 protocol . <p> The same histogram-based technology applies to DACs . It can solve the many problems that designers encounter when the DAC is embedded in a complex SoC design . <p> Traditionally , DACs have been tested by successively applying all of the digital codes to the DAC input signals to cause the analog output of the DAC to swing over its entire range . Analog instruments are then typically used to measure the DAC output voltage in response to each input code . These discrete measurements are examined to determine the gain and offset parameters of the DAC under test and to calculate its integral and differential nonlinearity . <p> Some common problems are associated with these traditional methods . A mandatory test @ @ @ @ @ @ @ @ @ @ codes . Other problems include analog instrument-measurement errors , settling times , and the controllability of the DAC digital inputs . All of these issues can be addressed with a variation on the basic HABIST methodology . <p> Let 's refer to the previous example configuration ( Fig. 4 ) . After the ADC is tested through the HABIST implementation , the tested ADC can be used as the on-chip measurement instrument for any embedded DACs to be tested . A multiplexer at the DAC output routes the signal under test to the integrator and comparator circuitry . Next , the BIST circuitry simply treats the DAC output as another analog signal to be evaluated , reading the data digitally and analyzing it by histogram methods . <p> Alternatively , if no sample-and-hold and ADC circuitry is available on-chip for this purpose , a dedicated DACBIST circuit can be implemented ( Fig. 5 ) . For test purposes , the test control circuitry permits the replacement of the DAC inputs by code-pair combinations that will exercise it as required . Switched capacitors alternately sample the reference voltage , derived on-chip @ @ @ @ @ @ @ @ @ @ are fed to an up-down counter . Typically , this counter is 4 bits wider than the number of DAC input bits to obtain maximum accuracy . The output from the counter is stored in the Result register as digital data . <p> There are significant test-time advantages to using a BIST approach for DAC testing . A comparison of traditional ATE test times and BIST test times for various DACs based on the number of bits in the DAC implementation is shown in Figure 6 . As the chart illustrates , unless the DAC under test is very precise ( 16 or 18 bits ) , the advantages of short test time and , therefore , lower test cost offered by using a BIST approach are very significant . Also , with this technique , the DAC can be tested at its full operating speed , so it can be checked for both its static and dynamic operating characteristics . <p> As device speeds continue to increase , timing accuracy be-comes a much more critical factor for both clocks and data circuits . Timing budgets are tightening and thorough @ @ @ @ @ @ @ @ @ @ becoming more important too . The most significant parameters that must be tested for PLLs and VCOs are for various kinds of jitter " peak-to-peak ( p-p ) jitter , root-mean-square ( rms ) jitter , and long-term jitter . <p> Traditional methods for testing these values include time-interval-analyzer and counter-timer solutions . These methods are based on traditional ATE systems equipped with mixed-signal capability in the form of specialized and expensive instrumentation . <p> For VCOs and PLLs , a BIST technique implemented with a pair of ring oscillators can be used to measure true p-p jitter and rms jitter ( Fig. 7 ) . In operation , the two ring oscillators are set to different frequencies , the second slightly higher than the first . Both oscillators begin at the same time and eventually coincide with each other on a specific edge of the signal under test . At this juncture , the coincidence detector stops the measurement cycle , and the results are read from the serial scan register as digital data , eliminating the need for expensive and time-consuming analog instrumentation . <p> Constructed of simple @ @ @ @ @ @ @ @ @ @ ring oscillators can be " tuned " to the correct frequencies ( normally about half the frequency to be tested ) for maximum test speed and accuracy . This BIST technique self-calibrates before each jitter measurement and does n't require an external low-jitter reference signal . The technique has the advantage of running at full device operating speed . <p> Moreover , it 's not subject to the measurement errors that can occur when the assumption is made that all jitter exhibits Gaussian behavior , which frequently does n't happen . Using BIST for jitter measurements can conserve much of the requisite test time . The time required for each measurement decreases as the device speed increases . <p> When this VCO-based BIST technique is combined with the histogram-based technique , it 's possible to write code for a PC that will display the test results ( Fig. 8 ) . Or , they may be downloaded to a digital-ATE system for analysis . Alternatively , the comparison can be implemented completely on-chip . <p> This VCO-based BIST technique has been implemented , for example , on a 500-MHz programmable @ @ @ @ @ @ @ @ @ @ with its 0.18--m advanced CMOS process . Another advantage of the VCO-BIST technique is that its speed , resolution , and accuracy keep pace with increasing device speed . In fact , this VCO-BIST technique has no theoretical limits . <p> As mentioned previously , the results from the histogram-based BIST circuitry can be obtained with digital-only ATE for major reductions in cost and complexity using the JTAG testability bus interface . Normally , this interface is included in designs to provide access to the on-chip boundary-scan circuitry . The histogram-based analog BIST results ( either go/no-go or actual measurement data ) are placed in the user-defined test-data registers provided by the JTAG architecture ( Fig. 9 ) . These are accessed using the IEEE-Std-1149.1 protocol . <p> Implementing the standard test-access port offers significant advantages . Synthesizable versions of the TAP ( Test Access Port ) logic are widely available , both from design-automation vendors as well as within the intellectual-property libraries of most IC manufacturers . Additionally , almost every digital ATE system today has both the hardware and software in place to interact with TAP logic . @ @ @ @ @ @ @ @ @ @ to get data into and out of the BIST circuitry . <p> Analog and mixed-signal BIST techniques can often be employed as an alternative to complex and expensive mixed-signal ATE systems . Or , they can be used to augment those systems implementing a distributed test strategy where some BIST circuitry is included in the chip design and some of the processing hardware is placed on the tester 's load board . The software can often be similarly distributed . <p> Designers frequently tout BIST as a complete replacement for ATE systems . In reality , though , it 's not a replacement strategy . Instead , it 's a very valuable adjunct to extend the life of existing digital ATE systems when new SoC designs include mixed-signal circuit blocks . <p> The techniques described in this article can be implemented on-chip with minimal silicon . They often result in reduced test-development and debug times , which can speed up time-to-market . Furthermore , shorter production test times reduce product testing costs . Finally , because of its increased fault coverage , BIST leads to higher product quality . 
@@21004689 @1004689/ <h> Circuit Aging : A New Phenomenon For SoC Designs <p> The Electronic Design Automation ( EDA ) industry continues to face new challenges as it targets ever shrinking deep-submicron geometries . Each successive advancement of semiconductor technology has brought about a new very-deep-submicron ( VDSM ) phenomenon , such as heat dissipation , electromigration , and interconnect coupling . Many EDA design tools have been enhanced to deal with these issues . Now another issue , circuit aging , has come to the forefront . This phenomenon must be addressed to ensure VDSM performance . <p> Circuit aging refers to the deterioration of circuit performance over time . The length of time can be a few years to a few months under worst-case conditions . Circuits have always aged . But , this aging was n't significant until the latest iteration of Moore 's Law , which pushed transistor channel lengths to 0.18 -m . The simultaneous use of extremely small channel lengths and higher operating frequencies has elevated circuit aging from an academic exercise to a growing , and perhaps detrimental , concern for system-on-a-chip ( SoC @ @ @ @ @ @ @ @ @ @ ignored . All portions of the SoC , whether analog , digital , or memory , will be affected . These negative impacts can include slower speeds , irregular-timing characteristics , and increased power consumption . In ex-treme cases , circuit aging may even cause functional failures to occur over time . <p> The predominant cause of circuit aging is the degradation of individual deep-submicron transistors . This behavior , known as hot-carrier-Induced ( HCI ) degradation , has been extensively studied since the early 1980s . A transistor conducts when carriers are sent from one side of the transistor , known as the source , to the other side , the drain . The force that propels these carriers is called the electric field . In VDSM transistors , these electric fields become much more intense . As a result , the carriers travel much faster , leading to the increase in speed . Such speeds , however , come with a price . <p> The carriers have been accelerated so much and travel so fast that upon their arrival at the drain side of a transistor , they @ @ @ @ @ @ @ @ @ @ that occurs , called impact ionization , results in the splitting of each atom into two new carriers : one electron and one hole ( Fig. 1 ) . The longer the transistor is in operation , the greater the number of new carriers that are generated . Both HCI and circuit aging are cumulative behaviors over time . <p> The newly created carriers would n't be so bad if they did n't cause damage to the physical structure of the transistor . Unfortunately , they do cause harm . In the NMOS-type transistor , the electrons cause damage at a particular area , between the gate oxide and the silicon surface . This interface can become populated with so-called interface " states " causing the NMOS transistor to have higher threshold voltages . As a result , they produce less current which translates into slower switching speeds . The exact amount of this decrease can be quantified by measuring the newly created holes that flow out through the silicon substrate ( represented by ISUB ) . <p> For PMOS transistors , the degradation mechanism is a little different . @ @ @ @ @ @ @ @ @ @ This time , though , they lodge and trap themselves inside the gate oxide of the transistor . Such electron-trapping causes the PMOS transistor to have lower threshold voltages . As a result , PMOS transistors will have more current than before HCI degradation . The monitor for PMOS transistors is gate current ( by IGATE ) . <p> The precise amount of degradation for a transistor is a complicated function of its bias or operating conditions . Usually , a fixed amount of device degradation is assigned . The time to reach this amount is used to gauge the robustness of the technology to HCI degradation . For example , it might take five months to reach a 10% change in the drain current of a transistor . Therefore , the lifetime of the transistor would be five months . For the past 15 years , lifetimes have rapidly decreased from roughly 10 years to just a few months . This downward spiraling trend has caught the eye of many semiconductor manufacturers , and is indicative of the severity of HCI and circuit aging . <p> Circuit aging is @ @ @ @ @ @ @ @ @ @ depth of its degradation will only expand as designs use smaller transistors and operate at faster speeds . Critics have argued that lowering the level of the power supply with each successive semiconductor-technology generation will significantly lower the electric fields inside each transistor . Furthermore , they claim , this will make HCI and circuit aging disappear . But , evidence proves otherwise ( Fig. 2 ) . <p> Incremental drops in power-supply voltage simply are n't enough to offset the rigorous pace of Moore 's Law . Electrical fields inside transistors will still increase . HCI effects will still occur . Plus , SoCs will be prone to circuit aging . Given this fact , it 's important to understand why each part of the SoC design " analog , digital , and memory " will be at risk . <p> Traditionally , analog circuitry has been implemented with technology that 's at least one to two generations behind the current , state-of-the-art digital process . With the explosion of wireless communications devices , such luxuries can no longer be afforded . Current mixed-signal designs require real-time analog-to-digital or @ @ @ @ @ @ @ @ @ @ As a result , the analog portions of the SoC are now being designed with the same short channel lengths as their digital counterparts . <p> Certain principles of analog design make it very susceptible to circuit aging . First , analog circuitry is constantly biased even if it is n't in active operation . This means that HCI degradation is constantly occurring as transistors are always conducting currents . Next , analog performance is more closely linked to such characteristics as gain than to drain current levels . It has been shown that while current levels might degrade only slightly , the gain can degrade significantly . Third , HCI worsens a long-time enemy of analog designs " mismatch . This occurs when identically designed devices differ from one another . Experimental studies have shown that mismatch in differential amplifiers and current mirrors ( two staple components of analog designs ) are enhanced by HCI degradation . They ultimately contribute to circuit performance degradation over time . <p> In addition , analog design has been plagued with the so-called nonscalability of power-supply voltage . The continual reduction of the @ @ @ @ @ @ @ @ @ @ designs . Therefore , more amplification stages have to be added at a cost to other design specifications , such as area and power consumption . Many state-of-the-art technologies now have dual-mode power supplies . One is reduced for the digital portion and another higher voltage supply is for the analog portion . With the combination of short channel lengths and high power-supply voltages exacerbating analog circuit aging , the overall conclusion for analog portions of SoCs is n't good . <p> The outlook for the digital portion of SoCs is n't much better . Circuit aging is a strong function of the rise and fall times of input and output signals of digital blocks . The longer the transition times , the greater the amount of aging . This is due to the fact that the transistors within these blocks spend more time in degradation-prone bias conditions . The digital section of the SoC has a myriad of such transition times , owed in part to different loading conditions at different nodes . Consequently , some blocks will invariably age more rapidly . As a result , the timing @ @ @ @ @ @ @ @ @ @ their intended design specifications . Such disturbances can degrade circuit performance and place the operation of the entire digital portion in jeopardy . <p> This uneven aging is compounded by the fact that circuit aging also depends on switching activity . Higher switching activities mean more input and output transitions for the same period of time and , consequently , more aging . Because different parts of the design switch at different speeds , nonuniform circuit aging will again cause timing patterns to differ . Aside from switching activity , minute voltage spikes or overshoots can cause circuits to age too . Voltage overshoots as small as 0.020 V can cause dramatic increases in HCI degradation for the transistors attached to the overshooting node . This is because such voltage spikes are similar to raised power supply levels . Such is the case even if it 's only for a very brief moment in time . Nonetheless , they can suddenly increase the electric fields within the affected transistors and place the transistor under stress . Voltage overshoots occur all the time in digital circuits as a result of interconnect @ @ @ @ @ @ @ @ @ @ between a block 's input and output nodes during switching events . <p> The sensitive nature of circuit aging is n't lost upon the embedded memory portions of the SoC . In SRAM-type memory cells , for example , circuit aging can manifest itself through HCI degradation of the pass transistors . These transistors act as gatekeepers during the write and read phase of memory operation . Their bidirectional operation ( meaning it sees twice the activity of ordinary transistors ) enhances HCI degradation . The end result is an increase in access time , which is one of the most critical memory design performance specifications . Sense amplifiers , crucial for proper operation of DRAM- and SRAM-type memories , suffer from circuit aging too . This is due to the fact that they are one of the basic analog blocks and share many of the previously mentioned analog characteristics . <p> Simulating Circuit Aging Circuit aging is a design phenomenon and requires the creation of design solutions to properly detect , analyze , and solve its potential problems . A good circuit-aging simulator must have the traditional levels of @ @ @ @ @ @ @ @ @ @ be extremely accurate . <p> The first step in simulating circuit aging is developing accurate models to faithfully predict real-life degradation . The simulator will use two kinds of models . The first requires the modeling of transistor substrate and gate currents , which are the two monitors of HCI degradation . This model must be accurate over a broad range of operating conditions and different transistor sizes in order to be usable in SoC designs . Without such attributes , the simulator can not accurately calculate the age of each individual transistor within a design . Presently , these two current types are either poorly modeled , or not modeled at all inside most simulators . <p> The second type of model is the degradation model . The simulator will use it to map the age of each individual transistor to its respective current degradation levels . The formulation of this type of model requires that individual transistors be constantly measured , or stressed , at an accelerated pace over a period of days . Such prolonged testing times are needed in order for the data , and the @ @ @ @ @ @ @ @ @ @ attention to detail introduced at the modeling stage is necessary and underscores the importance of modeling accuracy involved in simulating VDSM effects . <p> Furthermore , in circuit-aging simulations , the underlying simulation technology must be very precise . Voltage waveforms have to be extremely accurate for the sake of reproducing actual transistor bias conditions , which are used to calculate substrate and gate currents . The dependencies of ISUB or IGATE currents on transistor voltages are exponential in nature . Any small inaccuracies in voltages can have a large impact on current levels and , ultimately , age calculations . <p> For example , in a typical 0.18--m technology , 10% error in drain voltage can result in substrate current levels that are off by approximately 150% ! Such sensitivities on voltage waveforms imply that any coupling effects within the design must be captured very accurately . This is particularly true for SoCs where the high densities of interconnect wires can produce capacitive coupling between adjacent wires . Even small voltage overshoots between 0.020 and 0.050 V can increase circuit age as much as five times in some situations @ @ @ @ @ @ @ @ @ @ simulation technology as well as in the input model is of paramount importance . <p> To truly evaluate circuit aging in SoC designs , both dynamic and static timing approaches need to be considered at various stages in the design flow ( Fig. 3 ) . A large-capacity , high-speed , and accurate dynamic simulator can be used during the final verification phase . This is where maximum simulation accuracy is possible because of the availability of parasitic information , ( like interconnect capacitance ) used for calculating interconnect coupling . <p> In order to run a meaningful dynamic simulation , designers need to specify how many years the design is supposed to operate reliably . They need to provide a set of input-voltage waveforms or vectors as well . These hot-input vectors should be selected to cause the most switching activity , hence degradation , within the design . The idea is to evaluate the performance of the design after simulation in order to see if the functionality is still preserved after the specified years of operation . If functionality is preserved , then the next step is to @ @ @ @ @ @ @ @ @ @ While a dynamic verification tool offers the most accuracy , it has some drawbacks . One is its reliance on a set of hot vectors that are responsible for true worst-case circuit aging . These are very difficult to generate . To do so , an exhaustive number of input vectors need to be randomly generated and fed into the dynamic simulator . Once this feat has been accomplished , a worst-case input vector must be located for each transistor . Then , all of these vectors have to be combined to find the worst-case degradation of the entire circuit . For any current 32-bit-input design , the number of total possible input combinations is astronomically too large to be realistically simulated during short product-design windows . <p> Static Analysis Eliminates Vectors Another approach is the use of static timing analysis . By its very nature , a static approach does n't rely on input vectors . When properly implemented , static analysis finds not only the worst-case degradation for each transistor , but also the worst-case delay paths . The static circuit-aging simulator can trace through the entire SoC @ @ @ @ @ @ @ @ @ @ . Worst-case conditions are used for interconnect coupling and transistor rise/fall times . <p> In the end , designers will receive a report detailing which paths have aged the most . Designers can then examine whether or not those delays exceeded any design specifications for proper circuit operation . If there 's a problem , the static tool will output a list of devices within each path that need to be fixed . The case against static analysis is that it can produce nonphysical results . An example would be finding a delay path that does n't exist . This is a possibility for certain logic styles making extensive use of feedback loops , whereby a dynamic simulation is the better approach . <p> In summary , circuit aging is a new phenomenon to SoC designs at 0.18 -m and below . Hot-carrier-induced degradation is the responsible physical mechanism . All parts of the SoC can be affected . But , the parts especially affected are those that have a combination of short channel lengths , high switching activity , and elevated power-supply voltages . Precise simulation of the effects @ @ @ @ @ @ @ @ @ @ of dynamic and static approaches . <p> Several solutions on the market can address the circuit-aging issue . For example , BTA Technology is working on tools which simulate circuit aging at the Spice and gate levels . These tools are coupled with software to accurately model the underlying physical ailment , the hot-carrier effect . Such two-prong approaches are necessary in the EDA industry to successfully describe VDSM phenomena as well as migrate them into the design-tool chain flow . <p> Regardless of the analysis strategy , circuit aging creates a strong requirement for a simulator that 's both accurate and fast . The sensitive dependencies of the underlying degradation mechanisms forbid any less-accurate solution . At the same time , the increased complexity of SoC designs requires fast simulation times . The EDA industry has responded before to similar challenges . Will it now rise up and respond to the latest one ? 
@@21004694 @1004694/ <h> Poster : Internet of Things ( IoT ) <p> Sponsored by : Keysight Technologies <p> Jun 21 , 2016 <p> The internet of things ( IoT ) will transform our everyday life as it enables billions of things to be connected anytime , anyplace , with anything and anyone . Applications span from consumer usage such as smart homes , connected cars and wearable devices to industrial applications covering energy systems , agriculture , mining , transportation , healthcare and more. - This poster maps out the various wireless protocols being used and/or evaluated to build out the IoT infrastructure . 
@@21004696 @1004696/ <h> SOT-23 's FET Boasts Of Low On-Resistance <p> The TN5325 has a guaranteed n on-resistance of just 8 ohms maximum , reportedly the lowest recorded by a SOT-23 packaged 250V MOSFET . The device 's drain-to-source breakdown voltage is 250V minimum and its drain-to-source on resistance is 7 ohms maximum . Also , maximum switching times are as follows : td(on) = 20 ns , tr = 15 ns , td(off) = 25 ns , and tf = 25 ns . The device is also available in a SOT 89 ( TO-243AA ) package and a TO-92 package , designated as the TN5325N8 and TN5325N3 , respectively . Prices range from $0.23 to $0.31 each/10,000. 
@@21004697 @1004697/ <p> A common application seen throughout the industrial and commercial sectors is proximity sensing " detecting when some object is physically close to a sensor . A variety of processes can be implemented with proximity sensors , which come in a range of flavors , each with varying degrees of detection range , sensitivity and reliability . However , a new inductive sensor has arrived that could change the face of proximity sensing . <p> Proximity-Sensing Applications <p> In terms of common applications , one of the most prevalent is the pushbutton . When the button is depressed , it initiates some action . In its simplest form , the pushbutton closes mechanical contacts . However , over time and heavy usage , these contacts can become worn or dirty , making the electrical connection problematic . Inductive non-contact switching can eliminate this situation . <p> Another typical application is door or window open/close detection . This requires a highly reliable indication of door or window state. - A common use is in industrial equipment or home-security systems . <p> Proximity sensing also is often employed for event counting @ @ @ @ @ @ @ @ @ @ or detecting fan-blade or gear-rotation speed . Rotary encoders and flow meters are other use-case examples . <p> In event-counting applications , proximity sensors are typically photodetectors and Hall-effect devices . The combination of a light source and photodetector sensor is fast and simple , but it can become dirty in a harsh industrial environment and give false or no indication . Hall-effect detectors are expensive and require a magnet for detection. - <p> However , it 's been shown that implementing inductive sensing in these and the other applications can improve reliability and accuracy . <p> How Does Inductive Sensing Work ? <p> The inductive-sensing method uses two matched inductors connected into oscillator circuits with a resonating capacitor . One coil is a reference and the other is the sensor ; the oscillators generate an ac magnetic field in the coils . An object is detected when it comes close to the coils . To be detected , the object must be conductive . <p> When the object comes within range of the coils , the ac magnetic field induces a current into the conductive object called an eddy @ @ @ @ @ @ @ @ @ @ field that induces an opposing current back into the sense coil , thus lowering the coil 's inductance . Decreasing the inductance increases the frequency of oscillation , which is detected and converted into an off/on switching signal . <p> Inductor-Sensing Details <p> The inductors are usually flat , spiral coils of wire . Their size depends on the size of the object to be detected and the sensing range . The coils are usually mounted side by side on a flat surface. - Alternately , the coils can be etched on a printed-circuit board . When using a PCB , the coils can be stacked one on top of the other by making the coils on both the top and bottom of the board . <p> Coil size can range from about 10 to 50 mm in diameter . The inductance is in the microhenry ( -H ) range , and along with a capacitor , produces an oscillation frequency somewhere in the 300-kHz to 19-MHz range . <p> In general , a larger coil means a longer sensing range . Sensing range is usually short , mostly less @ @ @ @ @ @ @ @ @ @ size also affects range . The sensing range decreases when the target is smaller than the coil size . As a rule of thumb , the coil diameter needs to be at least 2.5 times greater than the sensing range to be fully reliable . <p> If the sensed target is non-conductive , the solution is to attach a small patch of copper foil tape. - Make the target as large as possible with respect to the coil size for best results . <p> The Secret to Reliable Proximity Sensing <p> The key to a reliable and repeatable proximity switch is the use of two inductance coils in a differential circuit arrangement . This arrangement compares the inductance of a sense coil to an identical reference coil . Switching occurs when the inductances are equal . One arrangement for implementing this method is shown in the figure . The identical coils are resonant with a common capacitor . The oscillation frequency of each coil is then converted into a dc level by the inductance converters . These dc levels are compared in a comparator circuit that generates the switching output @ @ @ @ @ @ @ @ @ @ with the inductance detection and switching circuits contained in a single IC . <p> - <p> In general , the output switches low when the sense inductance drops below the reference and returns high when the reference inductance is higher than the sense inductance . Switching occurs during the crossover point when the two inductances are equal . <p> The comparator actually has built-in hysteresis that helps prevent false switching due to noise or mechanical vibration . This hysteresis is set so that the output switches on when the sense-coil inductance drops 0.4% below the reference-coil inductance and returns to the off state when the sense-coil inductance exceeds the reference-coil inductance by 0.4% or more . <p> The switching threshold can be altered by applying an external dc input ( see voltage divider R1-R2 in the figure ) that changes the reference level of the reference-coil input to the comparator. - This allows for fine-tuning of the switching condition to match the application . <p> The advantages of the dual-coil inductance-sensing method are repeatable and reliable switching despite any physical impediments inherent to the environment . It also eliminates magnets @ @ @ @ @ @ @ @ @ @ the final product . <p> All of these above mentioned features are implemented in a single IC developed by Texas Instruments , the LDC0851 . <p> Implementing a Design <p> The inductive-sensing circuit is commonly used with a microcontroller to convert the switching pulses into a more useful output . The output pulses from the comparator are connected to an interrupt input on the microcontroller that in turn accumulates a count value . The value may be useful as is , or it may be combined with a time factor to calculate a rotational speed in RPM or other desired measurement . <p> One possible application is a flow meter . The flow meter incorporates a rotary impeller with blades that are moved by the flowing liquid. - The impeller 's rotational speed can then be determined with the inductive sensing and converted into a flow rate , such as liters per minute , by the microcontroller. 
@@21004700 @1004700/ <h> Addressing The Challenges of Mixed-Signal Internet of Things Designs <p> IoT designs include sensors/MEMS , analog and digital on the same IC . Designing all three together on a single IC has unique challenges such as handling three different modes simultaneously . Watch this 20-minute presentation to learn about a complete flow addressing analog , mixed-signal , MEMS/Sensors domains together with system-level simulation and verification solutions . <p> Dec 06 , 2016 <p> Brought to you by Type <p> On-Demand Webinar <h> Speaker <p> Jeff MillerProduct Marketing ManagerMentor Graphics " Tanner EDA <h> Description <p> IoT designs include sensors/MEMS , analog and digital on the same IC . Designing all three together on a single IC has unique challenges such as handling three different modes simultaneously . Watch this 20-minute presentation to learn about a complete flow addressing analog , mixed-signal , MEMS/Sensors domains together with system-level simulation and verification solutions . <p> All three modes ( schematic , RTL , and behavioral @ @ @ @ @ @ @ @ @ @ system-level verification can be performed . Layout and verification is easily handled when integrating the different domains including the ability to generate a 3D model of your layout for advanced 3D finite element modeling . <p> You will learn about : <p> The typical architectural make-up of IoT designs and the associated EDA tool of creating and verifying such a design . <p> What makes IoT design different than regular IC design . <p> The Tanner EDA IoT product offering and how it can be used to address IoT design and verification challenges . 
@@21004703 @1004703/ <p> There are many standards for short-range wireless technologies , but this variety often perplexes designers who want to select a standard for an application . The popular IEEE 802.15.4 standard and its relative ZigBee often are confused . They are n't the same thing . <p> A designer of wireless applications has multiple choices of standards and protocols ranging from the simple to the amazingly complex . The most familiar choices are Bluetooth and Wi-Fi . Bluetooth has found a niche in the audio space with billions of cell-phone headset connections , automotive hands-free connections , and wireless speakers . Its newer low-energy versions are finding many applications in the medical and sports/fitness world to monitor an individual 's physical status . <p> Wi-Fi is the premier local-area network ( LAN ) technology for high-speed Internet access for laptops , smart phones , and tablets . New faster versions are used in smart TV sets for video transfer . In a stripped down form , it can also be used in data acquisition applications . Low-power versions are now available . Many versions and supplement use the 2.4- @ @ @ @ @ @ @ @ @ @ medical ( ISM ) bands . <p> The proprietary Z-Wave standard has found a niche in the home monitoring and control market . There are other proprietary standards for specific applications , such as WirelessHD for 60-GHz video transfer . Many of these proprietary variations use the ISM bands below 1 GHz , including garage door openers at 315 MHz , remote temperature monitors at 433 MHz , and data acquisition at 915 MHz . A growing category is cellular connectivity for machine-to-machine ( M2M ) and Internet of Things ( IoT ) applications . <p> Most of the rest of the standards use some variation of the 802.15.4 standard . <p> The Institute of Electrical and Electronics Engineers ( IEEE ) supports many working groups to develop and maintain wireless and wired communications standards . For example , 802.3 is wired Ethernet and 802.11 is for wireless LANs ( WLANs ) , also known as Wi-Fi . The 802.15 group of standards specifies a variety of wireless personal area networks ( WPANs ) for different applications . For instance , 802.15.1 is Bluetooth , 802.15.3 is a high-data-rate category @ @ @ @ @ @ @ @ @ @ for body area networks ( BAN ) . There are several others . <p> The 802.15.4 category is probably the largest standard for low-data-rate WPANs . It has many subcategories . The 802.15.4 category was developed for low-data-rate monitor and control applications and extended-life low-power-consumption uses . The basic standard with the most recent updates and enhancements is 802.15.4a/b , with 802.15.4c for China , 802.15.4d for Japan , 802.15.4e for industrial applications , 802.15.4f for active ( battery powered ) radio-frequency identification ( RFID ) uses , and 802.15.4g for smart utility networks ( SUNs ) for monitoring the Smart Grid . All of these special versions use the same base radio technology and protocol as defined in 802.15.4a/b . <p> The 802.15.4 standard defines the physical layer ( PHY ) and media access control ( MAC ) layer of the Open Systems Interconnection ( OSI ) model of network operation ( Fig. 1 ) . The PHY defines frequency , power , modulation , and other wireless conditions of the link . The MAC defines the format of the data handling . The remaining layers define other measures @ @ @ @ @ @ @ @ @ @ final application . <p> 1 . Most networking systems , both wired and wireless , use the OSI communications model . Most systems also use at least the first four layers , but many do not use all seven layers . <p> 2 . The 802.15.4 standard uses only the first two layers plus the logical link control ( LLC ) and service specific convergence sub-layer ( SSCS ) additions to communicate with all upper layers as defined by additional standards . <p> The goal of the standard is to provide a base format to which other protocols and features could be added by way of the upper layers ( layers 3 through 7 ) . While three frequency assignments are available , the 2.4-GHz band is by far the most widely used ( see the table ) . Most available chips and modules use this popular ISM band . <p> The standard uses direct sequence spread spectrum ( DSSS ) modulation . It is highly tolerant of noise and interference and offers coding gain to improve link reliability . Standard binary phase-shift keying ( BPSK ) is used in @ @ @ @ @ @ @ @ @ @ O-QPSK ) is used for the higher-data-rate version . O-QPSK has a constant wave envelope meaning that more efficient non-linear power amplification techniques can be used to minimize power consumption . <p> With regard to channel access , 802.15.4 uses carrier sense multiple access with collision avoidance ( CSMA-CA ) . This multiplexing approach let 's multiple users or nodes access the same channel at different times without interference . Most transmissions are short packets that occur infrequently for a very low duty cycle ( &lt;1 % ) , minimizing power consumption . The minimum power level defined is " 3 dBm or 0.5 mW . Most modules use 0 dBm or 1 mW . However , some 20-dBm or 100-mW modules are available . <p> Transmission range varies considerably depending on the nature of the path that must for the most part be line of sight ( LOS ) . Transmit power level and receiver sensitivity are also factors . Under the best conditions the range can be as great as 1000 meters with a clear outdoor path . Most applications cover a shorter range of 10 to 75 meters @ @ @ @ @ @ @ @ @ @ two topologies . One of them is a basic star ( Fig. 3a ) . All communications between nodes must pass through the central coordinator node . A basic peer-to-peer ( P2P ) topology is also defined ( Fig. 3b ) . Any device may then talk to any other device . This basic topology may be expanded into other topologies in the upper network layers , such as the popular mesh topology . <p> The most widely deployed enhancement to the 802.15.4 standard is ZigBee , which is a standard of the ZigBee Alliance . The organization maintains , supports , and develops more sophisticated protocols for advanced applications . It uses layers 3 and 4 to define additional communications features ( Fig. 4 ) . These enhancements include authentication with valid nodes , encryption for security , and a data routing and forwarding capability that enables mesh networking . The most popular use of ZigBee is wireless sensor networks using the mesh topology . <p> 4 . The ZigBee protocol is defined by layer 3 and above . It works with the 802.15.4 layers 1 and 2 . @ @ @ @ @ @ @ @ @ @ any node can communicate with any other node , if not directly if within range , but indirectly by relaying the transmission through multiple additional nodes ( Fig. 5 ) . The network then can spread out over a larger area . Furthermore , it increases network reliability as it still functions even if one node is disabled . There are usually alternate paths through the network to sustain a connection . For example , if node A wishes to communicate with node G , it can relay data through nodes C and E. If node C fails , another path is via nodes B , D , and F. ZigBee mesh networks are self-configuring and self-healing . <p> 5 . In a mesh network , each node communicates with its closest neighbor as conditions permit . Note that there are alternate paths between any two nodes . <p> ZigBee is also available in a version that supports energy harvesting where no battery or ac mains power is available . And , one of the key benefits of ZigBee is the availability of pre-developed applications . These upper-layer software additions @ @ @ @ @ @ @ @ @ @ include : <p> Building automation for commercial monitoring and control of facilities <p> Remote control ( RF4CE or RF for consumer electronics ) <p> Smart energy for home energy monitoring <p> Health care for medical and fitness monitoring <p> Home automation for control of smart homes <p> Input devices for keyboards , mice , touch pads , wands , etc . <p> Light Link for control of LED lighting <p> Retail services for shopping related uses <p> Telecom services <p> Network services related to large mesh networks <p> The ZigBee Alliance also offers full testing and certification of ZigBee-enabled products to ensure interoperability . <p> ZigBee has been around for more than 10 years now and is widely used . It is a great option for many applications . For some simpler communications projects it may be overkill with its extra complexity and cost . Plain old 802.15.4 may be a better choice in such cases . <p> Other Variations <p> While ZigBee is the most notable example of the use of the base 802.15.4 standard , other protocols are defined for specific applications . The 802.15.5 standard defines a @ @ @ @ @ @ @ @ @ @ version of the wired HART ( highway addressable remote transducer ) protocol standard widely used in automation and industrial control applications . It defines a time multiplexed protocol for accessing multiple nodes of sensors and actuators . <p> The International Society of Automation 's ISA100.11a industrial control standard is used in process control applications . It adds channel hopping , variable time-slot multiplex options , and mesh networking to the 802.15.4 base . <p> One other interesting variation is 6LoWPAN , created by the Internet Engineering Task Force ( IETF ) ( RFC 5933 and RFC 4919 ) . This protocol adaption allows 802.15.4 radios to carry 128-bit addresses of version 6 of the Internet Protocol ( IPv6 ) . It uses header compression and address translation techniques so 802.15.4 devices can access the Internet . The IPv6 packets are compressed and encapsulated so they fit into standard 802.15.4 packet frames . This variation facilitates the use of the standard to implement IoT , Smart Grid , and M2M applications . 
@@21004707 @1004707/ <h> A Short History Of The Pacemaker <p> The advantages of pacing the heart electrically were well known as far back as the early 1900s . Early pacemakers were large , bulky external devices that used vacuum tubes , relied on external ac power , and were frequently too traumatic for young patients . It was n't until shortly after Medtronic was founded that significant progress began . <p> Earl Bakken and his brother-in-law Palmer Hermundslie formed Medtronic in April 1949 as a medical equipment service company . Later , it manufactured some of the equipment . Both men conceived the idea of the cardiac pacemaker while Bakken was working part time at Northwestern Hospital in Minneapolis , Minn . There , Bakken had become acquainted with pioneer open-heart surgeon Dr. C. Walton Lillehei of the University of Minnesota , where Bakken was also studying electrical engineering during the 1950s . <p> Lillehei was looking for a better pacemaking system . One day when Bakken was visiting the hospital , a storm knocked out power , and a patient hooked up to an external pacemaker died . Bakken was @ @ @ @ @ @ @ @ @ @ pacemaker . He had read an article in Popular Electronics on how to build a metronome out of newly available devices known as transistors . He proceeded to build such a circuit in a box the size of a paperback book . This external pacemaker with a 9-V output was tried at the hospital on patients , and the results were successful . This was the genesis of Medtronic 's external pacemaker . <p> Elsewhere , others like Siemens in Europe were working on an implantable pacemaker with rechargeable batteries . But these efforts did not bear fruit , since the battery lifetime was only a few hours . <p> It was n't until late 1959 , when Dr. William Chardack and Dr. Andrew Gage at the Veterans Administration Hospital in Buffalo , N.Y. , working with electrical engineer William Greatbatch , came up with a viable implantable pacemaker using primary cells as a power source . It was known as the Chardack-Greatbatch implantable pacemaker . The National Society of Professional Engineers ( NSPE ) recognized Greatbach 's work , the implantable pacemaker ( patent number 3,057,356 ) , in @ @ @ @ @ @ @ @ @ @ society during the past 50 years . " Greatbatch , through his company Greatbatch Enterprises , licensed his patent to Medtronic in 1961 . The company now produces most of the world 's lithium batteries used in many current pacemakers and defibrillators. 
@@21004709 @1004709/ <h> Fred Terman : The Father Of Silicon Valley Raises An Industry <p> Frederick Emmon Terman was known as " The Father of Silicon Valley . " But even a nickname like that fails to capture his contributions to the electronics industry . Under his leadership , Stanford University evolved from a respected university to a world-class institution . His work in radar countermeasures in World War II saved countless lives . Radio Engineering , which he revised and expanded in three additional editions , is a cornerstone of electronics scholarship . Yet this Father of Silicon Valley was a caring father at home as well . <p> " As a family , we always ate dinner together , " said his son Lewis Terman , a Research Emeritus at IBM and a former president of IEEE . " He came back around 5:30 from the office . He would do something in the study . We had dinner from 6 to 7 . He would rest from 7 to 7:30 , and then hed be back working on the books . But I could interrupt him at any @ @ @ @ @ @ @ @ @ @ Termans family was very important to him , he also had a lifelong devotion to Stanford University , and the Termans and the school have enjoyed a very long association . Freds father Lewis Terman , who invented the Stanford-Binet IQ test , was the chair of the psychology department there from 1922 to 1945 . Fred earned his undergraduate degree in chemistry and his masters degree in electrical engineering there in 1920 and 1922 , respectively . <p> After earning his ScD in electrical engineering under Vannevar Bush at the Massachusetts Institute of Technology in 1925 , he returned to Stanford to join the faculty . He was named the head of the Electrical Engineering Department in 1937 , Dean of Engineering after World War II , and provost of the university in 1955 , retiring at the age of 65 in 1965 . Even then , he continued to consult for the university , and the school honored him with the Frederick Emmons Terman Engineering Center in 1977 and Stanfords Uncommon Man Award in 1978 . <p> " He was proud that the Terman name was going up @ @ @ @ @ @ @ @ @ @ " There was a t-shirt of a map of the Stanford campus and on it was the Terman Engineering Center . When I was wearing it one time , he said , What 's that ? He asked us to buy him one , which we did . " <p> While Fred Terman was dedicated to Stanford during the early years of his teaching career , in 1942 he answered his countrys wartime call and led the secret Radio Research Laboratory ( RRL ) at Harvard University . According to Terman biographer C. Stewart Gillmor , postwar analysts claimed the more than 150 radar countermeasures developed there saved approximately 800 Allied bombers and their crews . <p> " I think he was very well aware that this was saving lives , " Lewis said . " That part of it was very important to him . The German radar , around 43 or so , was really formidable . It was probably equal to ours , maybe not quite as good . They had it set up around Germany in waves . The Germans did n't  have a lot of fighter @ @ @ @ @ @ @ @ @ @ they thought the attacks were coming . When what was called chaff was dropped , it would look like there were thousands of planes coming , so they did n't  know where to send fighters up , and that made a big difference . " <p> Once the war was over , though , it was time for Fred Terman to initiate his plan to bring the school to the forefront of engineering education , as his old mentor Vannevar Bush was directing war-related research funding to American schools . <p> " He definitely felt that there was a game change after the Second World War , and the game change was that he knew there was going to be government money to sponsor research . He knew some people in the industry . Hewlett and Packard were getting started , and there were a number of others . And he said there were really three elements here , " Lewis said . <p> " There is the government money , there 's the university , and the industry . He wanted a tight tie together between industry and the university @ @ @ @ @ @ @ @ @ @ would then go into the industry . That was the model he was working on that he thought had really great opportunities to do great things . " <p> And so Silicon Valley was born . <p> The Father of Silicon Valley <p> While the electronics industry had been centered on the East Coast , Terman felt there was an opportunity to attract established companies and engineers , as well as inspire new ones , in California . In 1951 , he developed the Stanford Industrial Park on land owned by the university on the campus in Palo Alto , Calif . Varian Associates was the first company to sign a lease , followed by Termans former students Bill Hewlett and Dave Packard . Instead of taking all the credit , though , Terman attributed the complexs success to three factors . <p> " One was the California climate . You bring people out from Bell Labs in New Jersey or Boston or wherever in February and its 30 or 40 degrees warmer , and , by the way , February is after the rains have fallen in California so @ @ @ @ @ @ @ @ @ @ gorgeous time . And they say , This is heaven . Why am I in Boston or working for AT&amp;T or Bell Laboratories in New Jersey ? " Lewis said . <p> " The second thing , he would say , was Bill Shockley , the future Nobel Prize winner from Bell Labs , who came out and started a company in Palo Alto . Basically , he was not a good technical or people manager . His employees thought he was going in the wrong direction . He was hard to get along with , so they left to form Fairchild Semiconductor , and then Fairchild people started Intel , and that created this culture of startups out there , that people would move around , starting a new company , and being successful , " Lewis said . <p> " The third thing was my father . He did n't  do anything about the climate . He did n't  do anything about Shockley . But Stanford itself , having a world-class university there , was really important because it was an educational center that people could really rely @ @ @ @ @ @ @ @ @ @ interact . Your employees could get educated and get higher degrees , " Lewis said . <p> The symbiotic relationship between Stanford and Silicon Valley couldnt have happened with the vast network of incredibly talented engineers that Terman had known . When he was a professor , his students included Hewlett and Packard , O.G . Villard Jr. , Robert Helliwell , and Edward Gintzon , according to Gillmor . He also was friends with William Hansen and Russell and Sigurd Varian . These relationships made it easy for Terman to pursue his " Steeples of Excellence " philosophy . <p> " One of his comments was , You do n't  get an 8-foot high-jumper by hiring two 4-foot high-jumpers , " Lewis said . " So you look for the best person you can get . When he was provost , that was one of the big focuses he had , to go out and find the best person he could to head the department , to fill in this chair , and so forth . " <p> An Influential Author <p> Termans reach extended far beyond the engineers @ @ @ @ @ @ @ @ @ @ first edition of Radio Engineering . The second and third editions came out in 1938 and 1947 . When the fourth edition appeared in 1955 , it was called Electronic and Radio Engineering . The different editions were part of the coursework at Stanford and elsewhere . <p> " The second edition in the late thirties was really good . That became the book of record that literally thousands of people around the world used . Then the Second World War ended and he realized that three years of intense progress had been made . He sat down and went through all the stuff in those publications and conferences and incorporated all the changes , all the advances , in the third edition , " Lewis said . <p> " He worked night and day to get the third edition out because he knew the game had changed . If he was n't the first person to get it out , he would lose his place as the textbook leader . So the third edition came out , and again , it was a real winner , and then he did @ @ @ @ @ @ @ @ @ @ , Lewis used the book in his own undergraduate career at Stanford when he took the course under radar pioneer William Rambo . <p> " The fourth edition I got for free , " Lewis laughed . <p> " I took the course . Read the next chapter for tomorrows class. Okay , I read it . My heavens , how am I going to absorb all this ? But somehow you absorb it and you come back three weeks later for a midterm or for reviewing for PhD orals , and its all laid out beautifully . Its all there . Its clear . It was really something spectacular in how well he wrote that book and how much work he put into it , " Lewis said . <p> " People keep coming up to me and say , Are you related to the person who wrote the book ? And they always say , That was it . That 's when I learned electronics . That 's the great book . I still have it. This is 40 or 50 years after they 've studied from it , " Lewis @ @ @ @ @ @ @ @ @ @ Terman is most known as a visionary administrator , he was no slouch in the lab either . Between 1930 and 1947 , he had 36 patents . Still , he was humble when it came to his own technical achievements . <p> " He always felt that he was not as good as people like Bill Hansen . My mother said that was nonsense . He was every bit as good as these guys . But then he had this bent to be in the management side of things . By the time he came back from the Second World War , he was ensconced in management , so I did n't  see his inventiveness , " Lewis said , though he noted his father was particularly proud of one development . <p> " He defined the bandwidth of data transmission by the 3-dB loss points , which quickly became the standard definition of bandwidth . He noted with a smile that nobody remembered that he had defined it , " Lewis said . <p> There were other accomplishments to treasure too . Lewis said his father was primarily @ @ @ @ @ @ @ @ @ @ of being the first president of the Institute of Radio Engineers ( IRE ) , the IEEEs predecessor , from west of the Mississippi River . He had an honorary doctorate from Harvard University that meant a lot to him . And , he received the 1975 Medal of Science from President Ford . <p> " That was a high point of his life , " Lewis said . " There is a picture of him talking to Ford after he received the medal and the family joke is that he was telling Ford how to run the country . " <p> Considering how well Stanford University and the companies in Silicon Valley flourished under his leadership , Ford would have been wise to take this visionarys advice . 
@@21004714 @1004714/ <h> The Engineer 's Guide To High-Quality PCB Design <p> Eventually , almost every EE must design a PCB , which is n't something that 's taught in school . Yet engineers , technicians , and even novice PCB designers can create high-quality PCBs for any and every purpose with confidence that the outcome will meet or exceed the objective . <p> Virtually every electronic product is constructed with one or more printed-circuit boards ( PCBs ) . The PCBs hold the ICs and other components and implement the interconnections between them . PCBs are created in abundance for portable electronics , computers , and entertainment equipment . They are also made for test equipment , manufacturing , and spacecraft . <p> Eventually , almost every EE must design a PCB , which is n't something that 's taught in school . Yet engineers , technicians , and even novice PCB designers can create high-quality PCBs for any and every purpose with confidence that the outcome will meet or exceed the objective . Also , these designs can be completed on schedule and within budget while meeting the design requirements . @ @ @ @ @ @ @ @ @ @ steps and strategies , and final checks . <p> Download a special PDF version of this article , which is exclusive only to Electronic Design community members . <p> The Basic Design Process <p> The ideal PCB design starts with the discovery that a PCB is needed and continues through the final production boards ( Fig. 1 ) . After determining why the PCB is needed , the product 's final concept should be decided . The concept includes the design 's features , the functions the PCB must have and perform , interconnection with other circuits , placement , and the approximate final dimensions . <p> 1 . The ideal PCB design flow begins when designers recognize a need that must be fulfilled , and it doesn+ ? ? t end until testing verifies that the design can meet those needs . <p> Ambient temperature range and concerns regarding the operating environment should be addressed and used to specify the materials selected for the PCB . Components and PCB materials must be selected to guarantee operation under all expected and potential forms of duress the board may be exposed @ @ @ @ @ @ @ @ @ @ drawn based on the concept . This detailed diagram shows the electrical implementation of each function of the PCB . With the schematic drawn , a realistic drawing of the final PCB dimensions should be completed with areas designated for each of the circuit 's schematic blocks ( groups of components closely connected for electrical reasons or constraints ) . <p> Bill Of Materials <p> Simultaneously with the schematic 's creation , the bill of materials ( BOM ) should be generated . The components in the circuit should be selected by analyzing the maximum operating voltages and current levels of each node of the circuit while considering tolerance criteria . With electrically satisfactory components chosen , each component should be reconsidered based on availability , budget , and size . <p> The BOM must be kept up-to-date with the schematic at all times . The BOM requires the quantity , reference designators , value ( numeric value of ohms , farads , etc. ) , manufacturer part number , and PCB footprint for each component . <p> These five requirements are critical because they define how many of each @ @ @ @ @ @ @ @ @ @ exactly describing each circuit element used for purchasing and substitution , and explain the size of each part for area estimations . Additional descriptions may be added , but it should be a condensed list describing each circuit element , and too much information can over-complicate library development and management . <p> PCB Documentation <p> The PCB 's documents should include the hardware dimensional drawings , schematic , BOM , layout file , component placement file , assembly drawings and instructions , and Gerber file set . User guides also are useful but are n't required . The Gerber file set is PCB jargon for the output files of the layout that are used by PCB manufacturers to create the PCB . A complete set of Gerber files includes output files generated from the board layout file : <p> Silkscreen top and bottom <p> Solder mask top and bottom <p> All metal layers <p> Paste mask top and bottom <p> Component map ( X-Y coordinates ) <p> Assembly drawing top and bottom <p> Drill file <p> Drill legend <p> FAB outline ( dimensions , special features ) <p> Netlist file @ @ @ @ @ @ @ @ @ @ but are not limited to notches , cutouts , bevels , back-filled vias-in-pad ( used for BGA-type IC packages that have an array of pins under the device ) , blind/buried vias , surface finish and leveling , hole tolerances , layer count , and more.1 <p> Schematic Details <p> Schematics control the project , so accuracy and completeness are critical for success . They include information that is necessary for the proper operation of the circuit . A schematic should include adequate design details , such as pin numbers , names , component values , and ratings ( Fig. 2 ) . <p> 2 . Proper schematics , such as this one for the IDTP9021R wireless power receiver+ ? ? s buck regulator block , include pin numbers , names , component values , ratings , and other vital details . <p> Embedded within each schematic symbol is the manufacturer part number used to determine price and specifications . The package specification determines the size of the footprint for each component . The first step should be to make sure the exposed copper for each pin is in the @ @ @ @ @ @ @ @ @ @ ( 3 to 20 mils ) depending on available area and soldering method . <p> Consider assembly when designing footprints , and follow the manufacturer 's recommended PCB footprint . Some components come in microscopic packages and do not allow room for extra copper . Even in these cases , a stripe of 2.5 to 3 mils of solder mask should be applied between every pin on the board . <p> Follow the rule of 10 . Small vias have a finished hole size of 10 mils with 10 additional mils of pad ring . Traces should be 10 mils or further from the edge of the board . Trace-to-trace pitch is 10 mils ( 5-mil air-gap , 5-mil trace width , 1-oz copper ) . Vias with 40-mil diameter holes or larger should have a pad ring added for reliability . An additional 15 to 25 mils of clearance beyond the design rule should be instated for copper planes on outer layers from plane to pins . This reduces the risk of solder bridging at all solder points . <p> Component Placement <p> Component placement is next in the @ @ @ @ @ @ @ @ @ @ and electrical noise considerations . A first-pass component placement step commences after the outline of component and interconnect position has been assigned . Immediately after the individual components are placed , a placement review should be held and adjustments made to facilitate routing and optimize performance . <p> Placement and package sizes are often reconsidered and changes are made at this point based on size and cost . Components absorbing greater than 10 mW or conducting more than 10 mA should be considered powerful enough for additional thermal and electrical considerations . Sensitive signals should be shielded from noise sources with planes and be kept impedance-controlled. - <p> Power management components should utilize ground planes or power planes for heat flow . Make high-current connections according to the acceptable voltage drop for the connection . Layer transitions for high current paths should be made with two to four vias at each layer transition.Place multiple vias at layer transitions to increase reliability , reduce resistive and inductive losses , and improve thermal conductivity . <p> Thermal Issues <p> The heat generated by the IC is transferred from the device to the @ @ @ @ @ @ @ @ @ @ The ideal thermal design will result in the entire board being the same temperature . The copper thickness , number of layers , continuity of thermal paths , and board area will have a direct impact on the operating temperature of components . <p> 3 . IC thermal conduction can be achieved through the use of thermal vias and copper planes . <p> To reduce operating temperatures easily , use more layers of solid ground or power planes connected directly to heat sources with multiple vias . Establishing effective heat and high-current routes will optimize heat transfer by means of convection . The use of thermally conductive planes to spread the heat evenly dramatically lowers the temperature by maximizing the area used for heat transfer to the atmosphere ( Fig. 4 ) .2 <p> 4 . Effective heat spreading can distribute the heat uniformly from a heat source to all of the PCB+ ? ? s exposed surfaces . <p> With even heat distribution , the following formula can be used to estimate surface temperatures : <p> P = ( heatConvection ) x area x ( + " T ) @ @ @ @ @ @ @ @ @ @ = power dissipated on the board <p> Area = board ( X axis x Y axis ) <p> + " T = surface temperature " ambient temperature <p> HeatConvection = convection constant based on ambient conditions <p> Fine-Tuning The Component Placement <p> Components should be placed in the following order : connectors , power circuits , sensitive and precision circuits , critical circuit components , and then the rest . The schematic is built around each part on the PCB and completely interconnected . Routing priority for the circuit is chosen based on power levels , noise susceptibility , or generation and routing capability . <p> In general , trace widths of 10 to 20 mils are used for traces carrying 10 to 20 mA and 5 to 8 mils for traces carrying less current than 10 mA . High-frequency ( greater than 3 MHz ) and rapidly changing signals should be carefully considered when routed along with high-impedance nodes . <p> The lead engineer/designer should review the layout , and physical locations and routing paths should be adjusted iteratively until the circuit is optimized for all design constraints . @ @ @ @ @ @ @ @ @ @ . Add layers in pairs since the copper cladding is produced that way . The routing of power signals and planes , the grounding scheme , and the board 's ability to be used as intended all influence operation . <p> Final inspections should involve verification that sensitive nodes and circuits are properly shielded from noise sources , solder mask exists between pins and vias , and the silkscreen is clear and concise . When determining layer stack-up , use the first inner layer below the component sides as ground and assign power planes to other layers . Stack-ups are created in a manner that balances the board relative to the midpoint of the Z axis . <p> Consider any concerns the PCB designer has during the reviews , and correct the PCB based on feedback generated by the reviews . Create and verify lists of changes during each review iteration until the board is finalized . During all stages of the layout , keep the design error free by using the design rule checker ( DRC ) . <p> The DRC can only catch errors that it has been @ @ @ @ @ @ @ @ @ @ based on individual designs . At the minimum , the design rule checking should cover package-to-package spacing , unconnected nets ( a unique name identifying each node of the circuit ) , shorted nets , air-gap violations , if vias are too close to solder pads , if vias are too close to each other , and vertical clearance violations . <p> Many other important DRC rules can be set to ensure a robust design , and they should be researched and understood . For example , keep clearances at or above 5 mils . Vias should not be located within surface-mount pads ( unless back-filled ) . And , solder mask should be between all solder points . <p> Cost is often a driving influence behind PCB design , so it is good to understand the cost adders in PCB manufacturing . A typical board is two to four layers , with no drill holes less than 10 mils in diameter and 5-mil minimum air gaps and trace widths . It also should be 0.062 in. thick with standard FR-4 and a copper foil weight of 1 oz . @ @ @ @ @ @ @ @ @ @ , back-filled vias ( non-conductive preferred due to conductivity limitations and thermal expansion differences ) , blind/buried vias , and lead time all substantially add to the overall cost . <p> Manufacturer capabilities should be understood when the PCB design commences . PCB fabs are routinely contacted about capabilities and cost reduction techniques when designing PCBs for manufacturability . <p> Summary <p> PCB design may be complex , but it is quite possible to design good boards with a little technique and practice . Using these guidelines and adding research when needed , seasoned veterans may continue honing their skills and novice designers may learn to create high-quality PCBs that exceed expectations . <p> Nicholaus Smith- is an applications engineer at Integrated Device Technology with more than 10 years of experience working on printed-circuit boards ( PCBs ) and in semiconductor engineering . He was educated at the University of Arizona and San Jose State University while working as a technician and PCB designer . During his career , he has designed and used PCBs for engineering evaluation , customer demonstration , IC qualification , and automatic test equipment. - 
@@21004715 @1004715/ <p> Wearing my newly donned hat of Editor-in-Chief , my goal in this column is both to introduce myself and to set the stage for creating a relationship with you . I 'm honored to be working with the team here at Electronic Design " an incredible group of electronics experts and editorial professionals , in particular , Dave Bursky ( now Editor-at-Large and celebrating 30 years with this magazine ) and our brilliant band of seasoned technology editors . <p> Okay , so who am I , and what do I add to Electronic Design ? I 'm a magazine editor who loves electronics technology ! I spent a decade engrossed in the world of automated data capture ( ADC ) as the Editor-in-Chief of Automatic I.D . News , covering the application of some fairly leading-edge electronic designs , including radio-frequency identification ( RF-ID ) , biometrics , machine vision , and even wearable computers . My tenure there provided a fantastic opportunity to see technology applied across the complete spectrum of industries , spanning everything from the robotic assembly of nuclear missiles to the use of @ @ @ @ @ @ @ @ @ @ especially proud of being chosen as a member of the ADC 100 , the honorary society for the 100 founders of that industry . Many of my associate co-founders are engineers : individuals who not only invented new technologies but also went on to educate the business world about the benefits those technologies could bring to bear . <p> Subsequently , I spent some years creating " platform-specific " publications for many leading computing platforms , particularly of the handheld variety ( Palm and Handspring , Windows CE , Windows NT embedded ) , as well as publications for other embedded and development platforms . Since then , I 've been surfing the dot-com wave , doing business development for various online ventures , among them : 4mycommunity.com ( a charity portal ) , IZ.com ( e-mail newsletters ) , Palmtop Publishing ( custom publishing for handheld computers ) , and iShow.com ( Internet broadcast and smart-home demonstration projects ) . <p> I come to Electronic Design with a deep respect for electronics engineers , the incredible products you create , and the impact those products have on the world @ @ @ @ @ @ @ @ @ @ magazine publishing and , I believe , an ability to work with technologists to create a communications vehicle that will optimally serve you and your important work . I 'll apply my Internet experience to boost the integration of our print product with electronic media : an expanded e-mail newsletter program , Web tools , and , who knows , maybe some streaming video and/or some tools for you in a PDA format . <p> But to create the product YOU want , I need to build a relationship with you . I know editors always end their columns by saying , " Tell me what you think . " But I really mean it ! So much so that I 'm offering a BRIBE " limited-edition Electronic Design T-shirts . I 'll mail one to the first 25 readers who pick up the phone and call me at ( 201 ) 845-2467 to talk about how you use this magazine , what you like about it , and what you think should be improved . <p> Again , it 's a privilege to be working with all of you @ @ @ @ @ @ @ @ @ @ to create the technologies that build a better life and a safer world . 
@@21004717 @1004717/ <h> Fiber Optics Transmit Data and Power Over Same Cable <p> In the latest attempt to confront the growing power demands of wireless communications , a research team from the University of Electro-Communications in Japan has invented a fiber optic system that transmits both data and power over the same cable . <p> The research team , led by Motoharu Matsuura , has shown that the new system is capable of sending up to 60 watts over a distance of 300 meters . The researchers suggest that the fiber optic cable would be ideal for the growing infrastructure behind small cells " low-power , short-range- radio terminals that backhaul- data from the edge of a wireless network . <p> In recent years , fiber optic power cables have been the subject of quiet but hard-nosed research , but most systems developed so- far transmit little power . In 2012 , scientists from Sandia National Laboratories in New Mexico invented one of the earliest power-over-fiber systems , using laser diodes on one end of the cable and a miniature photovoltaic cell on the other end . However , the scientists @ @ @ @ @ @ @ @ @ @ only- power the fiber 's internal electronics . At the time , the researchers were also adding the capability to send power externally into low-power sensors and control systems . <p> Last year , Matsuura and his research set out to design a system that could effectively supplement the main power delivered to small cells . As described in research published last June , the research team bundled two multimode power fibers with one multimode data fiber , fusing them into a single double-clad cable at one end . The double-clad cable , which consists of an inner core surrounded by two outer layers of optical fiber , helps to prevent- crosstalk . <p> The team linked the cable to a central data station and a radio antenna . A laser diode created test signals to IEEE 802.11g specifications , while separate laser diodes supplied the optical power . When an amplified optical signal traveled through the cable , however , most of the power escaped as heat . Although the power output reached 40W in this initial experiment , the power efficiency was only 20% . <p> This table @ @ @ @ @ @ @ @ @ @ , and total optical feed power in both designs from the University of Electro-Communications research team . ( Image courtesy of University of Electro-Communications ) . <p> After these early experiments , Matsuura 's research team discovered that the power efficiency was being limited by the cross-sectional area of the fibers . When bundled together , the two multimode fibers left empty space in the cable , so that their combined area was less than the area of the fused cable further down the line . The result , Matsuura said , was a very inefficient power transfer . <p> In the research published earlier this month , the team adjusted- their design . As described in the journal Optics Letters , they narrowed the power-carrying fibers and increased their number to six . This helped to optimize the cross-sectional area without introducing other limitations that additional fibers might have caused . <p> The other benefit of the power-over-fiber system is that it protects the antenna units from unexpected breaks in the main power supply , such as a lighting strike or power surge . The point is " to @ @ @ @ @ @ @ @ @ @ " says Steve Sanderson of Sandia- National Laboratories . <p> However , - optical fibers that send more power over longer distances will be required to alleviate some of the problems with small cell infrastructure. - Peadar- Forbes , product marketing manager for integrated transceivers at Analog Devices , says one of the- problems with deploying small cells is- the logistics of- connecting them to a power source and fiber optic cable . While he understands the thought behind the research , - he adds that a power-over-fiber cable is not a " silver bullet " for this problem . <p> Small cells located indoors , which typically consume between 13 and 50W depending on their capacity , already use a system that transmits power and data over the same cable : power-over-Ethernet . Because power-over-Ethernet is the de facto standard for indoor models , - the power-over-fiber cable would only be suited for outdoor small cells , which Forbes says consume between 50 and 350W . Forbes adds that small cells typically have to haul data over longer distances than the 300 meter- range of the new cable . 
@@21004721 @1004721/ <p> Capacitive sensing is a contactless-sensing technique with numerous applications , ranging from proximity sensing ( Fig. 1 ) , gesture recognition , automotive rain sensors , and remote liquid-level sensing to material handling and high-resolution metal profiling . It 's even used to make music , as we 'll discover . <p> 1 . Capacitive proximity sensors are available in rugged housings for industrial applications . ( Courtesy of Automation Direct ) <p> - <p> The sensor in a capacitive-sensing system can be any metal or conductor , allowing for highly flexible system design . Due to their low power consumption , low cost , and high resolution , capacitive sensors are replacing inductive , optical , and ultrasonic technologies in many applications . <p> Although a capacitive sensor can be as simple as a dedicated area on a printed-circuit board , many other options exist for system designers , including devices with integrated electronics . <p> Capacitive sensing is n't the same as capacitive touch , a related technology that 's optimized to perform a digital switch function . A capacitive-touch system often uses many channels in @ @ @ @ @ @ @ @ @ @ on your cell phone of tablet . It requires contact to operate and works over a short range " a few millimeters at most. - <p> In contrast , a capacitive sensor is an analog system that operates at distances of up to 70 cm . It has much greater sensitivity and precision since it must resolve changes in capacitance of a few picofarads . <p> Principles of Capacitive Sensing <p> The capacitance of a system represents its ability to store an electrical charge and is a fundamental electrical property. - A capacitor is a component used to store electrical energy in an electrical field ; the simplest model consists of two electrical conductors or plates separated by an insulating dielectric ( Fig. 2 ) . <p> 2 . The simplest model of capacitor consists of a charged plate , a dielectric , and a ground . The dielectric is between the two plates . The capacitance is a function of the plate area , the dielectric material , and the distance between them . ( Courtesy of TI ) <p> - <p> For the capacitor shown in Fig. 2 @ @ @ @ @ @ @ @ @ @ where : <p> A = the area of the plates ( W x L ) <p> d = the plate separation in meters <p> +r = the dielectric constant of the material between the plates <p> +0 = the permittivity of free space ( 8.85 x 10-12 F/m ) <p> When the sensor plate is charged , it creates an electric field ( Fig. 3 ) . <p> 3 . The electric field of a parallel plate capacitor is uniform between the plates , but can extend far from the plates and includes fringing effects near the plate edges ( Courtesy of TI ) <p> - <p> Turning a Capacitor into a Sensor <p> How do we turn this device into a capacitive sensor ? Figure 4 shows three options . <p> 4 . Three topologies for capacitive sensors : proximity sensor using a finger as the ground plate ( a ) , liquid-level sensing with parallel sensor and ground ( b ) , and material detection and analysis ( c ) . ( Courtesy of TI ) <p> - <p> A proximity sensor is formed by constructing an isolated @ @ @ @ @ @ @ @ @ @ board and charging it . Then a capacitor will be formed any time a grounded , conductive object , or an object with a dielectric constant different from air , comes close to the sensor plate . A finger qualifies because the human body is essentially at ground potential . <p> The capacitance increases as the finger approaches the sensor . Even though the variation is nonlinear , a detectable difference is sufficient for proximity detection. - <p> To expand this into a gesture sensor , we can use multiple independent sensors for up/down and left/right detection ( Fig. 5 ) . As the finger moves over the sensors , it changes the capacitance of all four sensors . A multichannel detector reads all four values ; then software can calculate speed and direction based on the difference in readings . <p> 5 . Decoding gestures requires four capacitive proximity sensors and a multichannel converter . ( Provided by the author ) <p> - <p> In many applications , such as chemical storage , industrial process control , or commercial washers , it 's necessary to sense the level of @ @ @ @ @ @ @ @ @ @ ground plates can be situated next to each other , as shown in Fig. 4b , resulting in a configuration with high sensitivity along the vertical access . <p> As the liquid level varies , it changes the dielectric value and hence the capacitance . This sensor configuration makes use of fringe field lines ; thus , the capacitance calculations are more complicated than in the case of a simple plate . <p> A sensor for materials analysis consists of the basic plate topology shown in Fig. 4c with the material to be analyzed " paper , for example " changing the dielectric constant between the plates as it 's added or removed. - The unloaded sensor has an air dielectric and serves as the reference capacitance . Then the capacitance increases as paper or other material is inserted between the plates . <p> These are n't the only sensor configurations , of course . Other options include multiple sensor and ground arrangements , either separate or arranged in an interlocking comb pattern that requires a large sensor area and high sensitivity . <p> Shielding and Capacitive Sensing <p> One @ @ @ @ @ @ @ @ @ @ will flow from the sensor plate to any nearby ground potential . Ideally , the target being sensed will be the dominant influence . However , numerous parasitics ( e.g. , ground planes or ground traces ) will usually steal away charge and reduce the sensor 's sensitivity and detection distance . This is a particular problem in noise-sensitive environments , since ground planes are a standard design solution . <p> 6 . The effects of PCB parasitics ( a ) on sensor performance can be reduced by driven shield electrodes ( b ) . Shield drivers are included in capacitive-sensor interface devices and specialized microcontrollers . ( Courtesy of TI ) <p> - <p> Adding an active shield can help reduce parasitic and environmental interference , and allow the sensor to operate at full capability ( Fig. 6 ) . - A well-designed active shield will also focus the sensor output and direct it in the desired direction . <p> The shield driver is an active output that 's driven at the same voltage as the sensor input . Therefore , no difference in potential exists between the shield @ @ @ @ @ @ @ @ @ @ the shield electrode with minimal interaction with the sensor electrode . <p> Capacitive Sensor Interface Block Diagram <p> A specialized analog front end converts the signal from the capacitive sensor into a digital value suitable for further processing ( Fig. 7 ) . It periodically samples the sensor output and provides an excitation signal to charge the sensor plate . The sensor output sampling rate is relatively slow " less than 500 samples per second " but high-resolution analog-to-digital conversion is needed to capture small differences in capacitance . A 16-bit sigma-delta ADC provides a good compromise between speed , resolution , and low power consumption . <p> 7 . In a capacitive-sensing device , the excitation step waveform charges the sensor electrode . Subsequently , the charge is transferred to a sample-and-hold circuit and measured by an analog-to-digital converter . ( Courtesy of TI ) <p> - <p> A multichannel device can perform differential measurements to obtain an accurate representation of the capacitance difference between two sensors . For example , if environmental factors cause variations in capacitance , one channel can be dedicated to an environmental sensor that @ @ @ @ @ @ @ @ @ @ material type , stress on the material , and so on. - A differential measurement can null out changes due to these variables . <p> For certain applications , ratiometric measurements are also valuable . In liquid sensing , one channel measures capacitance related to the liquid level ; a second channel is for the reference sensor , which measures the capacitance of the zero level . Since the level capacitance is proportional to liquid height , a ratiometric measurement measures the ratio or difference between the level sensor and reference . <p> LC-Based Capacitive Sensing <p> One of the issues with capacitive sensing is the coupling in of stray noise . Modifying the sensor to include a frequency-sensitive component is a useful way to increase noise immunity . In addition to the variable capacitor element , an additional capacitor and inductor is added to the sensor to form a resonant inductive tank circuit ( Fig. 8 ) . <p> 8 . Shown is the LC tank circuit ( a ) and its characteristic curve ( b ) . The narrowband response allows it to reject out-of-band noise . ( @ @ @ @ @ @ @ @ @ @ of the LC tank is simple , it has a couple of major advantages when integrated as part of a capacitive sensor ( Fig. 9 ) . First , due to its inherent narrowband characteristics , an LC resonator provides excellent immunity to electromagnetic interference ( EMI ) . Second , if noise sources are known to exist at certain frequencies , shifting the sensor 's operating frequency can filter out these noise sources without using external circuitry . This will help increase system sensitivity and reduce complexity . <p> Using this approach , a change in the capacitance of the LC circuit is seen as a shift in the resonant frequency . TI applied this principle in its FDC2214 , a capacitance-to-digital converter that measures the oscillation frequency of an LC resonator-based sensor . The device outputs a digital value that 's proportional to frequency . This frequency measurement can be converted to an equivalent capacitance by a downstream MCU . <p> Time for a Break ! <p> And now for something completely different ... in addition to its many industrial uses , it 's even possible to use @ @ @ @ @ @ @ @ @ @ in 1919 by Leon Theremin , can produce sounds over a seven-octave range ( Fig. 10 ) . Each of performer 's hands acts to vary the capacitance in an LC circuit , controlling volume and pitch via two independent heterodyne circuits. - <p> In action , the performer looks like she 's simply waving her hands around next to two radio antennas , but the sounds are reminiscent of voice , violin , and even bass . Here 's a video of thereminist Pamelia Kurstin explaining the technique and performing two old jazz tunes . As you can imagine , making music in this way requires precise control of hand and arm position . An unexpected sneeze or cough can be disastrous ! <p> Conclusion <p> Capacitive sensing is a flexible technology that 's becoming increasingly popular . Constructing a sensor can be as simple as adding a conductive area to a printed-circuit board , and low-cost integrated interface chips are readily available . Its low cost and low power consumption make it an ideal choice for a wide range of consumer and industrial applications . 
@@21004722 @1004722/ <p> Serious issues surround the countless videos of hoverboard falls posted on social media , and especially the hoverboard fires shown on the news . Delving into the technical side of this fire-hazard situation , I found out the following : <p> The Consumer Product Safety Commission ( CPSC ) recently released a statement saying that it is working non-stop to find the root cause of hoverboards becoming a fire hazard ( Fig. 1 ) . In the meantime , Northbrook , Ill. -based Underwriters Laboratories ( UL ) announced that currently there is no UL certification for hoverboards themselves . In other words , neither hoverboards nor their components have been certified under any standard for safety . <p> It is very likely that the cause of fire is related to the battery packs inside the hoverboards " even though the fires have started in all sorts of different circumstances ( e.g. , during charging or while riding ) . Hoverboards use lithium-ion battery packs ; there are usually around 20 rechargeable cells per pack . An individual cell looks very similar to an AA nickel-metal hydride ( @ @ @ @ @ @ @ @ @ @ . Hoverboards are controlled by the rider+ ? ? s feet standing on the sensor pads . ( Courtesy of Kentucky ) <p> Fires caused by lithium-ion batteries in laptops , phones , and even airplanes have occurred in the past . Now , such incidents have put hoverboards under the public microscope . Recently , some U.S. airlines banned hoverboards on passenger flights . Similarly , the U.S. Postal Service stopped shipping hoverboards by air . <p> Inside a lithium-ion battery , there is a thin sheet of micro-perforated plastic ( a separator ) that keeps the anode and cathode apart while allowing lithium ions to pass through . The battery is charged by sending ions from the cathode to the anode . The battery is discharged when ions are transferred back from the anode to the cathode ( Fig. 3 ) . <p> Until recently , the use of lithium-ion batteries had become more popular among small power tools or IT devices , such as laptops , cordless drills , electric screwdrivers , and e-bikes . Compared to other rechargeable batteries likr NiMH , lithium-ion batteries can store @ @ @ @ @ @ @ @ @ @ of view , lithium-ion batteries do not contain environmentally harmful material and therefore are environmentally friendly . <p> Although lithium-ion batteries have great advantages , lithium does heat up and expand during charging . This causes leaked lithium ions to build up on a battery 's surface , which might originate short-circuits and decrease overall battery life . Also , when a lithium-ion battery is overheated or damaged , it can burst into flames or even explode . - <p> Lithium-ion battery assembly techniques focus on avoiding short circuits within the cell . Because of the natural properties of lithium , however , this task is very challenging and expensive . Researchers are trying to find the solutions to lithium 's disadvantages . For example , a team of researchers at Stanford University just developed a lithium-ion battery that does not overheat through the use of nanotechnology . <p> A hoverboard is an application that increases the risks of problems with the lithium-ion battery . Just during a single ride , a hoverboard might get kicked and abused . If something goes wrong , a hoverboard 's 4,000 mA/hour- battery @ @ @ @ @ @ @ @ @ @ energy- in just seconds . <p> 3 . When delivering energy to a device , lithium ions move from the anode to the cathode . The ion moves in reverse when recharging . ( Courtesy of Argonne National Laboratory ) <p> Because the single most expensive component in a hoverboard is the lithium-ion battery pack , some hoverboard manufacturers are unfortunately using non-brand batteries to minimize costs . Many of these batteries clearly do not provide the same high quality and safety standard as , for example , those manufactured by Samsung SDI Co . Ltd. ( one of the largest providers of lithium-ion batteries ) . <p> It is suspected that most of the hoverboards produced in China might not use original Samsung or LG batteries , with non-brand or counterfeit Samsung trademark batteries being used in their place . Plenty of those batteries are finding their way into the country inside hoverboards . Obviously , not all of the off-brand batteries are catching fire , with thousands of batteries produced per year . But the problem has become widespread enough to where the CPSC has sufficient cause to @ @ @ @ @ @ @ @ @ @ a battery or hoverboard recall . <p> Unfortunately , to date there is no specific resource online where consumers can check the safety of their hoverboards . If you are planning to purchase one and/or keep one at home , do yourself a favor : Keep a fire extinguisher nearby , and never charge it while unattended . 
@@21004723 @1004723/ <h> What 's The Difference Between EPON And GPON Optical Fiber Networks ? <p> EPON and GPON are popular versions of passive optical networks ( PONs ) . These short-haul networks of fiber-optical cable are used for Internet access , voice over Internet protocol ( VoIP ) , and digital TV delivery in metropolitan areas . Other uses include backhaul connections for cellular basestations , Wi-Fi hotspots , and even distributed antenna systems ( DAS ) . The primary differences between them lie in the protocols used for downstream and upstream communications . <p> Passive Optical Networks <p> A PON is a fiber network that only uses fiber and passive components like splitters and combiners rather than active components like amplifiers , repeaters , or shaping circuits . Such networks cost significantly less than those using active components . The main disadvantage is a shorter range of coverage limited by signal strength . While an active optical network ( AON ) can cover a range to about 100 km ( 62 miles ) , a PON is typically limited to fiber cable runs of up to 20 km ( @ @ @ @ @ @ @ @ @ @ the home ( FTTH ) networks . <p> The term FTTx is used to state how far a fiber run is . In FTTH , x is for home . You may also see it called FTTP or fiber to the premises . Another variation is FTTB for fiber to the building . These three versions define systems where the fiber runs all the way from the service provider to the customer . In other forms , the fiber is not run all the way to the customer . Instead , it is run to an interim node in the neighborhood . This is called FTTN for fiber to the node . Another variation is FTTC , or fiber to the curb . Here too the fiber does not run all the way to the home . FTTC and FTTN networks may use a customer 's unshielded twisted-pair ( UTP ) copper telephone line to extend the services at lower cost . For example , a fast ADSL line carries the fiber data to the customer 's devices . <p> The typical PON arrangement is a point to multi-point ( @ @ @ @ @ @ @ @ @ @ OLT ) at the service provider 's facility distributes TV or Internet service to as many as 16 to 128 customers per fiber line ( see the figure ) . Optical splitters , passive optical devices that divide a single optical signal into multiple equal but lower-power signals , distribute the signals to users . An optical network unit ( ONU ) terminates the PON at the customer 's home . The ONU usually communicates with an optical network terminal ( ONT ) , which may be a separate box that connects the PON to TV sets , telephones , computers , or a wireless router . The ONU/ONT may be one device . <p> In the basic method of operation for downstream distribution on one wavelength of light from OLT to ONU/ONT , all customers receive the same data . The ONU recognizes data targeted at each user . For the upstream from ONU to OLT , a time division multiplex ( TDM ) technique is used where each user is assigned a timeslot on a different wavelength of light . With this arrangement , the splitters act as @ @ @ @ @ @ @ @ @ @ , occur at random as a user needs to send data . The system assigns a slot as needed . Because the TDM method involves multiple users on a single transmission , the upstream data rate is always slower than the downstream rate . <p> GPON <p> Over the years , various PON standards have been developed . In the late 1990s , the International Telecommunications Union ( ITU ) created the APON standard , which used the Asynchronous Transfer Mode ( ATM ) for long-haul packet transmission . Since ATM is no longer used , a newer version was created called the broadband PON , or BPON . Designated as ITU-T G.983 , this standard provided for 622 Mbits/s downstream and 155 Mbits/s upstream . <p> While BPON may still be used in some systems , most current networks use GPON , or Gigabit PON . The ITU-T standard is G.984 . It delivers 2.488 Gbits/s downstream and 1.244 Gbits/s upstream . <p> GPON uses optical wavelength division multiplexing ( WDM ) so a single fiber can be used for both downstream and upstream data . A laser on @ @ @ @ @ @ @ @ @ @ data . Upstream data transmits on a wavelength of 1310 nm . If TV is being distributed , a wavelength of 1550 nm is used . <p> While each ONU gets the full downstream rate of 2.488 Gbits/s , GPON uses a time division multiple access ( TDMA ) format to allocate a specific timeslot to each user . This divides the bandwidth so each user gets a fraction such as 100 Mbits/s depending upon how the service provider allocates it . <p> The upstream rate is less than the maximum because it is shared with other ONUs in a TDMA scheme . The OLT determines the distance and time delay of each subscriber . Then software provides a way to allot timeslots to upstream data for each user . <p> The typical split of a single fiber is 1:32 or 1:64 . That means each fiber can serve up to 32 or 64 subscribers . Split ratios up to 1:128 are possible in some systems . <p> As for data format , the GPON packets can handle ATM packets directly . Recall that ATM packages everything in 53-byte packets @ @ @ @ @ @ @ @ @ @ also uses a generic encapsulation method to carry other protocols . It can encapsulate Ethernet , IP , TCP , UDP , T1/E1 , video , VoIP , or other protocols as called for by the data transmission . Minimum packet size is 53 bytes , and the maximum is 1518 . AES encryption is used downstream only . <p> The latest version of GPON is a 10-Gigabit version called XGPON , or 10G-PON . As the demand for video and over the top ( OTT ) TV services has increased , there is an increasing need to boost line rates to handle the massive data of high-definition video . XGPON serves this purpose . The ITU standard is G.987 . <p> XGPON 's maximum rate is 10 Gbits/s ( 9.95328 ) downstream and 2.5 Gbits/s ( 2.48832 ) upstream . Different WDM wavelengths are used , 1577 nm downstream and 1270 nm upstream . This allows 10-Gbit/s service to coexist on the same fiber with standard GPON . Optical split is 1:128 , and data formatting is the same as GPON . Maximum range is still 20 km . @ @ @ @ @ @ @ @ @ @ upgrade path for service providers and customers . <p> Most PONs are configured like this . The number of splitters and split levels varies with the vendor and the system . Split ratios are usually 1:32 or 1:64 but could be higher . <p> - <p> - <p> EPON <p> The Institute of Electrical and Electronic Engineers ( IEEE ) developed another newer PON standard . Based on the Ethernet standard 802.3 , EPON 802.3ah specifies a similar passive network with a range of up to 20 km . It uses WDM with the same optical frequencies as GPON and TDMA . The raw line data rate is 1.25 Gbits/s in both the downstream and upstream directions . You will sometimes hear the network referred to as Gigabit Ethernet PON or GEPON . <p> EPON is fully compatible with other Ethernet standards , so no conversion or encapsulation is necessary when connecting to Ethernet-based networks on either end . The same Ethernet frame is used with a payload of up to 1518 bytes . EPON does not use the CSMA/CD access method used in other versions of Ethernet . Since @ @ @ @ @ @ @ @ @ @ ( LANs ) and now in metro-area networks ( MANs ) , no protocol conversion is needed . <p> There is also a 10-Gbit/s Ethernet version designated 802.3av . The actual line rate is 10.3125 Gbits/s . The primary mode is 10 Gbits/s upstream as well as downstream . A variation uses 10 Gbits/s downstream and 1 Gbit/s upstream . The 10-Gbit/s versions use different optical wavelengths on the fiber , 1575 to 1580 nm downstream and 1260 to 1280 nm upstream so the 10-Gbit/s system can be wavelength multiplexed on the same fiber as a standard 1-Gbit/s system . <p> Summary <p> Telecommunications companies use PONs to provide triple-play services including TV , VoIP phone , and Internet service to subscribers . The benefit is much higher data rates that are essential to video distribution and other Internet services . The low cost of passive components means simpler systems with fewer components that fail or require maintenance . The primary disadvantage is the shorter range possible , commonly no more than 20 km or 12 miles . PONs are growing in popularity as the demand for faster Internet service @ @ @ @ @ @ @ @ @ @ in the U.S. , such as Verizon 's Foist system . EPON systems are more prevalent in Asia and Europe . 
@@21004731 @1004731/ <h> Ada 2012 : The Joy of Contracts <p> The relationship of a software developer to his or her programming language sometimes seems to follow an arc that is common in a romance/marriage : wild infatuation , a brief honeymoon , unrealistic expectations , realities and incompatibilities , and then separation or perhaps passionless cohabitation . The key question is , what next ? A bitter divorce and a search for a new mate , or reconciliation and a renewed enthusiasm ? <p> In the case of Ada , smart money is on the latter outcome , thanks to the new Ada 2012 standard recently approved by ISO ( the International Organization for Standardization ) . For a while , the common perception of Ada was that of a niche language that was being replaced by sexier competition such as C++ and Java . This perception was rather distorted . Ada was still being used heavily ( although perhaps without as much fanfare as in earlier times ) in industries where reliability was critical . And importantly , the language was not standing still ; it was undergoing some @ @ @ @ @ @ @ @ @ @ into account the technological trends in both the software and hardware realms . Newly refreshed and rejuvenated , Ada is well poised to capture the hearts and minds of today 's software developers . <p> The most exciting addition to Ada 2012 is the facility known as contract-based programming . The concept is straightforward : program elements such as subprograms are designed to satisfy specific software requirements ( " contracts " ) , so the syntax of these program elements should support specifying such requirements . As a concrete example , the contract for a subprogram includes its preconditions ( properties that the subprogram assumes on entry ) and its postconditions ( properties that the subprogram assures on exit ) . Figure 1 shows an example of the contracts associated with an insertion procedure for adding an element to a simple queue . Contracts may be checked statically by the compiler or a supplemental analysis tool , or enforced dynamically with run-time checks . <p> Contract-based programming is an increasingly important style of software development , especially in high-integrity systems where reliability , safety , and/or security are essential . @ @ @ @ @ @ @ @ @ @ objectives such as the Formal Methods supplement to the DO-178C avionics software safety standard 1 . A tool can attempt to prove that a subprogram 's postconditions are derivable from its preconditions , or find counterexamples otherwise . Contracts can also be used to show that a program will not have run-time errors . The idea of contracts is not new , but Ada is now the most widely used language that includes explicit support as part of the standard syntax and semantics ( versus as stylized comments , for example ) . This means that the contracts are always in synch with the program and can be processed by any compiler that complies with the language standard . <p> Integrating contract-based programming with the language 's existing facility for Object-Oriented Programming presented a challenge , in particular how to manage the interaction of inheritance with pre- and postconditions . Ada 2012 addresses this issue by supplying semantics consistent with a design approach known as the Liskov Substitution Principle 2 , which in effect ensures that a subclass serves as a specialization of its superclass . <p> Beyond contract-based programming @ @ @ @ @ @ @ @ @ @ , multiprocessor and multicore support , and the predefined library . The language revision also includes a variety of small improvements , along the lines of tidying up some loose ends . <p> The Ada design has always focused on reliability , readability , and early detection of errors . Ada 2012 is significant because these goals are becoming increasingly critical in today 's software-intensive and interconnected world . Bugs that would have simply been inconveniences in standalone systems twenty years ago can now have far-reaching effects with major financial cost and perhaps even loss of life . In a sense , the software industry has caught up with Ada . Further , Ada 2012 features like contract-based programming are fun to use . The language revision recognized that notational expressiveness and convenience are important , so Ada 2012 supplies a natural and succinct ( but readable ) syntax including quantification and conditional expressions . <p> In short , if software developers take a fresh and thorough look at Ada 2012 , a new spark may be kindled . 
@@21004732 @1004732/ <h> Wireless 101 : Basic Physics of Radio <p> With all the wireless design activity going on these days , it makes me wonder just how many engineers are actually educated in wireless principles anymore . Not many , I suspect . From what I have seen of EE education , the curricula are still based on classical circuit theory , basic devices , some linear , and a massive dose of digital , along with microcontrollers and related software programming . No radio theory . <p> For this reason , I thought I would explain one basic wireless concept that might help illustrate how wireless works : free space path loss ( FSPL ) . If you are working on an Internet-of-Things ( IoT ) or other wireless product , this may be helpful . And you wo n't have to learn Maxwell 's equations . <p> FSPL is the attenuation a radio signal experiences on its way from transmitter ( Tx ) to receiver ( Rx ) . It is usually expressed in dB . Radio signals in the VHF , UHF , microwave , and millimeter-wave @ @ @ @ @ @ @ @ @ @ line of sight ( LOS ) . In general , the attenuation is proportional to the square of the distance ( d ) between the Tx and Rx . The attenuation is also proportional to the frequency of operation ( f ) . <p> FSPL determines how far you can transmit reliably for a given factors such as transmitted power(Pt) , received power ( Pr ) , transmitter antenna gain ( Gt ) receiver antenna gain ( Gr ) , and receiver sensitivity ( R ) . The power is in watts , of course , and antenna gains are power ratios . Antenna gains are unity if you assume an isotropic source ( spherical radiation pattern ) . If you use a dipole or its equivalent , the power ratio is 1.64 . Both antennas should have the same polarization . <p> All these factors are summed up in what is known as the Friis formula : <p> Pr = PtGtGr++2/16-2d2 <p> Distance ( d ) is given in meters and wavelength is also in meters . Remember ++ = 300/fMHz . <p> The key takeaways from this formula @ @ @ @ @ @ @ @ @ @ distance is increased and as the wavelength gets shorter . In other words , for a given transmit power and fixed antenna gains , the signal at the receiver gets smaller at the higher frequencies . The higher the frequency , the greater the FSPL . Higher frequencies are great , as they offer lots more bandwidth and antennas are shorter . The range is more limited , however . <p> The Friis formula is messy to handle , so a more convenient form has been created using decibels . <p> Now that you know the path loss , you can consider some other factors like transmitter power ( Pt ) . You can express it in dBm ( milliwatt reference ) . Assume a power of 400 mW . <p> dBm = 10log ( Pt/1mW ) = 10log(400) = 26 dBm <p> Knowing the path loss and the transmitter power , you can figure the received power . Pr will also be in dBm . <p> Pr = Pt " FSPL = 26 " 80 = " 54 dBm <p> Now let 's add the antenna gains . The @ @ @ @ @ @ @ @ @ @ ( G ) of 1 . A dipole or its equivalent has some gain " specifically , a 1.64 power ratio that translates to a gain of 2.15 dB . If both transmitter and receiver use a dipole , the calculation goes like this : <p> Pr = Pt + Gt + Gr " FSPL = 26 + 2.15 + 2.15 " 80 = " 49.7 dBm <p> The missing quantity in all this is receiver sensitivity ( R ) . This is a specification of all wireless receivers , and is the smallest signal the receiver can process . It is given in " dBm . Assume a value of -98 dBm . As you can see , since -47 dBm is greater power level than -98 dBm , the receiver will get enough power with a good margin . <p> Using the transmit power , receiver sensitivity , and antenna gains , you can compute the maximum path loss for this combination . <p> FSPL ( max ) = Pt + Gt + Gr " R = 26 + 4.3 " ( - 98 ) = 128.3 dB @ @ @ @ @ @ @ @ @ @ and calculate the maximum possible range ( d ) for this situation . The math is left to you but the range is 25.8 km . <p> For any given design , you can use this process to get a first approximation how your system will work . You can play around with the factors and optimize your design . Just remember we are using LOS FSPL . There are no obstacles between transmit and receive antennas . If you introduce walls , trees , etc. , you will need to increase path loss accordingly . Reflections and multipath , diffraction , and scattering are also not accounted for . Attenuation estimates for these factors are available , but beyond the scope of this blog . For a first estimate , just be sure you have extra margin ( say 20% ) to ensure a reliable link . 
@@21004742 @1004742/ <p> There are many cases where a power supply needs an internal current-limiter function , usually built using a current sensor , a control circuit , and a pass transistor . The current sensor itself can be a simple low-value resistor ; since the voltage across it is proportional to the current , this voltage can be used to control the current flow through the pass transistor . <p> In one example of this configuration ( Fig. 1 ) , RSENSE is a low-value resistor used for sensing the current.1 As long as the voltage across this resistor is less than 0.6 V , only transistor T1 will conduct . Whenever load current IL reaches a value such that when RSENSE voltage ( equal to IL + RSENSE ) exceeds 0.6 V , transistor T2 starts conducting . The base current of T1 is drawn by T2 and , as a consequence , the emitter current of T1 drops . <p> 1 . A simple , widely used current limiter consists of a current sensor ( usually a low-value sense resistor ) , a control circuit , and a @ @ @ @ @ @ @ @ @ @ circuit has a limitation due to the associated voltage drop ; when activated , there will be a voltage drop at T1 ( VCE , SAT ) of 1 V and across RSENSE - of 0.6 V. The total voltage drop is 1.6 V. Therefore , if the current limiter is connected with a +5-V supply , the load will get 3.4 V , which is unacceptable in low-voltage circuits . <p> An alternative is to use the well-known LM317 voltage regulator as a current limiter.2 This approach also incurs a voltage drop of 2 V. Another current limiter uses a P-channel MOSFET as a pass device , with gate voltage controlled by a transistor that amplifies the RSENSE voltage drop.3 This circuit experiences a drop as low as 0.6 V. <p> The current limiter of Figure 2 has very low voltage drop , so it does n't hamper low-voltage circuit operation . The circuit operates from minimum supply voltage of 5 V , to higher values set by some components . The voltage across the 0.1-+ ? - sense resistor is amplified by op-amp IC1 in differential mode ; @ @ @ @ @ @ @ @ @ @ acting as a regulator . <p> For adjustable current limit , the gain of the op amp is controlled by the variable resistor R5 . The output of IC1 controls the drain-source resistance ( RDS ) of low-threshold MOSFET Q2 , and the drain current of Q2 controls the LED current of VOM1271 , a photovoltaic MOSFET driver.4 <p> When the load current is low , the RSENSE voltage is low , and the low IC1 output remains below the threshold of Q2 . The resultant higher LED current of the MOSFET driver produces an output voltage of 8 V , which is high enough to drive Q1 well into full conduction . When the load current reaches a value that drives Q2 into conduction , gate-source voltage VGS of Q1 goes low , which forces the load current to go low . <p> The circuit was tested with a +12-V supply and a 100-+ ? - high-power variable resistor as a load . Potentiometer R5 was adjusted to set the current limit a little above 1 A. The load resistor was slowly reduced from its maximum value , and @ @ @ @ @ @ @ @ @ @ measured ( Fig. 3 ) . For load current from 0.25 to 1.3 A , the voltage drops across Q1 and Q1 + RSENSE were 0.09 V and 0.235 V , respectively . <p> 4 . The expanded view of Q1 and Q1+RSENSE voltages more clearly shows the current-limiting foldback action that occurs when the load current exceeds the set limit . <p> - <p> At the maximum load current of 1.3 A , the voltage drop across RSENSE of 0.145 V is a significant contributor to the overall drop . The drop can be reduced further by choosing lower values of RSENSE . The expanded view of the voltage drops at Q1 and Q1+RSENSE ( Fig. 4 ) shows how these two drops vary with load current . When the load current exceeds the set limit , it triggers a current-limiting foldback action . <p> This current limiter is suitable for low-voltage applications beginning at +5 V. For higher voltages or operation in a wider voltage range , Zener biasing resistor R6 can be replaced with a constant-current regulator ( CCR ) , and Q1 should be chosen for @ @ @ @ @ @ @ @ @ @ can be packaged and used as a three-terminal device ( Fig. 5 ) . <p> Sajjad Haidar is an Electronics Technologist at the Electronics Engineering Services of the University of British Columbia ( UBC ) . He holds an M.Sc. in applied physics and electronics from the University of Dhaka ( Bangladesh ) . Previously , he worked in Japan for seven years in the field of tunable solid-state lasers and optoelectronics . He can be reached at email protected . 
@@21004745 @1004745/ <h> Getting Rid of Cable : Good Luck With That <p> Just recently I decided to get rid of one of the cable boxes in our guest bedroom that was never used. - With the cable bill that includes a VoIP phone and high speed Internet almost hitting $200 per month , it seemed like a good way to cut expenses. - And it was. - Even though the guest TV rarely got used , I thought I could just connect an antenna and get the local stations free . <p> Roughly 90% of all households get subscription TV from cable or some alternative like VDSL-based U-verse from AT&amp;T , or fiber from Google , Verizon , or other . That also includes satellite . So only about 10% get TV over the air ( OTA ) from local stations. - With all OTA TV being digital HD today , it seemed like a good idea to go this route as theoretically I could get ABC , CBS , CW , Fox , NBC , PBS and a few others. - With that line up , some have opted @ @ @ @ @ @ @ @ @ @ with streaming over the top ( OTT ) video from Apple , Netflix , Hulu , Amazon and others. - Not a bad deal and a great deal cheaper than cable and other subscriber TV. - Do n't tell me you have n't thought about it . <p> I found an old Radio Shack rabbit ears antenna in the garage that I hooked up to the TV set. - I did a scan and could only get three stations , the local Fox station and two snowy Spanish channels. - I was disappointed. - I live in the hill country outside of Austin , TX about 20 miles from most of the local station antennas. - The only station I got was channel 7 a VHF channel which naturally has greater range than the other stations which are all UHF. - My solution was to invest in a better TV antenna. - I bought a couple to test out . <p> Both of the antennas , indoor models , were promoted as being good up to 30 miles. - Both were flat panel types with amplification . The manufacturers will @ @ @ @ @ @ @ @ @ @ got the same result as with the rabbit ears. - I even tried the rabbit ears with one of the amplifiers and again , no better results. - I must be in a dead zone or something. - I suspect I will need an outdoor antenna at some height to get the results I want. - The home owners association does not permit such outdoor antennas except those for satellite TV. - I could try an antenna in the attic but that is a major hassle. - I wo n't do that. - So I am stuck with a one channel TV set in the guest bedroom. - I suspect that will be OK as no one uses it any way . <p> If you are thinking of going with the local OTA channels in lieu of cable you had better check out your reception first with an antenna before cutting the cord. - A good resource is TV Fool. - It can estimate the results that you can expect. - It was dead wrong in my case but it may work for you . <p> My alternative is satellite @ @ @ @ @ @ @ @ @ @ cable but not much. - Looks like our B&amp;B guests wo n't get good TV. - But we will feed them well instead . 
@@21004753 @1004753/ <h> The Benefits " And Hazards " Of Scan Compression <p> Though scan compression can offer great performance and cost rewards in EDA design , too much of a good thing could derail those positive gains . <p> Chris Allsup Aug 01 , 2007 <p> IC designers now have a powerful weapon in the struggle against rising test costs : commercially available EDA solutions that provide fast and effective means to implement scan compression on-chip . By reducing the amount of data needed to thoroughly test digital circuits , compression frees up enough tester memory to add tests ( e.g. , transition delay pattern sets ) that further improve quality . Because off-the-shelf tools have become increasingly automated and easier to use , semiconductor firms are rapidly embracing scan compression to lower costs at the tester . <p> It 's because scan compression has proven so successful in reducing test costs that designers and managers alike often maintain , mistakenly , that more is better . Although it 's reasonable to assume that ever-higher levels of compression will achieve ever-higher cost savings , the economics underlying the technology suggest @ @ @ @ @ @ @ @ @ @ . <p> In this article , we 'll see why this is the case by exploring how compression reduces test time and what factors degrade compression performance and cost savings . We 'll determine what level of savings designers can realistically expect and how to maximize these savings . In the process , we 'll arrive at some practical implementation guidelines that will help designers reap the benefits of scan compression while avoiding its hazards . <p> Test Execution Cost and Test Time Reduction Assume that a design with F scan flops has C scan chains of equal depth , each connected to a pair of dedicated scan I/O pins . Then without scan compression , the chain depth is F/C and we can approximate the cost CT of testing each yielding device on the tester as : <p> R is the tester cost ( $/sec ) , PB the number of basic scan ATPG patterns , Y0 the manufacturing yield , and f the tester scan shift frequency . The multiplier + reflects a slight decrease on average in test time due to failing die ( Y0G + G @ @ @ @ @ @ @ @ @ @ test execution cost. - <p> Test application time reduction ( TATR ) is accomplished by increasing the number of scan chains by a factor of " x " so that the depth of each chain is reduced by the same factor . The variable " x " is loosely referred to as the amount of compression , but it 's actually the compression ratio , the number of internal scan chains divided by the number of scan channels , C.- <p> For example , if your design has C = 10 scan channels , then implementing x = 20 compression creates 20 X 10 = 200 chains 1/20th the size of the original depth. - Compression and decompression circuits between the chain I/Os and the scan I/O pins ensure that the number of scan I/O pins remains the same . Sharing of internal inputs to the scan chains means that the number of bits in each scan ATPG pattern is reduced by the same factor , x. - Likewise , reducing scan depth by the same factor makes it possible to scan in and test x times more patterns in @ @ @ @ @ @ @ @ @ @ + " Cost from TATR is the difference in test execution costs between basic scan and scan compression : <p> - <p> Dividing by C T gives the percentage cost reduction : 1 " 1/x. - Cost savings garnered by Equation 2 are ideal because the formula does n't account for various negating effects that offset savings . Let 's now examine each of these effects in turn , using a 65-nm design consisting of 97.1 million gates , 1.3 million scan flops , and 10 scan channels for the examples . For this article we 've adjusted measurements of tool-specific behavior in order to highlight the described phenomena . <p> Pattern Inflation As the compression ratio increases , more patterns are needed to maintain the same high fault coverage . Pattern inflation from compression is always present to some degree , although the use of multiple clock domains in today 's systems-on-a-chip tends to increase pattern inflation . That 's because it increases the level of unknown logic values propagating through the circuits . To compensate , commercial compression tools employ various methods , including X-blocking , to ensure @ @ @ @ @ @ @ @ @ @ of compression levels . <p> The number of patterns generated for a scan-compressed design P ' ( x ) is a function of the basic scan ATPG pattern count PB and the pattern inflation rate + , which is the percentage increase in pattern count per unit increase in the compression ratio x:2 <p> - <p> From a cost-savings perspective , the pattern inflation rate itself has only a minor impact as long as it remains linear in x. - This is because differences in compressed test times for different inflation rates are insignificant compared with the test times using basic scan. - To illustrate , the black curves in Figure 1 display tester cycle count for zero pattern inflation and + = 4% , an extraordinarily high pattern inflation rate . <p> Further impact on savings can result if there 's a pronounced step increase in pattern count relative to PB for any compression level x , such that the pattern count in Equation 3 is instead described by : <p> The step increase is illustrated in Figure 2 , wherein the red line , representing P ' ( @ @ @ @ @ @ @ @ @ @ of different compression data points . The basic scan pattern count is PB = 1100 , whereas the y-intercept of the line is nearly 50% greater : <p> - <p> The blue curves in Figure 1 show the tester cycle count for e = 0% and e = 4% , assuming the step increase of Figure 2 . <p> Growth in Die Size In addition to compression and decompression circuits , compression tools insert multiplexers and X-gating logic with each synthesized scan chain . Gate overhead of compression contributes to a relatively small , linear increase in the die size . As compression increases , however , there 's increasingly high fan-out of decompressor outputs to scan chain inputs and fan-in of scan chain outputs to compressor inputs . <p> Due to wire-routing congestion , the area of wiring that connects all scan chains to the compression logic increases nonlinearly so that it dominates the area overhead of compression. - Routing congestion can be such a problem that it may become difficult to efficiently route a highly-compressed design . Die size as a function of compression level can be described @ @ @ @ @ @ @ @ @ @ circuitry that 's independent of compression level ( cm2 ) , A0 the die size without compression ( cm2 ) , + a linear area-scaling factor , and + a nonlinear multiplier that accounts for the large area increase from scan chain interconnect . The variables affecting die size are both design- and tool-dependent . <p> Measurements taken from the example design at different compression levels indicated the gate count increased at + = 1.1 -m per unit increase in compression , or 11.8 gates per scan chain . This is the red curve in Figure 3 , which plots the estimated percentage increase in A(x) across compression levels using Equation 5 with + = 0 . When only gate area overhead is considered , the area increase is almost flat across the compression range. - The blue curves , however , consider also scan chain interconnect area overhead reflecting different rates of nonlinear growth in area due to wire routing congestion . <p> Manufacturing yield is inversely proportional to die size , so increasing die size by adding compression circuitry decreases yield from Y0 , the yield of the @ @ @ @ @ @ @ @ @ @ the design with compression level x. - To illustrate , Figure 4 plots Y0/Y(x) for several manufacturing yields using Equation 5 for A(x) and the exponential yield equation relating yield to die area and defect density , 3 assuming the same parameters as in the previous example . The decrease in yield at higher compression levels makes it more costly to manufacture each yielding part. - <p> Cost Savings from Compression In the section on test execution cost , we described a simplistic cost-savings model that ignored all of the underlying effects contributing to reduction in cost savings from compression . Now that we understand the behavior of these effects , let 's observe their combined impact on cost savings . <p> Assume a design is implemented first without compression using basic scan , then with compression using compression ratio x . Thus , the cost savings + " Cost from test time reduction is the difference in test execution costs for the two designs , CEXEC , subtracted by the silicon area overhead cost of compression CSILICON : <p> - <p> We can formulate the cost savings per good @ @ @ @ @ @ @ @ @ @ component with coefficient C T equivalent to test execution cost of the basic scan design ( $/sec ) given by Equation 1 , and the silicon-area overhead cost component with coefficient C S , the cost of silicon ( $/cm 2 ) : <p> - <p> The formulation for cost savings in Equation 7 includes all compression cost variables that offset ideal savings from test time reduction . To illustrate their relative contributions , Figure 5 displays compression cost savings as a percentage of total costs calculated from Equation 7 for the design example ( design and cost parameters are indicated in the figure ) . Four curves are shown , each reflecting a different set of assumptions about the cost variables , as summarized in the table . <p> Scenario 1 assumes zero area overhead so that A(x) = A0 and Y(x) = Y0 , and zero pattern inflation so that + = 0 and <p> - <p> The expression in Equation 7 is reduced to its simplified form given by Equation 2 . Therefore , this scenario reflects ideal savings from test time reduction . Without considering the @ @ @ @ @ @ @ @ @ @ that increasing compression ad infinitum is the most cost-effective strategy ! <p> Scenario 2 takes into consideration pattern inflation , which tends to pull the cost curve downward . Most of this difference is due to a 60% step increase in pattern count from PB that is common across all compression levels ( the cost difference between zero and 0.42% pattern inflation rate is too negligible to be displayed separately on the graph ) . <p> Scenario 3 accounts for non-zero compression area overhead . Savings from test time reduction are offset by the silicon-area overhead cost of compression . An optimal compression level occurs at x = 32 , at which the incremental increase in silicon cost is equal to the incremental decrease in test execution cost . Above this level , silicon cost increases at a faster rate than the decrease in execution cost ; net savings decline precipitously with higher compression until a break-even point is reached at x = 196 , above which compression actually increases costs . <p> Scenario 4 takes all of the negating factors into account by highlighting the cost impact of decreasing @ @ @ @ @ @ @ @ @ @ to x = 174 , while the optimal compression level decreases slightly to x = 29 , where cost savings reaches the maximum level of 86% . <p> Conclusion : - Steps to Maximize Savings The preceding analysis indicates that real cost savings from scan compression are substantial , though less than the ideal levels usually claimed by the marketers of compression tools . You should expect typical savings from test time reduction in the 80% to 95% range , depending on die size , manufacturing yield , tester scan shift frequency , tester cost , cost of silicon , and the compression cost variables , which are both design- and tool-dependent . You can maximize savings by following these guidelines when implementing scan compression in your designs : <p> Utilize as many I/O pins as feasible while avoiding very high compression levels . <p> Increasing the number of scan chains from C1 to C2in the uncompressed design reduces the chain depth and requires less compression to reduce test time to a given level . The amount of compression needed to achieve the same test time is reduced by approximately @ @ @ @ @ @ @ @ @ @ utilizes 100 scan channels instead of 10 , then the compression ratio needed to achieve the same test time is reduced by 90% . This is advantageous at nominal compression levels , but keep in mind a very large number of chains at high levels could increase routing congestion . <p> Select a compression ratio in the range of the optimal compression level . <p> Regardless of the number of scan channels , cost savings start to plateau " even under ideal assumptions " by x = 20 . Maximum savings occur at a level higher or lower than this , depending on the compression cost variables . Use the cost-savings formula in Equation 7 to estimate the optimal compression level for your design . <p> Minimize the number of unknown logic states . <p> Although it may not be possible to produce an " X-clean " design , there are ways to reduce the amount of unknowns during scan testing . Timing exceptions associated with multiple internal clocks that are n't skew-balanced are a leading culprit of unknown logic states . The problem often occurs when using a single @ @ @ @ @ @ @ @ @ @ control many internal clock domains . A better approach is to employ different on-chip clock controllers to generate separate capture clocks ( one for each clock domain ) , thereby using the skew-balanced clock trees in test mode . Although there will be an area penalty associated with the additional clock controllers , no increase in routing congestion should occur . <p> Another way to reduce unknowns is to resolve all internal tri-state buses to known values in test mode . Finally , consider bypassing all embedded memories during stuck-at testing . For transition delay tests , techniques to propagate known memory states are possible though more involved to implement . <p> Minimize wire routing congestion from scan chain interconnect . <p> Embedding the compression logic inside the design 's physical hierarchy can reduce routing congestion . To illustrate , Figure 6 shows two large physical partitions , A and B , each containing its own compression circuits . Smaller cores C and D connect with compression circuits at the top level , along with other top-level logic . Embedding compression in the largest physical blocks decreases routing at the @ @ @ @ @ @ @ @ @ @ of the blocks , and this reduces the length of wires that connect the compression logic to the scan chain I/Os . To maintain compression performance , it 's essential that all scan chains have approximately the same depth. - <p> Perhaps the most important cost not factored in by the equations concerns implementation cost " the engineering time and effort required to implement compression . After all , reducing test time is n't very cost effective if it adds weeks to your design cycle and delays your tape-out . To manage implementation cost , it might be best to invest in EDA solutions such as Synopsys ' Galaxy Design Platform for Test , which have a high degree of predictability and correlation . Predictability reflects the extent to which your compression performance goals are achieved by the tool.4 Correlation considers the impact of compression on area , timing , power , and routability . Correlation reflects self-consistency of the design platform as a front-to-back implementation flow . Thus , results you achieve at the logical level are observed in silicon , with a minimal amount of effort. - <p> @ @ @ @ @ @ @ @ @ @ , will help you maximize savings from compression . 
@@21004756 @1004756/ <h> The Cell Phone " Now That 's Entertainment <p> With music , games , and now video populating today 's cell phones , who has time to talk ? <p> Louis E. Frenzel May 10 , 2006 <p> There was a time when children could convince their parents they needed a cell phone because wherever they were , they would always be just a phone call away . It 's hard for a teenager to use that excuse now . <p> Today 's cell phones are as much portable entertainment devices as they are phones . So many models boast MP3 players , games , cameras , and even video , some experts say we soon will spend as much as 80% of the time using our phones for entertainment . <p> This is n't necessarily a bad thing . It makes some sense to combine applications , especially popular items like MP3 players , with cell phones . One thing 's for sure , though . Whether we want it or not , we 're going to get it anyway . <p> THE ENTERTAINMENT TRIAD : AUDIO @ @ @ @ @ @ @ @ @ @ cell phones from Motorola , Nokia , Samsung , and other companies . Most contain an MP3 player with flash memory and can store from about 50 to 100 songs . Hard-drive models can store thousands of songs . Most of these music cell phones get their downloads from their PC . <p> Now , Sprint Nextel offers songs for sale directly online . At $1.99 per song , this is expensive music , given Apple 's iTunes $0.99 price . But some users want the convenience of getting their music here and now . Since MP3 players and music are such hot markets , this will continue to be a valuable niche for cell phones . Perhaps the biggest development would be an Apple iPod cell phone . With Apple 's continued consumer leanings , do n't be surprised . <p> As for games , most cell phones come with a few , but they 're simple and boring , and not many people play them . More interesting games , however , could attract more attention , especially from the younger market . Yet because of the small @ @ @ @ @ @ @ @ @ @ the ideal platform . Expect the market to turn to more exotic games , though , as video arrives with bigger and higher-resolution screens . PCbased games do n't translate well to phones , so look for a new market involving video games optimized for small color screens and limited control options . <p> The ultimate entertainment media is still video . While almost everyone will tell you it 's silly to contemplate TV on a cell phone , that 's exactly where we 're headed . With its limited resolution and download speeds that force video into a slower 12- to 15-frame-per-second ( fps ) mode , the small screen makes for crummy video . <p> Just as consumers were upset with snowy and distorted pictures on their TV sets , they will be just as picky with bad video on a cell phone . Noise , dropped connections , and a poor user experience will put consumers off more than anything " anything except , perhaps , worse program and content selection . <p> With regular TV as bad as it is , do we really want to @ @ @ @ @ @ @ @ @ @ of cell-phone owners reveals that subscribers do n't really want or care about cell-phone video . <p> But what do consumers know ? Nearly every cell-phone operator , handset manufacturer , and chip company , as well as gobs of service and content providers , are hell-bent to build and develop this market . Cell-phone TV is on the way , big time . Maybe we 'll learn to like it . One potentially exciting example is the N92 video phone from Nokia ( Fig. 1 ) . <p> HOW TO PUT A TV IN A CELL PHONE While most of the industry 's attention is focused on video today , all sorts of other things are going on with cell phones ( see " Next-Generation Cell Phones , " p. 44 ) . Yet the biggest challenge is putting video into a handset . <p> There are two basic ways to deliver video to a handset " through established networks with 2.5G or 3G technology , or by transmitting it on a separate broadcast channel . We 've already got limited versions of network-delivered video . In fact , @ @ @ @ @ @ @ @ @ @ for later viewing and streaming video . <p> The downloads let viewers store short clips in flash memory for viewing at a more convenient time . These include music videos , short segments from network TV shows , and sports clips . Expect more download-specific varieties soon . As for streaming video , viewers can watch in real time . It takes more on-the-air time , so it uses more minutes , making it potentially the bigger money maker for cellular operators . <p> Users also will be able to stream video to their cell phone via the Internet with a Slingbox . With this device , users can take TV from off the air or cable and send it over a broadband connection to a laptop or cell phone with Internet access . People desperate for TV will love this interim option until the arrival of real mobile TV . <p> While you 'll continue to see new video offerings from the big cell operators , this mode is n't the future of cellphone TV . If too many subscribers decide to use video at the same time , @ @ @ @ @ @ @ @ @ @ of the network , 3G or not . In fact , streaming video could easily bring any cell network to its knees with too many connections.The solution ? Establish a new broadcast TV network for cell phones . <p> Before we get into building a new network , let 's discuss why we ca n't . The first question that comes to mind is why we ca n't just put a regular TV tuner in a cell phone and watch the available on-the-air channels . Tiny single-chip NTSC tuners have been available and affordable for years . They have three flaws , though . <p> First , they boost power consumption . Second , they require an impractical antenna . On the low VHF bands where most TV channels are available , antennas must be at least several feet long for good reception . No one will want that on a cell phone . FM radios in cell phones now use the headset cable as the antenna . Maybe this will work for a TV cell phone . <p> The third and most important flaw is that the newer ATSC @ @ @ @ @ @ @ @ @ @ in 2009 , and ATSC was n't designed for mobile units . Its complexity and power consumption do n't make it a practical alternative . Instead , multiple efforts are attempting to build a broadcast system for videoenabled cell phones . Two competing systems have been developed , and projects are under way to build them out . <p> MODEO AND DVB-H The first " competing " system is Modeo . A subsidiary of Crown Castle International Corp. , Modeo LLC owns , operates , and deploys over 10,000 cell sites in the U.S. and other countries . Modeo also is the name of the video service expected later this year . The company will develop its own unique programming and content that best fits the small screen and the battery limitations of handsets . Programs will be a mix of news , weather , sports , music , and short clips . The offerings also will include multiple music channels and podcasts . Modeo uses the well-established Digital Video Broadcast-Handset ( DVB-H ) standard . DVB-H is a mobile version of the DVB-Terrestrial standard developed by the European Telecommunications @ @ @ @ @ @ @ @ @ @ 034 ) defines a digital mobile TV method that can be used in cell phones , PDAs , laptops , and even special handheld or vehicle-installed consumer TVs . <p> This broadcast system can use any available spectrum , most of which will fall in the 400-MHz to 2-GHz range . Frequencies below 700 MHz are generally preferred , since they produce the most reliable reception . Yet the Modeo system uses a 5-MHz segment of spectrum at 1.67 GHz , which was previously used for weather balloons . Crown Castle bought it at an FCC auction several years ago , and it 's now available nationwide . Services using only one continuous piece of spectrum are called single-frequency networks ( SFNs ) , as opposed to the usual paired spectrum ( for frequency duplexing ) employed in most cellular networks . <p> Modeo develops video content , stores it on a server , and then distributes it to the company 's stations nationwide via a satellite system ( Fig. 2 ) . Each local area station has its own tall transmission tower , which is similar to other radio @ @ @ @ @ @ @ @ @ @ to cover a radius of up to 20 miles . However , each installation will be different , depending on terrain and other factors . In some cases , multiple local stations or repeaters may be needed to get reliable coverage over the desired area . The transmit sites use kilowatt-level transmitters to emit the signal out to handhelds using the DVB-H protocol . <p> The handsets are also connected to their native cellular provider using a 2.5G or 3G network . While the DVB-H broadcast does n't need the cellular network to function , an uplink would make consumer response and feedback possible . A two-way connection can even make the video interactive . Besides , there must be a tie-in to a cellular carrier just to get the receiver chips inside the handsets , which are almost always specified and/or subsidized by the carrier that sells them . The cellular operators also probably will handle billing , which they 're already equipped to do . <p> The primary DVB-H requirement was a system that can reliably receive a 15-Mbit/s data stream in 8 MHz of bandwidth . However @ @ @ @ @ @ @ @ @ @ 6- , and 7-MHz bandwidths at lower rates . Also , DVB-H addresses the power-consumption problem many portable devices face through a feature called time slicing . <p> While the transmitter transmits continuously , the receiver gets bursts of data . The tuner 's front end only turns on when it expects to gets its data . The single high-speed data stream is divided up into multiple time-multiplexed " channels . " With 10 channels , a receiver need only be on for about one-tenth of the time . With the receiver off 90% of the time , great power savings accrue . DVBH handhelds should provide a viewing time of two-and-a-half to three hours . <p> DVB-H 's real success is its use of the robust and flexible orthogonal frequency-division multiplexing ( OFDM ) . Few other access and modulation methods provide better performance under the severe conditions a mobile handset experiences . Multipath is a given , as is higherthan-usual levels of manmade noise . Add to that the Doppler effects present when a handset or other receiver is in motion . Indoor reception is expected , too @ @ @ @ @ @ @ @ @ @ " 2K , 4K , and 8K . These figures represent the number of OFDM carriers . The 2K and 8K formats are common in DVB-T , while the 4K mode is new for DVB-H . Carrier modulation may be quadrature phase-shift keying ( QPSK ) , 16QAM ( quadrature amplitude multiplication ) , or 64QAM . The broadcaster selects the exact mode and modulation method for the spectrum and desired coverage . The receivers adapt themselves to the received signal . <p> DVB-H also offers multiprotocol encapsulation with forward error correction ( MPE-FEC ) . The video data comes as IP datagrams that are encapsulated in MPE packets or sections . Each has a 12-byte header , the data payload , plus a 32-bit CRC . The video IP datagrams comprise the compressed video . <p> DVB-H is designed to use the MPEG-2 compression scheme . However , most new systems are expected to use the MPEG-4 Part 10 standard , which is the ITU 's H.264 compression method and codec definition . Audio-compression formats such as Microsoft Windows Media Audio ( WMA ) , MP3 , and AAC @ @ @ @ @ @ @ @ @ @ data are then time-multiplexed before transmission . The number of time slots or channels depends on the selected number of OFDM carriers and the final peak data speed . DVB-H is expected to support up to 10 video channels . The actual rate of each will be in the 100- to 300-kbit/s range . Because of the timeslicing feature , channel change time is expected to take 1 to 2 seconds , which is a bit slower than the average channel-surfing experience . A GPS-based clock at the transmitter will control the time slicing and demultiplexing . <p> Most DVB-H handsets will use LCD color screens in the 2- to 2.5-in. diagonal size with a 320- by 240-pixel **27;516;TOOLONG ( QVGA ) and up to 256k colors . Frame rate will be 30 fps for the highest quality , but 15 fps may be used in some cases . <p> Modeo LLC heavily tested the system in Pittsburgh last year . It 's expected to go into operation later this year in selected U.S. cities , including New York City . A rollout to 30 major markets is planned for @ @ @ @ @ @ @ @ @ @ which is the industry forum supporting and promoting DVBH in the U.S. , at www.mdtvalliance.org . <p> MEDIA FLO MediaFLO is the invention of CDMA cell-phone pioneer Qualcomm.FLO stands for forward link only , which implies a broadcast or multicast mode . It resembles Modeo and DVB-H , with a similar distribution system ( Fig. 2 , again ) . And , MediaFLO uses a 6-MHz chunk of spectrum from 716 to 722 MHz ( formerly UHF TV channel 55 ) , recently acquired by Qualcomm . It 's available nationwide . <p> MediaFLO 's air interface , also OFDM , can support a very fast data rate because of the wider 6-MHz channel . Qualcomm states a maximum of about 2 bits/s/Hz up to 12 Mbits/s . As a result , MediaFLO can provide up to 20 video channels and 10 audio channels . Again , the bit stream is divided for flexibility to fit local situations . Compression is MPEG 4 . <p> Like DVB-H , MediaFLO was designed with serious power efficiency for a maximum viewing time of several hours . Two or three transmitters about 50 @ @ @ @ @ @ @ @ @ @ frame rate on a **33;545;TOOLONG ( QCIF ) screen is the standard . But 30 fps on a QVGA screen also is possible . MediaFLO will work with cdma2000 networks owned by Sprint Nextel and Verizon using 1xRTT EV-DO . The FLO Forum ( www. floforum.org ) , which supports MediaFLO , maintains the air interface specification . <p> Modeo and MediaFLO are expected to be the two competing mobile TV systems in the U.S. Look for greater availability of both in 2007 . Subscription rates are expected to range from $10 to $15 per month . Cingular and T-Mobile will no doubt partner with Modeo and use DVB-H , while Verizon and Sprint Nextel will adopt MediaFLO , though the final arrangements are still under wraps . <p> DVB-H will dominate Europe . It 's already operational in some countries . Japan has developed a digital system called integrated services digital broadcast-terrestrial ( ISDB-T ) that 's expected to be operational this year . Korea uses a system called digital media broadcast ( DMB ) , which is available now . Both are quite different from the U.S. systems @ @ @ @ @ @ @ @ @ @ market ( see the table ) , with chips once again forming the heart of all designs . But most of these chips are special processors , and they need the right software to work . 
@@21004758 @1004758/ <h> RF Detectors For Wireless Devices <p> What is an RF detector ? An RF detector monitors or samples the output of an RF circuit and develops a dc output voltage proportional to the power at that point . <p> What do you do with an RF detector ? RF detectors are used primarily to measure and control RF power in wireless systems . <p> Why are power measurement and control so important ? RF power , rather than voltage , is the primary measure of a wireless signal . In a receiver , signal strength is a key factor in maintaining reliable communications . In the transmitter , the amount of power transmitted is critical because of regulatory guidelines . It 's also important for maintaining the range and reliability of the radio link . <p> What is the unit of power measurement in RF applications ? The unit of power is the watt . However , it is common in most RF and wireless applications to express power in terms of dBm or decibels related to 1 mW : <p> dBm = 10log power(mW) / 1 mW @ @ @ @ @ @ @ @ @ @ dBm . This unit of measurement is usually referenced to an impedance of 50 O. <p> What is the main application of RF detectors ? Transmitter output power measurement is the primary application . It is essential to know the RF output power because the application specifies it in most cases , and certain maximum values must not be exceeded according to Federal Communications Commission regulations . In many cases , the transmitter power is controlled automatically . As a result , the output power is measured and compared to a set point level in a feedback control circuit so power can be adjusted as required . <p> In receivers , power measurement is usually referred to as the received signal strength indicator ( RSSI ) . The RSSI signal typically is used to control the gain of the RF/IF signal chain with an automatic gain control ( AGC ) or automatic level control ( ALC ) circuit to maintain a constant signal level suitable for analog-to-digital conversion and demodulation . <p> What are some other uses of RF detectors ? Voltage standing-wave ratio ( VSWR ) measurement and control @ @ @ @ @ @ @ @ @ @ mismatches ( high VSWR ) at the antenna cause reflections and lead to loss of transmitted power . Furthermore , high VSWR can damage an amplifier or a transmission line . <p> When two logarithmic detectors are used , the power gain of a circuit can be measured by subtracting the input reading from the output reading . Normally , a gain calculation calls for dividing the output power reading by the input reading . This is a difficult math operation in analog circuits . But when the quantities are logarithmic , the division can be performed using a simple subtraction . Power amplifier linearization is another common use . <p> Are there different types of RF detectors ? There are two basic types : the logarithmic type and the rms type . The log type converts the input RF power into a dc voltage proportional to the log of the input , making the output directly related to decibels . The rms detector creates a dc output proportional to the rms value of the signal . <p> What does the output response of a log RF detector look like @ @ @ @ @ @ @ @ @ @ , the output is linear over the logarithmic decibel input range ( Fig. 1 ) . The slope of the curve is typically in the 20- to 25-mV/dB range . <p> What are the general criteria for selecting one type of RF detector over another ? The type of RF signal to be measured is the most important determining factor in the type of detector to use . For most general power measurement and control applications , the log type is the most useful . For pulsed RF signals , the log type is also best because of the fast response times available . In those applications where the signal has a high crest factor or a widely varying crest factor , the rms type is generally better . <p> The crest factor is the ratio of the peak to rms value of the signal . For example , higher-order quadrature amplitude modulation ( QAM ) signals ( e.g. , 16QAM , 64QAM , and 256QAM ) have high crest factors . In the case of spread-spectrum signals such as those used in CDMA and WCDMA cellular systems and orthogonal @ @ @ @ @ @ @ @ @ @ and WiBro , the high crest factor ( typically 10 to 13 dB ) will change dynamically . In such applications , an rms detector is generally more desirable . <p> What about temperature stability ? Temperature stability is an expression of the variation of the measurement accuracy versus temperature . Temperature stability is generally expressed in dB , that is , the voltage variation at the output of the detector converted into dB . Some devices have a worst-case temperature stability of 0.5 dB over their full power range . Some detectors , though , achieve 0-dB temperature stability at the top end of their input range . Figure 2 shows a typical temperature error graph for a dual detector , where the 0-dB crossover point is at an input amplitude of -13 dBm . <p> How can designers take advantage of the 0-dB crossover point ? The output of a power amplifier ( PA ) is sampled with a directional coupler . With the PA at max power , the coupler output should be attenuated down to the 0-dB crossover point of the RF detector . The detector @ @ @ @ @ @ @ @ @ @ ADC ) and sent to an embedded controller that calculates the power level based on previously stored calibration coefficients . <p> The power level is compared to a set point value . If the measured value is higher or lower than the set point , the controller uses a digital-toanalog converter ( DAC ) to control the gain of a variable gain amplifier ( VGA ) . This results in a change in the output power at the PA . The near 0- dB temperature drift of the detector at the crossover point enables the ALC loop to very accurately control the PA 's output power . 
@@21004761 @1004761/ <h> WHICH WAY DOES CURRENT REALLY FLOW ? <p> If you are an EE you definitely know the answer to this , or at least you think you do . If you said positive to negative , you are wrong . Then you remember that current flow is a charge of electrons moving in a conductor and they go from negative to positive . Of course , that is the right answer . So why does everyone usually get this wrong ? Simply because this is what they were taught in college . It seems to be a universal convention , but what I ca n't understand is why colleges do n't teach the truth ? But then you are wondering , should we really care ? And why am I even bringing this up ? Just an interest of mine I guess . <p> As a professor of electronics , once full time and now an adjunct , I teach that current is electron flow then switch over to teaching a positive to negative flow that most colleges and universities insist is the correct way to teach about @ @ @ @ @ @ @ @ @ @ . Most of the textbooks show current arrows from positive to negative . Why is that ? Ever since I started teaching , I have asked that question over and over again of professors I meet . All say the same thing in different ways . For example , " That is the way I learned it . " Or " All the textbooks show it that way . " Or " It is tradition . " Some even say that the concept is easier to understand or that all the diode and transistor symbols use arrows that point that way . I do n't see it that way at all . Am I really that dense ? For me that whole effort is just perpetuating a myth . Why not teach the truth ? Say that to any college professor and you will get the argument of a life time . I have never seen so much passion about such a topic . I love to bring this up at faculty meetings every now and then just to witness the chaos . <p> I suppose tradition is the most @ @ @ @ @ @ @ @ @ @ really did n't know what direction current flowed or what current really was anyway . Some visualized it as juice or a fluid . Others thought it was some undiscovered particle . But they all seemed to agree on a common direction , positive to negative . This has come to be known as conventional current flow . Then in 1897 , British physicist Thompson , discovered that current flow was really electrons as he was doing some research on a crt . Nevertheless , even once the truth was known , everyone stuck with the old model . Professors got used to teaching it this way and books were written , standards were established and the rest is history . End of story . <p> I came to engineering by way of the technician route . I learned electronics in a technical school and was taught that current flow was electron flow and all circuit analysis was done that way . Even the textbooks for techs showed the real truth of negative to positive flow . Still do . And the military also teaches negative to positive flow . @ @ @ @ @ @ @ @ @ @ teaching although the colleges still insist that we emphasize conventional flow . I never saw it as a handicap . In fact , what is so difficult that a professor can not teach both ? Students are definitely smart enough to grasp the difference . Why obfuscate , shun or mock the truth as often happens in academia ? <p> One quirky thing that really nags me is that many textbook publishers actually go to the trouble and expense of creating two versions of their texts , one with conventional flow and another with electron flow . If they do n't get the direction right , professors wo n't adopt the book . Silly , huh ? But that is the way of the academic world . One would not like to get caught teaching current flow the " wrong " way . <p> In the end , I guess it really does n't matter . When we are designing these days , who cares ? Even advanced network analysis with mesh or nodal solutions is done with software where as in the past you had to really pay attention to which way you drew the arrows . 
@@21004764 @1004764/ <h> Simple Tester Provides Readout of Crystal Frequency <p> Using this Pierce-oscillator circuit , users can test and verify the basic operation of a crystal in parallel-resonance mode . It allows the user to calculate and set the critical external capacitor values and then read the oscillation frequency . <p> Jose B. Castro-Miguens and Carlos Castro-Miguens Dec 02 , 2014 <p> Although oscillators are critical components in most electronic devices , designers need n't design oscillators themselves in most cases , because the device contains a great deal of the oscillator circuitry . Instead , they only have to select the crystal and external capacitors needed for the oscillator function . If an incorrect crystal or external capacitors are selected , it can lead to a device that does n't operate properly , fails prematurely , or will not operate over the intended temperature range . <p> Quartz crystals have parallel and series modes of resonance , and an oscillator circuit is calibrated for one mode or the other , but not both . The common Pierce-gate oscillator ( Fig. 1 ) uses a parallel crystal mode . Here @ @ @ @ @ @ @ @ @ @ load capacitance ( CL ) , which is the capacitance that the crystal needs to see to oscillate at the desired frequency . Phase-locked loops ( PLLs ) are commonly used to obtain inexpensive , high-frequency clock signals from low-frequency signals generated by oscillator circuits like the one shown , which mitigates the use of very-high-frequency crystals . <p> 1 . The Pierce-gate oscillator , which uses the parallel-resonance mode , is among the most common crystal-oscillator topologies . Any useful model of the circuit must take into account the gate and other parasitic capacitances . <p> Designers must select the value of capacitors CL1 and CL2 to match the specified crystal load capacitance ( CL ) . The most common mistake is to assume that the value of CL1 and CL2 in parallel is equal to the value of the CL , which is n't accurate . This is because most designers neglect the internal input and output capacitances of the inverter gate ( see CIN and COUT ) and some other parasitic capacitances . These capacitances are significant in value compared to the external ones ( CL1 and @ @ @ @ @ @ @ @ @ @ and CL2 to match the CL as specified by the manufacturer using Equation 1 : <p> If CIN and COUT are n't specified , then assume each to be 5 pF and CSTRAY to be 3 pF , as a starting-point rule of thumb . The oscillator circuit must be optimized by changing the starting values of CL1 and CL2 to get a total capacitance equal to CL specified by the crystal manufacturer . A trimmer capacitor can be substituted for CL1 and/or CL2 in order to manually tune their value . ( Be sure to use ceramic capacitors with a low temperature coefficient ( COG or NP0 types ) for CL1 and CL2 , and avoid capacitors made from Z5U material . ) <p> 2 . This basic test circuit is a Pierce-gate oscillator , which provides readout of crystal frequency . There are two resistor adjustments ( POT1 and POT2 ) for optimal performance , which is a function of frequency as well as crystal and parasitic capacitances . <p> Figure 2 shows the schematic of a circuit that provides the frequency ( in megahertz ) of a @ @ @ @ @ @ @ @ @ @ uses a Pierce-gate oscillator configured for parallel resonance ( U1 ) . Its output goes through an unbuffered inverter ( U3 ) , to - a series of four-bit synchronous counters ( U4 , U5 , U6 ) functioning as a frequency divider , and then to a frequency-to-voltage converter ( U7 ) , to generate a voltage proportional to the signal frequency as generated by the oscillator . This voltage is digitized by the 3 1/2-digit analog-to-digital converter with internal seven-segment drivers ( U8 ) to display the frequency of the crystal via a two-digit LED readout . <p> - The user needs to make two adjustments to the circuit before it can be used : <p> Adjust potentiometer POT1 to obtain the voltage VAUX a little higher than 10 + mV for a crystal of fOSC = + MHz . Thus , for a crystal of fOSC = 4 MHz , voltage VAUX must be approximately 42 mV . <p> - After making the adjustments , calculate the value of the capacitors CL1 and CL2 to measure the frequency of a crystal , using Equation 1 ; assume @ @ @ @ @ @ @ @ @ @ is approximately 3 pF , and CL1 = CL2 . <p> Jose B. Castro-Miguens , design engineer at Cesinel Co. for power electronics , instrumentation engineering , signal processing , and electric power control , received an electrical and electronic engineering degree from UPCO University , Madrid , Spain . He can be reached at email protected . <p> Carlos Castro-Miguens , associate professor in the Electronics Department at Vigo University , Spain , received an electronic engineering degree from Vigo University . His primary research interests are in power electronics ( dynamic modelling and control of power converters , design of magnetic components for powerconverters ) and design of embedded systems . 
@@21004765 @1004765/ <h> Construction And Classification Of Hybrid-Electric Vehicles <p> HEVs typically consist of an electrical storage device , such as a battery , flywheel , or an ultracapacitor . They also combine this energy storage source with a mechanical device , like an internal-combustion engine ( ICE ) , gas turbine , or a fuel cell . This combination reduces both fuel consumption and tailpipe emissions . In general , hybrids capture energy lost during braking and return it to the on-board battery . This process is termed regenerative braking . <p> The nature of HEV configuration enables several important advantages over pure electric vehicles ( EVs ) . Because the HEV engine shares the workload with the electric motor , it can be constructed smaller . This reduction in size engenders weight reductions , leading to greater fuel economy . Also , HEV engines can be optimized to operate within a specific speed range characterized by better fuel economy and reduced emissions . This allows HEVs to eliminate the higher emissions and poor fuel economy associated with conventional ICE vehicles . <p> While all hybrid-electric vehicles require a hybrid @ @ @ @ @ @ @ @ @ @ of options open to automobile manufacturers . The most commonly employed HPU is the combustion engine . Optional HPU technologies include the **37;580;TOOLONG ( CIDI ) engine , the spark-ignition/ direct-injection ( SIDI ) engine , the stirling engine , and the gas turbine engine . <p> Providing greater driving range than systems that use only batteries , HEVs utilize liquid fuels , including gasoline , diesel , biodiesel , methanol , and ethanol , or gaseous fuels , including natural gas and liquefied petroleum gas , in addition to battery power . Although the advantages of dual power result in the increased range of HEVs over pure EVs , the increased complexity of the hybrid vehicle configuration somewhat offsets these benefits . Two such drawbacks are additional cost and increased emissions from the nonelectric portion of the fuel . <p> While the environmental benefits of an HEV depend on the design of the power system , emission levels are lower than those of typical combustion vehicles even in the worst cases . The reduced emissions of HEVs result from the nature of the HEV genset ( engine/generator system ) @ @ @ @ @ @ @ @ @ @ producing zero emissions , or it operates at a predetermined output where it produces the lowest emissions and achieves the best fuel economy per unit of output . In general , the hybrid genset is n't throttled for variable output , as is the engine of conventional vehicles . Because it 's technically easier to control combustion-engine emissions when the engine runs continuously at a constant output , HEVs offer more effective emissions control . <p> One of the most prominent advantages of the HEV over the battery-electric vehicle ( BEV ) is the inherent bidirectionality of the HEV energy/work loop . The HEV powertrain converts stored energy into vehicle motion . Moreover , it converts vehicle motion back into stored energy through the employment of regenerative braking . Regenerative braking provides vast benefits . An estimated 60% of the total energy consumed in urban driving is spent overcoming the effects of inertia . Theoretically , up to half of this lost energy may be reclaimed by an HEV upon deceleration . <p> The optimal integration of subsystems united by a comprehensive control structure is the most promising approach to @ @ @ @ @ @ @ @ @ @ integral to monitoring and balancing the energy flow throughout the vehicle . The proposed future control system will be a self-adaptive , integrated propulsion system that utilizes batteries ( or supercapacitors ) as an energy reservoir for load levelling . This approach differs from the traditional structure in which batteries merely supply the total vehicle motive power . To a great extent , current research is aimed at developing the most effective control strategy , the most efficient bias between subsystems , and the correct choice of subsystems to minimize hardware , mass , and manufacturing costs . 
@@21004767 @1004767/ <p> For decades , power-supply designers have set their inductor ripple current to somewhere between 20% and 40% of their power supply 's full rated output current . This is considered a good starting point for selecting the step-down converter 's inductance . However , not all engineers even agree on this specific percentage range . <p> Furthermore , is the inductor ripple-current percentage always a useful metric or design goal for every power-supply design ? While a percentage representation of inductor ripple current may have been useful in previous years ( and still may be useful for higher-current power supplies ) , it 's less important in highly integrated , low-power , step-down converters used in small , portable applications such as tablets and notebooks . <p> Step-Down Converter Overview <p> Figure 1 shows a basic diagram of a synchronous step-down converter , while Figure 2 provides the **26;619;TOOLONG ( CCM ) operating waveforms for the switch node ( SW ) and inductor ripple current ( + " iL ) . <p> 1 . A synchronous step-down converter contains two power MOSFETs that create a square wave at @ @ @ @ @ @ @ @ @ @ inductor . <p> The inductor ripple current , + " iL , is given as a percentage of the full output current . For example , a 50-A power supply with a 40% ripple current has a + " iL of 20 A. Convention implies that the 20 A is a peak-to-peak value , so the inductor current goes between 60 A and 40 A at a 50-A load . <p> 2 . An ideal step-down converter produces waveforms like these for its SW node and inductor ripple current . <p> How Can You Use Inductor Ripple Current ? <p> Equation 1 calculates the inductor ripple current in an ideal step-down converter : <p> Power-supply designers routinely use Equation 1 to solve for inductance ( L ) with a given inductor ripple current ( + " iL ) . This is the first use of inductor ripple current " to greatly simplify finding an inductance value for a given design . With all designs , you still have to optimize the value and pick an actual inductor , but Equation 1 is a quick start to getting close . <p> @ @ @ @ @ @ @ @ @ @ calculating the discontinuous conduction mode ( DCM ) /CCM boundary load current , determining the peak inductor current , and computing the ripple current in the output capacitors . <p> Step-down converters have two possible modes of operation : DCM and CCM . Synchronous converters without a power-save mode only operate in CCM , but all other converters operate in both modes depending on the load current . At lower load currents ( DCM operation ) , the inductor current reaches 0 A before beginning another switching cycle . At higher loads ( CCM operation ) , the subsequent switching cycle begins while the inductor current is still positive . <p> DCM and CCM have different operating waveforms , states , and equations . The boundary between the modes occurs when the load current is one-half of + " iL . Thus , + " iL is sometimes used to keep the step-down converter in CCM at the power supply 's lowest load current . Removing the DCM state simplifies the analysis and calculations for the power supply . <p> Once you know + " iL , you can calculate @ @ @ @ @ @ @ @ @ @ plus one-half of + " iL . This is important for sizing the saturation current of the inductor " which should be greater than the calculated peak inductor current " as well as setting the current-limit level for a peak-current-limit system . <p> The + " iL current must be absorbed by the output capacitance in order to present a dc current to the output bus . The output capacitors must be rated for this + " iL for reliability . Typically , you convert + " iL into a root-mean-square ( RMS ) value for these calculations . The amount of + " iL is also directly proportional to the output-voltage ripple , especially for capacitors with significant equivalent series resistance ( ESR ) . <p> Using Inductor Ripple Current in a Low-Power Step-Down Converter <p> The typical low-power step-down converter used in portable devices like tablets and notebooks is different than the 50-A power supplies used in other applications . To begin with , the power-supply integrated circuit ( IC ) is much more integrated , often containing the MOSFETs and control-loop compensation . For such devices , @ @ @ @ @ @ @ @ @ @ since the loop compensation is fixed and therefore must match the inductance used . Table 1 shows the recommended inductance table from the TPS62130A datasheet , which is a common low-power step-down converter used in portable applications . <p> Operating the power supply in CCM only and calculating the ripple current in the output capacitors is n't usually important in portable applications . For most portables , each power supply has a very low current idle or sleep mode , during which it must operate efficiently . <p> At these very low load currents " less than 10 mA " the power supply 's power-save mode operates and the device enters DCM to maintain acceptably high levels of efficiency . Since CCM vastly reduces efficiency , sometimes to levels below 10% , the portable application accepts DCM operation to maintain efficiency targets . The power-save modes used in these devices help minimize any extra output-voltage ripple that occurs in DCM . <p> The high integration and small size required in portable-device power supplies also requires a higher switching frequency . A higher frequency enables the use of ceramic output capacitors @ @ @ @ @ @ @ @ @ @ . However , this type of capacitor has virtually no ESR , and therefore no + " iL limit . Unlike the ESR-containing tantalum or electrolytic capacitors used in higher-power supplies , ceramic capacitors accept high ripple currents without reduced reliability . <p> Calculating the peak inductor current is still somewhat useful in low-power , step-down converters . While the device datasheet likely already has a list of recommended inductors from which to choose ( Table 2 ) , you should calculate the peak inductor current if you 're using an inductor not listed in the table . <p> When selecting an inductor , the minimum approach is to choose a saturation current rating above the calculated peak inductor current , as well as ensuring that this peak inductor current is below the minimum value of the peak-current limit in the IC . The most conservative power-supply designers pick a saturation current rating above the maximum value of the current limit , since this is the highest current ever seen by the inductor . <p> If you follow the datasheet guidelines regarding the IC 's settings , such as switching @ @ @ @ @ @ @ @ @ @ , you can dispense with the + " iL calculations . The designers of these easy-to-use , small and low-power ICs have already done the work for you . <p> In low-power applications , a more common challenge is finding a small-enough inductor to fit in the system , combined with a low-enough inductance to meet aggressive transient-response targets . In some cases , exceeding the 20% to 40% + " iL rule of thumb may be necessary to meet this challenge , along with other concrete design goals . <p> Conclusion <p> Selecting an inductance in order to meet a desired percentage of ripple current is less important in highly integrated , low-power step-down converters used in portable devices , such as notebooks and tablets . Instead , selecting an inductance within the allowable range from the IC 's datasheet is best for control-loop stability and achieving optimal operation . <p> In many cases , the chosen inductance allows for more than the standard 20% to 40% + " iL in order to meet size and transient-response requirements . As long as this inductance is within the datasheet 's @ @ @ @ @ @ @ @ @ @ , and do n't reach the IC 's current limit , you can exceed this age-old rule of thumb to meet other design requirements . 
@@21004772 @1004772/ Type <p> On-Demand Webinar <h> Speaker <p> Alan Wadsworth Market Brand Manager Semiconductor Test &amp; Power <h> Description <p> Why this webcast is important : At some point in their careers , most engineers and scientists need to make accurate current and voltage ( IV ) measurements. - Unfortunately , this type of practical measurement knowledge is rarely taught in universities. - This presentation will cover the basics of IV measurement , with an emphasis on tips and tricks to improve the results you obtain and to increase your efficiency in making these types of measurements. - <p> Who should view this webcast : Engineers and scientists who need to properly make IV measurements in order to characterize thie device . 
@@21004773 @1004773/ <h> White Paper Details Benefits Of Dual-Channel Spectrum Recording <p> X-COM Systems is offering a new application note entitled , Benefits of Time-Synchronized Dual-Channel Spectrum Recording . The white paper describes a technique for recording two channels of spectrum synchronized in time , from seconds to minutes or even longer . Many applications , such as analyzing aircraft radar cross-section and monitoring of wireless networks to find and identify interference , can significantly benefit from this process . A signal analyzer is not always practical in such applications , as the breadth of spectrum to be analyzed often exceeds its capture bandwidth , causing signals of interest to be missed . Signal analyzers are also designed to store only recordings of short duration , so they are unlikely to detect signals that occur randomly or intermittently . However , with two signal analyzers acting as front end , preselector and digitizer , streaming their output to a spectrum record and playback system , accounted for , all transient emissions can be . Available for download at the companys web site , Application Note 101 : Benefits of Time-Synchronized Dual-Channel @ @ @ @ @ @ @ @ @ @ of how and where it can be used . 
@@21004779 @1004779/ <h> A Chronology Of The AED 's Development <p> U.S. patent number 6,871,093 B2 , assigned to Koninklijke Philips Electronics N.V. , Eindhoven , the Netherlands and listing the inventor as Kim J. Hansen , Renton , Wash. , describes the earliest details of the HeartStart defibrillator 's design . The patent , which included the drawing below , was filed Dec. 28 , 2000 and issued March 22 , 2005 . <p> Major milestones in the AED 's history are listed below in descending chronological order : <p> Sept. 16 , 2004 : The FDA clears the HeartStart automated external defibrillator ( AED ) for over-the-counter prescription-less sale to home users . On the same day , the AHA endorses this move . <p> April 12 , 2004 : A U.S. Federal Aviation ( FAA ) mandate goes into effect , requiring U.S. airlines to carry AEDs on all large passenger-carrying aircraft . <p> Nov. 13 , 2002 : The FDA clears Philips ' HeartStart AED , the first of a new generation of defibrillators for home use . <p> May 2 , 2001 : The FDA clears @ @ @ @ @ @ @ @ @ @ the age of eight , when equipped with specially designed defibrillation pads . <p> Oct. 25 , 2000 : CVS/Pharmacy offers defibrillators to consumers with prescriptions at CVS.com , marking the first time a device is available through a consumer retail channel . <p> March 2 , 1999 : The American Red Cross announces the inclusion of defibrillator training as part of its standard CPR training course for U.S businesses to ensure that employee lay rescuers are trained and equipped to save lives at work . <p> Sept. 12 , 1998 : The FDA clears the industry 's first AED using biphasic technology . Published studies later demonstrate that this waveform , which uses less energy , has superior first-shock efficacy and induces less cardiac dysfunction in the heart . 
@@21004783 @1004783/ <h> Signal-to-Noise Ratio ( SNR ) Equation <p> The maximum error made by an ideal converter when digitizing a signal is --+ LSB , as shown in the transfer function of an ideal N-bit ADC . The quantization error for any ac signal that spans more than a few LSBs can be approximated by an uncorrelated sawtooth waveform having a peak-to-peak amplitude of q , the weight of an LSB . Another way to view this approximation is that the actual quantization error is equally probable to occur at any point within the range --+ q . <p> The quantization error as a function of time is shown in more detail in the figure . A simple sawtooth waveform provides a sufficiently accurate model for analysis . The equation of the sawtooth error is given by : <p> The mean-square value of e(t) can be written as : <p> Performing the simple integration and simplifying : <p> The root-mean-square quantization error , therefore , is : <p> Quantization noise as a function of time . <p> The sawtooth error waveform produces harmonics that extend well past the Nyquist bandwidth @ @ @ @ @ @ @ @ @ @ rate . However , all these harmonics fold ( alias ) back into the Nyquist bandwidth and sum together to produce an rms noise equal to q/G12 . <p> Quantization noise is approximately Gaussian and spreads uniformly over the Nyquist bandwidth of interest , typically dc to Fs/2 . The underlying assumption here is that the quantization noise is uncorrelated to the input signal . The theoretical signal-to-noise ratio can now be calculated assuming a full-scale input sine wave : 
@@21004784 @1004784/ <h> Devices Automate Design Of Flash Memory , Single-Chip Sub-Systems <p> An effortless , automated design flow for the addition of in-system and in-application programmable flash memory , SRAM , and programmable logic to 8-bit CISC microcontroller-based systems is provided with a new family of EasyFlash PSDs . The chips provide a complete single-chip memory sub-system , including the programmable logic for the MCU interface , address decoding , chip selects and other logic functions . The design flow is completely automated , using point-and-click menus in the firm 's Windows-based PSDsoft Express EDA tool.Three devices have been introduced : the PSD913F1 , the PSD913F2 and the PSD934F2 . In 52- or 64-pin PLCC and PQFP packages in lots of 10,000 , the devices are priced from $6.40 each for the PSD913F2. 
@@21004785 @1004785/ <h> Getting at the Core of Windows 10 <p> Microsoft Windows has always come in a variety of flavors . However , until the arrival of Windows 10 , the variance between instances could be quite diverse . Windows has run on systems like Intel 's Itanium , MIPS , and the DEC Alpha . Recently , we had the ARM-based Windows RT . And Windows CE was designed to run on ARM . <p> Developers had to use toolsets designed specifically for these different platforms , which was less of an issue when systems tended to operate in a standalone environment . With the Internet of Things ( IoT ) , though , that scenario does n't make much sense . <p> Numerous challenges popped up with the various systems , including the way Microsoft split their development and delivery . Visual Studio has been Microsoft 's development platform , but a design team within Microsoft would typically take a snapshot and lock it down to provide support for a platform like Windows CE . Unfortunately , that left those developers out of sync with the latest version @ @ @ @ @ @ @ @ @ @ and the latest Visual Studio are designed to change that paradigm . <p> At this point , Windows 10 IoT Core supports a small but growing number of platforms in addition to the usual x86 platforms targeted by desktop and server versions of Windows . Of note is the Raspberry Pi 2 , which is one of the first platforms to support Windows 10 IoT core . <p> That+ ? ? s a Raspberry Pi 2 running Microsoft Windows 10 for IoT Core under the patch board to the left . It controls the custom-made plotter driven by a digital-camera input . <p> Upon a recent visit to Microsoft , I saw many Raspberry Pi units driving robots to an interesting plotter application that also used a digital camera for input ( see the figure ) . These were stock units programmed using the latest version of Visual Studio . <p> Perhaps the biggest change is that the Windows 10 IoT Core is a subset of other Windows 10 versions . It will run on ARM platforms as well as x86 variants like the Minnowboard , which runs an Intel @ @ @ @ @ @ @ @ @ @ Core is not on par with Windows running on a desktop or other platform with a sophisticated user interface . Instead , it 's more like a headless version of Linux . It allows Windows 10 IoT Core to be small , suiting it for embedded applications . It also makes the core easier for Microsoft to maintain compatibility between versions . <p> The advantage for embedded developers is that the languages and tools used for other Windows 10 platforms will be the same for Windows 10 IoT Core . Languages like C++ , C# , Python , and Visual Basic can be used on all platforms . There 's a single debug interface as well . <p> Dealing with the subset of services is well-understood among embedded developers . Displays or graphics can be part of the mix , but they will not be standardized at this point . This is generally less of an issue for custom designs that might use something like a 2-line LCD display driven by an I2C interface . <p> Features like security and communications are common because of the base software . Many @ @ @ @ @ @ @ @ @ @ remote update and administration . This may not have a huge impact on the maker community , but the features are critical in the commercial IoT space . <p> Understanding the scope and limitations of Windows 10 IoT Core will be crucial to its adoption . It 's not a stripped-down version of the desktop . On the other hand , that 's not what most embedded applications need or what most developers want at this level . It 's definitely an option worth investigating for those working on embedded applications . 
@@21004786 @1004786/ <h> The History of Personal Computers " Part 1 : The East Coast Version <p> Have you ever wondered where PCs and all their derivatives came from ? If not , I am going to tell you anyway , at least my version of it . Of course , the source was the development of the microprocessor in the early 1970s . <p> One of the things that really ticks me off is to hear that the PC had its start in Silicon Valley . Naturally , much of the development occurred there but lots went on outside of the west coast . If you read the book Fire in the Valley ( Osborne/McGraw Hill , 1984 ) you get the impression that the whole PC and hobby computing movement occurred in Silicon Valley and that Steve Wozniak and Steve Jobs invented the PC and Bill Gates invented software . But there is more to the story than that . <p> My first remembrance of a hobby computer movement was in the late 1960s when I first subscribed to Stephen B. Greys Amateur Computer Society newsletter . The microprocessor @ @ @ @ @ @ @ @ @ @ was in minicomputers made by Digital Equipment Corporation ( DEC ) , Data General and others . They were made with ICs and discretes and were horrendously expensive . DEC made the cheapest mini called a PDP-8E for about $9000 . A small hardy group of electronic hobbyists were trying to build their own computers out of cheap digital ICs ( RTL and DTL mostly ) and surplus magnetic core memories out of old IBM 1620 computers . Solid state memory was not available yet . The ACS newsletter served as an information source on ICs , memories and potential I/O terminal devices . <p> In the late 1960s and early 1970s , a couple of computer kits came into being . One was the Kenback made with 7400 series TTL . An educational training computer by Fabri-Tek called the BiTran 6 was available to schools and the military . I developed a computer kit for McGraw Hills National Radio Institute ( NRI ) in 1972 using TTL called the 832 . It used a 16 word 8-bit programmable ROM made with slide switches . Another 16 words of RAM @ @ @ @ @ @ @ @ @ @ were 8 instructions , a serial CPU and a clock of 500 kHz . We sold several thousand of them as part of a home study course in computer technology . It worked great and was a great training device . It is amazing what you can program in just 32 words . <p> Other kit computers came along in 1974 like the Scelbi-8H , a kit based on Intels first 8-bit micro the 8008 . Also in 1974 , Radio-Electronics magazine published an article on the Mark-8 a computer also based on the 8008 . Radio-Electronics also published an article on how to make a video terminal with a TV set . Written by Don Lancaster , the article described a TV Typewriter and the article was eventually expanded into a book by SAMS . <p> The Intel 8080 arrived in the 1974 time period and that really changed things . The first real 8080 kit named the Altair 8800 came from an Albuquerque company called MITS . It was featured on the cover of Popular Electronics magazine and generated massive interest and sales . It was just a @ @ @ @ @ @ @ @ @ @ known as the S-100 bus . Programming was in hex with front panel binary lights and switches . A similar machine was also available from IMSAI . I had one of these in 1976 with a Teletype ASR-33 terminal . Programming was in BASIC using paper tape I/0 . Slow and primitive but it did work . The most popular accessory was 4K ( yes , 4KB ) memory boards . <p> All hell broke loose after that . Dozens of computer kits came and went , most using the 8080 or later the Z80 . Some used the Motorola 6800 . The MOS Technology 6502 was also popular ( Commodore , KIM and Apple ) . Program storage was on an audio cassette using the so-called Tarbell Kansas City standard . It was primitive but very effective for such low cost . <p> It was during the 1975-1977 time period all sorts of new computers came along the most notable being the Apple I followed by the Apple II , the Radio Shack TRS-80 , and the Commodore PET . The OS and language was BASIC . Packaged applications @ @ @ @ @ @ @ @ @ @ such a hit mainly because of a fabulous program called VisiCalc . Remember that ? The first spreadsheet . <p> Hard disks were not popular because of the cost . You could get 8 " floppy for some machines . The 5 " mini drives came along later and became popular because of their lower cost . Gary Kildall wrote his famous CP/M operating system for the 8080 . Adam Osborne made the first portable PC with an 8080 and CP/M . <p> A whole slew of small cheap game computers emerged next . Remember the Atari 400/800 , the Commodore 32 , the Sinclair ZX-81 or the Texas Instruments 99/4 ? <p> Magazines , computer shows and clubs drove the whole movement . Some of the magazines were Byte , Kilobaud , Creative Computing , Dr. Dobbs Journal , and Interface Age . I wrote for Interface Age for a while . The very first computer show was put together by John Dilks in 1976 in Atlantic City , NJ . MITS put on an Altair conference in Albuquerque in 1976 as well . Jim Warren created the first @ @ @ @ @ @ @ @ @ @ all three shows . Local clubs sprang up everywhere . And computer stores became a new retail outlet . <p> I lost track of all the S-100 bus PCs that were made . All are history today . Intel finally announced the 8088 and 8086 16-bit processors in the late 1970s . The IBM PC came along in August of 1981 . I got one in December . The IBM PC changed everything . Suddenly it was no long a hobby business . And the rest , as they say , is history . <p> One final point . The computer business really developed on the east coast thanks to IBM , DEC , Burroughs , Univac , Data General , and other big mainframe and minicomputer computer manufacturers . Most semiconductor development went on in Silicon Valley , obviously , but much of the computer business itself was elsewhere , less one forgets . I guess that 's history for you . Everyone involved has their own view of it . The truth lies in many places in many forms . <p> As for Heathkit , that is another whole story I will tell you next time . 
@@21004788 @1004788/ <h> Will Noise and Interference Throttle the Internet of Things ? <p> If the projections for the volume of the Internet of Things ( IoT ) actually happen , we will have tens of billions of devices , mostly wireless , vying for spectrum space amongst what will be an increasingly noise environment . That 's the bad news . The good news is that the IoT movement is going to be good for most players in the electronic industry . How do we deal with the potential bad news ? <p> Noise is unwanted signals generated by electrical and electronic equipment . Interference is one signal on the same or a nearby frequency that disrupts the transmission . Let 's talk about the noise first . It comes from many sources . A large percentage is derived from the ac power line. - Impulse noise caused by high-voltage transformers with poor connections ; motors and other devices turning off or on ; fluorescent and neon lights , welders , CFLs , light dimmers , HVAC systems , and connected appliances like microwave ovens make up most of it @ @ @ @ @ @ @ @ @ @ product , most of which have a switching power supply. - TV sets , computers , printers , audio systems , and smartphones all have a switch-mode power supply ( SMPS ) . We also have inverters in UPS and solar power systems . Switch-mode power supplies are major generators of impulse noise with heavy harmonic output . <p> What all these devices do is collectively produce a noise floor above the natural thermal noise floor all radios have to deal with . And imagine this noise floor continuing to increase year after year as more and more electrical and electronic devices are put into service . The result is that wireless communications will be disrupted . Some transmissions will fail completely . Some will make it through after several tries . Others will endure a lower data rate or just be delayed . <p> Luckily , most of this noise is worse at the lower frequencies , less than , say , a few hundred MHz. - Noise tapers off above that as harmonic content amplitude of impulses continues to decline with frequency . Good design will also help @ @ @ @ @ @ @ @ @ @ " shielding , filtering , and good grounding " and it will help . <p> As for interference , it is a fact of life in the shared unlicensed spectrum . If two radios are near one another and on the same or close frequency , both radios will be affected . Most wireless technologies incorporate some co-existence methods to reduce interference . Furthermore , the use of low power helps . The range is also limited so interference is usually only a problem with devices that are very close. - <p> Up to now interference has not been a major problem . But when the number of devices increases by an order of magnitude or more , this will become a major issue . And it will be especially felt as multiple IoT radios will be interfering with one another as well as increasing the impulse noise level as they turn lights , HVAC , door locks , and appliances off or on . <p> My guess is that this may not be as bad as it sounds , but the whole issue is something to think about as you design your IoT products . 
@@21004791 @1004791/ <h> Addressing the Challenges of IoT Design <p> Sponsored by Mentor Graphics <p> Oct 10 , 2016 <p> Internet of Things ( IoT ) designs mesh together several design domains in order to successfully develop a product . Individually , these design domains are challenging . Bringing them all together to create an IoT product can place extreme pressure on design teams . The Tanner design flow is architected to seamlessly work in any of these design domains by employing an integrated design flow for design , simulation , layout , and verification . Using a racing team tire pressure system , this paper walks you through this design flow , pointing out the unique solutions to IoT design . 
@@21004792 @1004792/ <h> The Art of Military Communications <p> This webcast gives an overview of recent trends in radio hardware in the military communications ( MILCOM ) field including what technologies and requirements are driving these trends . The main focus will be the shift to more widespread satellite communications ( SATCOM ) . In addition , specific ADI solutions and signal chains are presented to demonstrate modular architectures and applicable solutions . <p> Oct 28 , 2016 <p> Brought to you by <p> Sponosred by Type <p> On-Demand Webinar <h> Speaker <p> Brad Hall joined Analog Devices in 2015 as an RF hardware design engineer working on Signals Intelligence systems . Currently , he is an RF Systems Applications engineer working in the Aerospace and Defense Business Unit . He received his BSEE from University of Maryland in 2006 . <h> Description <p> This webcast gives an overview of recent trends in radio hardware in the military communications ( MILCOM ) field including what technologies @ @ @ @ @ @ @ @ @ @ will be the shift to more widespread satellite communications ( SATCOM ) . In addition , specific ADI solutions and signal chains are presented to demonstrate modular architectures and applicable solutions . <p> - Trends in MILCOM with a focus on SATCOM - Important transceiver specs for MILCOM/SATCOM - Solutions to address current and future needs <p> Who should attend : RF and System Engineers involved with MILCOM and SATCOM systems . 
@@21004797 @1004797/ <h> Hardware Emulation : A Weapon of Mass Verification <p> Greater time-to-market pressures , along with escalating hardware/software integration and quality concerns , make the verification process a strategically important step in chip design . Coming to the rescue is a new generation of cost-effective hardware emulators . <p> Despite the third adjustment to Moore 's Law , which now sets the doubling of transistors in an integrated circuit to about two years , the march continues on toward larger and larger designs/devices . <p> The average design size today hits or exceeds 50 million application-specific integrated-circuit ( ASIC ) gates , with individual blocks topping out at over 10 million gates . Top-end designs in leading semiconductor companies routinely surpass 100 million gates . The largest designs in the processor/graphics business have already reached one billion gates , or will surpass that number in the near future . <p> Driving this steep rise in design complexity is demand for new features and capabilities either added to existing products or implemented in completely new designs . As if the soaring silicon complexity is n't enough , the swell of @ @ @ @ @ @ @ @ @ @ differentiator . The pressure to get products to market faster is unbearable , forcing engineering teams to get creative . <p> Limitations of Verification Methods <p> While engineers have an abundance of verification choices , most come with inherent disadvantages . In the early days of digital circuit design , when chip complexity ranged between a few hundred to a few thousand gates , designs were verified via breadboard prototyping . With a breadboard populated by TTL logic devices , such as SSI/MSI chips , a design could be verified and debugged in its target system environment before fabrication of the silicon . Because the design was tested under real operating conditions , functional correctness was assured . <p> Breadboarding became impractical when chip complexities reached 10,000 gates , and was eventually replaced by the logic simulator based on an event-driven algorithm . This change spawned the electronic design automation ( EDA ) industry , under the early acronym of CAE ( computer-aided engineering ) . Event-driven simulators , still in use at the register transfer level ( RTL ) and seldom at the gate level , allow for accurate @ @ @ @ @ @ @ @ @ @ to use , cost effective , and have sophisticated debugging capabilities . However , their execution speed rapidly degrades when design sizes reach 100 million gates due to cache misses and memory swapping . While parallelizing simulators through PC server farms might alleviate the runtime plunge , they can not be used to test embedded software , which is a fundamentally serial process . <p> Executing one second of real time in a 100-million-gate circuit designed to run at 200 MHz would require the execution of 200 million cycles . Even on the fastest CPU with a generous cache size and a vast amount of RAM , an RTL simulator would require more than three weeks at 100 cycles per second " " an optimistic assumption " " to run through the design . <p> This poor runtime performance prevents an event-driven simulator from testing a design in its target system . Event-driven simulators are best used to simulate tiny fractions of real device behavior , which means that functional failures go undetected and engineering teams incur costly design respins . <p> For all of the advantages that formal or @ @ @ @ @ @ @ @ @ @ , they can not test design functionality . Dynamic testing using testbenches is the only choice available , especially when embedded software " " software drivers , real-time operating systems ( RTOSs ) , or custom applications " " must be tested . <p> Hardware verification languages ( HVLs ) , such as e and Vera as well as C/C++ class libraries of test functions , increase productivity through the massive generation of tests that can not be created manually . Functional verification coverage tools increase an engineer 's level of confidence in testbenches produced with a HVL , but do not reduce the amount of time required to apply those tests and can not be used when developing embedded software . <p> Hardware-assisted verification tools narrow the gap between the engineer 's goals and results from traditional logic verification . Let 's look at a few . <p> FPGA Prototyping <p> FPGA-based prototyping is used to address embedded software validation . Prototypes are basically breadboards with FPGAs replacing the SSI/MSI parts . <p> In-house-developed FPGA prototypes have been around since the advent of these programmable devices . Unfortunately , @ @ @ @ @ @ @ @ @ @ increase of design size and becomes impractical when the number of required FPGAs exceeds 10 or so devices . Debugging an FPGA-based prototype is awkward , forcing the engineer to work on complex prototyping issues instead of debugging the design . It 's often heard that a home-built FPGA prototype is ready when the design has already been taped out . <p> To address these shortcomings , a cottage industry came into existence several years ago with the goal of supplying ready-made and scalable FPGA prototypes . This trend is gaining traction if judged by the sheer number of small companies offering FPGA proto boards . They remove the cumbersome in-house development process " " the main reason for their success . Even in the largest configurations , they address designs with about 100 million gates . <p> Having the fastest execution speed , short of the speed of real silicon , is the main selling point of a proto board . Conversely , very long setup time to map a design into a proto board and rather limited design visibility are its two main drawbacks . <p> Hardware Emulation @ @ @ @ @ @ @ @ @ @ problems that afflict event-based software simulators . It achieves execution speeds five to six orders of magnitude faster than that delivered by RTL simulators . <p> Hardware emulators have not always been viewed favorably . Previously , the prohibitive cost of ownership limited adoption to engineering teams testing the largest designs , such as microprocessors and graphics chips . That 's changed as new generations of hardware emulators capable of handling up to a couple of billion or more ASIC gates offer lower overall cost of ownership . This makes them a good choice for a broad range of designs , regardless of complexities and topologies . <p> Hardware Emulation as a Verification Solution <p> Hardware emulation performs well as the ultimate bug killer . It can be invaluable for debugging hardware and testing hardware/software integration within an SoC ahead of first silicon . <p> When hardware designers and software developers both use emulation , they can share the same system and design representations . Thanks to combined software and hardware views of the design , they can work together to debug hardware and software interactions . They are able @ @ @ @ @ @ @ @ @ @ embedded software and the underlying hardware to determine whether the problem lies in the software or in the hardware . <p> A debugging methodology based on multiple abstraction levels starts with embedded software at the highest level and moves down in abstraction to trace the behavior of individual hardware elements . Starting from a database of multi-billion clock cycles , a software debugger can localize a problem to within a few million clock cycles . At this level , the software team identifies the source of each problem in the software code . Or , they call in the hardware team to use a software-aware hardware debugging approach to zoom into a lower level of abstraction . <p> Such multi-level debugging would not be possible with RTL simulators , because they are too slow to effectively execute embedded software . Likewise , the same methodology would not be possible with FPGA-based prototypes since they lack visibility and access into the design to trace hardware bugs . <p> Modern Hardware Emulation Platforms <p> Hardware emulation systems in today 's design environment run faster and are easier to use with a cost @ @ @ @ @ @ @ @ @ @ the figure ) . These highly scalable , cost-effective tools can handle up to a couple of billion ASIC gates . They boast rapid setup time and fast compile time , offering a powerful debug environment and support for multiple concurrent users . The best of the breed are packaged within an environmentally friendly footprint . <p> This comparison of RTL simulation , FPGA prototyping , and hardware emulation is based on performance , setup/compile time , design capacity , and design debug . <p> What 's more , hardware emulators can be deployed as emulation systems driven by physical target system in-circuit emulator testing ( ICE ) . It can be used as an acceleration system driven by a virtual , software-based testbench written in any combination of Verilog , VHDL , SystemVerilog , C++ , or SystemC , at the signal level or at the transaction level . Alternatives include synthesizable testbenches or test vectors . <p> Typical performance is approximately 2 MHz on a 10-million-gate design and a top speed of 1 MHz on 100-million-gate designs . When design size increases , an emulator 's performance degradation @ @ @ @ @ @ @ @ @ @ <p> Greater time-to-market pressures , along with escalating hardware/software integration and quality concerns imposed on engineering teams , make the verification process a strategically important step in chip design . A new generation of cost-effective hardware emulators provides a great choice for state-of-the-art designs . That 's why hardware emulation has become the weapon of mass verification . <p> Dr. Lauro Rizzatti is a verification consultant . He was formerly general manager of EVE-USA and its vice president of marketing before Synopsys ' acquisition of EVE . Previously , he held positions in management , product marketing , technical marketing , and engineering . He can be reached at email protected . 
@@21004798 @1004798/ <p> Until now , end-to-end connectivity for Gigabit Ethernet over copper has been a costly proposition . But , that 's about to change thanks to the development of two new ICs from Broadcom : an integrated switch , the BCM5680 , and a PHY ( physical-layer interface ) , the BCM5401 . Together , these chips promise to drive the per-port system cost of a Gigabit Ethernet switch below the $50 mark for OEMs . <p> A glance at the block diagram of the BCM5680 shows that eight Gigabit Ethernet ports have been integrated onto the chip ( Fig. 1 ) . It 's a triple-speed switch " 10/100/1000 Mbits/s " which gives it flexibility . It can be used in gigabit backbone applications and also has the ability to connect to 10/100 network-interface cards ( NICs ) on the desktop . Both copper and fiber are supported on each port . <p> The company has accelerated the switch fabric to be able to accommodate the gigabit ports . A few other minor enhancements have been made as well , but essentially the device has layer 2 through @ @ @ @ @ @ @ @ @ @ <p> One major change from its earlier models is an on-chip packet buffer . According to the company , putting the memory on the chip , 512 kbytes in this case , alleviates many I/O bottlenecks , and reduces cost . In addition , integrated onto the chip are address-resolution logic tables and a rules engine . The rules engine can look into a packet , up through layer 7 filtering . <p> The rules engine let 's users set rules based upon different fields within the packet . A rule might forward the packet to the CPU , drop it , or do various other functions . The engine can support up to 128 rules at any given time . The chip does n't do layer 4 through 7 switching , because that requires a different level of functionality . Still , it does do filtering . <p> The chip can process 8K-media-access-control ( MAC ) addresses and 2000 layer 3 IP addresses at full line rate . Layer 2 only , layer 3 only , or layer 4 through 7 filtering can all be done at line rate . @ @ @ @ @ @ @ @ @ @ ) queues . Thus , the chip can classify traffic , for example , as voice , video , web traffic , e-mail , and so forth . The filter engine can look into the packet for socket IDs and other information to figure out what CoS queue to use . <p> For very high-performance systems , a PCI bus interface is on the chip . Typically , this is the interface used by the company 's customers . Additionally , there 's an I2C serial interface . In Broadcom 's view , this opens the door for a new class of product " a low-cost , unmanaged 8-port switch . <p> The BCM5680 is stackable too . The company says it could fit very well with the StrataSwitch stacking-compatible interface , as a gigabit member of the family . Presently , the company has a large group of customers writing software around the StrataSwitch . These customers can take full advantage of that software for this gigabit switch . The company considers this a significant time-to-market benefit . <p> Essentially , the application programming interface ( API ) for @ @ @ @ @ @ @ @ @ @ are the same . The only difference is that the user has to program the drivers for eight gigabit ports in the new chip instead of two . And , some recompilation of software is required . <p> Improved Bit-Error Rate Providing the other half of this solution is the BCM5401 PHY ( Fig. 2 ) . Like the 5680 , it works at three speeds " 10/100/1000 Mbits/s . As a second-generation device , the 5401 's bit-error rate has improved to be well below 10-12 . Other new features include enhanced echo cancellation , the ability to work over longer distances , and improved tolerance to cable variations . <p> The 5401 offers a number of plug-and-play features . Automatic MDI crossover determination eliminates the need for crossover cables and ensures operation over the existing cable plant . Also , the chip automatically detects and corrects pair swaps , skew , and polarity . It supports both GMII and 10-bit physical medium-attachment ( PMA ) interfaces . <p> The 5401 has the same proven DSP technology that 's available on the company 's 5400 PHY . Like its @ @ @ @ @ @ @ @ @ @ variety of filter coefficients . These ultimately end up characterizing a cable , so data can be transmitted across it . In other words , the chip has a built-in cable tester . <p> To further enhance this feature , the company includes software code that uses the coefficients to supply information about the cable . The data tells users how long the cable is , if there is a break in it , and about 30 other useful characteristics of the cable . The net effect is a kind of green light that indicates if the cable is gigabit ready . <p> In addition , the company has de-creased the overall power consumption of the 5401 . Because a fan or heat sink is no longer necessary , this should open-up new applications , like NIC cards or very small switches . <p> Both chips are 0.25--m CMOS designs . The 5680 is packaged in a 400-pin tape ball-grid array " a very low-cost package . The key for Broadcom is to drive the system cost to less than $50 per port . This includes chassis , power supply @ @ @ @ @ @ @ @ @ @ an 8-port standalone system at an OEM cost of less than $400 . <p> Price &amp; AvailabilitySample quantities of the BCM5680 are available now for $240 each and of the BCM5401 for $70 each . For very high-volume pricing " greater than 50K units for a complete 8-port switch " a set of chips , which includes one BCM5680 and eight BCM5401s , will cost less than $300. 
@@21004801 @1004801/ <p> Touchscreens have become one of the most intuitive interfaces in almost all consumer electronic devices . They 're popular in tablets , laptops , mobile phones , desktop monitors , kiosks , gaming machines , point-of-sale devices , automobiles , GPS systems , and more . The Windows 8 operating system has made them more popular in laptops , desktop monitors , and all-in-one computers . Most touchscreens use projected-capacitance technology and require high-quality transparent conductors to provide a rich user experience . <p> The incumbent technology for transparent conductors uses indium tin oxide ( ITO ) . Indium is a byproduct of zinc mining that is sourced mainly from China . There have been supply shortages from time to time . ITO has played a major role in the growth of various electronic devices , particularly electronic displays and solar cells . To create a transparent conductor , ITO is sputter-coated onto a target substrate using a vapor deposition process in a vacuum chamber . The resultant coated substrate ( usually glass ) is chemically etched and patterned to form a transparent conductor that is used in @ @ @ @ @ @ @ @ @ @ ink with silver nanowires ( SNW ) suspended within . The nanowires are made of crystalline silver with a diameter in the tens of nanometers and a length in tens of micrometers , giving it a high aspect ratio . When coated on a plastic ( typically PET ) substrate , the resultant film has a percolated network of highly conductive yet transparent silver nanowires ( Fig. 1 ) . The single crystal silver wires overlap , creating a network that is highly conductive since silver is the most conductive element on the planet . <p> 1 . Silver nanowires are made of crystalline silver with a diameter in the tens of nanometers . <p> The requirements for transparent conductors used in touchscreens vary by the touchscreen 's application and size . In general , they all require highly transmissive materials for good viewability , good conductivity to allow fast response to touch , and thinner materials so end products weigh less and are aesthetically pleasing . Most importantly , transparent conductors offer a lower cost of ownership to touchscreen makers and thereby a lower priced device for the consumer @ @ @ @ @ @ @ @ @ @ 23-in. monitors , the higher conductivity is essential to offer fast response time with 10-finger touch capability . For mobile devices such as laptops , the need for thinner , lighter , and stronger touchscreens is driving the need for transparent conductors on film rather than traditional glass . As flexible displays become a reality , transparent conductors that can be conformed , bent , or even rolled to non-flat surfaces are part of the new requirements . Most importantly , as prices of consumer electronic devices continue to reach levels that cause mass adoption , the cost of the transparent conductors needs to keep pace . <p> OEMs increasingly prefer film-based transparent conductors . Commercially available index-matched ITO films have good transmission of over 98% , which makes them suitable for smaller diagonal size touchscreens like mobile phones where lower resistance is not mandatory ( Fig. 2 ) . <p> In case of the SNW transparent conductor , the material can be coated on film since the temperature needed to coat and dry it is around 100-C , much lower than the softening temperatures of plastic films . Also @ @ @ @ @ @ @ @ @ @ sheet resistance requirements . To obtain lower sheet resistance , a thicker coating of the exact same SNW ink at the same speed of coating ( hence same throughput ) is implemented . SNW has higher transmission than best-in-class ITO and offers well over 95% light transmission at sheet resistances significantly below what is achieved via film-based ITO . <p> Higher transmission means brighter display since the touch sensors do not impede light . Higher-transmission transparent conductors also mean longer battery life per charge in mobile devices . <p> Tablets , laptops , and LCD monitors of the past were heavier and thicker . Today the trend is to create truly portable devices and sleek all-in-one computers that demand thinner , lighter components . This is an area of advantage for film-based SNW sensors . <p> Flexible , Bendable , Rollable Touchscreens <p> Different display technologies and touchscreens have been pursuing flexible display applications for portability , ruggedness , and unique designs . In particular , organic LEDs ( OLEDs ) and e-paper are being targeted at new mobile applications . The touchscreens for these applications also need to be @ @ @ @ @ @ @ @ @ @ Imagine flexible mobile phones that are unbreakable . Imagine folding your 10-in. tablet so it fits in your pocket . Imagine rolling out a display from within your pen . Or , imagine notepad-size flexible displays or displays that wrap around a pillar or building . These types of products are becoming a reality . To enable these applications there is a need for flexible , bendable , rollable touchscreens ( Fig. 3 ) . ITO is a brittle ceramic material . It can be flexed slightly , but it 's likely to crack and become non-functional in bendable , transparent conductor applications . <p> 3 . Flexible touchscreens can be a challenge to ITO displays . <p> SNW materials have been coated on flexible and rollable displays and tested by customers , successfully passing 100,000 turns around a 3-mm radius of bend . Film-based touch sensors using SNW transparent conductors are flexible , rugged , and already in use even on glass-based rigid display monitors , mobile phones , and all-in-one computers . For these applications , the flexible transparent conductor/touchscreens reduce the weight and thickness even though the @ @ @ @ @ @ @ @ @ @ Of Ownership <p> Silver is the best conductor of electricity on the planet and is roughly 100 times more conductive than ITO . From a material standpoint , a given touchscreen uses a lot less silver than indium . There are three areas for cost comparison : the infrastructure/equipment needed to coat the material onto a substrate , the cost of patterning the material , and the cost of the material stack that makes up the touchscreen . <p> In contrast , SNW materials are solution-coated with significantly lower upfront investment in equipment such as pilot coaters ( Fig. 4 ) . The throughput/capacity of a given line does not vary with the conductivity/sheet resistance required for different applications . The roll-to-roll process employed to make SNW-coated material allows for expanding capacity very rapidly . The process is much more efficient . Also , the material utilization is better and does not suffer from the huge waste generated in the ITO deposition process . <p> 4 . Pilot coaters are used to make roll-to-roll flexible transparent conductors . <p> Patterning costs for both SNW and ITO are the same if @ @ @ @ @ @ @ @ @ @ However , SNW has a cost advantage when the material is patterned using a room temperature laser process . The cost of laser patterning is roughly one-fourth the cost of photo patterning since the equipment costs are lower and there are no consumables like photo resist , etchants , or strippers . In addition , since the laser process does not use chemicals there are no waste disposal issues. - <p> The throughput is high , and the quality of patterning is similar to the high-end photo process . The laser power required to pattern the SNW film is quite small and the quality of pattern is very high with excellent optical performance . Laser patterning on ITO could result in the substrate film being damaged since ITO requires more power or a longer duration to pattern , and the resultant patterned film could have pattern visibility that is objectionable . <p> Stack cost or per unit costs vary by stack configuration . Many more configurations are possible with SNW , and these configurations provide best-cost options for a given application . Some have fewer process steps ( five steps @ @ @ @ @ @ @ @ @ @ of SNW embedded in a dry film resist material . In other configurations like the one-film-solution ( OFS ) , the stack does not use optically clear adhesives ( OCAs ) , which further reduces cost . Overall , SNW-based touchscreens have shown to be slightly less to significantly less expensive than equivalent ITO film-based solutions . <p> Advantages Of ITO And SNW <p> ITO has enjoyed market dominance over several years since it is a well-proven technology that manufacturers understand . In some cases , manufacturers have already invested hundreds of millions of dollars in vapor deposition/sputtering equipment in well-depreciated factories . <p> The ITO process is well understood . The transmission is not better than SNW , nor can ITO film get to low sheet resistance , yet its performance is adequate for traditional applications for small diagonal size touchscreens . ITO is also very uniform , the pattern visibility is minimized , and the material is very stable . <p> SNW has an advantage over ITO in both transmission and low sheet resistance . The material is proven in several consumer products , manufacturing and per unit @ @ @ @ @ @ @ @ @ @ easier . The roll-to-roll processed SNW transparent conductor is a great choice for newer production facilities that need high throughput , easier processing , and material suited for flexible display touchscreens . <p> Rahul Gupta- is the senior director of business development at Cambrios . Previously , he had more than 13 years of experience developing new technologies and products such as lasers for optical telecommunications at Lucent , full-color OLED displays and OLED lighting at Osram , and Generation 8 inkjet printing equipment for making color filters for LCDs at AKT ( Applied Materials ) . He received his PhD from the University of California at Santa Barbara and an MBA from the Hass School of Business at the University of California at Berkeley . <p> Sriram Peruvemba- serves as chief marketing officer for Cambrios ' worldwide operations . He manages the company 's global marketing , applications engineering , and business development efforts . He has more than 25 years of experience in the electronics industry . Prior to joining Cambrios , he served as CMO for E Ink Holdings , where he oversaw global marketing efforts for @ @ @ @ @ @ @ @ @ @ senior level positions at Sharp Corp. , Planar Systems , and TFS Inc . He serves as executive advisor to YFYJupiter as well . 
@@21004805 @1004805/ <h> Instruments Race To Stay Abreast Of Advances In Fiber Optics <p> It weighs in at a scant one ounce per kilometer . Yet just one fiber-optic strand , smaller than a human hair , can carry all the telephone traffic in the U.S. at the peak busy period of the year . With such credentials , it 's understandable why fiber is well on the way to becoming the predominant transmission medium of the 21st century . Fiber also brings extraordinarily wide bandwidths that will become commonplace 20 years from now ( see " Fiber Optics ' Ascendance In Digital Transport Networks , " p. 62 ) . <p> As is well known , fiber trunks tie the nation together , though much of it is idle . But connecting the trunks to the end users through the " last mile " has been limited by the sluggish economy and lack of financial incentives for local operating companies to bring wideband into every home and enterprise , mixed together with a variety of technical issues . <p> But never mind that these obstacles have yet to be swept @ @ @ @ @ @ @ @ @ @ driven in part by a zeal to bring component costs down . Optical devices are being combined with electrical devices and , in some cases , moving onto a common substrate , shrinking size and cost . These innovations pressure optical test manufacturers to keep pace by introducing innovative instrumentation . <p> Consider dense wavelength-division multiplexing ( DWDM ) fiber-optic communication systems . For their sales to accelerate , production costs must diminish so component prices can begin to spiral downward . One manufacturer predicts that prices need to drop by as much as 40% . This is the situation facing designers of fiber-optic products , such as laser-diode modules ( LDMs ) " a critical element of DWDM communication systems . Testing is costly in LDM production due to the high value added during manufacturing . <p> Instruments of primary interest to those designing products fall into two categories : device and module testing . <p> VCSELs were developed in the mid-1990s . From a testing standpoint , the VCSEL has the advantage that its vertical-cavity construction can be tested as a laser right on the wafer . VCSELs @ @ @ @ @ @ @ @ @ @ last-mile . The long haul primarily falls to edge-emitter lasers . But the latter ca n't really be fully tested at the wafer level because it 's the cleaving process that turns them into lasers . So one must devise special technologies to test , but not until the bars are cleaved . <p> McLin adds that the major hurdle is the " at speed " test of optical electronic devices , which means testing at full data rates . At the wafer level there are a few standards , device topologies , and test methodologies . McLin points out that his customers require several kinds of testing . There are the dc parametrics that characterize basic electro-optical characteristics of devices " whether they are emitters or detectors . These tests are often called " structural , " distinguishing them from performance parameters . <p> " What our customers are looking primarily at , " says McLin , " is the electro-optical performance of laser diodes " light emission versus voltage and current , and slope efficiency . " This is the efficiency at which electrical energy is converted into @ @ @ @ @ @ @ @ @ @ , that may be present on the device in the wafer form ) prior to singulation . <p> The basic characteristic customers test is electrical-to-light conversion . This is achieved by sweeping a current while measuring both the forward voltage and the optical output . Usually , users evaluate the " slope efficiency , " which is the optical output as a function of that current . Because such testing requires the integration of diverse technologies , McLin and his design group create the test systems to fit the bill . <p> Pulsed Power For Nondestructive Test : Weeding out defective laser diodes early in the production process is another cost cutter . Typically , a laser diode is coupled to a fiber-optic pigtail during the final stages of manufacturing , prior to its integration into a complete , temperature-controlled laser-diode module . At this point in the manufacturing process , the module contains temperature measurement and control components , as well as the laser diode . <p> The Model 2520INT consists of a 1-in. sphere with a germanium detector to provide a wide operating range of telecom wavelengths . @ @ @ @ @ @ @ @ @ @ low-level power measurement . It also shortens testing time by providing an SMA fiber tap to enable measured light to be sent to another instrument simultaneously for additional optical measurements . <p> Test Systems For Do-It-Yourselfers : Over 90% of the fiber-optic component test systems used in R&amp;D and manufacturing are assembled in-house . Test engineers usually choose instruments or instrument modules , one by one , and then add a computer . So it 's understandable that modularizing is a popular approach to fulfilling test needs . <p> Modularization is attractive because it enables test engineers to economize . They can configure and later reconfigure test systems , and swap and interconnect modules as testing requirements change . A number of customizable test-configuration entries have arrived in the marketplace this past year . <p> Anritsu 's version , the ME7894A optical component test system , evaluates optical components slated for wideband transmission ( WDM ) systems operating in the C- and L-bands ( 1530 to 1570 nm and 1570 to 1610 nm , respectively ) . This test system comprises a tunable laser source , an optical power meter @ @ @ @ @ @ @ @ @ @ exhibits a wide dynamic range , enabling it to conduct accurate analysis of optical filters , couplers , isolators , and splitters during R&amp;D and manufacturing . <p> Another entry is Agilent 's E2156A customizable optical amplifier ( OA ) test system . This open , extensible platform can be customized to meet user-specific needs . Test engineers can configure it with just the right amount of test capabilities for budget-sensitive applications and still protect their investment , upgrading as necessary . <p> FlexTest , until recently known as Instrumentation Engineering , has introduced two test platforms ( see the table , again ) . They are aimed at implementing test solutions for various protocols , including Gigabit Ethernet , 10-Gbit Ethernet , InfiniBand , and Fibre Channel . These test stations can be supplied with single or multiple device-under-test ( DUT ) sites . Both single- and parallel-channel configurations are available . <p> JDS Uniphase has six new cassettes that are actually modules for its Multiple Application Platform ( MAP ) . These additions , which enable the testing of fiber-optic systems and components , broaden the MAP portfolio @ @ @ @ @ @ @ @ @ @ tunable source cassette with 110-nm of tunable range over C- and L-bands and a broadband source cassette that provides an amplified spontaneous emission output . This output exhibits a flattened , high-power density across the C-band . A utility cassette simplifies the mechanical integration of passive optical components for test sets . Finally , an electrical clock and data recovery cassette supports five key 10-Gbit/s data rates . <p> Optical Switches To The Rescue : A critical question for test engineers is if light signals can switch between multiple input and output channels . If they can , costs during the design and manufacturing test phases can be slashed . <p> Such is the path pursued by Mink Hollow Systems Inc . Its designers configured a National Instruments PXI chassis and controller with an optical switch in a compact solution that can be easily customized and reproduced . National Instruments ' LabView was used to write an automated test that was quick to develop and increase equipment usage , thereby reducing costs . With this optical switching configuration , users can connect a unit under test ( UUT ) to @ @ @ @ @ @ @ @ @ @ Fig. 2 ) . Conversely , four UUTs can be connected to a cluster of instruments . <p> First , the software identifies and displays the characteristics of any optical switches in the PXI chassis . By selecting a specific switch , a control appears on the screen of the companion PC to show the number of available connections . Clicking on a specific switch location then toggles the connection . <p> Moving Up To 40 Gbits/s : Although 40-Gbit/s deployment is still in its infancy , a rush of products with this technology is being developed . To meet instrumentation needs , a number of new module test systems have debuted . Agilent Technologies ' OmniBER optical transport network ( OTN ) , 40-Gbit/s communications performance analyzer ( CPA ) is a multirate Sonet/synchronous digital hierarchy ( SDH ) and OTN test set that can assist engineers in developing and qualifying 40- and 43-Gbit/s line cards , modules , and subsystems . Equipped with all line rates from 52 Mbits/s to 40 Gbits/s , the CPA makes it possible to validate device operation and conformance to design criteria and @ @ @ @ @ @ @ @ @ @ thru " mode for both Sonet/SDH and OTN at 40 and 43 Gbits/s . At 43 Gbits/s , the OmniBER OTN analyzer offers ITU-T G.709-compliant OTU-3 testing with forward-error-correction ( FEC ) analysis plus error-add capability . This let 's engineers simulate realistic network conditions . High-accuracy jitter testing to 10 Gbits/s for Sonet/SDH and the ITU-T G.709 optical channel is another feature . Moreover , the analyzer can map defects when encapsulating Ethernet payloads into Sonet/SDH , up to 2.5 Gbits/s . <p> Dreaded " chirp " becomes a huge bandwidth-limiting factor as telecommunication networks soar from 10-Gbit/s DWDM systems to 40-Gbit/s systems . Chirp is a carrier wavelength shift that occurs when a laser rapidly generates optical pulses . Measures must be taken to ensure that chirp does n't impair signal quality . <p> Advantest 's Model Q7607 Chirp Test Set ( CTS ) measures chirp at data rates up to 50 Gbits/s . It can be used to develop active optical components , like modulators , systems , and subsystems , as well as components composing such products . Measurements can be performed in less than 30 seconds @ @ @ @ @ @ @ @ @ @ MHz and includes an interferometer with a free spectral range of 300 GHz . An optical amplifier , available as an option , covers optical frequencies in the C- and L-bands . <p> Turn Noisy Lasers Into Sharp Sources : Enhanced channel isolation is essential in situations that require a single channel to be analyzed for preproduction testing of new DWDM designs . Needless to say , transforming inexpensive , noisy lasers into sharp laser sources for a fraction of the cost of high-end lasers becomes invaluable . <p> Digital Lightwave 's Automatic Channel Locking Filter ( ACLF ) suppresses noise on laser sources and isolates and tracks transmission channels ( Fig. 3 ) . It can isolate and select a single WDM channel while attenuating all other channels . In a single , 6.5- by 3.9- by 0.9-in. package that weighs 6.6 pounds , the ACLF combines the high performance of the fiber Fabry-Perot Tunable Filter ( FFP-TF ) with automatic scan and lock circuitry . <p> After light enters the ACLF through the input port , it 's passed via an isolator and the FFP-TF . A small @ @ @ @ @ @ @ @ @ @ optical tap and sent to the detector . The electrical signal from the detector is then fed to the ACLF scan and lock circuitry , where a phase-locked loop ( PLL ) ensures that the peak of the tunable filter passband locks to the frequency of peak lasing intensity . The remaining 99% of the optical signal is fed from the ACLF to the output port . <p> Bit-Error-Rate Testing : Another essential qualifier of data-handling equipment is bit-error-rate testing . Agilent recently enhanced its modular test platform , the 81250 ParBERT 10-Gbit Ethernet , and its 40-Gbit/s testing capabilities . It can test a wide range of bit rates and devices without the inconvenience and extra cost of mastering a totally new test instrument . In fact , measuring is rather easy . The instrument can test electrical , optical , and combined integrated product configurations at 45 Gbits/s , matching the range of OC-768 DUTs . <p> Enhancements include new modules that support 45-Gbit/s electrical and optical measurements and expand ParBERT 81250 's scalable , SFI-5 capabilities . The platform now offers an integrated solution for users who @ @ @ @ @ @ @ @ @ @ optical components and optical transport semiconductors used in such transponders . Other enhancements are a 10-Gbit Ethernet frame editor and post-processing software that enable parametric , OSI layer 1 tests of XAUI and 10-Gbit Ethernet interfaces . <p> Jitter Analysis : With rapidly rising clock speeds and data rates resulting from the exponential growth in data transmission , designers are coming to grips with a new reality " control of jitter has reached critical status . To that end , the Wavecrest SIA-3000 family of instruments enables high-speed design , debug , characterization , and production testing of optical signals in Gigabit Ethernet , Fibre Channel , Very Short Reach ( VSR ) , Sonet , and InfiniBand applications . <p> SIA-3000 family members can perform a 1000-sample period measurement in less than 9 ms . These instruments can separate jitter into its random and deterministic components and analyze jitter in a wide range of applications . They also can measure data rates up to 4.5 Gbits/s with 200-fs resolution and high accuracy . <p> Looking Ahead : Much of the fiber-optic component industry is now where the semiconductor industry @ @ @ @ @ @ @ @ @ @ and then assembling them manually . Integration and automation in both manufacturing and testing are just getting started . No silicon lasers exist , so materials of primary interest are gallium arsenide and indium phosphide . <p> DWDM is slated to comprise 160 wavelengths of 10 Gbits/s ( 1.6 Tbits/s ) spaced 25 GHz apart . However , some vendors propose narrowing the spacing to 12.5 GHz , which translates to 320 wavelengths of 10 Gbits/s ( 3.2 Tbits/s ) . That 's why the challenges to those who supply the components and modules , and those who develop the instrumentation to meet test requirements , are formidable indeed . 
@@21004806 @1004806/ <h> Improving the value proposition of advanced driver assistance sensors <p> As the role of ADAS sensors expand , improving its value proposition by adding new features , reducing cost and enhancing performance will further accelerate the installation and usage of such systems into the mainstream , thereby benefi ting a much broader group of drivers . <p> Satoru Arita , David Goff and Georg-Otto Geduld Sep 01 , 2007 <p> Advanced driver assistance systems ( ADAS ) offer excellent potential for increasing driver comfort and improving the safety of the driving experience . These systems have gained worldwide acceptance since the early 1990s . Some examples of ADAS include adaptive cruise control ( ACC ) , lane departure warning ( LDW ) and other vision systems . <p> At this year 's SAE World Congress , NHTSA administrator Nicole Nason emphasized the importance of active safety technologies . " Active safety technology is going to play an increasingly signifi cant role in the agency 's injury prevention and reduction strategy , " Nason said . Therefore , in the near future it is expected that the role of @ @ @ @ @ @ @ @ @ @ as crash mitigation and other safety features . <p> Sensors act as the receptors and the link to the environment for operation of these ADAS systems . They are one of the cost drivers for the entire system . By focusing on the value proposition of these sensors we can assist in accelerating the installation and usage rates of ADAS. 
@@21004810 @1004810/ <h> 5 Ways To Break Copyright Law Online <p> Only 5 ways to break copyright law online ? Actually there is only one but that is too generic . Essentially breaking the law would be sharing something covered under copyright law when you should not . The five types of items that could be found on a website that I was thinking of when I came up with the title include text , images , videos , audio and program code . <p> I am not a lawyer ( IANAL ) so take most of this with a grain of salt . What prompted this latest entry was a takedown notice for an image for an article I wrote . It turned out to be a composite and evidently the image in the background I used was one someone else laid claim to . <p> It was something like this but not quite as extreme ( Fig. 1 ) . You might be able to recognize the type of figure on the left but it might be a little more difficult to figure out what the base was given @ @ @ @ @ @ @ @ @ @ background is a photo of the Wright Brothers from the Library of Congress that was done back when copyright duration was a bit more sane . The owners of the rodent were a factor in getting those limits to where they are now . <p> Figure 1 . Composite works like this are allowed to a degree and this is not limited to images . The challenge for those creating new works is knowing what is legal versus what is possible . <p> It is actually composite works that I wanted to talk about because that is the business we are all in whether it is constructing a blog post for you to read or building the latest smartphone . This does get us into related areas like trademarks , patents and licensing but I 'll try to limit the discussion to copyrights and licensing . That is challenging enough . <p> Most are familiar with copyrights for the written word , images , videos and audio plus the mixture of these so we can group them all under the multimedia category . Copyright coverage begins when these items are @ @ @ @ @ @ @ @ @ @ a formalization . Many electronic multimedia formats provide a way to embed this information although few use it . Some devices like digital cameras and scanners can be set up to do this with each transaction . <p> This would be helpful when working with content because so much of it is readily available via the Internet . This includes software . Initially the creator has control over their content but licensing can be used to set the limits on how content can be redistributed . Eventually copyrights run out at which point the material would be in the public domain available for any use . This was the case with the background in the image above but my new creation has a much longer run . Of course , Penton gets control of this one since it is part of my job . <p> Open source software is one place where licensing and copyrights come together for the benefit of all . Platforms like Linux would not exist without a more liberal set of distribution rights . Linux is covered by licenses like General Public License ( GPL ) @ @ @ @ @ @ @ @ @ @ can pertain to hardware designs and other items as well . <p> For multimedia content , Creative Commons ( CC ) licensing is another open source approach . Quite a bit of content on Wikipedia is covered by CC . CC actually address a range of requirements with six distinct licenses that address use . It may require attribution to use the content , or not . It may be restrict commercial use , or not . It can address modification , or not . <p> Developers dealing with software need to consider licensing issues and even multimedia content issues since so many applications have user interfaces . For my encounter , it is a simple matter of changing a file on a server . For a company with a million devices in the field , having to change a background image or video could be costly . <p> For most people , it would be nice to make use of anything they find on the Internet but that is not the way things work . It is also a challenge to balance the rights and needs of those who @ @ @ @ @ @ @ @ @ @ The content on our site can be linked to , paraphrased , etc. but not replicated wholesale on another website or in other forms without meeting additional licensing terms . This is how many Internet businesses run and they do provide benefits to their users that would not be possible without the income from sources such as advertising . <p> These days , everyone needs to be educated about issues like copyrights because so much of what was once private and a single instance , such as a photograph , is now online for all to see , copy and redistribute . 
@@21004814 @1004814/ <h> DSOs Tackle The Challenges Of Faster , More Complex Designs <p> Like an octopus , the oscilloscope on today 's design bench must sprout multiple tentacles , reaching out to monitor signals in many parts of a circuit and displaying the measured values all at once " with all events synchronized to a common time base . But with the increasing prevalence of both analog and digital signals in new designs , getting to the heart of a problem quickly and effortlessly has never been more critical . <p> Also , designers often need to capture events in real time , then scroll through to find where a glitch or other anomaly is stifling performance . That means huge memories . In digital designs , discerning a " high " from a " low " is simply no longer good enough . So oscilloscopes with multiple inputs , on-board data processing , and mixed analog/digital analysis capabilities are a must . <p> It turns out that oscilloscopes are edging closer to fulfilling these requirements . The digital storage oscilloscope ( DSO ) has become indispensible . In addition @ @ @ @ @ @ @ @ @ @ therefore , highly capable of performing many computations on their own " with the ability to communicate . <p> A recent example of these trends is the Agilent Technologies 54642D mixed-signal , deep-memory scope ( Fig. 1 ) . It 's called mixed-signal because it can measure and display two analog and 16 digital channels with all 18 channels time aligned . Consequently , it combines a scope 's detailed signal-analysis capability and a logic analyzer 's multitiming measurements . Intended for designs with lots of digital signals , it let 's users view the complex interrelationships among all displayed signals . <p> Therefore , the 54642D is well suited for mixed-signal developmental projects , like cell phones , where the input and output to the user is analog while much of the signal processing occurs in the digital domain . Each of its analog channels provides 500 MHz of bandwidth . Its standard acquisition memory captures up to 8 Mbytes . The high-definition display is mapped into 32 levels of intensity that instantaneously disclose subtle details . <p> Powerful Triggering Necessary : Viewing analog and digital channels on a single @ @ @ @ @ @ @ @ @ @ and digital designs , it 's sometimes difficult to trace an anomaly back to its cause unless the user can trigger on it and correlate it with another trace . <p> Consider a situation that employs the serial I2C ( inter-integrated circuit ) protocol as a communication channel . I2C is popular because it needs only two I/O lines for full implementation . However , along with the benefits of using two I/O lines comes the hassle of a complicated protocol . So a tool on the bench that eases I2C troubleshooting is certainly a benefit . <p> If the designer is working with microcontrollers that use PC serial communications , the 54642D 's I2C bus trigger mode can be employed to first verify inter-IC communication handshaking . Then the I2C trigger can be used again to ensure that correct data is being transmitted to the desired device . Other triggers provided with the 54642D include CAN , USB , and SPI . <p> In summary , the deep memory capability on this mixed-signal oscilloscope ( MSO ) accelerates troubleshooting and verification . It permits the user to see slow @ @ @ @ @ @ @ @ @ @ sample rate , providing excellent resolution . The high definition realized , in turn , makes it easy to view subtle details that the deep memory captures , while serial triggering makes it possible to locate complex data patterns . <p> In the past , collecting data and transforming it into some type of desired format was a cumbersome job . But Gould Instrument Systems has streamlined this task and automated it in the Ultima 500 , bringing the benefits of a sophisticated PC to a high-performance oscilloscope . This DSO provides 500-MHz bandwidth at the probe tip and a 2-Gsample/s sampling rate with 1 million points of data storage per channel . Internal floppy and hard drives " coupled with high-speed 100-Mbit/s Ethernet , USB , and PCI connectivity " enable virtually unlimited data storage and flexible communication . Users can easily transfer data to other computers ( Fig. 2 ) . <p> Automatic Logging : As it 's capturing data , the Ultima 500 can transfer data to various analysis packages , such as Excel , for graphing and data logging . If the user wants to perform @ @ @ @ @ @ @ @ @ @ that data , it can be readily logged into a file , then graphed later in Excel . <p> Likewise , whenever the Ultima 500 triggers , the user can take advantage of a Windows feature called Decom Technology . It takes the desired parameters " like a peak , a mean , or a date and time " and transfers them to Excel . As data arrives , all analysis previously set up in the report is updated on-the-fly , behind the scenes . Once measurements have been set up , acquiring data and printing reports become routine . <p> In dual-video mode , an external monitor is connected to the Ultima 500 . Then the user can view two different images simultaneously without having to click back and forth . The image on the scope comes directly from the test probe , while the data on the external monitor is derived from the analysis of collected data that has been massaged by Excel or some other software package . <p> Long a proponent of deep memories , LeCroy Corp . recently introduced the WaveMaster . This 5-GHz DSO @ @ @ @ @ @ @ @ @ @ , high-speed signals and very fast edges ( Fig. 3 ) . Its architecture 's front end starts with silicon-germanium ( SiGe ) amplifiers and ADCs that track the arriving signal , digitize it at 10 Gsamples/s on each of its four input channels , and stream data to a fast acquisition memory that can store up to 48 million points arriving at a 10-Gbyte/s data rate . <p> This acquisition memory performs a variety of operations , including packetizing the data arriving from the ADC , and then transferring the packets in a real-time streaming mode via a high-speed data bus directly into cache memory on the CPU board . Instructions and calculations can be fetched and performed much faster by operating on cache than on data stored in RAM . <p> After the initial batch of data arrives at the CPU , a number of display , measurement , and analysis routines can be invoked . The CPU can analyze the initial portion of a long , complex waveform , while the remainder of the signal continues to flow through the streaming architecture . <p> Doubling The Memory @ @ @ @ @ @ @ @ @ @ or two signals while using a four-channel digital oscilloscope . In such instances , the WaveMaster doubles the sampling rate to 20 Gsamples/s and doubles the acquisition memory length when using one or two of the channels . Dual-channel measurements , such as setup-and-hold time , can be characterized in this mode of operation . <p> Introduced earlier this year , the Tektronix TDS6604 is a second-generation , high-performance SiGe instrument . It let 's digital design engineers rapidly and effectively pinpoint faults in emerging serial bus architectures , like InfiniBand , RapidI/O , 3GIO , and HyperTransport . This four-channel , real-time instrument provides a 6-GHz bandwidth as well as simultaneous 20-Gsample/s sample rates on two channels . It can support clock recovery at 2.5-Gbit/s data rates and 1.25-Gbyte serial pattern triggers . <p> The TDS6604 is the first Tektronix DSO to incorporate an open Windows platform , providing access to industry-standard peripherals , networking elements , and analysis tools . It supports various automated measurement packages for jitter measurements and USB 2.0 compliance testing . <p> Traditionally , the oscilloscope and PC have been separate entities that communicate with @ @ @ @ @ @ @ @ @ @ Gage Applied Inc. has merged these entities in a line of high-speed digitizers . Called CompuScopes , they plug into a PCI slot in virtually any PC and provide up to 5-Gsample/s sampling speeds . <p> Each digitizer is normally equipped with two , simultaneous input channels . When multichannel applications are required , additional digitizer cards can be simply plugged into adjoining PC slots for simultaneous sampling on up to 32 channels on a single PC . Though the system comprises physically distinct cards , the ensemble behaves functionally as one multichannel module . <p> The CompuScope supplies up to 2 Gsamples of onboard acquisition memory . The digitizers are then well suited for communications applications where users want to sample very quickly over human-type time scales of , say , several seconds . Also , the acquisition memory can be segmented for the rapid acquisition of repetitive signals . A user can capture millions of thousand-point radar records in the onboard memory without CPU intervention . <p> High resolution generally is n't important for probing repetitive , continuous wave-like signals . But for signals with a wide dynamic @ @ @ @ @ @ @ @ @ @ the norm , Compu-Scope can supply 14- and 16-bit digitizers with 16,384 and 65,536 levels , respectively . <p> A classic application is the acquisition of radar , lidar , or ultrasonic signals . Quite similar , they all comprise large and small echo pulses that result from reflected wavelets . The user ca n't increase the gain beyond the point where the largest echo almost saturates the digitizer input range . Therefore , vertical resolution sets a limit on the minimum echo amplitude that can be detected . With an 8-bit digitizer , echoes under 1/256 of the largest echo ca n't be detected . In contrast , with a 12-bit digitizer , the resolution limit is 16 times smaller " or 1/4096 of the largest echo . <p> This real-time DSO combines the functionality of a conventional benchtop oscilloscope with the benefits of a PC . It requires no external power supply because it draws its power from the PC 's parallel port . Measuring 5.5 by 7.5 by 1.77 in. , it 's well suited for portable use with a laptop . <p> Traditional benchtop instruments have @ @ @ @ @ @ @ @ @ @ outdated . But PC-based instruments can easily be updated with software upgrades that enhance functionality and increase useful life . <p> The equivalent-time sampling function was achieved via software en-hancements to the application running on the host PC and a new firmware configuration within the ADC-212s . This configuration is automatically installed in the resident hardware when PicoScope is run , and it boosts the performance of the scope far beyond its 100-Msample/s real-time capability . The 12-bit resolution ADC-212/100 and the 50-Msample/s version , the ASC-212/50 , also transform PCs into spectrum analyzers " with 50- and 25-MHz capabilities , respectively . <p> The PicoScope 's FFT-based spectrum analyzer has the same trigger features as the DSO , making it possible to capture the spectrum of a one-off event . Other features include normal , average , and peak detect modes plus linear/log scales for amplitude and frequency . <p> Because they use a 12-bit ADC , the PicoScopes provide a basic dc accuracy of 1% . Both scopes have nine input ranges , from -50 mV to -20 V. Due to their 1% accuracy , they can be @ @ @ @ @ @ @ @ @ @ . When implemented as a spectrum analyzer , the 12-bit resolution in the Y-axis means that the ADC-212 can deliver a dynamic range of 80 dB and can detect changes as small as 0.024% . <p> In the handheld space , Fluke Corp . has added color and enhanced the capabilities of its dual-input 100- and 200-MHz ScopeMeters ( Fig. 4 ) . Designated the 196C and 199C , respectively , these dual-channel DSOs feature separate high-speed digitizers for each channel . Just 10.1 by 6.6 by 2.5 in. deep and weighing in at 4.3 lbs , these instruments sport bright 4.5- by 3.4-in. displays ( 320 by 240 pixels ) . <p> The color displays make identification of individual waveforms significantly easier . In particular , they let users distinguish individual traces if waveforms fall on top of each other or are too close to one another . Moreover , the ScopeMeters use color for warnings and other onscreen labels . A brighter , high-contrast display enables clear reading under varying light conditions while preserving a full 4 hours of battery life . <p> The instruments always memorize the @ @ @ @ @ @ @ @ @ @ screen , a 10-second time window let 's the user activate process-and-hold , allowing review . Also , if the user sets up a ScopeMeter for triggering on glitches or intermittent anomalies , the instrument operates in a babysit mode and captures 100 such events . <p> Where It 's Heading : Is the time close at hand when we will run all of our T&amp;M instruments from a mouse ? That 's not likely . While more and more test and measurement instruments are choosing the PC as the host environment , instrument designers know that customers are quite settled in their tried and proven ways . There would be plenty of customer resistance against abandoning user paradigms , such as knobs , that have become so comfortable . <p> But DSO development , with ever-more-sophisticated onboard computer capabilities , wo n't stop . Already , instrument users are initiating closed-loop testing . It will soon be common for designers to use these modern , powerful oscilloscopes for programming tests as well as for monitoring results . <p> For almost half a decade , design engineers have been looking for @ @ @ @ @ @ @ @ @ @ test , freeing them to tackle engineering challenges without interference . That day is at hand . 
@@21004817 @1004817/ <h> Handbook of Fingerprint Recognition <p> Although biometrics are becoming more common in security applications , incorporating them into a system is more than just dropping a fingerprint scanner next to a PC keyboard . This book takes a look at the issues involved in using one of these biometric techniques " fingerprint recognition . <p> The book does a great job , starting with a chapter covering the history and an overview of fingerprint use before moving onto a very interesting chapter on fingerprint-sensing systems . These two chapters provide an excellent background even for those unfamiliar with fingerprint technology . <p> The chapters on analysis , recognition , matching , and indexing are a mix of theoretical concepts and mathematical analysis . There are also a sufficient number of concrete examples to keep most readers interested and informed , even if they are less interested in the mathematical aspects . <p> A chapter is dedicated to the SFINGE program . This program was used by the authors for generating fingerprints to test theories and fingerprint-recognition hardware and software . The accompanying DVD contains real and synthetic databases @ @ @ @ @ @ @ @ @ @ It also contains a copy of the SFINGE program used to create synthetic fingerprints . <p> The book wraps up with a discussion of system security . It addresses the usual attacks , such as replay , Trojan Horse , denial of service , fake fingers , and so on . There is also a discussion of key-based encryption algorithms and their relationship with fingerprint systems . It is short but useful . Overall , the book provides an excellent background for anyone that is going to be working with fingerprint systems . 
@@21004820 @1004820/ <h> Chip , Product Bonanza Drives Comm To The Top Of The Charts <p> Rapid-fire technological breakthroughs in cell phones , wireless LANs , and other systems have the wireless/communications arena percolating . <p> Louis E. Frenzel Jan 12 , 2005 <p> " We are drowning in information but starved for knowledge . " " Robert Naisbitt in his 1982 book Megatrends . Naisbitt certainly got it right more than 20 years ago , yet the situation is even worse today . Not only are we more inundated than ever before with information , but the problem has worsened simply because it 's now so easy to communicate it . Of course , one of the main culprits is the Internet , which arrived in earnest about 10 years after Naisbitt 's book hit the stands . <p> We certainly know how to communicate information , and electronics have given us the technology to store it in massive hard drives , optical drives , DRAM and flash , and all of the various storage-area-networking solutions . How we extract knowledge from all that information is another dilemma , though @ @ @ @ @ @ @ @ @ @ created through better communications . <p> Today , communications represents the largest segment of electronics , surpassing the computer sector . Why have so many semiconductor companies shifted their focus from PCs to communications ? It should be obvious with the rapid growth and acceptance of myriad wireless technologies . <p> If any one sector dominates electronics today , it 's cell phones . Because of them , wireless local-area networks ( WLANs ) , and other wireless systems , communications has recaptured the lead in new chips , products , and services . You could say that our communications options have expanded beyond our imaginations . <p> This section takes a look at the overall trends in the hottest communications and networking segments of electronics , including VoIP , Ethernet , and optical fiber , followed by broadband , short-range wireless , and cell phones . 
@@21004821 @1004821/ <h> What 's All This Transimpedance Amplifier Stuff , Anyhow ? ( Part 1 ) <p> One of the first things you learn about operational amplifiers ( op amps ) is that the op amp 's gain is very high . Now , let 's connect a feedback resistor across it , from the output to the -input . When you put some input current into the -input ( also known as the summing point ) , the gain is so high that all of the current must go through the feedback resistor . So , the output will be VOUT = - ( IIN + RF ) . That 's neat ( Fig. 1 ) . While we used to call this a " current-to-voltage converter , " which it is indeed , it 's also sometimes referred to as a " transimpedance amplifier , " where the " gain " or " transimpedance " is equal to RF . <p> There 's a whole class of applications in which this configuration is quite useful and important . An important case is when you need an op amp @ @ @ @ @ @ @ @ @ @ a photodiode . Photodiodes put out current at high impedance ( high at dc ) , but often they have a lot of capacitance . If you just let the photo diode dump its current out into a resistor , there are two problems ( Fig. 2 ) . If the sense resistor is large , then the gain can be fairly large , but the response will be slow and the time-constant will be large : t = RL + CS . But if you choose a small sense resistor to get a small t , the gain will be low . The signal-to-noise ratio ( SNR ) may also be unacceptable . How can you avoid poor gain and/or poor response ? Kay garney ? ( That 's Nepali for " What to do ? " ) <p> To avoid this terrible compromise , it 's a good idea to feed the photodiode 's output current directly into the summing point of a transimpedance amplifier ( Fig. 3 ) . Here , the response time is not RF + CS , but considerably faster . Plus , the @ @ @ @ @ @ @ @ @ @ use a larger RF . This helps improve the signal-to-noise ratio too ! <p> When you connect up the diode like this , the first thing you realize is that the darned thing is oscillating ! Why ? Well , it 's well known that the input capacitance of an op amp ( and its circuitry ) can cause instability when the op amp is used with a feedback resistor . You usually need to add a feedback capacitor across RF to make it stable . In the old days , it was stated that : <p> CF + RF = CIN + RIN <p> So if you have a unity-gain inverter with RIN = RF = 1 MO , and the input capacitance of the op amp is 10 pF , then you 're supposed to install a feedback capacitor of 10 pF . That 's what people said for years . The LF156 data sheet stated this , and it still does . But that 's not exactly true . A complete explanation is a bit beyond the scope of this column , but in practice you can @ @ @ @ @ @ @ @ @ @ In many cases , you can get a response that 's improved by a factor of five or 10 , and still not get excessive ( more than 5% or 10% ) overshoot . In practice , you have to tweak and optimize the feedback capacitance as you observe the response . <p> The formula for the optimized amount of CF is , if : <p> then : <p> but if : <p> the feedback capacitor CF should be : <p> - <p> Now , whenever you have an op amp with a large CS , a large RF , and a small CF , the noise gain will rise at moderate frequencies . The definition of noise gain is the reciprocal of the attenuation from the output back to the -input . In other words , if the attenuation is ZIN/ ( ZIN + ZF ) , then the noise gain is 1 + ZF/ZIN . <p> At moderate frequencies , the ZF is determined by RF , and ZIN is established by CS . So , the noise gain will rise until the frequency where the impedance of @ @ @ @ @ @ @ @ @ @ flattens out , typically at a large number , such as 20 , 40 , or 80 . We do this because if the noise gain kept rising at 6 dB/octave while the op amp 's gain is rolling off at 6 dB/octave , the loop is going to be unstable , and it will oscillate . The reason that we choose a small value of CF is to make the noise gain flatten out , make the loop stable , and stop the oscillation and ringing ( Fig. 4 ) . <p> If you make CF = CIN , you can get the noise-gain curve to stay flat as in line A-E . It will be very stable but have a very slow response . If you add no feedback capacitor , the noise gain will tend to rise as per line A-B-C . This will cause instability . Selecting a suitable small value for CF can get the smooth results shown by line A-B-D . Yeah , it 's as easy as ABD to get fast , stable response by picking a small CF. So , we have @ @ @ @ @ @ @ @ @ @ and minimize the overshoot . Now what ? <p> There 's a pretty good book by Jerald Graeme ( ex-Burr-Brown ) on the topic of the transconductance amplifier : Photodiode Amplifiers " Op Amp Solutions . Jerry and I have definitely come to the same basic conclusion . When you want to optimize a transimpedance amplifier , everything interacts . Therefore , every time you compute the response and the noise , and change any factor , the computations may change considerably . There 's no simple or obvious way to compute or optimize the performance . The performance , in terms of response or bandwidth , in terms of peaking or overshoot , and in terms of noise or SNR , is an extremely complicated , nonlinear , and highly interacting function of : <p> Jerry and I certainly agree on that . Jerry 's book is well written , and for just $55 , it 's pretty much a bargain . I recommend it : ISBN = 0-07-024237-X . <p> But I also have worked on this general problem many times over the years and have several suggestions @ @ @ @ @ @ @ @ @ @ later . <p> There are several basic rules of thumb that Jerry and I agree upon : <p> ( A ) You want to avoid an op amp with high voltage noise ( nV/vHz ) . <p> ( B ) You want to avoid an op amp with high current noise ( pA/vHz ) . ( Most bipolar op amps have much higher current noise than FETs . ) It 's a rare case when an op amp with bipolar input transistors is better , except when RS is very low or resistive ( or in cases where the input is capacitive but the bandwidth is narrow ) . <p> ( C ) You usually want to avoid an op amp with large input capacitance . Unfortunately , most data sheets do n't properly specify the op amp 's input capacitances , neither differential-mode nor common-mode . But it 's fair to assume that most " low-noise " op amps have a larger input capacitance than ordinary op amps . You may want to ask the manufacturer , or you might just decide to measure it yourself . <p> ( @ @ @ @ @ @ @ @ @ @ amplifier is proportional to vBW &amp;215 ; CSOURCE + VN of the op amp . So if you want to get low noise , you must optimize very carefully . Specifically , begin by computing the im-pedance ZS of your sensor at the maximum frequency of interest : <p> ZS = 1/2pFCS <p> For a good amplifier , the voltage noise and the current noise times ZS should both be as small as you can get . If one of these noises is much larger than the other , then you 're probably far off optimum . <p> ( E ) If you have any choice of what sensor you employ , try to find a lower-capacitance sensor . Furthermore , make a low-capacitance layout between the sensor and the op amp . <p> If you want to get fast response , low noise , or wide bandwidth , Jerry 's book offers some pretty good advice . More on that later . <p> But Jerry did n't include a list of good op amps that have low voltage noise , and/or low current noise , and/or low input capacitance @ @ @ @ @ @ @ @ @ @ you can use Paul Grohe 's selector guide to find some low-noise op amps . See **25;647;TOOLONG for free " Selguide " software that can run on your PC to help you select a good , low-noise , inexpensive op amp . <p> Also , Jerry neglected to mention that you can design your own op amp with better , lower voltage noise and better bandwidth . I mean , op amps that you can buy off the shelf cover a wide array of cases where they are optimized for low VNOISE and low INOISE , wide bandwidth , low power drain , and so on . But you can " roll your own " surprisingly easily and accomplish even better performance for a specified application ! I 'm not proposing that you design a complete op amp , but it 's simple to just add a new low-noise front end ahead of a suitable op amp . <p> The basic idea is to add a couple of good low-noise FETs in front of an existing op amp . Most op amps do n't operate the front-end transistors as rich @ @ @ @ @ @ @ @ @ @ , there 's no reason at all not to run more current through the front end than in the rest of the op amp . My first pick is the 2N5486 , which has less than 1 pf of CRSS , but has a lot of gms ( 4 millimhos ) and low voltage noise ( at IS = 3 mA ) . So for my first design , I 'll just put a matched pair* of 2N5486s in front of a decent wideband op amp , such as the LM6171 ( Fig. 5 ) . What 's the voltage noise of this amplifier ? We may be able to get an average of 3 nV/vHz , out to 10 kHz . <p> When you 're designing an op amp , remember this : adding gain is one of the cheapest things you can add . You on-ly need to be careful about how to give that gain away " to roll it off . <p> In this case , it 's easy . The R1-C1 network in Figure 5 just rolls off the gain for a fairly smooth frequency @ @ @ @ @ @ @ @ @ @ fairly good , smooth 6-dB/octave rolloff , I suggest R1 = 75 O , and C1 = 100 pF as a good place to start your design . <p> But now , look at the refinements in Figure 6 . We can roll off the amplifier 's gain simply in two swoops . The low-frequency gain is rolled off by RX and CX . Then after the gain rolls off flatly , we roll it off some more by RY and CY . When we are finished , it should look something like curve X in Figure 7 . This is n't exactly rocket science . We just want to make it a practical design . But this is a whole system design . You ca n't very well design and optimize the op amp alone . It 's the op amp , the feedback system , the noise filters , and the post-amplifiers that have to be considered and optimized all together . My first-hack proposals for these damping/stabilization components are : <p> RX = 5.1 kO , CX = 50 pF <p> RY = 330 O , CY @ @ @ @ @ @ @ @ @ @ own op amp is that you do not have to just build an op amp with a smooth 6-dB/octave rolloff , all the way out to a few megahertz . You can roll off the gain at a 6 dB/octave out to some intermediate frequency , and then flatten out the gain . Then , at a higher frequency , let it roll off some more in some vaguely controlled way . This would make a lousy general-purpose op amp , but it might be ideal for a case where the noise gain is rising , such as in a transimpedance amplifier . ( Look at the old LM709 . When you choose the correct damping networks , it can provide a gain of 1000 out to some high frequency like 1 MHz . ) <p> Also note that I added a second pair of 2N5486s to improve the voltage noise . Yes , this will approximately double the input capacitance . But if your CS is already large , this may easily improve the signal-to-noise ratio . If it 's good to have two , will three be better @ @ @ @ @ @ @ @ @ @ , yes , four or five may provide definite improvements ... or that might not be the case . <p> I wo n't recommend that you design your own op amp if you can buy one that does the job . But if the best one you can buy is n't good enough , then there 's some hope here . Designing your own composite op amp is not that hard , and not that expensive , even if you are going to build one or 10 or 1000 . The post-amplifier can be inexpensive . Of course , all of the basic designs will be somewhat different if you are running on -5-V supplies , or -15-V supplies . <p> Either way , it 's not that difficult , but the design compromises are slightly different . Here , I just showed a couple of -15-V applications . ( The -5-V designs differ mostly by using a low-voltage , rail-to-rail-output op amp . ) <p> In future columns on this topic , I will comment on other aspects of design and optimization for transimpedance am-plifiers . <p> Meanwhile , @ @ @ @ @ @ @ @ @ @ They often cause poor signal-to-noise ratios . Next time , I 'll explain that completely . Yes , a Tee network might help you avoid buying 1000-MO resistors , but that 's only okay when you have proven that the noise is okay . <p> All for now . / Comments invited ! RAP / Robert A. Pease / Engineer <p> *For this case , grade a good number of 2N5486s into 20-mV bins of VS , with VGD = 7 V , and IS = 3.8 mA . Take units out of the same bin for good matched pairs . <p> P.S. If you design in an op amp , try to avoid relying on nonguaranteed characteristics , such as noise , which is rarely guaranteed . <p> P.P.S. I neglected to mention that any resistor may have a built-in capacitance of 0.3 to 0.8 pF . If you add that to any imperfect layout , the capacitance could be so big that you wish it were smaller . Good layout and good engineering can easily cut the C to less than 0.2 pf . For example , make @ @ @ @ @ @ @ @ @ @ series , and install a shield land between the ends of the resistor . More later . /rap 
@@21004822 @1004822/ <h> What 's All This P-I-D Stuff , Anyhow ? <p> Recently , I wrote about refrigerators , 1 pointing out that there are several ways to control a servo loop , such as a temperature chamber , or an oven , or a refrigerator using thermoelectric coolers ( let 's leave bang-bang controllers and on-off heat-movers out of this ) . Fuzzy Logic controllers can work pretty well , and so can a P-I-D ( or PID ) controller . That 's pronounced " pee-eye-dee " , not " pid " . Several readers said that they were not very knowledgeable about PID controllers . They do n't teach very much about them in schools these days , I guess . They asked me , " Please show us a good example of a PID controller . " Well , I agree completely that an example is one of the most powerful tools . I 'll show you a couple of examples , so you can see how easy it is to come up with one yourself . And I will point out that , after a Fuzzy @ @ @ @ @ @ @ @ @ @ simple F.L. controller , I had no idea how to make it myself . Do you know how to run a F.L. controller after seeing an example of one ? I do n't . I hope that would not be true for my examples . <p> One example is found in my book on Troubleshooting , 2 where I had to control the temperature of a blast of heated air . When you apply more watts to the heater , there 's a delay before the sensor warms up to its new temperature . In fact , there are transport delays and thermal lags . This is a fairly interesting kind of system for closing the loop accurately , but not really difficult . Engineers have known how to do this for many years " about 140 years , I would say . Back in the 1880s , when most servo loops were mechanical or pneumatic , and the instrumentation was crude , it was a wise person who understood how to close a loop with good accuracy and loop stability . But for the last 40 years , when @ @ @ @ @ @ @ @ @ @ it 's been a piece of cake . <p> Note , a wise old colleague observed that the introduction of the Integral term to Control Theory is credited to the 1930s . But I found good documentation in my Encyclopedia Brittanica3 that a flyball governor with an added integral term was invented by Sir W. Siemens in 1853.4 Never bet that the British did n't get there first . However , I ca n't say that I 've seen the Derivative effect exploited in that 1894 Encyclopedia . So maybe the PID controller is only about 60 years old ... <p> First of all , let 's discuss the nomenclature " " PID . " That stands for Proportional , and Integral , and Derivative . You can build some controllers using only P and I , and others using only P and D , but when you need good performance , using all three terms can provide REAL advantages . Let 's see how these terms are made , and how they are used . <p> First , these functions are used to operate on the error signal , @ @ @ @ @ @ @ @ @ @ . Let 's spell out an example . Say that we want to define a precision heater controller " perhaps for an electric frying pan " with a sensor for the controlled chamber that puts out 10mV/-C . The input command is -350mV ( which corresponds to a desired temperature or " set point " of +35-C ) , the output of the temperature sensor is +250mV ( which coresponds to a temperature of 25-C ) , and the load must be heated to get the feedback voltage to track ( equal but with opposite sign ) . What 's needed , then , is a circuit to operate on the error , namely ( Vout + Vin ) , or -0.1 V. Op amp A1 does just that ( Fig. 1 ) . ( Let 's keep things simple by considering primarily linear systems ; if the system actually has some nonlinearities , we can address them later . ) <p> After we generate that error term , you will want to generate a correction signal that 's a function of the Error Signal . As I discussed back @ @ @ @ @ @ @ @ @ @ a heater has its watts linearly Proportional to the temperature error . " If chamber temperature is very cold , turn heat up high " is how the Fuzzy Logic guys like to say this . This is partly wise , because if the temperature really is too cold , turning on the heat is one of the good things to do . That is the Proportional term . <p> Referring to Figure 1 , we follow the error-detector amplifier A1 with a Proportional amplifier A2 . We can control the gain of the Proportional path by adjusting the pot P2 at its output , so as to get the right gain going to the power amplifier , A5 . Eventually , we will figure out what to do with A3 and A4 , but right now we can set their trim pots to ZERO , and then they 're out of the picture . Let 's keep things simple , one step at a time . <p> Now , let 's say you pour a bucket of very cold water into the electric frying pan , where the controller @ @ @ @ @ @ @ @ @ @ 's much too cold , so the heater turns on pretty hard . As the temperature of the sensor gets near the desired temperature " the set point " the heater will eventually be turned off . The problem is that any heater has a delay before its heat gets to the chamber and load and sensor . So , when the error gets to zero , and you turn off power to the heater , the chamber still keeps on heating for a while and overshoot occurs . If you turn the gain down low , this overshoot may be minor . But if you decide that you must have very high accuracy and turn up the gain , overshoot is certain , and oscillation or bad ringing is likely . <p> Now , how can we avoid this overshoot by foreseeing this situation and recognizing that the power needs to be shut down a little early ? The best solution is to add in A3 to compute the Derivative of the temperature error " the rate of change " while the proportional amplifier is computing when the error @ @ @ @ @ @ @ @ @ @ , the Derivative signal let 's the controller decide , " Whoa , we are getting very close to the set point , and the sensor 's temperature is still rising pretty rapidly " time to cut back on the power . " In practice , this works quite well . This is called P-D control , using just A2 and A3 for the Proportional and Derivative terms . You trim P3 to the setting that gives good results " not too much overshoot ( not enough derivative ) and not too slow ( too much derivative term ) . The Fuzzy Logic guys achieve this same function by using the words : " If the temperature error is small ( negative ) and the rate-of-change is small ( positive ) , heating power should be small . " This works , too . <p> In theory , you can make a differentiator " a rate-of-change computer " by taking op amp A3 and just connecting an input capacitor Cin and a feedback resistor Rf . But in practice , with real op-amps , this will cause a local oscillation of @ @ @ @ @ @ @ @ @ @ loop . The fix is fairly simple " for most cases , to prevent local oscillations , add a small resistor R111 in series with Cin , and add a small capacitor ( Cf ) in parallel with Rf . In practice , if you make R111 about 1/10 or 1/100 of Rf , and Cf about 1/20 or 1/200 of Cin , that works pretty well . In other cases , it may be a bit more critical which value you choose , either to prevent local oscillation or avoid degradation of loop stability . <p> The P-D controller is quite good for many servo control applications . To a large extent , many Fuzzy Logic ontrollers are quite analogous to a P-D loop , and often they work well . NOW let me invent a case where the P-D controller ( and the simple F.L. controller begins to work lousy ( that 's a technical term ) . Let 's take this +35-C controller outside on a cold day . The water stays warm for a while , but the air starts to cool it off . After @ @ @ @ @ @ @ @ @ @ . But there 's still an error " always an error . If the fry-pan needs 50 W to keep the water at about 35-C , then the error will be 50 W divided by the gain . <p> To avoid a large error , it 's natural to just turn up the gain " which is what some people propose to do . But when you turn up the gain , the loop stability is hurt . How badly ? Ahhhm that is hard to predict " hard to model . The reason is that the thermal transfer from the heater to the water and the sensor is n't a simple model . It 's not a simple lag . The transfer might be similar to a cascade of 5 or 10 lags , so that a step of heat causes a slow change of the sensor temperature . It 's possible to do this in a computer " or within SPICE " but it 's not really easy . Furthermore , you basically have to measure some real response of the system . You can guess , but @ @ @ @ @ @ @ @ @ @ take enough data and generate an accurate-enough model , you can show that you can turn up the Proportional Gain a certain amount . But , if you go any higher your loop will oscillate , or ring severely . Let 's say that you can only set the Proportional gain as high as 50 W/5-C , without oscillation . Your need is for less than 1-C of error . But there remains about 5- . <p> FIRSTLY , you might add as much insulation as you can to cut down the amounts of watts needed . But let 's say there is still more than 2- of error . What can we do ? <p> One alternative ( secondly ) is to sense the outside temperature . We could then use that to predict that 20 or 40 W of power will be needed . We could add that information into the controller " which does work at times , sometimes very well . This is known as feedforward . <p> Another thing we could do ( thirdly ) is add not just extra insulation , but a heated @ @ @ @ @ @ @ @ @ @ could greatly improve the accuracy , but often this amount of complexity is unacceptable . <p> Okay , the fourth option " and a fairly popular and inexpensive one " is to look at that error signal ( the output of A1 ) , and if there 's any dc error , just INTEGRATE that signal using A4 . Then feed that output through its adjustment pot ( P4 ) and sum it with the other signals . This beats the conundrum : to get full accuracy in view of the rule , " You can only turn on the heat high when the error signal is large . " In this case , you can turn on the heat high even if the error signal is NOT large " but you may have to wait a while for the integrator to do its job . Why not just turn up the GAIN for the Integrator ? You can do that to some extent . If you overdo it , that makes the loop unstable . So do n't overdo it . <p> The best thing about using the Integrator @ @ @ @ @ @ @ @ @ @ the Proportional amplifier . If you turned up the Proportional gain too high to try to cut down the error , that will cause instability as I mentioned earlier . When you have the integrator working , you can turn down the Proportional Gain and improve the loop stability a LOT , yet still have infinite gain at dc . You can have ZERO static error . <p> But , do n't turn the Proportional Gain down TOO FAR . If you did that , the I and D terms would act like an L-C filter with no damping . So if you turn P2 down to zero , that 's sure to cause oscillation , too . Now that you have the Integral path working , the gain setting for the Proportional term acts as a DAMPING FACTOR to prevent the loop from ringing . As you can imagine , the optimization of such a loop is n't trivial . Also , in many cases , these loops may be slow , so it 's hard to see if any changes you 're making are doing more good than @ @ @ @ @ @ @ @ @ @ recorder so that you can see the shape of the loop 's step response , and if you 're making any improvements . Or use a storage scope . Or a Rustrak meter . <p> - <p> Hint 2 : Take a little open-loop data to show the delay from a step of heat to a change of output temperature . Build up a cascaded R-C network to stimulate that slow lag ( Fig. 2 ) . Then change the lag 's response by a factor of 100 by decreasing all of the capacitors by a factor of 100 . Then design your controller to make that loop stable at a speed that 's easy to observe . Then scale that controller 100:1 slower , and you 're fairly close to having a controller that will work . This is one form of Analog Computer . <p> - <p> Hint 3 : If the system changes " if the amount of water in the fry-pan decreases " you will probably need to change the coefficients of your system . You could turn those pots , or you could use multiplying @ @ @ @ @ @ @ @ @ @ , to get the coefficients you want . Not trivial " because the system wo n't do it for you " you have to tell it what you want . But this IS feasible . <p> - <p> Hint 4 : This circuit wo n't work well at all with general-purpose op amps An LM741 at A3 or A4 would cause HORRIBLE errors , because the resistors in the differentiator and in the integrator will be quite high " perhaps 2 or 5- megohms " forcing you to get op amps with low bias currents . But , fortunately , good op amps with low imput current ( 50 pA or 0.05 pA ) are n't expensive these days . <p> - <p> Hint 5 : When you have all of this worked out and optimized pretty well , you can do the whole thing with one op amp " you may not need five amplifiers . In Figure 3 , op amp A6 does the whole thing . Of course , you do n't have the flexibility of three independent controls , but in many cases you do n't @ @ @ @ @ @ @ @ @ @ A6 is a summation of the Derivative and the Integral terms , with a Proportional ( damping factor ) term also included . <p> Can Fuzzy Logic likewise take advantage of an Integrator to convert from PD to PID ? Yes , and pretty easily , if you figure out the right trick . Of course , if the system is REALLY nonlinear , or a nonlinear controller is really needed , then nothing is simple , and you might have to write 125 or 343 rules . Still , a small Integral term could let you effectively turn down the " gain " of the Proportional path and greatly improve the dc accuracy AND the loop stability . Of course , this does n't mean that you can easily get fast settling under difficult conditions , such as " we have no idea how much water is in the pan . " But there 's still a definite opportunity for improvement by adding in the integrator5 . <p> As I mentioned in ' 93 , F.L. does not , by itself , compute a derivative . So if you @ @ @ @ @ @ @ @ @ @ derivative and digitize it , then present it to the F.L. controller : OR , you digitize the proportional signal and take a DIFFERENCE every few seconds , then present THAT as a derivative signal to the F.L. controller : So , in exactly the same way , the F.L. controller ca n't generate an integral . But , you can program a subroutine to compute the integral of the Error Signal and present it to the F.L. OR , you could compute the Integral term and just ADD it to the Proportional term , and then process that total without any fanfare . If the system is fairly linear , nobody will ever know that you cheated , and it will probably work perfectly . You may not have to write 343 rules " maybe 25 or 49 will work just fine ! <p> So , if you have a few bucks worth of op amps and a little time , you can make a pretty darned good controller : Much better than a bang-bang controller . When I came to NSC back in ' 76 , I found @ @ @ @ @ @ @ @ @ @ . But either the controller had finite gain ( i.e. , poor low gain ) or else ran bang-bang , with various kinds of noise and inaccuracy " and bad error ! ! In my App notes , I recommend that a proportional controller with stability enhanced by the PID terms , can be fairly simple and effective . <p> OF COURSE , if the delay from the heat to the sensor is just too slow that makes everything much harder . Locating the sensor where it gets a prompt response to the heat can help a lot . Also , you may get better results from having two sensors . The one that drives the Differentiator may be located very close to the heater as an aid to stability . But the one that drives the integrator may live in the " sweet spot " " the exact place where highest precision is needed . If there 's an extra lag there , that will certainly make the loop difficult to engineer . <p> Then the other tricks mentioned above " the feedforward path and the oven-within-the-oven " may @ @ @ @ @ @ @ @ @ @ delays occur , system design can be very challenging . But it need n't be considered impossible or even very difficult . And it 's usually not a situation where Fuzzy Logic has any inherent advantages . In fact , PID usually has advantages over a Fuzzy Logic controller if that controller tries to do without any Integral term . <p> Comments invited ! /RAP Robert A. Pease/Engineer <p> P.S. If you have a heater " such as a gas furnace " you do not want to be turning it ON and OFF every few seconds because you would wear it out . The same is true for an electromechanical refrigerator . But if you have a thermoelectric cooler , you can turn that ON to any desired extent by driving the number of amperes the loop calls for . The same thing applies with dc resistive heaters , but BEWARE " the amount of heat is normally porportional to the SQUARE of the current . If you use the power transistor AND the resistor as heaters , the total watts is about linearly proportional to the current , but @ @ @ @ @ @ @ @ @ @ ( a small source ) compared to the power resistor , which often is made of wire wrapped all around the temperature chamber . The management of thermal flow is a very important and tricky subject ; I ca n't give any easy answers " you really have to study it . <p> Modulating or controlling a high-power heater , such as a kilowatt of 115-V line power , sounds like it would be much harder , but actually it 's easy . You can drive a power Triac using a MOC3030 ( zero-crossing firing circuit ) and add a dither circuit to ensure that the average heating of the power resistor is linearly porportional to the duty cycle . In my book , I showed a 17-Hz dither that turned the Triac ON and OFF about 17 times per second . Averaged over the internal time constant of the heater , you can hardly see any noise , and the duty cycle is very well controlled without much heating in the control circuit . ( You certainly do n't want to control a kilowatt of resistive heat with a @ @ @ @ @ @ @ @ @ @ THIS is not just about PID . THIS is not just about Analog Computers . THIS is not just about Op-Amps . THIS is not just about Fuzzy Logic . This is about THE REAL WORLD . The whole world . If you ask for something and you get it , are you happy ? If not , why not ? I have seen some F.L. scientists who were wise enough to agree that they could make do with a LOT LESS than 343 rules , by adding the I term or the D term to the P term . Of course , this works best when there is not much nonlinearity . And when there is not much nonlinearity , F.L. does not have much advantage over PID controllers . <p> Minor correction on the circuit referenced in my book : on page 109 , I show a good circuit with a " 17 Hz triangle wave . " The main function of the triangle wave is so you can see the LED blinking , and guess when the loop is pegged , or whether the duty cycle is @ @ @ @ @ @ @ @ @ @ , recently . The LED did not seem to blink right . I checked , and the frequency was 170 Hz . So please mark up that schematic , to change the capacitor that is connected to " 17 Hz " from 0.01 -F to 0.1 -F , so you would see the right kind of blinking . This is the only error I have found in my book . I think we can get the 1998 printing to have the correct C value . " rap . 
@@21004825 @1004825/ <h> A Dozen Top Applications For Mesh Networks <p> Louis E. Frenzel Sep 14 , 2005 <p> 1 . Home monitoring and control : It 's a snap to turn lights off and on or dim them . It 's also easy to control gadgets like ceiling fans , power drapes , air conditioning , and heating appliances using simple ZigBee nodes . One or more access points can control a whole house . <p> 2 . Building monitoring and control : Monitoring and controlling lights , HVAC , and other functions in large office buildings , hotels , hospitals , and other structures can yield huge energy savings . The wiring to do this is too expensive to be practical , but with mesh networks , it becomes simple . <p> 3 . Industrial monitoring and control : Sensors in a mesh can provide massive amounts of detail about any process or manufacturing procedure . Wireless can serve as the feedback link in control systems . Machine conditions can be checked to provide maintenance information . Wireless mesh simplifies installation and maintenance , and the savings in wiring @ @ @ @ @ @ @ @ @ @ can be enormous . Some unexpected applications include mines and railroads . <p> 4 . Military communications and reconnaissance : A mesh makes soldier-to-soldier communications more reliable with longer range . Meshes also help tie together and coordinate many weapons and systems in monitoring and managing the battlefield . <p> 5 . Medical monitoring : Meshes make patient monitoring easier and more reliable , and it helps expand the range . <p> 7 . Automotive : New cars get more internal electronics and networks each year . A wireless mesh eliminates wiring and provides an improved way to monitor and control the hundreds of functions in a vehicle . <p> 8 . Broadband wireless access : A mesh network using Wi-Fi can be created to provide high-speed Internet connections as well as other broadband services in areas where cable TV or DSL lines are n't available . Many such networks already exist , and more are on the way . <p> 9 . Public service communications : A mesh network enhances and broadens police , fire , and other public service communications functions with a mesh network . <p> 10 @ @ @ @ @ @ @ @ @ @ meter is a huge task . Now it can be economically implemented with low-cost mesh networks . <p> 11 . Environmental monitoring : With dozens or even hundreds of temperature , humidity , pollutant , and other sensors , the condition of any area can be easily monitored and tracked . Even individual trees , ponds , fields , and other sensitive places are trackable . <p> 12 . Security systems : Inexpensive sensor nodes can monitor virtually every entry point or approach to a facility . 
@@21004826 @1004826/ <h> Automated Testing Speeds Effective Deployment Of Java Functionality <p> To fulfill its " write-once , run-anywhere " promise , Java technology must be widely deployed in resource-constrained information appliances and embedded devices . In addition to limited memory resources , developers face challenges in testing this highly heterogeneous class of products . <p> Dominating the desktop world is one major operating system , the Windows family , and one major processor , the x86/Pentium . But the **26;674;TOOLONG application environment in an information appliance or embedded device could be one among dozens of possible combinations . Each operating system and processor " when combined together , along with any necessary middleware , applications , and the Java virtual machine ( JVM ) solution " present unique testing challenges that can dramatically affect how soon a product comes to market . <p> This article discusses the benefits and challenges of test automation , plus its use in effectively and quickly deploying Java functionality in these highly diverse devices . It describes how engineers at Insignia Solutions developed test automation to test its Jeode virtual machine for these de-vices . @ @ @ @ @ @ @ @ @ @ manual testing <p> Repeatability to identify regressions immediately <p> Insulation from human factors , such as boredom or carelessness <p> Improved audit trail to identify bugs <p> Shorter residence time of bugs in the code , reducing the manual effort of development and test engineers <p> Ability to test code in live development <p> The main challenge of automation is the difficulty in implementing it . Some tests , particularly those involving devices that feature a graphical user interface , are hard to automate . Automated testing of embedded devices that employ real-time operating systems can also be challenging . Automation generally takes longer to set up and requires more skilled software engineers than a manual test . <p> Testing the Jeode platform : Insignia Solutions develops and markets Java virtual machine technologies , branded under the Jeode name . These products are targeted at information-appliance and embedded developers building devices with limited resources , like memory and battery power . Such devices can be characterized as heterogeneous because they employ a wide variety of **26;702;TOOLONG combinations . For example , to support the diversity in the embedded industry , @ @ @ @ @ @ @ @ @ @ , VxWorks , Linux , ITRON , Nucleus , pSOS , and BSDi Unix operating systems , and ARM , MIPS , x86 , SuperH-3 , SuperH-4 , and PowerPC processors . <p> Naturally , the multiplatform nature of this product complicates testing . At any one time , ports for up to six targets will be in development for an upcoming general release , perhaps six more for specific customers , and another 20 for internal development , which could be promoted to release candidates if needed . <p> It 's important to automatically test as many platforms as possible . Some target systems , such as Windows NT and most Unix variants , are easy to automate . Others , including Windows CE and most embedded operating systems , are much more difficult . They must all be tested because the target market is n't in PC-type systems , where regular computer crashes are tolerated . Instead , it 's in devices like Web terminals , set-top boxes , and networking infrastructure , where uptime and reliability are expected . <p> The Jeode Embedded Virtual Machine ( EVM @ @ @ @ @ @ @ @ @ @ code used in all ports , and platform-specific code , which is only used in some . For example , in Insignia 's dynamic adaptive compiler , the code that decides which Java bytecodes to compile is common among all platforms . But the code generator is different , depending on which CPU the code is for . In addition , platform-specific code exists for different operating systems . <p> Engineers testing the Jeode EVM on a device test the amalgamation of the platform-specific and the target-neutral code . Both are equally important . Platform-neutral code may behave in unexpected and different ways on different platforms . For instance , on one real-time operating-system platform , the company discovered thread-priority problems in the platform-neutral code of the finalizer . These were due to the operating system 's strict thread-scheduling behavior not seen under other less-strict schedulers . <p> Automated testing methodology : Automatic testing starts with the automatic building of the product . An important part of Insignia 's automatic testing is the build and bench ( bb ) queuing system , in which both building and testing of the @ @ @ @ @ @ @ @ @ @ At midnight every night , a cron job starts the overnight build " conducted by a build farm that consists of 20 to 30 NT and Linux computers . They produce about 200 builds for approximately 30 target systems , totaling around 6 Gbytes of executables and supporting libraries . These are then stored on a central file server for about 30 days , where the automatic test tools , developers , and testers access them . When each build completes ( most do by 3:00 a.m. ) , an automatic queuing system automatically starts the test scripts . Because most automatic building and testing takes place at night , the robustness of the system is important . <p> Types of automated test : The first step in establishing the quality of the EVM is to consider the quality of its source code . To accomplish this , we examine the warning and error messages that occurred during its compilation . This process can be easily automated . The verbose output files from the build system are analyzed by a series of scripts . This produces an HTML table of @ @ @ @ @ @ @ @ @ @ each build . <p> A system of color coding categorizes the status of the builds : those highlighted in green have no warnings ; those in yellow have some warnings ; and those in red have errors that prevented successful compilation . The table displays all builds done overnight , grouped by branch , target OS and processor architecture , Java type ( among others are PersonalJava and EmbeddedJava ) , and build variant ( production , feedback , and many different debugging variants ) . <p> A second process that can be readily automated is regression tests , which test if the EVM , or one of its features , works correctly . These tests range from the trivial and ubiquitous " Hello World " application to the Technology Compatibility Kit ( TCK ) compatibility test suite . Some regression tests test if a particular Java API is present and operates correctly . Others work by testing the limits of the Java specification . For example , they may start thousands of concurrent threads , all communicating with each other . Or , they might attempt to provoke a @ @ @ @ @ @ @ @ @ @ hundreds of arguments . <p> All regression tests can only pass or fail . They do n't produce a score . If they fail , they might do so in an unpredictable manner , making test automation more difficult . Some tests politely report their failure , or throw an uncaught Java exception . Others , especially those that test the limits of the specification , can cause a JVM to create a hardware exception ( null-pointer exception , access violation , undefined instruction , and so on ) . On many embedded targets that the company works with , such exceptions may not be properly handled , potentially rendering the entire system unstable . This could require human intervention to perform a soft reset of the entire system . <p> The final category of tests that merit automation is benchmarking . These are often the easiest to automate because they have well defined outputs . As a result , capturing the output and extracting the result is easy . Interpreting the results is generally more difficult than in regression tests . <p> Benchmarks can generally be divided into two @ @ @ @ @ @ @ @ @ @ do as much work as possible in a given time period ( perhaps one minute ) , while Fixed-Work benchmarks are assessed on the time taken to perform a given work unit ( say 100 iterations ) . Both derive their score by repeatedly doing a task , and then dividing the amount of work done by the time taken . However , benchmarks designed for modern high-performance desktop PCs are often ill suited to resource-limited , low-power devices . <p> All benchmarks suffer on embedded devices because they run differently than normal desktop Java applications . When designing the compiler in the Jeode EVM , an important assumption was that it would run standard Java applications that exhibit slack times ( e.g. , while waiting for user input ) . The compiler uses these slack times to function . Unfortunately , benchmark programs allow no slack times , so the compiler thread has to steal cycles from the Java thread . <p> Also , there are a variety of challenges with benchmarks . For example , Fixed-Time benchmarks can be problematic because there may not be enough time for @ @ @ @ @ @ @ @ @ @ , the reported score reflects only the interpreter performance . Internally , we can work around this problem by running the benchmark twice . The first time shows it to the compiler , and the second time , after a short sleep , gauges true performance . <p> Tools for automated testing : Because the EVM runs on a wide range of devices and operating systems , we ca n't use a single , all-encompassing test tool like MS Test . Instead , it takes a variety of tools , some developed internally , and some from outside . <p> The most important glue holding these systems together is Perl . Another useful external tool is the TCK test suites provided by Sun Microsystems to Java licensees . This software suite consists of several thousand tests that a JVM must pass to be certified as compatible . A typical test system consists of a harness running on a host PC ( Windows or Unix ) , and a slave running on a small device . <p> The harness dispatches the tests in sequence to its slave and reports the result @ @ @ @ @ @ @ @ @ @ generates an HTML report . That lists the passed and failed tests , with links to more detailed output . Both the harness and slave can be run as command line applications , making auto-mation easy . <p> The TCK is useful for test automation . In addition to the large test suites that provide a convenient regression test , users can adapt the system to run their own internal regression tests through the same harness . <p> Three main internal tools are used for test automation . One is the Embedded Remote Console ( ERC ) , a feature of the Jeode EVM that was added early in its development to assist developers working on small devices with limited display capabilities . ERC let 's developers run the EVM on PDA-type devices with small screens and no keyboard . Simultaneously , they can use the large keyboard and screen on their development PCs for input and output . For test automation , Insignia has adapted ERC as a way to capture output from the EVM and any Java programs running under it . <p> Another tool of key importance to @ @ @ @ @ @ @ @ @ @ server socket on the target and accepts commands from the host . It can transfer files between the host and target , plus start and stop processes . <p> The remote-scripting tool , developed by the author last year , builds on both ERC and iRemote . It attempts to unify test automation across platforms and simplify test automation by hiding an embedded target 's test details behind layers of abstraction . Instead , the test developer sees a common API for all targets . The remote-scripting tool handles the details of downloading a test to the target , running the test , and capturing the results . The abstraction makes the test script very short and simple , and permits its reuse for a wide variety of test targets . <p> Figure 2 illustrates how the automatic-testing process provides layers of abstraction between the data-management code in the host PC and the iRemote Java code . The latter interacts with the target device . <p> Future developments : Over the past two years , test automation at Insignia has developed from a series of piecemeal scripts to the unified @ @ @ @ @ @ @ @ @ @ automated test on each platform had a test script to do the job . In the future , Insignia hopes to eliminate as much of this test- and platform-specific complexity as possible by using cross-platform automation tools , especially the remote-scripting tool previously discussed . <p> By using an upgraded iRemote , the company would like to set up overnight TCK runs on as many platforms as possible " running both the official TCK-compatibility tests , and its own internal-regression tests . For benchmarks and stress tests , Insignia wants to expand testing via the remote-scripting tool . 
@@21004827 @1004827/ <h> Mappers Reduce Cost Of Ethernet Services <p> The DS33M30 , DS33M31 , and DS33M33 Ethernet-over-SONET/SDH ( EoS ) mapping devices merge new protocols for transporting Ethernet with the protocols of legacy optical networking , allowing service providers to deliver emerging Ethernet services using the existing optical transport infrastructure . Reportedly , they are the industry 's first monolithic SONET/SDH mapping ICs to support the Ethernet-over-PDH ( EoPDH ) protocol over optical networks . The DS33M31 and DS33M33 both have a 17 mm x 17 mm footprint with the DS33M33 including three additional DS3/E3 add/drop interfaces . The DS33M30 lacks the DS3/E3 functionality and , measuring 10 mm x 10 mm , logs in as the industry 's smallest EoS mapper . The DS33M31 and DS33M33 perform EoPDH mapping of Ethernet frames from a Gigabit Ethernet interface into a DS3/E3 frame format , then rely on traditional SONET/SDH mapping techniques to place the DS3/E3 tributaries into an optical OC-3/STM-1 . They support not only EoPoS mapping , but also the more traditional EoS mapping in virtually concatenated high-order containers , as does the DS33M30 . Supported frame encapsulations include @ @ @ @ @ @ @ @ @ @ ) . Prices for the DS33M30 , DS33M31 , and DS33M33 are $55.77 , $65.25 , and $72.50 each/5,000 , respectively . MAXIM INTEGRATED PRODUCTS , Sunnyvale , CA. ( 800 ) 998-8800. 
@@21004828 @1004828/ <h> Ecosystems : A Critical Component to Successful Development of IoT Applications <p> Feb 27 , 2017 <p> Brought to you by <h> Date &amp; Time <p> Tue , April 11 , 2:00pm EDT <p> 02:00 PM Eastern Daylight Time <h> Event Type <p> Live Webinar <h> Description <p> IoT applications require some development expertise that is significantly different from those required in a traditional embedded application . For example , the UI will typical reside on a mobile device rather than on the device itself . Most obviously , the device will need to connect to an IoT platform , which in turn will collect and analyze data . In addition , the IoT is encouraging many companies with no previous embedded development background to investigate embedded sensor-based solutions . As a result , embedded system integrators and product design houses are also an important component an IoT . <p> In this session , we will look at various IoT application developments flows and examine the underlying ecosystem required to support them , as well as understand the diversity of choice of IoT platforms and mobile SDKs that @ @ @ @ @ @ @ @ @ @ . <h> Speakers <p> Nick Lethaby Texas Instruments <p> Nick Lethaby works in TI 's Connected MCU Organization where his recent focus has been on IoT applications and sensor-to-cloud ecosystem solutions . He has over 25 years of experience in embedded systems software , including Linux and real-time operating systems , for microcontrollers , microprocessors , and DSPs . He has a BS in Computer Science at the University of London . 
@@21004831 @1004831/ <h> Jitter And Its Measurements <p> Louis E. Frenzel Aug 05 , 2001 <p> Jitter is the unwanted variations of a binary signal 's leading and trailing edges . It occurs as the signal is processed or transmitted from one point to another . Most jitter is caused by noise picked up from a phase-locked loop ( PLL ) in the signal path . Jitter also is a time displacement , either periodic or random , of a signal 's switching edges . You can think of jitter as the lengthening or shortening of one signal element , usually one bit time , in an NRZ binary signal . Jitter also can be considered as a form of FM , and it produces an FM-like spectrum . <p> Whatever you call it , jitter is a nuisance for engineers . It 's difficult to eliminate and measure . During the design of OC-48 and OC-192 Sonet systems with DWDM , or the new 1-Gbit/s and 10-Gbit/s Ethernet networks , jitter became a major focus due to the decrease in timing margins . Excessive jitter always increases the bit-error rate @ @ @ @ @ @ @ @ @ @ , most serial data-communications systems have jitter standards that must be met to ensure robust performance and the quality of service ( QoS ) expected in today 's networks . <p> The three critical jitter specifications are : <p> Jitter tolerance " the amount of jitter that a system can accommodate at its input . It 's directly affected by the capture and tracking characteristics of the PLL in the clock and data recovery ( CDR ) circuit . <p> Jitter transfer " the amount of input jitter passed through to the output . It 's a function of the PLL bandwidth . <p> Jitter generation " the amount of jitter produced with the PLL . Low-bandwidth loops produce more jitter . <p> Most jitter results from internal noise produced by the circuits in the PLL , coupling through sensitive nodes such as analog-loop filter connections , and power-supply ripple , as well as coupling from surrounding circuits or equipment , especially clocks . <p> The units of jitter measurement are picoseconds peak-to-peak ( ps p-p ) , rms , and percent of the unit interval ( UI ) . @ @ @ @ @ @ @ @ @ @ time deviation , usually in picoseconds . A jitter measurement can also be the p-p average over a 30- or 60-s duration , or over , say , 10,000 cycles . Rms jitter is one standard deviation ( - ) of the p-p jitter value where the distribution is Gaussian in nature ( see the figure ) . Jitter also is expressed as a percentage of time compared to the UI or one bit time . For example , one UI at 10 Gbits/s is 100 ps . A jitter specification might be 40 mUI , meaning 4 ps . <p> Bellcore ( Telecordia ) GR-1377-CORE , Issue 5 specifications list the jitter specifications that Sonet/SDH systems should meet . The typical specification for OC-192 is a maximum jitter of 100 mUI p-p , and the rms value is approximately 1/10 to 1/8 of the p-p value , or around 10 to 12.5 mUI. 
@@21004834 @1004834/ <p> A filter is a signal-processing component that removes unwanted parts of an input signal such as noise , extracts useful parts of an input signal lying within a certain frequency range , or reshapes the frequency spectrum of the input signal . Analog filters operate on analog or continuous signals , while digital filters operate on digital samples of a signal . <p> An analog filter comprises electronic components like resistors , capacitors , and op amps . These filters are widely used in noise reduction , video signal enhancement , graphic equalizers , high-fidelity audio systems , and many other areas . Design techniques for analog filters are well known . At all stages of the filter circuit , the signal undergoing filtering is a voltage or current that is the direct analog of the physical quantity involved . <p> Digital filters are implemented in software as an algorithm . This algorithm can be executed on a digital processor , such as a general-purpose CPU like those found in PCs , or an embedded digital-signal processing unit . Digital-signal processors are popular largely due to their use @ @ @ @ @ @ @ @ @ @ also can be configured to act as digital filters . The availability of powerful PC platforms with equally powerful graphical user environments simplifies and expedites the design of all digital filter types . 
@@21004835 @1004835/ <h> Weighing The Pros And Cons Of Vendor-Specific Certifications <p> There was a time when professional engineering certification meant something . Every state in the United States has long had education and experience requirements for being licensed as a professional engineer , or PE . Holders of that license were generally accorded a higher salary and more professional respect . The PE license typically requires an accreditation board for engineering and technology ( ABET ) -accredited degree , several years of experience , and a passing score on two daylong exams administered by the state . <p> Over the last decade , however , certifications have proliferated beyond government-run standards to many different types of vendor-specific technologies . Software certifications are perhaps best known . This is because the skills and accompanying exam tend to be performed by third parties and promoted widely . In this category , Novell 's certified NetWare engineer ( CNE ) and certified NetWare administrator ( CNA ) were among the first . But the Microsoft certified systems engineer ( MCSE ) and its derivatives are perhaps the most recognized and pervasive . <p> @ @ @ @ @ @ @ @ @ @ . It 's possible to acquire certification in Sun Microsystems servers , Cisco routers and switches , and others . Microprocessor vendors are beginning to provide courses and certifications in applying and programming their chips . Certifications ranging from real-time operating-system ( RTOS ) internals to logic design are coming into the market . The common ground among virtually all of these certifications is that they involve the implementation , rather than the development , of technology . <p> This kind of certification serves plenty of useful functions . For the vendor , it 's a way of ensuring that customer implementations are done correctly and reasonably consistently . A small investment in time and money for certification can pay large dividends for both the vendor and the customer in a correct and standard implementation . <p> Certification Aids Vendors And , of course , certification of independent engineers provides a highly skilled and aggressive sales base for that vendor 's wares . For example , at its height , Novell claimed over 60,000 CNEs . Many of these CNEs were self-employed , or worked for systems integrators , and @ @ @ @ @ @ @ @ @ @ , Novell improved sales of its products by providing a valuable service for those who implemented them . <p> From an industry point of view , vendor certification provides a measurable amount of accomplishment and ability that college degree programs in engineering and computer science no longer convey . In many cases , companies take new college graduates and spend months or even years training them in the practical aspects of engineering . Companies may also have to update the skills of new graduates . This is because a number of engineering fields move so quickly that university curricula rapidly get out of date . <p> In the realm of engineering , vendor certification could benefit a new graduate , or even someone without formal engineering education . It can help either one to gain a toehold in an industry that badly needs more capable and proven people . With no degree and no documented skills , it 's difficult for entry-level people to show what they 're capable of . In these situations , a vendor-specific certification can open doors that might otherwise stay closed . <p> For mid-career @ @ @ @ @ @ @ @ @ @ skills that may be of greater value to an employer . Having an engineering degree from the 1970s , twenty years of solid engineering jobs , and a new certification in programming Texas Instruments ' DSPs demonstrates a compelling mix of both experience and the willingness to learn new technologies . <p> As a career alternative , however , pursuing certifications is a Hobson 's choice . Vendor-oriented certification tends to focus on how to implement that vendor 's technology , rather than providing any sort of context around the technology . In the short run , this may pay off , allowing a vendor-certified engineer to ride a popular product to a superb new job . <p> But over the course of a career , it could be far more damaging than helpful . Hot products and vendors that produce them tend to decline over time , and the career of an engineer counting on product-specific expertise may decline along with them . That 's exactly what happened to Novell CNEs in the mid-1990s . It was at this time that NetWare ceased to be the universal standard in @ @ @ @ @ @ @ @ @ @ exclusively in that technology saw their careers grind to a halt . <p> It gets worse . Those trained only in a vendor-specific technology may be less capable of evaluating alternative approaches to a problem . An engineer with Cisco-specific implementation training would understandably be reluctant to recommend a competitor 's switching model . This holds true even when there are clear technical merits in the alternative . <p> This does both the engineer and the employer a large disservice . The engineer fails in the task of engineering , which not only includes making a given solution work , but also analyzing the value of the solution to begin with . The employer loses the benefit of that analysis , and in doing so , perhaps implements an improper or at best sub-optimal solution . <p> This is one place where an old-fashioned college education , despite the time and money required , still has a significant advantage over the fast and focused vendor certification . Today , college computing labs and individual courses are encouraged and even sponsored by commercial vendors . Ironically , there 's usually little @ @ @ @ @ @ @ @ @ @ Instead , the technology is a learning tool used to explore broader technical concepts . <p> That 's not to say that a college education is an absolute requirement for career success in engineering . But college is a venue that attempts to answer the question " why " rather than " how . " The how of a technology changes swiftly and sometimes drastically . Why , on the other hand , remains largely bound by the natural laws of physics and engineering , and changes less rapidly . <p> That 's why ( no pun intended ) we tend to complete our college experience early in our careers , with exceptions for graduate degrees or learning newly developed techniques . Once we have mastered the basic principles of science and engineering , as well as a few generic techniques , we 've established a right to be in the engineering profession . <p> Since we 're not yet trained , we 're pretty much useless right out of college . Employers want us to be able to answer the question " how . " The " why " @ @ @ @ @ @ @ @ @ @ expected to know so that we can respond to a subsequent " how . " We can either figure out how to work with a specific product or technology , or we can get a certification in it . <p> Still , the " why " is part of our lifelong career baggage . We can learn how to do something without necessarily understanding it . But if we understand it , we can adapt to new and different situations . A vendor-specific certification program trains within a single set of technologies . It 's useful in the immediate sense , but less so in the broader context . In short , training through certification addresses an immediate symptom , while education gets to the root cause . <p> Where Certification Fits In None of this is meant to disparage vendor-specific certifications as one component of a career plan . Over the short term , certification in a vendor 's successful product line could mean a substantial increase in salary and responsibility . This may also add new skills to an already-established career . But this advantage lasts a few @ @ @ @ @ @ @ @ @ @ short cuts to a high-paying , long-lasting career . Furthermore , even if a certification may open the door to new and challenging work , it does n't automatically enable you to do that work . You still have to perform , day in and day out , often doing tasks that bear little relation to the subject of the certification . <p> Given all of this , where do vendor-specific certifications fit into the engineering profession ? Such certifications are n't a foundation upon which to build a career . They 're too brittle , and highly dependent upon the whims of the market as well as of a specific vendor . Anyone who summarizes their total expertise as being an MCSE , for example , risks that expertise in performing any task that is n't related to the MCSE training subject matter . <p> For most , the formal engineering education , obtained at a college or university , remains the foundation of a career . With a sufficiently broad and comprehensive education , an engineer should be able to integrate virtually any new product or technique into @ @ @ @ @ @ @ @ @ @ education rarely teaches an engineer how to perform a particular duty with a specific commercial product . The tasks we accomplish during college labs are typically trivial and artificial . They 're nothing like the complex assignments we take on as working engineers . Usually , the most difficult tasks revolve around a vendor 's popular new product . An engineer has two choices at this point " either figure the problem out independently , or take a workshop or short course on the topic ( usually vendor-sponsored ) . If offered , a certification in that product may be a logical next step . <p> So it 's not so difficult to balance the goals of a formal education with a quick certification . Be well educated . Understand your profession and the broad technical concepts and limits . Find the important technologies and products in the area that interests you most . They 'll change from year to year , both because of market forces and your personal preferences . <p> Use your interests and new engineering projects as opportunities to pick up new product-oriented skills . If @ @ @ @ @ @ @ @ @ @ be a career advantage for you , consider taking the certification . Insofar as it helps you succeed in a current or future job , so much the better . But within a few years at most , it will be replaced by a hot new vendor and product . Be prepared to jettison the old certification and fall back on your engineering education and experience until you get up to speed on new products . 
@@21004841 @1004841/ <h> Embedded Systems Will Make Cars More Aware Of Their Surroundings <p> Mercedes-Benz expects improvements across all fronts , from increased performance through engines with higher specific output to wireless communications , providing advanced consumer services . Overall , cars will be much more aware of their surroundings through the use of new sensors . This information will be processed by a network of embedded systems providing drivers with immediate feedback regarding critical information , like road hazards and engine performance . <p> We expect to achieve even lower emissions through a combination of new engine design ( cylinder head ) , as well as the use of improved electronics for engine management control . Our current S500 five-liter models are already ultra-low-emission vehicles with very low cold-start emissions . We expect our present very good emissions at the exhaust port , prior to the catalytic converter , to continue to improve . <p> Safety systems will keep improving with more anticipatory safety systems , such as collision-detection systems , becoming standard features . These kinds of changes will be based on advances in vision , radar , and @ @ @ @ @ @ @ @ @ @ technology . <p> Finally , intelligent maintenance will improve automobile life and reliability while reducing costs . For example , advanced monitoring systems will allow scheduling of oil changes based on details like engine operating conditions instead of simplistic three-month or 3000-mile rules . Advanced monitoring will notify drivers that service is needed sooner for heavy-duty driving and later if a vehicle sees light use . Likewise , many systems , such as braking and the transmission , are essentially sealed for life , requiring maintenance under rare conditions . <p> We expect future gains in transmissions through the use of continuously variable transmission ( CVT ) technology . In the past , a CVT was available from another vendor on a specific model , but it 's used in any car sold today . While a CVT requires sophisticated electronic controls , it delivers a smoother ride , improved engine efficiency , and lower emissions . <p> Hybrid systems will eventually be used , especially with electrical engines coming into play for low-speed operation . The time frame for these hybrid systems to emerge is still in a state @ @ @ @ @ @ @ @ @ @ available hybrid designs by 2005 . <p> Voice-recognition ( VR ) development will be critical . We were first with user-independent VR in our cell-phone system . VR will play an important part in future wireless and entertainment controls . We expect greater wireless bandwidth in cars , making new services available , like Internet access and travel planning . <p> Overall , cars for the 2005 model year will be more efficient , more reliable , and easier to maintain . They will also have more safety and wireless features that will be less expensive and more advanced than those in the current vehicles . 
@@21004843 @1004843/ <h> Thermocouple Thermometer Features A 1-mV/&amp;deg ; F Output <p> An inexpensive , battery-powered , **25;730;TOOLONG , thermocouple thermometer with an output of 1 mV/-F can be constructed using type-K thermocouple wire . Because type-K thermocouple wire has a relatively linear output characteristic , only an ice-point reference and a scaling factor are necessary to produce an output that can be measured with a digital meter . <p> By plotting the thermoelectric voltage versus temperature , it can be seen that the slope of the type-K thermocouple approaches a constant over a range of G0- to 500-F . The best straight-line fit between G40- to 500-F yields the equation : <p> Y= 0.226X G 0.707 <p> where Y is the thermoelectric voltage in millivolts and X is the temperature in degrees Fahrenheit . <p> Solving the equation for X and multiplying by 101 for the gain of the inverting amplifier , the following equation can be derived : <p> X= ( 101Y+71.4 ) / 22.8 <p> Therefore , by adding 71.4 mV to the thermoelectric voltage ( 101Y ) and dividing the summed voltages by 22.8 , 1-mV/-F output @ @ @ @ @ @ @ @ @ @ function by adding a cold-junctioncompensated voltage to the thermocouple ( LT1025 ) and amplifying the output by 101 ( MAX430 ) ( see the figure ) . Then 71.4 mV is added ( via the LM336 and associated circuitry ) to the amplified signal and the voltages are summed together in the summing amplifier ( LF356 ) . Finally , the output voltage is divided using a 15-turn , 10k potentiometer . <p> This method takes into account the small thermocouple voltages generated wherever dissimilar materials are joined together . They can be generated where the thermocouples are soldered to the circuit board , or can even occur at the junction between the IC package and sockets . <p> The circuit was optimized to measure temperatures from G40- to 500-F , although higher temperatures up to 1800-F can be measured with lower accuracy . The circuit is ideal for many HVAC , automotive , or laboratory applications . 
@@21004844 @1004844/ <h> Display Technologies Get Ready For The Challenges Of The Wireless Age <p> Those who are curious about the future of display technology in communications may wish that they had access to that most ancient wireless display device : the crystal ball . This approach , however , has a number of drawbacks . While simple in construction , the spherical glass communicator with the hands-on user interface is tough to operate , typically requiring a trained specialist . Its use is further limited by a non-standard , poorly documented video interface that 's only compatible with a poorly understood and unreliable communications " medium . " <p> Even when reception is steady , image quality can be limited by low resolution and distortion caused by curvature of the glass . Image size , brightness , and viewing angle also may be restricted , because users are forced to hover over the display . Advocates might point out that the device 's very low power consumption makes it a candidate for some portable applications . Unfortunately , its fragility , weight , size , and odd form factor automatically @ @ @ @ @ @ @ @ @ @ communications products . <p> Luckily , there are alternatives to the crystal ball . Current market trends give us some indications of the display performance levels that will be required a few years from now . As a starting point , consider cellular phones . According to David Mentley of Stanford Resources , San Jose , Calif. , the cell-phone industry can be expected to generate $2 billion in revenue by 2003 . Given the size of this market , its products will clearly drive much of the development of portable-display technology . <p> Existing requirements for these products ' displays will either remain or grow more stringent . Designers will aim for smaller size , lighter weight , lower power , less cost , better readability in variable ambient lighting , and greater durability . Take power , for example . An existing paradigm for mobile phones is that they must provide eight hours of operating time and 24 hours of standby time on a single battery charge . But manufacturers are pushing to raise these numbers through the development of better batteries and more power-efficient designs . <p> @ @ @ @ @ @ @ @ @ @ , such as Li-ion , Li-polymer , and Li-S , will produce higher energy densities.While some of this additional energy will probably go to increasing operating time , it also will give designers the option of switching from monochrome to the more power-hungry color displays . Of course , display vendors will be working to reduce this power penalty by developing more efficient LCD and alternative technologies . <p> The demand level for displays that can deliver high information content is going to depend largely on the pace of development in wireless networks . Today , those networks typically provide data communications at 14.4 kbits/s , which limits them to tasks like downloading e-mail and text-only web sites . Such applications can be handled by the low-resolution LCDs currently found in portable cell phones and wireless-enabled PDAs . But as wireless service providers upgrade their networks to third-generation standards , data rates will rise into the range of hundreds of kbits/s and beyond , allowing transmission of color graphics and video . <p> For wireless phones and other handheld information products , the need for color graphics and video will @ @ @ @ @ @ @ @ @ @ The Gartner Group , Stamford , Conn. , states that by 2004 , 70% of new cell phones and 40% of new PDAs will use wireless technology for direct access to web content and enterprise networks . Increases in the bandwidth available for such data connections will move us beyond text-based web access , to the live-action color graphics we 've grown accustomed to on our desktop and notebook PCs . <p> Indeed , expectations for portable devices have been raised substantially by the quality of images produced by the active-matrix LCDs ( AMLCDs ) found in our notebooks . Factor in the emergence of communications products with built-in digital cameras for transmitting still or moving images , and those low-resolution monochrome displays run out of steam . <p> A transition to 800- by 600-pixel SVGA looms ahead , as this is the standard specified by Windows that also accommodates both NTSC and PAL video . To save power , though , some applications will likely opt for lower resolution , such as quarter VGA . <p> Jumping up to SVGA will require a move away from the direct-view LCDs @ @ @ @ @ @ @ @ @ @ displays are generally monochrome passive-matrix LCDs with 1- to 2-in. maximum diagonal measurements and resolutions in the neighborhood of 60 by 90 or 120 by 90 pixels . For handheld organizers or PDAs , which are making inroads as communications devices for e-mail , the displays tend to run a bit larger . They go up to about 3.9 in. with quarter-VGA ( 320 by 240 ) resolution . In certain cases , vendors have begun opting for the more expensive , **26;757;TOOLONG AMLCDs to obtain color . But in doing so , they will sacrifice some battery life . <p> Even though these direct-view LCDs are ill-equipped to handle heavy graphics and video , they probably wo n't disappear anytime soon . Improvements in their design will produce thinner and lighter displays , with lower power and greater brightness and contrast . Sharp Microelectronics has gone into production with a **25;785;TOOLONG display . It is said to produce thinner , lighter , and more reliable displays than those fabricated with the usual liquid-crystal-on-glass . In the future , such an approach may foster the creation of cell phones that @ @ @ @ @ @ @ @ @ @ toward thin-film-transistor ( TFT ) AMLCDs will continue as demand for color grows . Supporting this trend will be the ongoing development of low-temperature polysilicon TFTs as an alternative to amorphous-silicon TFTs . Building the transistor array in polysilicon allows the integration of peripheral circuits , such as drivers , on the display 's substrate . Ongoing efforts to reduce power also will help , as manufacturers push to improve on liquid-crystal performance and develop more efficient drivers . They will also work to reduce losses in the transistor array and incorporate more efficient backlighting . <p> A more radical change will be the growth of microdisplays . When viewed under magnification , these 1.5-in. or smaller devices can produce an SVGA or higher-resolution image . That 's while consuming a fraction of the power of an equivalent but physically larger TFT display . In portable applications , the display is magnified by a viewfinder that 's either housed in a headset or handheld unit " perhaps embedded in the communications device . A virtual image is created that appears recessed in the viewfinder . <p> Say you 're watching @ @ @ @ @ @ @ @ @ @ the effect of watching a 15-in. display at a distance of 12 in. from the eye . Optics will play a key role in determining the success of these devices , because they 'll affect image quality and the comfort of the user . The microdisplay will probably be an add-on or plug-in accessory for cell phones and other mobile products , which will still offer direct-view screens for dialing , messaging , and other tasks . <p> LCOS For Microdisplays At present , different technologies are vying for the emerging microdisplay market . **25;812;TOOLONG ( LCOS ) appears to have the edge , with actual products currently available ( Fig. 1 ) . Two methods are used to fabricate LCOS : polysilicon , which is an extension of traditional AMLCD technology ; and single-crystal silicon , also known as silicon-on-insulator ( SOI ) . The former approach is popular with Japanese display companies , while single-crystal silicon is favored by U.S. manufacturers . <p> Transistors made in single-crystal LCOS can be made smaller , allowing denser packing of pixels . This , in turn , leads to smaller displays @ @ @ @ @ @ @ @ @ @ for field-sequential operation , a method whereby a color image is produced by strobing one set of pixels with red , green , and blue light . Polysilicon is too slow for this operation , so its displays resort to the use of subpixels covered with red , green , and blue filters . This ultimately lowers spatial resolution . <p> Graphics output usually is in spatial RGB format , so an ASIC is required to convert this data into the field-sequential format . In time , OEMs will most likely incorporate this function into their graphics controllers , which will free up some board space and save on cost and power . <p> On the other hand , display vendors might choose to integrate the field-sequential conversion function into their silicon . Part of the attraction of single-crystal LCOS is that it provides a path for integration . The silicon in LCOS could be standard CMOS in a 0.5- or 0.35--m process . They might be putting drivers on the display silicon now , but expect other functions to be incorporated into the display in the near future . @ @ @ @ @ @ @ @ @ @ and color tables . <p> LCOS also holds promise because as silicon design rules shrink , the display can be made smaller . Voltages and power also can be reduced . But concerns remain about production yields , which must be improved to make LCOS feasible . The timing of this progress is critical , as it faces competition from technologies like organic light-emitting-diode ( OLED ) displays . <p> As their name implies , OLEDs are emissive-style displays , so they do n't require backlighting . In one design approach , the basic OLED cell contains a series of carbon-based ( organic ) layers stacked in between a transparent anode and a metallic cathode . Within the stack are a hole-injection layer , a hole-transport layer , an emissive layer , and an electron-transport layer . <p> Applying a few volts to the OLED cell causes positive and negative charges to recombine in the emissive layer , which then generates light . By doping the emissive layer with fluorescent molecules , the designer allows the cells to produce color output . These cells can form into both passive-matrix and @ @ @ @ @ @ @ @ @ @ using polysilicon TFTs . <p> OLEDs have been gaining attention because they offer several advantages over conventional LCDs . They sport much wider viewing angles , going as high as 160- . The displays also feature greater brightness and contrast , more uniform light output , lower power consumption , and thinner packaging . <p> OLEDs Show Potential The first applications of OLEDs were passive-matrix displays for car audio equipment . More recently , Eastman Kodak Co. and Sanyo Electric Co. introduced a full-color , active-matrix model that hints toward the OLEDs ' greater potential . This 2.5-in. display with quarter-VGA resolution is a mere 1.8-mm thick , compared to 6 or 7 mm for an equivalent LCD ( Fig. 2 ) . While a backlit AMLCD would devour 800 mW of power , the OLED 's power consumption is approximately 300 mW . <p> The plans at Kodak call for the development of bigger displays with higher resolution , including a 5.5-in. version with VGA resolution . Like some of its LCD counterparts , the 2.5-in . OLED display was built using low-temperature polysilicon that permitted the integration of @ @ @ @ @ @ @ @ @ @ and DSP functions may be incorporated . <p> Kodak 's display should be in production somewhere around 2001 . This will provide some interesting competition for the more traditional direct-view AMLCDs . <p> The structure of the OLED actually makes microdisplays a possibility , as well . Because the OLED is an emissive device , the display aperture factor is n't significant like it is in LCDs , which modulate light from an external source by passing it through an aperture . As a result , pixel count , resolution , and size can be scaled down to produce microdisplays . Treading down this path is FED Corp. , which has a 0.78-in. diagonal display in development that offers 256-level gray-scale and SXGA resolution . The company 's roadmap calls for even further development of XGA and SVGA versions . <p> According to Gary Jones of FED Corp. , an OLED microdisplay will have advantages over LCOS for applications like cell phones that would employ a microviewer or headset . With an OLED display , the microviewer would n't need to be held as precisely to see the complete image @ @ @ @ @ @ @ @ @ @ smaller and cheaper optics . OLED is n't strobed like LCOS , so its display would n't suffer any color separation when vibrations are present , such as when the viewer is riding in a car or train . Lower power is another advantage for OLED over LCOS . <p> For now , though , LCOS microdisplays appear to be ahead in the race to bring high information content to the portable world . It remains to be seen how LCOS and OLED technology will fare against each other in the microdisplay arena and versus the steadily improving direct-view AMLCDs . The final outcome will put a new face on cell phones , PDAs , and other handheld communications devices . It also will change the ways that we interact with one another via the wireless world . 
@@21004846 @1004846/ <h> Numbers for Sale : A Different Kind of Standard <p> Networked devices make the world go round ( and you thought it was love ) . Millions of devices connected to each other via standards such as Ethernet and Wi-Fi drive modern communication . But there 's more to the network than just devices and standards . Each device , in order to communicate with the rest , must have its own unique designation . This designation is known as a Media Access Control Address , or MAC address . Your laptop has a MAC address , as does your smartphone , and every server in a data center . The MAC address , built into the device 's network card , is n't of any concern for most people . <p> When you look deeper , though , MAC addresses can be quite interesting . Start with this : Imagine if all manufacturers made up their own addresses for each individual network card and simply hoped that other manufacturers would n't use the same ones . The result would be a chaotic mess of numbers and characters @ @ @ @ @ @ @ @ @ @ to identify each other , making any type of network impossible . <p> There must be a standard to bring order to the chaos . This is a different kind of standard than a file format or API , such as the standards used for electronic design , but it 's no less critical for building networkable electronic products . All manufacturers use an existing standard numbering scheme to uniquely identify each network card they produce . <p> If you assume that some higher authority passes out the address numbers and oversees this process to minimize errors and cheating , then you are correct . That higher authority , which manages the standard and distributes numbers , is called a Registration Authority . You might be surprised to learn that the IEEE Standards Association is responsible for assigning MAC addresses through its IEEE-SA Registration Authority Committee ( RAC ) . <p> Simply defined , a Registration Authority is an agency that 's responsible for issuing , controlling , and maintaining lists of codes under international standards . In a broad sense , authority control keeps society organized . We live @ @ @ @ @ @ @ @ @ @ International Standard Book Numbers ( ISBNs ) , social-security numbers , motor vehicle registration , telephone numbers , Universal Product Codes ( UPCs ) , and passport numbers . Each allows for unique identification of an object , location , or person by virtue of some type of code . <p> For objects , the code can be an Object Identifier ( OID ) . The specific definition of the OID standard comes from the joint efforts of the International Organization for Standardization ( ISO ) , International Electrotechnical Commission ( IEC ) , and International Telecommunication Union ( ITU-T ) , and is known as ASN.1 . <p> For MAC addresses of network cards , the OID comes in the form of an Organizationally Unique Identifier ( OUI ) plus a Company Identifier ( CID ) . The OUI represents the manufacturer , and the CID is the serial number of the network card . MAC address formats comprise six octets ( hexadecimal ) " three for the OUI and three for the CID . In human-readable form , it looks like : <p> MM:MM:MM:SS:SS:SS <p> OUIs obtained from @ @ @ @ @ @ @ @ @ @ device addresses in addition to MAC addresses . As examples , Xerox was assigned the OUI , 00-00-00 , and Hitachi was assigned FC-FE-77 . The list of OUIs , maintained by the IEEE-SA 's Registration Authority Committee , is updated daily on its public website . Vendors can opt to make their OUIs private , so finding out who owns the MAC address of your device could be futile . <p> To be effective , the IEEE-SA 's Registration Authority " or any Registration Authority for that matter " it must meet certain requirements . First and foremost , the Authority must be widely accepted as a trusted authority . It has to be meticulous in its processes , controls , and maintenance . In addition , excellent customer service and long-term continuity is mandatory . <p> Because a Registration Authority needs funding to ensure continued , quality operations , it sells the numbers it assigns . The price ca n't be too high , though . In fact , it should be sufficiently inexpensive so that it 's attractive to everyone , and to discourage cheating or a @ @ @ @ @ @ @ @ @ @ devices are being manufactured and sold , a Registration Authority must never run out of numbers for sale ! <p> The IEEE-SA 's Registration Authority Committee reports to the IEEE Standards Association 's Board of Governors , the highest governance body of the IEEE Standards Association . The RAC consists of up to 21 volunteer members ( although usually less than 10 ) , along with at least one member of the IEEE-SA 's professional staff . The RAC is responsible for assigning , reporting , and maintaining its international OUI registry . It also administers other types of unique identifiers beyond the scope of this article . RAC members are dedicated experts who understand not only the technical requirements of the OID standard , but also the market conditions at play in an ever-evolving world of networks and devices . <p> If you are one of the special individuals that find this kind of standard fascinating , there is a Registration Authority , such as IEEE 's RAC , waiting for you to join , helping ensure order and effectiveness in the critical field of networking . 
@@21004847 @1004847/ <h> Gear Motors Feature 500 in. -lbs . Of Torque <p> The VWDIR104 AC gear motors are available in four versions with either 1/10- or 1/15-hp ( 74.5- or 49.2-W ) , 115/230-V , 60/50-Hz permanent split-capacitor motors . The new devices bring to 79 the company 's line of Von Weise drop-in replacement motors . For efficiency and durability , the compact , integral gear reducers feature hardened steel helical and spur gearing with ratios ranging from 108:1 to 266:1 . Corresponding fixed output speeds are from 15 to 6 rpm , with continuous torque ratings from 340 to 500 in-lbs ( 38.4 to 56.5 N-m ) . The gear motors feature built-in face mounting that is compatible with Genesis mounts and overhung load ( OHL ) capability up to 400 lbs . ( 181.8 kg ) . The motors are designed for high-torque , single-phase commercial , industrial , and agricultural applications such as in food service , office , and medical equipment , as well as a wide variety of conveying equipment . BISON GEAR &amp; ENGINEERING CORP. , St. Charles , IL . ( 800 ) 282-4766. 
@@21004849 @1004849/ <h> The Move to Higher Levels of Abstraction <p> Shiv Tasker Aug 21 , 2006 <p> Let 's just assume that after adding communications costs and management overhead , the cost to move offshore to a low-cost country is half of the cost of having engineers in a high-cost location . This would argue that , given adequate availability of talent , a productivity improvement of 2x would obviate the need for off shoring . <p> Unfortunately , the electronics industry has locked itself into a mindset that hardware design today takes as long as it has always taken . And , in the face of growing complexity of the circuits being designed , even accounting for sourcing off-the-shelf IP , it is going to take more engineers , more time , and a bigger budget to get future chips designed , verified , and fabricated . <p> There has only ever been one real answer to growing complexity , and that is to raise the level of abstraction . Software went through its successive generations of languages , from assembly to Fortran to C/C++ , Java , and @ @ @ @ @ @ @ @ @ @ the register transfer level ( RTL ) of design for over 15 years . <p> Several attempts have been made to raise the level of abstraction . Most of them failed . Conventional wisdom rests those failures at the feet of tools such as Behavioral Compiler . I believe that the root cause was an inadequate deconstruction of the challenges of hardware design and an incorrect assessment of the root cause . <p> Using a taxonomy outlined by Martin et al , a hardware program describes concurrency , communications , structure , and resources . Most errors caused in describing structure and resources can be quickly identified and rapidly corrected . Some of them stem from inadequate language constructs in Verilog " lack of structures and unions , for example , though VHDL did not suffer from these inadequacies . Other ambiguous language semantics allowed tool developers latitude in implementation , such as blocking versus non-blocking assignments and arbitrary processing order . <p> The real bugs are in complex race conditions with shared resources . These are hard to find , consume enormous verification cycles to flush out , and @ @ @ @ @ @ @ @ @ @ is a killer . If we could abstract concurrency , especially in circuits dominated by complex datapaths or control logic , we have a chance of making dramatic improvements in time , cost and quality of circuits . <p> Unfolding nested loops in a **25;839;TOOLONG algorithm is a fairly straightforward process to create a data pipeline . Companies are beginning to report some success in taking such sequential programs and transforming them to hardware . Control logic is a much tougher problem and requires out-of-the-box thinking to abstract upwards . <p> The solution may lie in a software technique called Term Rewriting Systems ( TRS ) , which are rule based . The formal semantics that underlie a TRS deliver predictability and transparency . Their biggest benefit may lie not just within a module , but also in composing designs where each module is self-documenting and can assemble itself with other modules , automatically creating the controlling interface logic required for the parts to function smoothly together . <p> Formal semantics around interfaces may also benefit hardware/software co-design and co-verification . By designing a module harness while leaving out details @ @ @ @ @ @ @ @ @ @ with a design structure that can be resilient to change and robust to alternate implementations . <p> The question then becomes : Are U.S. and European engineers ready and willing to explore new tools and methodologies to improve their productivity and make level the playing field ? Or will the offshore engineers move more aggressively to adopt these ESL techniques so that they are not only cheaper , but also faster and better ? 
@@21004853 @1004853/ <p> All companies in the transportation sector strive to provide safe , economical , and comfortable transportation for passengers and cargo . To accomplish this goal , vehicle manufacturers are increasingly turning to semiconductor-based solutions to make cars , planes , and trains more fuel efficient , safer , and even more comfortable along the route . <p> Semiconductor content in cars already ex-ceeds several hundred dollars . Over the next few years , that figure promises to double as more systems get assists from improved power devices , sensors , digital ICs , and displays . <p> Even though every transportation sector is lev-eraging semiconductor advances , the automotive market is the most visible sector in which we see how the ad-vances supply direct benefits to the vehicle and subsystem manufacturers . Additionally , we directly witness the result of adopting many features on the car , whether it 's the linking of the cell phone and global positioning system to offer a location in case of an emergency , or control circuits to prevent engine knock , or digital radio broadcasts . <p> The scope of silicon @ @ @ @ @ @ @ @ @ @ Technology Forecast article package could n't cover it all . This year , our Technology Forecast examining Silicon In Motion will be split into two sections . The first appears in this issue . The second part will come out on January 22 . <p> Here , we examine four main themes in staff-written reports : Command and Control Systems , Sensors and Actuators , Electric and Hybrid Vehicles , and Telematics and Smart Highways . Each of these areas brings into play many different technologies and component developments that continue to push the envelope for performance and reliability , while also maintaining a bead on low cost . <p> In the second issue , we will provide two additional reports . One will focus on the entertainment and comfort features that vehicle manufacturers are adding to improve the transportation experience . The other will feature the advances in ruggedized surface-mount IC packaging needed to handle the rugged , wide-temperature-range environments the vehicles must endure . <p> Both report packages will be complemented by a series of interviews with key engineering executives . These executives are directing the design of @ @ @ @ @ @ @ @ @ @ transportation system companies as well as at some of the companies supplying the key technology building blocks for next-generation cars and other vehicles . <p> Leading off this issue , Embedded Technologies/Software Technology Editor Bill Wong examines advances in embedded processors , system architectures , and system control buses presently under development for next-generation vehicle engine and drive-train control . In order to perform the control , the systems must be able to sense conditions and actuate valves , gears , and other parts . Analog , Power Devices &amp; DSP Technology Editor Ashok Bindra then explores advances in sensor , micromachining , and actuator technologies . <p> Making vehicles run more efficiently to achieve better fuel economy and reduce pollutant emissions are only two aspects of what can be done to help keep our planet green while preserving some of our fossil-fuel supply . One approach is better engine control , as described by Bill Wong . <p> David Morrison , our Power , Packaging &amp; Components Technology Editor , along with Lisa Eccles , our Associate Editor , details the design of electric and combination electric/gas ( hybrid @ @ @ @ @ @ @ @ @ @ currently achieve about double the fuel economy of gas-only powered cars , with little or no effect on performance . This part of the forecast looks at the new battery , battery charging , and motor/motor-control technologies coming to bear . <p> The last report in this issue examines the ability to add intelligence into the vehicles and along the pathways on which they travel . Future scenarios project that we will be able to enter a car and describe our desired destination , and it will then compute the best route and automatically take us there . Although we 're still a long way from that dream situation , global-positioning systems , on-board computers , radar-controlled braking systems , electronic toll systems , and many other features are now possible . These give us the basic technology that will eventually make the hands-free car a possibility . Our Communications and Networking Technology Editor , Louis Frenzel , explores this entire field of what the industry calls " Telematics . " <p> To complement these in-depth articles , we have included interviews with key executives at several automobile , automotive @ @ @ @ @ @ @ @ @ @ and Boeing " to get their views regarding what the industry must do in different segments to move forward . These commentaries reveal some excellent additional perspectives on the future of transportation systems . <p> In Part II of our Technology Forecast , our Convergence Technologies Editor , Steve Grossman , will delve into what companies are doing to keep passengers entertained . His report will illustrate developments in music , digital broadcast radio , in-vehicle video , and other aspects that help make the ride more comfortable . <p> In the second report of that issue , David Morrison will provide an in-depth view of forthcoming advances in packaging and surface-mount technologies . These technologies will help the next generation of power devices and digital circuits to better meet the demanding environmental conditions faced by silicon devices in the vehicle . <p> Complementing these reports will be interviews with top executives at some major component and subsystem manufacturers that supply the key building blocks to the companies manufacturing the cars , planes , and other vehicles . Included in this list are Delphi Automotive Systems , Lear Corp. , @ @ @ @ @ @ @ @ @ @ hope that you find the subjects we selected as fascinating and as important as we felt they were while we did our research . Although these technologies may first be applied to transportation products , many of them might migrate from one application area to another as you find new ways to apply the technology . 
@@21004855 @1004855/ <h> Chopper-Stabilized Op Amps <p> What is a chopper-stabilized operational amplifier ( op amp ) ? Chopper-stabilized amps constantly correct low-frequency errors across the inputs of the amplifier . This makes them attractive alternatives to conventional op amps in many industrial , medical , energy , and automotive applications to simplify and accelerate the design process . When designing with chopper-stabilized op amps , you do not need to be concerned about compensating for low-frequency errors such as input offset voltage , input bias current , temperature drift , or pink ( 1/f ) noise . Recent developments in process technologies and circuit design have overcome previous limitations that discouraged their use . <p> How significant are the offset and noise advantages of the latest chopper- stabilized op amps ? Where you might see 2 mV of offset error in a conventional amp , which might be corrected to 100 V with internal trim-resistor offset-correction , a chopper- stabilized amp may have a maximum input offset as low as 8 V. Similarly , accuracy over temperature may be as low as 0.02 V/C , across the 40C to 125C @ @ @ @ @ @ @ @ @ @ , or half that with trim-resistor correction . <p> What 's the problem with 1/f noise in typical designs ? Its most often a problem in high-precision industrial , automotive , and medical applications . Typical op-amp 1/f noise is greatest right in the area of the sensor bandwidth , limiting possible analog-todigital converter ( ADC ) resolution . This dc noise can contribute to noise gain errors , affecting the overall accuracy of the output signal in particular for sensor applications requiring high gain . <p> What applications can best use chopper op amps ? Chopper op amps are generally used in industrial and instrumentation applications , especially when low operating power is also a requirement . Coupled with a suitable ADC , reliable performance with up to 24-bit precision is achievable . A typical application might be a chopper-stabilized op amp used as a buffer precision voltage ( or current ) source , as a front-end gain amplifier in a sensor application , or in both roles . <p> In such an application , the output of the pressure sensing bridge is digitized using a high-precision 24-bit sigma-delta ADC @ @ @ @ @ @ @ @ @ @ of a highend sigma-delta ADC often needs to be buffered to prevent it interfering with the sensor performance . <p> A chopper-stabilized amp is attractive for use as that buffer because as conventional instrumentation topologies can not meet the noise , voltage offset ( VOS ) , or drift specs required . Moreover , a voltage reference by itself typically wont drive a pressure-sensor bridge . Its output must be buffered to guarantee that the active voltage to the bridge sensor is stable over temperature and time . <p> Some of the latest chopper amps also operate across a wide voltage range ( 1.65 to 5.5 V ) and draw as little as 25 A of quiescent power , making them attractive for battery-powered instrumentation and handheld medical diagnostic devices , wireless sensors , and energy harvesting applications . <p> How does chopper stabilization work ? Classical chopper ( not chopper-stabilized ) amplifiers modulated the input signal with a square wave before it was processed by the main amplifier , and they demodulated the signal at the output . Consequently , the signal transfer function was ideally unchanged , Meanwhile @ @ @ @ @ @ @ @ @ @ , being subject only to one modulation , were transformed into errors at the modulation frequency . Assuming that this was sufficiently high , they could then be filtered out by subsequent stages . <p> A chopper-stabilized amplifier is actually two amplification paths in parallel ( see the figure ) . A high-accuracy , low-frequency path ( A2 ) incorporates high gain and chopping , while high-frequency signals are amplified by the parallel wideband amplifier A1 . <p> The outputs of both stages are subtracted in a summer amplifier , whose output is fed back to the inputs of both amplifiers through a feedback resistor . In the case of the non-switched wideband amplifier A1 , it is fed back to the inverting input in classic gain-setting fashion . In the case of the low-frequency chopped amplifier A2 , the feedback signal is connected to one pole of a double-pole , double-throw ( DPDT ) switch on the die . <p> The other pole of that switch is connected to the signal input , which is also applied to the non-inverting input of A1 . A second DPDT switch on @ @ @ @ @ @ @ @ @ @ the front-end DPDT . A low-pass filter circuit gets rid of the high-frequency chopping noise and applies the output of A2 to the summing node . Connecting the inputs of A1 and A2 together allows the chopping in A2 to remove the low-frequency errors from both A1 and A2 . <p> Why the switches ? The switches implement the modulation , causing the input to be multiplied by a square wave at the chopping frequency . <p> What differentiates chopper-stabilized amplifiers from various suppliers ? The presence of chopping artifacts provides differentiation . The basic ideas of how to remove chopping artifacts such as ripple at the chopping frequency have been around since the days of vacuum tubes , but the current techniques are closely guarded secrets that are constantly being refined . 
@@21004856 @1004856/ <h> Eliminate RTD Self-Heating Errors <p> Mark Murphy Mar 05 , 2000 <p> Synchronous detection , long used in telecommunications because of performance potential , can now be effectively applied to sensor interface circuitry due to advances in low-cost ICs . This circuit ( see the figure ) employs a synchronous-detection scheme to measure the resistance of RTDs ( resistance-temperature detectors ) with self-heating errors of less than 0.001-C . <p> Waiting for the system to settle is pointless , because a self-heating-induced gain error remains . Drift errors can also be caused when the medium measured changes flow rate . This will cause a variation in the chill effect , which in turn will change + " T. <p> In the synchronous technique , the RTD is excited by a 1-kHz ac waveform . The RTD 's varying resistance then modulates this sine-wave carrier . The modulated waveform , which conveys information about the RTD value and hence sensed temperature , is demodulated using the same ac waveform as its reference . Because the demodulation process employs the same reference , uncorrelated perturbations like noise , offset , @ @ @ @ @ @ @ @ @ @ caused by RTD modulation . In this application , the frequency stability and distortion of the nominal 1-kHz carrier are n't critical , because the same waveform is used for modulation and demodulation . <p> The circuit in the figure uses a 100--A peak alternating current through the RTD to create an alternating voltage across it that 's proportional to temperature . IC1b ( half of an AD706 precision op amp ) supplies a reference voltage so that at some reference temperature , RT1 may be trimmed to yield a zero differential input voltage to the instrumentation amplifier , IC2 ( an AD620 ) . IC2 amplifies this differential voltage and RG sets the gain of the instrumentation amplifier to 408 . The output of IC2 is then demodulated with a synchronous detector IC , IC3 . IC3 's output is low-pass filtered , removing all uncorrelated disturbances , such as noise , offset , and drift , while retaining a dc voltage that 's proportional to the change in resistance of the RTD from its nominal value . IC4 ( a precision operational amplifier ) provides a noninverting gain @ @ @ @ @ @ @ @ @ @ gain accuracy . <p> The relationship between the RTD 's resistance and the output voltage is then : <p> When eliminating errors due to self-heating effects in RTD applications , the circuit shown in the updated figure is an enhanced version of the one in the original Idea For Design . Both solutions use a similar technique . The new circuit provides a digital-output representation of the temperature , however , while the original design offers an analog output that 's proportional to temperature . <p> Typically , a digital output is more beneficial in terms of further processing to drive LCDs , for example , in conveying the measured value to the end user . The new circuit is a more integrated solution . It removes the majority of the signal conditioning previously required . This allows implementation on a smaller board area , and removes issues associated with noise and layout in systems that use many signal-conditioning components . <p> In temperature-measurement applications , dc excitation has generally been accepted as the normal method of exciting RTDs . The excitation current through the sensor must be large enough @ @ @ @ @ @ @ @ @ @ in a voltage change that 's larger than the system 's noise , offset , and drift . The excitation currents required to overcome these errors are usually 1 mA or greater . <p> Also eliminated with ac excitation are the errors that arise from parasitic thermocouples produced by differential metal connections ( solder and copper track ) within the circuit . The ac excitation is a form of synchronous detection in which the sensor is excited with an alternating excitation source . The analog-to-digital converter ( ADC ) then measures information in the same phase as that excitation source . <p> In the updated circuit , an AD7730 high-resolution sigma-delta converter is used for the ac-excited RTD measurement application . The converter is operated with split supplies , such that AVDD and DVDD are at separate potentials , as are AGND and DGND . The one stipulation with this arrangement is that AVDD or DVDD must not exceed the AGND by 5.5 V. <p> When operating with -2.5-V analog supplies , the DVDD must be restricted to +3 V with respect to digital ground . In the system , @ @ @ @ @ @ @ @ @ @ , the ACX output from the AD7730 controls the reversing of the current . That output is with respect to the AVDD and AGND supplies . When ACX is high , a current of 100 -A flows through the RTD in one direction . When it 's low , that same current flows in the opposite direction through the RTD . <p> The switched-polarity current source is developed using op amps U1 and U2 in a standard voltage-to-current configuration . The AD7730 is configured for its ac-excitation mode and produces a square wave at its ACX output . During the conversion process , the ADC takes two conversion results , one on each phase of the ACX signal . It combines these to produce one data-output word representing the measured temperature . <p> DC-Induced Errors Are Revoved Say the RTD output during phase one of the ACX signal is 10 mV and a 1-mV circuit-induced dc error exists due to parasitic thermocouples . The ADC then measures 11 mV . During the second phase , the excitation current is reversed and the ADC measures G10 mV from the RTD and @ @ @ @ @ @ @ @ @ @ of G9 mV . These measurements are processed within the ADC ( 11 mV G ( G9 mV ) /2= 10 mV ) , thereby removing the dc-induced errors within the system . The use of ac excitation permits currents in the region of 100 -A to be effectively used in RTD applications , reducing self-heating effects substantially . <p> In the circuit shown , the resistance measurement is made with a ratiometric technique . Resistor values in the voltage-to-current converter do n't affect system accuracy . As the exact value of the drive current is n't critical , a tolerance of around 1% is acceptable . So 100-ppm/-C resistors will suffice . Resistor RREF , which develops the ADC reference , must be stable over temperature to prevent reference-induced errors in the measurement output . <p> In this circuit , temperature ranges from G200- to +200-C can be easily accommodated . Because very little rejection is offered at the chopping frequency , it 's recommended that this frequency be selected at 57 Hz to provide rejection to both 50- and 60-Hz components . With that update rate of 57 @ @ @ @ @ @ @ @ @ @ using the AD7730 in its unipolar 0- to 20-mV range . With the AD7730L version used with the same operating conditions , peak-to-peak resolutions of 14.5 bits are achievable . <p> The AD7730 also offers RTD applications its immunity to both radiated electric fields and fast transient bursts ( EFT ) . In a noisy environment , it 's recommended to use it in chop mode . The chopper-stabilization techniques within the AD7730 eliminate offset and minimize offset drift . When the converter is operated in chop mode , the signal chain , including the first stage filter , is chopped . Overall drift performance drops to less than 5 nV/-C . <p> The AD7730 can be operated in the presence of electric fields ( 1 V/m to 3 V/m ) from 30 MHz to 1 GHz . The offset remains flat across the frequency range . If chopping is n't incorporated , the offset performance degrades in the presence of an electric field and drifts with frequency . The following are the key advantages that the updated circuit offers over the original : <p> The integrated solution contains an @ @ @ @ @ @ @ @ @ @ current source , and processing power to handle the results from the ac excitation . <p> The new circuit provides the analog-to-digital function with all of the processing performed within the ADC . The AD7730 gives a digital representation of the measured temperature . This result can be further processed using the system microcontroller to drive LCD readouts , etc . <p> A peak-to-peak resolution of 16 bits is achievable , creating a data-acquisition system with high resolution and accuracy . <p> Minimal signal conditioning is required , so issues related to pc-board layout , noise , and decoupling are greatly reduced . The board area required for circuit implementation is also substantially smaller . 
@@21004857 @1004857/ <h> Measure Projectile Velocity Optically With An Ohmmeter <p> Archery and target shooting with firearms and air guns are just a few of the many sports and pastimes that involve high-speed projectiles . A handy accessory for any of these activities is some means of accurately measuring the speed of the projectile ( e.g. , air gun pellet muzzle velocity ) . This enables the condition of the gun , bow , etc. , to be monitored , allowing optimum performance and accuracy to be maintained . <p> Commonly called chronographs , such devices are commercially offered at reasonable prices ( less than $100 ) . For some folks , though , the do-it-yourself approach maintains its perennial appeal . For this group , the circuit shown is offered as a cheap , simple , and functional alternative . <p> Like most electronic chronographs , this one works via optical detection of the passage of the projectile over two points separated by a known distance , D ( in this case , the five inches separating phototransistors Q1 and Q2 ) . The time-of-flight , T , between the @ @ @ @ @ @ @ @ @ @ average speed , S , of the projectile : S = D/T . <p> Optical detection of a projectile whizzing past a given point is not always trivial " especially for BBs and other small-caliber air gun pellets that may fill only a small fraction ( about 1% ) of the detector 's field of view . The logarithmic optical-detection method employed here is borrowed from an earlier IFD ( " Available-Light Phototachometer Simplifies Outdoor Remote Sensing , " Electronic Design , January 25 , 1999 ) and has a wide dynamic range compatible with low-contrast signals in both outdoor and indoor lighting . <p> Velocity measurement begins with the passage of the projectile over Q1 . The resulting partial occlusion of Q1 's view generates a negative pulse at A1 's noninverting input of about 500 -V for every 1% of light blocked . A1 and A4 boost and invert by 70 dB to produce a reset ( start ) pulse to the free-running 14-bit ripple counter U3 . Following the projectile 's passage , U3 resumes counting from zero , tallying the time of flight ( T ) @ @ @ @ @ @ @ @ @ @ the projectile reaches Q2 , generating a reset ( stop ) pulse to U2 , marking the end of the flight between detectors . This action results in the capture of a phase difference between the 244-Hz ( 4 MHz/16,384 ) square-wave outputs of free-running U3 and U2 equal to T. This phase difference will persist until detection of a subsequent TOF event . Therefore , until then , the TOF measurement remains available for readout . <p> The problems then remaining are : ( 1 ) conversion of this time measurement into the desired reciprocal velocity measurement , a process usually accomplished with software division via a microcontroller , and ( 2 ) provision for display of the calculated velocity . This is where that ohmmeter comes into play . 
@@21004867 @1004867/ <h> Smart Pill Goes On A Fantastic Voyage <p> In science fiction , doctors often shrink themselves to enter the human body and investigate mysterious illnesses . But SmartPill Corp . has a much easier solution in mind for the 3 million Americans who have gastrointestinal ( GI ) problems severe enough to require hospitalization " 34% of which have no known causes . The company simply shrank the tools doctors would use for diagnosis . <p> The system comprises the SmartPill pH.p capsule , a data receiver , a docking station , a SmartPill activation feature , the MotillGI software , and a laptop computer ( Fig. 1 ) . It combines capsule manometry and RF telemetry to communicate pH and pressure measurements for accurate , flexible , and simple diagnosis of GI tract disorders . <p> A key element of the system is a 13- by 26-mm sensorladen ingestible and disposable pill that enables measurements of GI tract pressure , pH , and transit time parameters . It let 's GI specialists view GI tract motility and quickly and accurately diagnose disorders like irritable bowel syndrome , inflammatory @ @ @ @ @ @ @ @ @ @ and polyps , and gastroesophegal reflux disorder . <p> The patient 's body does n't absorb the pill after it 's swallowed . The pill does n't interact with the GI tract either , except to be propelled via peristalsis when patients empty their bowels . The pill 's sensors transmit data to a receiver patients wear on a belt while they go about their daily activities . The data then is downloaded in the doctor 's office , via the docking station , to the computer for analysis . <p> " The SmartPill Monitoring system is the most accurate on the market , " says John R. Semler , chief technology officer of SmartPill Corp . " It compares very favorably with current diagnostic methods for measuring gastric emptying time . " <p> Unlike other GI diagnostic systems , this system allows for greater patient mobility , which in turn provides a more natural test environment . Patients can go about their normal daily activities without any restrictions while the pill goes to work . <p> Standard gastric emptying scintigraphy tests ( GESTs ) are n't very sensitive . @ @ @ @ @ @ @ @ @ @ symptoms . In comparison , the SmartPill Monitoring system features a sensitivity of 0.85 ( versus 0.69 for GESTs ) at T50 . ( T50 and T90 are two standard medical imaging tests . ) <p> IT 'S ALL IN THE PILL The pill 's microelectromechanical system ( MEMS ) sensors measure pressure , pH , and temperature . One of these sensors is an insulated-gate FET ( IsFET ) . The pill also contains temperature-compensation circuitry , a 16-bit analogtodigital converter ( ADC ) , a microprocessor , and a transmitter . Power control circuitry is included along with a 1.5-V silver-oxide battery . Data is transmitted from the pill over the industrial , scientific , and medical ( ISM ) band in a pulsed burst-mode fashion ( Fig. 2 ) . <p> " Getting all of this circuitry into a small capsule was a great achievement , " says Dave D'andrea , the pill 's inventor and design engineering manager . " Working with Teledyne Microelectronics , which manufactured the pill , we made use of three-layer pc boards and flexible interconnects to get the job done . @ @ @ @ @ @ @ @ @ @ $15,000 . This includes the laptop computer , the docking station , an activation fixture , the data receiver , software , and user manuals . Pills cost $500 each . The Windows-based laptop has been optimized for working with the Smart Pill monitoring system . 
@@21004870 @1004870/ <p> Fig 3 . Designers can chose an alternative biasing arrangement that reduces the required startup voltage even lower " to less than 2 V. <p> The Pierce-type resonant crystal oscillator in Figure 1 was designed to run off two series-connected 1.5-V batteries and reliably start at a supply voltage as low as 2.4 V. Tests had previously indicated that Pierce crystal oscillators using standard CD4000 inverters could not reliably start at such a low supply voltage , although once started they could operate at lower voltages . <p> The low starting voltage was originally designed to allow a minimum battery life of one year in a particular clock design . The circuit shown was patented ( No. 5,220,291 ) , but the patent has expired . <p> The oscillator features a common-collector output drive having a rail-to-rail output , and it may be directly connected to digital CMOS logic . Most importantly , for long battery life , a very low operating current was required , so the output transistors were selected for their relatively high gain at low currents ( 20 -A ) . The crystal is @ @ @ @ @ @ @ @ @ @ to 1 Hz ) , having a frequency tolerance of -20 ppm . <p> R1 and R2 bias transistors Q1 and Q2 at the supply mid-point . The oscillator 's output ( at the collector connection ) is connected to R3 , which together with C1 , X1 , and C2 comprise a phase-shifting network . The output of this network is applied to the bases of Q1 and Q2 , completing a regenerative loop . <p> C2 is not required but is included in the event that it may be desired in other circumstances . The loop has 360- of phase shift at the oscillating frequency . The oscillator output is also connected to buffer U1 , which squares up the oscillator signal . A suitable buffer is a CD4000 series IC , such as an inverter , or a NAND or NOR wired as an inverter . <p> For a supply voltage of 3 V , the measured unloaded oscillator current was 1.4 -A ( with the oscillator not connected to U1 , a CD4011B NAND ) , the loaded oscillator current was 1.8 -A , and the @ @ @ @ @ @ @ @ @ @ Figure 2 shows oscilloscope photos of the oscillator and U1 outputs . Note that directly connecting the oscillator output to high-speed CMOS circuitry will result in considerably greater supply currents owing to rise time considerations of the oscillator output and higher transition currents for high-speed CMOS . Thus , the CD4000 series buffer or a suitable alternative is advised . <p> Also , Figure 2 shows an alternative biasing arrangement that allows operation at lower supply voltages . For the circuit in Figure 1 , the supply voltage must be greater than the sum of the two base-emitter voltages . For the arrangement in Figure 2 , the startup supply voltage is less than 2 V at 32.768 kHz . Interestingly , oscillations were observed for supply voltages as low as 0.65 V , with supply currents less than 1 -A. 
@@21004873 @1004873/ <h> What 's the Difference Between PLC and RF for Smart-Meter Backhaul ? <p> Despite their disparities , both technologies can be used in a complementary fashion to solve obstruction , interference , and attenuation issues . <p> Li Zhou Dai , gridComm Dec 02 , 2014 <p> Smart , self-configuring , fully adaptable networks that connect the power producer with the consumer represent the essence of smart grids . Smart grids create a platform of robust data networks that enable bidirectional exchange of data for all kinds of power supplies and electrical devices plugged into the power grid . This enables remote and active monitoring of operation and fault conditions of the electricity network , thereby delivering the benefits of a highly efficient power network that automatically regulates and controls the distribution and consumption of electricity " without failures or outages . <p> The use of power-line communication ( PLC ) and low-power radio frequency ( RF ) as the communications media for smart grids holds many advantages over the twisted-pair- RS-485- network . Due to the absence of data cabling between nodes , PLC and RF are @ @ @ @ @ @ @ @ @ @ communications security over RS-485 . <p> Low-Power RF Networking Technology <p> Low-power RF networking refers to the use of **32;866;TOOLONG frequencies with transmit power equal to or less than- 50 mW. - Low-power RF modules may be embedded within electrical meters , to enable the use of wireless data communications in automatic meter reading ( AMR ) for power-consumption monitoring and data collection. - Such modules can be embedded directly into the meter during production and installed on-site without laying cables when deploying . <p> Matured , wireless- mesh- networking technology allows the concentrator to communicate with all of the meters within its network control. - This kind of low-power RF network is best suited for deployment within a restricted range that has a concentration of a large number of low-power communications modules ( e.g. , within a single floor of a building or a room of networked electrical meters ) . <p> Because low-power RF communications use publicly available radio frequencies , other devices that utilize the same frequencies will inevitably cause signal interference . In addition , - RF signals are vulnerable to obstructions , such as walls @ @ @ @ @ @ @ @ @ @ communication distances. - <p> Frequency hopping can alleviate that signal interference . However , when other devices also use frequency hopping to counter interference , this in itself introduces more interference . Hence , it 's difficult to resolve the problem of mutual interference . <p> The fact that RF signals are vulnerable to obstructions limits their use in smart-grid applications , too. - For example , thick walls often impede wireless communications between different floors ( i.e. , between the basement and the ground floor ) , resulting in unstable or no communications at all . PLC networks can easily resolve such problems . <p> PLC Network Technology <p> PLC offers a unique means of communication for a power-supply system , which takes full advantage of the wide coverage of power-line installations without having to lay dedicated cables . The technology has attracted the attention of power producers as well as users . Like RF wireless modules , it 's easy to embed PLC modules into electrical meters . <p> Thanks to- mesh networking , DCUs can exchange data with all of the electrical meters within its network of @ @ @ @ @ @ @ @ @ @ the building . Therefore , theoretically , as long as there are power lines , it 's possible to achieve communications over them. - <p> However , power lines are constructed with the primary objective of delivering electricity . Electricity 's complex distribution network and noisy environments may cause various forms of interference to PLC , resulting in unstable communications. - Interference-inducing factors include : <p> Huge load-impedance variations : Load-impedance changes will affect PLC signal voltages coupled onto the power lines , which directly impacts the transmission distance. - Changes in power factor and location of power loads will change load impedances dynamically over time . <p> Attenuation on selective PLC carrier frequencies : The random switching of electrical devices on a power distribution network may lead to changes in power parameters , resulting in attenuation on PLC signals on selective frequencies . At the same location and instance , this impact may vary across different PLC carrier frequencies . When certain frequencies are unsuitable for PLC , changing to different frequencies for communication might yield better results . <p> Strong noise interference : - Electrical equipment on the @ @ @ @ @ @ @ @ @ @ , can produce significant amounts of interference on multiple frequencies that vary randomly . <p> PLC devices , like RF devices , can be networked , which boosts effective communication distances between the DCU and its meters . However , the realization of reliable long-distance communications between two points should be the basis of any PLC network. - Unlike low-power RF , PLC may often enjoy exclusive use of the entire power-line-communication frequency spectrum from- 50 to 500 kHz , thus triggering the above three issues and subsequently affecting the ability to address the reliability of PLC effectively . <p> There are two ways to tackle the above issues . First , depending on different load-impedance situations , transmitter output power must be automatically adjusted . This would boost the signals coupled onto the power line when required and maximize the transmit distance as much as possible . <p> The second method involves the use of single-frequency hopping . PLC orthogonal frequency-division multiplexing ( OFDM ) technology , which employs multiple carrier frequencies , effectively counters selective carrier frequency attenuation . However , its inherent peak-to-average power ratio issue presents @ @ @ @ @ @ @ @ @ @ averaged down as compared to using a single carrier frequency. - <p> Another method similar to frequency hopping in OFDM is to use a single carrier frequency to automatically change to the next , better carrier frequency when the current carrier frequency encounters interference . The advantage of this type of single-frequency hopping is that it ensures sufficient power is coupled to the power line , while addressing signal interference issues caused by load-impedance variations and selective carrier-frequency attenuation . <p> Changing the transmit output power and the carrier frequencies between two nodes in point-to-point communications helps overcome load impedance , line attenuation , and noise interferences . In turn , it improves the reliability and distance for point-to-point communications , thus providing a layer of robustness to mesh- networks . <p> Best of Both Worlds <p> While these measures are effective , they still ca n't guarantee a foolproof PLC network in all situations and at all times. - To achieve this goal , it 's best to integrate both low-power RF wireless networking technology and PLC technology. - <p> One proven solution is the use of PLC as @ @ @ @ @ @ @ @ @ @ - As a backbone , PLC easily works between different rooms or between different floors . Low-power RF then supplements the backbone in places of overly strong signal interference , or where the power lines are physically separated , or on different phases . Furthermore , RF that has reduced power to avoid mutual interference may be used in wide-open places with a high concentration of electrical equipment . <p> Smart grids deployed in this manner will form a highly robust network that should counter most of the issues of signal obstruction , interference , and attenuation. 
@@21004874 @1004874/ <h> Fundamentals Of LED Light Engine Design <p> Rolf Weber , Osram Opto Semiconductors Feb 23 , 2012 <p> The use of LEDs as light sources has become more popular . In many cases , LEDs are now mandatory to reach energy efficiency and color rendering standards . Unlike incandescent bulbs , LED light engines feature light-emitting devices as well as a heatsink , a constant current driver , and sometimes secondary optics to fulfill the light pattern requirements . All of these components contribute to the lumen-per-watt efficacy of the system and need to be optimized . <p> Introduction Long-term cost savings is a key motivation for introducing LED light engines . Savings result from low power consumption and low maintenance due to longer life with stable light output . These benefits have to be evaluated against the cost of LED light engines . Ultimately , good design is the key for success . <p> Managing Junction Temperature LED system design can be approached from many angles . One way is to start with the maximum expected LED junction temperature , or TJ , which can be estimated @ @ @ @ @ @ @ @ @ @ junction temperatures reduce the LED light output and LED life , TJ becomes one of the central design parameters . <p> Along with potential light losses in the light path , junction temperature helps define the required number of LEDs to reach a specified lumen goal . In combination with the maximum ambient temperature , the TJ limit also determines the performance of the heat management system , which includes an LED , a printed-circuit board ( PCB ) , a heatsink , and ambient air . <p> LED production lots differ in their lumen per watt ( lm/W ) efficacy . Therefore , the system has to pass the lumen requirements with the lowest LED efficacy values from the considered lumen bins . Further , as LEDs age , their light output can drop , which makes it important to know whether the lumen requirements are stated for a new light engine or for one that has been operating for a period of time , as well as whether the requirements are at room or maximum ambient temperature . <p> LED efficacy can be improved by applying a smaller @ @ @ @ @ @ @ @ @ @ , the efficacy of an Osram Oslon SSL LED can be increased approximately 25% by reducing the current from 700 mA to 350 mA.1 Several factors affect this increase . <p> First , light output is less than linear with the LED current , so doubling the current produces less than twice the amount of light . Higher currents require a slightly larger LED voltage , and a larger current also leads to a higher junction temperature , causing thermal degradation of the light production . The application of less current per LED requires a larger combined LED chip area , which means using more LEDs or LEDs with larger chip sizes . This measure can be the difference in passing the light fixture requirements . <p> Optic Selection Secondary optics for LEDs can be used as powerful tools to manipulate the light pattern . Today 's lenses typically use a reflector for efficient light collection and a lens/diffuser combination on top to further shape the beam . Efficiencies of greater than 90% are common for acrylic lenses . Other optics employ only a reflector , often with a segmented @ @ @ @ @ @ @ @ @ @ . Diffusers by themselves can be customized to generate more complex light patterns like an elliptical beam field . Made out of plastic , these diffusers add very little cost per LED . <p> Also , secondary optics are designed to manipulate light and are optimized for low light loss . Light fixtures , however , contain other elements that can dramatically reduce the overall system efficiency . For example , cover glasses are added to protect the lamp 's light engine from outside elements . At each glass surface , a Fresnel reflection of about 4% or higher occurs . The exact reflection value depends on the refractive index of the glass and the angle between light and glass . This light gets thrown back into the lamp , and a white lamp interior , including a white PCB surface , can recover some of the light . Cover glasses made from highly transmissive glass types and anti-reflective layers can improve the performance . <p> Finally , the lamp 's mechanical structure , including mounting poles or decorative artifacts , can absorb part of the light as well . @ @ @ @ @ @ @ @ @ @ are particularly susceptible to losses , up to 20% in some cases . These factors make it increasingly important to seek innovative lamp designs to increase the amount of light hitting the ground . <p> Soldering LEDs typically are soldered onto a PCB . The soldering process is important for ceramic LED packages in particular as thermal expansion differences can stress the solder joints between the LED and a metal core board . Optimizing the soldering parameters , the solder paste or the dielectric material can strengthen solder joints . 2 <p> 1 . A densely packaged two-color light engine , like the Osram Sylvania PrevaLED , works best with a metal-clad board . <p> Metal core boards have better heat conductivity than FR4 material equipped with thermal vias and are necessary for light engines with dense LED placement ( Fig. 1 ) . For larger PCB areas per LED " for example , one square inch or more per watt of heat " metal-clad boards reduce the junction temperature by only a few degrees over FR4 . Here , the lower-cost FR4 board might be sufficient . <p> Heatsinking @ @ @ @ @ @ @ @ @ @ beneficial for LED light output and is influenced by the performance of the heatsink . Thermal resistance characterizes heatsinks . In general , a heatsink is a compromise between good heat sinking , size , and costs . <p> Heatsinks transfer their heat to an outside medium like air . Since the thermal conductivity of air is low , convection dominates the mechanism . Heat transport increases based on the heatsink-to-air temperature difference , the exposed heatsink area , and potential airflow , which can be fan-driven . <p> Also , heatsinks produce their own micro airflow as lighter , warmer air moves up . This process makes convection and the heatsink performance orientation-dependent . A PCB temperature ends up lower for a heatsink with low thermal resistance , and systems allowing good vertical airflow usually perform best . <p> Because LED PCBs are often screwed onto the heatsink , enough screws need to be in place so the PCB does n't warp at high or low temperatures . A good interface material such as thermal conductive tape or grease between the PCB and heatsink is beneficial because it increases @ @ @ @ @ @ @ @ @ @ Due to the complexity of the heatsink 's function , it should be tested or simulated to optimize performance , size , and shape . Many heatsink suppliers can help with application support . It should also be noted that dust will settle on the surface of the heatsink and that the heatsink may require a protective paint , both potentially reducing performance . <p> To verify the heat management performance , thermocouples are popular for checking temperature . Though they provide straightforward measurements , they are n't always practical to use . To be accurate , thermocouples need to have good contact with the object , read one PCB spot only , and add wires to the test setup . <p> Thermal imaging works much faster , as it immediately reveals all the hotspots on the PCB or a heatsink in operation . For proper function , the imager should be calibrated and operated with the right emissivity factor as it detects radiation , which depends on the surface 's temperature and its capability to radiate . For example , unpainted shiny metal surfaces radiate significantly less than painted @ @ @ @ @ @ @ @ @ @ thermal imager suppliers . <p> Drivers As part of the lighting system , LED drivers are another factor in the overall efficiency of the solution and need be optimized . LEDs are best driven by constant current sources as the LED light output is fairly linear with the current . <p> Switching current sources turn their output on and off while an inductor and capacitor limit and store the LED current , creating a constant current with reduced ripple that is largely independent of the supply voltage . Driver efficiencies of 90% or more can currently be reached . For a light fixture , the constant current source needs to be integrated in a module that might , for example , need to satisfy the following requirements : <p> Though Energy Star compliance might not be required in all cases , it should be considered a goal since LED light engines are designed to save power and provide high-quality lighting . <p> In the past , it was common in light engines with multiple LEDs to place the LEDs in several parallel serial strings and to adjust the current per @ @ @ @ @ @ @ @ @ @ differences in forward voltage and the potential difference in current per string were simply ignored . The result was either a lower efficiency due to serial resistors or transistors , or uneven light production within the light engine . <p> Today , many switching current sources are offered with several , individually controlled constant current outputs . With this concept the LEDs are still organized in serial strings , but each string runs with a constant current at a high efficiency level ( Fig. 2 ) . <p> There have been many advances in LEDs , lenses , and LED driver technology . In each area , high-efficiency components are available . The light engine designer should strive to optimize each system component as the product of the efficiencies determines the final lumen-per-watt level of the light fixture . 
@@21004876 @1004876/ <h> What 's the Difference Between M.2 Modules ? <p> Using the M.2 interface to connect high-speed modules to a motherboard has become something of a trend . This space is currently dominated by flash memory M.2 cards of varying capacities , speeds , and interfaces although it can handle devices such as wireless adapters . The latter is a primary differentiation between modules as the interface that is used . These include SATA 3.0 , PCI Express 3.0 ( PCIe ) , and USB 2.0/3.0 using HSIC and SSIC support . Other interfaces can be provided , including audio , UIM , I2C and SMBus . <p> The M.2 modules are 22-mm wide and come in a number of lengths , including 30 , 42 , 60 , 80 and 110 mm . Motherboards can usually handle different-length M.2 modules , but 80 mm is the typical size for a flash memory module . Wireless adapters are often found on shorter modules . A motherboard does not have to support all lengths . <p> 1 . The B and M module can plug into a B or M @ @ @ @ @ @ @ @ @ @ plug into a matching B or M socket . <p> - <p> While a motherboard can incorporate a range of key M.2 socket options , the most popular are B and M ( Fig. 1 ) . The B interface provides x2 PCIe , SATA , USB 2.0 and 3.0 , audio , UIM , HSIC , SSIC , I2C , and SMBus support . The M interface provides x4 PCIe , SATA , and SMBus . The sockets are keyed so a module can not be plugged into a socket that does not support the module 's interface . M.2 modules are keyed to fit sockets that will support the interface used by the module . <p> SATA modules , like SanDisk 's X400 ( Fig. 2 ) , normally have a B&amp;M edge connector allowing them to be plugged into a B or M socket . The 80-mm long X400 holds up to 1 Tbyte of flash memory . It is a single-side M.2 module that is only 1.5 mm high . The 256-Gbyte version is rated at 40 Gbytes/day for five years . It employs SanDisk 's @ @ @ @ @ @ @ @ @ @ s X400 can hold up to 1 Tbyte of storage . <p> - <p> M.2 modules with a x4 PCIe interface must have a M connector . For example , Samsung 's 80-mm long , 256 Gbyte SM951 M.2 module can be plugged into Super Microcomputer 's ( Supermicro ) C7Z170-SQ gaming motherboard ( Fig. 3 ) . Its M-style socket only handles PCIe/NVMe devices like the SM951 . Some motherboards , like Gigabytes ' GA-170X , have M.2 sockets that can handle an B&amp;M-style M.2 module ( like the X400 ) or a PCIe module ( like the SM951 ) . <p> The main differences between the x4 PCIe/NVMe interface and the SATA interface are bandwidth and overhead . A single PCIe 3.0 lane can handle a 6 Gbit/s SATA 3.0 interface . There is also less overhead with a direct PCIe interface . A higher speed interface with lower overhead only makes a difference if the storage performance is comparable . Of course , flash memory performance varies but modules like the SM951 can take advantage of a x4 PCIe interface . Its sequential read performance is 2150 @ @ @ @ @ @ @ @ @ @ . This performance typically comes at a higher cost than a SATA M.2 module . <p> Device drivers typically insulate applications from the underlying hardware . This allows designers to choose the appropriate hardware for the application and processor balancing performance , capacity , and cost . <p> One or more M.2 sockets can be found new motherboards . An M.2 module can be the primary storage device eliminating the need for move conventional hard disk or SSD drives . Intel 's compact NUC form factor is designed to use M.2 internal storage exclusively . 
@@21004882 @1004882/ <h> Voltage-To-Frequency Conversion Simplifies Microvolt Measurements <p> In certain applications , like pH measurement based on electromagnetic field ( EMF ) changes in an electrochemical reaction , the change in voltage is very small and the voltage range varies with the solution 's concentration . Designers can make such microvolt measurements using a precision voltage-to-frequency converter ( VFC ) along with a programmable instrumentation amplifier ( IA ) . The setup measures the voltage in terms of frequency and can measure microvolt changes for different ranges of voltages . <p> The VFC is designed for -5-V operation , so the gain selected for the amplifier should reflect this limit and the input signal range . Variable resistor R1 allows offset adjustment . <p> With the AD650 configured in bipolar mode for an input signal range of -5 V , the device provides a maximum output of 100 kHz . R2 is the pull-up resistor , which is chosen to limit the current through the output transistor to 8 mA . Input resistor RIN determines the input signal span , and timing capacitor COS determines the nonlinearity . Integration capacitor @ @ @ @ @ @ @ @ @ @ the maximum frequency output , 10 V is the maximum input voltage range , and 50 kHz is the frequency output at 0 V input . <p> Designers can select IA 's gain to allow the VFC 's FOUT to measure different input voltage ranges ( see the table ) . The circuit 's measurement resolution ( minimum measureable voltage ) will also change accordingly . <p> This circuit offers four major advantages : Processing becomes easier once the analog voltage is converted to the digital domain. The resolution is equivalent to a 17-bit analog-to-digital converter ( ADC ) for the 100-kHz operating range of the VFC. The circuit is so simple that the microvolt measurement can be performed with any frequency-measuring device. The VFC can also be designed for a 10-kHz or 1-MHz frequency range , depending on the resolution required . <h> Anoop 's Analysis <p> This is an interesting application of a voltage-to-frequency converter IC ( AD650 ) to microvolt measurement . However , it is n't a new idea considering that the Analog Devices application notes for the AD650 propose some ideas for using the AD650 @ @ @ @ @ @ @ @ @ @ 10-V signal that is digitized using a 16-bit ADC , you 're bound to get a resolution of 10 V/65536 = 152.6 -V so you can make microvolt measurements . <p> The author provides a 17-bit equivalent ADC resolution to this solution . So , you have to really compare the cost of using the AD650 ( unit cost $16.00 or $11.80/1000 pieces ) against the cost of a 16-bit ADC ( $4 unit cost ) . Guess which one I will choose ? - ( Of course , both would require a microcontroller to be of any use . ) Even an 18- or 20-bit slow ADC will cost only a dollar more . <p> Since I have to consider the cost of my component choices as well as the cost of the overall implementation , as an engineer , I 'm most likely to not use the AD650 V-to-F converter for measuring voltages. 
@@21004883 @1004883/ <p> As our economy continues to drive the emergence of energy-efficient systems such as hybrid and electric vehicles , composite aircraft , and wind turbines , the need for power resistors has expanded . Electrical controls are replacing many heavy and large mechanical devices that have diminishing life due to frictional wear . But the standard electrical components do not completely optimize the system designs . <p> Next-generation electrical devices must be improved to reduce weight and size and operate at much safer temperatures . At a constant power level , the peak operating temperature of a resistor increases as the size and mass are reduced , making it difficult to reduce all three parameters simultaneously . These challenges have driven the emergence of new design concepts and considerations to manage and dissipate the heat generated from the power resistor . Thermal management considerations are the key to meeting the design goals within the desired operating conditions while reducing the overall system weight and size . <h> Reducing System Size : The Effect On Power Resistors <p> When reducing the size of a system that must be able to @ @ @ @ @ @ @ @ @ @ include the ultimate mass and space available to house the module . In addition , the operating environment and maximum internal package temperature must be defined to make the appropriate material selections for module construction and other internal device considerations . <p> The best way to reduce the resistor size and mass is to remove the thermal mass that accompanies the power resistor package . However , doing so increases the operating and exposed temperature of both the resistor element and neighboring components . This is where the new concepts of power resistor designs come into play . <p> The most effective and efficient way to reduce the size and mass of a power resistor is to utilize the existing material and construction of the module or the system where the module is to be placed as the thermal mass . For example , today 's electric vehicle designs operate on a 330- to 650-V dc high-voltage bus . At these voltage and current levels , traditional relay power switching is replaced with insulated gate bipolar transistors ( IGBTs ) , which already require heatsinks to operate efficiently and extend @ @ @ @ @ @ @ @ @ @ limit the inrush current to the charging system capacitors as part of this circuit , and they are easily mounted to the same heatsinking devices already necessary for the IGBT operation . Planar devices readily mount to the heatsink with negligible size and mass addition to the system , yet offer a tremendous power handling capability for surge conditions ( Fig. 1 ) . Even if the system does not have an internal heatsink , the module packaging may already be using an aluminum lid or box where the component can be mounted . <p> Mounting the heat-generating devices to internal heatsinks can solve the initial concern of component heat dissipation . However , the long-term operation effects can push the internal module temperature beyond acceptable limits . Many packaging designs either expose the heatsink fins to the exterior of the package to dissipate the heat to the outside ambient or include liquid-cooled heatsinks . These considerations may not be cost-effective if only required for the power resistor , but the designer can take advantage of these types of features that are already implemented for other internal components of the @ @ @ @ @ @ @ @ @ @ Some module designs do not allow for these considerations , but power and heat dissipation are still required . In these cases , an optimal approach would take the power to where it can be dissipated , preferably to an existing thermal mass within the system so the weight of the overall construction is n't increased . Electric and hybrid vehicles do have a cooling system where the heat can be dissipated . The devices in Figure 1 exhibit excellent power-handling capabilities on a static heatsink , or even better on an air-cooled heatsink . The functional operating limits are further increased if the heatsink is liquid cooled . Liquid is far denser than air and carries a much higher thermal capacity to transfer heat . <p> Heat transfer directly to the coolant flow is possible by depositing the same material systems and circuit designs onto tubular substrates . Replacing a section of the coolant path with the tube component is the most efficient approach to maximize the component power density and limit the operating temperature . Using the same construction as the planar components , the tube transfers the @ @ @ @ @ @ @ @ @ @ medium ( Fig. 2 ) . <p> 2 . Thick-film on steel tube components can enable heat transfer directly into coolant flow while maximizing power density and limiting the operating temperature . <p> This design can operate at power densities well beyond that of a planar device that relies solely on a static aluminum heatsink , and the thermal mass already exists within the vehicle cooling system . Figure 3 plots the average temperature rise of the power circuit against variable flow rates at four different power densities . Designers then can understand the size of the circuit and flow rate required to stay within the operational limits of the design . The product characterized here is a 0.75-in. stainless steel tube with a printed circuit area of 6 in.2Figure 4 shows thermal images at a few points along a 150-W/in.2 power density curve . <p> 3 . To help understand the requirements of circuit size and flow rate to keep within operational limits , the graph plots the average temperature rise of a power circuit against variable flow rates at four unique power levels . <p> Implementing the tube @ @ @ @ @ @ @ @ @ @ the tubes are directly formed with proven flares , flanges , beads , or barbs for hose or manifold interconnects ( Fig. 5 ) . Another true advantage of these products is the isolation of the electrical circuit where it is deposited and not subjected to fluid exposure . The thin wall construction of the tube itself allows for rapid heat transfer to the fluid flow , and the component does not introduce additional failure modes that would be found with submerged devices such as a glow plug or other liquid-cooled resistor element . <p> 5 . A 0.75-in. tube can be characterized for data with bead-formed ends . <h> Single Device , Dual Function , Multiple Power Levels <p> The tube product offers many advantages to the system designer . Most vehicles are likely to rely on a lithium-ion ( Li-ion ) battery pack that requires cooling during energy discharge cycles . Because the coolant is already flowing through the battery pack , the battery charge can be optimized using the same power resistor to heat the fluid flow during the plug-in charging cycle of the batteries . <p> @ @ @ @ @ @ @ @ @ @ decreases . Cold climate charging reduces the charging capacity and ultimately results in significant permanent capacity loss , both of which deplete the vehicle range . In contrast , heating the batteries during the charging cycle enables full-capacity charging while using the energy of the wall outlet to provide heat . Once fully charged and unplugged , the vehicle 's coolant system is preheated for instant cabin heat . As the batteries discharge during vehicle operation , they generate heat that is then provided to the cabin for passenger comfort . <p> Because the planar and tube components are thick-film circuits , the artwork used to deposit the circuit is very flexible to customize performance or provide additional circuits to address specific application requirements . Whether dissipating the heat of a power resistor or proving a specific heated region of the substrate , these products can be balanced to optimize the performance for each specific application while requiring very little space or increasing the overall system weight . <h> Power Resistor Thermal Management On A Relative Scale <p> The considerations for power resistors so far have focused on power dissipation @ @ @ @ @ @ @ @ @ @ and all placement options have limitations . On a control circuit level , the printed-circuit board ( PCB ) has thermal limitations based on the material chosen as the substrate . While most surface-mount devices ( SMDs ) on the PCB are well below a 1-W rating , what happens when a 5-W device or more is required ? The concern is then raised when the operating environment is defined to be 85-C , 125-C , or even 200-C for certain automotive , down hole drilling , or aerospace applications . <p> It does not take much localized heat for a resistor to exceed the rating of many PCB substrate materials at these elevated ambient temperatures . For example , FR4 is only UL rated to a 130-C operating temperature . Even if high-temperature boards are used , packaging proximity or other closely placed electronic components can be affected . While the resistor may only be a couple of watts , it can easily surpass the limits of the assembly design or reflow temperature of solder joint construction . It also can impact the lifetime and operating limits of the @ @ @ @ @ @ @ @ @ @ options . Depending on each unique set of boundaries of a specific application , one or more of the following approaches can help solve the problem of localized heat generated within the circuit : <p> Raise the resistor off the PCB to keep the heat away from the substrate ( Fig. 6 ) . <p> Add thermal vias directly below the insulated portion of the resistor to improve the thermally conductive path to the ground plane of the PCB . <p> Isolate a power resistor from direct contact with the PCB and use a secondary heatsink . <p> Optimize power-resistor proximity to precision devices to minimize measurement error , tracking drift , or premature aging of these components over a short period of time . <p> 6 . Some components raise the resistor element above the PCB to keep heat away from the PCB substrate . <h> Conclusion <p> Resistive components play a critical role in electronically controlling system inertia and surge energy . While the resulting creation of heat from a resistive device can not be avoided , it can be accommodated without adding mass and size to the @ @ @ @ @ @ @ @ @ @ heat can be directed to replace other components designed specifically to generate heat , when the energy is directed to these areas of the system . <p> Designers have quite a few options . Depending on each unique set of boundaries of a specific application , one or more of these approaches can help to solve the problem of localized heat generated within the circuit . The use of thick film on metal products offers a wide range of flexible options to solve the power handling and heat dissipation issues . The extremely high power density and low-temperature operation of this technology allow for significant space and weight savings that increase the overall efficiency of the system , and the flexible geometry allows for creative placement options . <p> Control-level circuits also can incorporate many different designs that remove heat from the PCB and solder joints , allowing for overall circuit size and packaging reductions . At the end of the design cycle , all weight and size reductions lead to overall system cost savings through purchased material costs and/or increased operating efficiencies . 
@@21004888 @1004888/ <h> What 's All This Capacitor Leakage Stuff , Anyhow ? <p> We all know that capacitors have a shunt resistance ( leakage ) and that leakage resistance should be pretty easy to measure , right ? Wrong ! I 've measured a lot of capacitors for short-term soakage ( dielectric absorption ) per LONG ... <p> After the short-term soakage stops , it 's possible ( not easy ) to measure the leakage . For example , if you charge a good cap up to 9 V for a few seconds , it will start discharging shortly for several millivolts . If you wait long enough , you may see leakage slow down to a few millivolts per hour . But you will see the long-term soakage . Is that different from the short-time leakage ? Maybe not . <p> Download this article and more as part of Electronic Design Library 's new eBook , Focus On : Bob Pease on Analog . <p> Now I will charge up some of my favorite low-leakage capacitors ( such as Panasonic polypropylene 1 -F ) up to 9.021 V dc @ @ @ @ @ @ @ @ @ @ will read the VOUT with my favorite high-input-impedance unity-gain follower ( LMC662 , Ib about 0.003 pA ) and buffer that into my favorite six-digit digital voltmeter ( DVM ) ( Agilent/HP34401A ) and monitor the VOUT once a day for several days . <p> Why did I choose 9 V ? Because that 's within the common-mode range of the op amp and the DVM at highest resolution . I keep the input ball hook connected to +8.8 V dc between readings . I also keep my left hand grounded to +8.8 V. <p> DAY BY DAY One of my e-mail colleagues had been monitoring some good 0.1--F polystyrenes , and he was impressed that they got down to a leak rate of better than a year after several months . Well , I could see that my polypropylenes had their leak rate improve even better than that in just a few days . Refer to the list of voltages below : <p> The first day after soaking for an hour , their leak rate was as good as 2.7 mV per day . Not bad . <p> If @ @ @ @ @ @ @ @ @ @ at the 9-V level , it would draw 9 pA , which would pull down the capacitor 778 mV per day . All the capacitor types I tested were better than this , except some " oil-and-paper " caps that supposedly had special qualities for audio signals . <p> If you had a 10-meg-meg resistance , that would cause the cap to leak down 78 mV/day . With 100 meg-megs , it would be 7.8 mV per day . Several good capacitors soon began to leak slower than that . After a mere week , some of the best caps were leaking at a rate down near 1 mV/day . Quite good . So , what 's the big deal ? <p> The big deal is that a time constant of 31.5 meg seconds is one year ! So any capacitor leaking less than 2.5 mV per day is leaking at a tau ( rate ) of 10 years or more . If you had to wait a few months to get this leak rate , well , that 's not bad . But achieving this leak rate in less @ @ @ @ @ @ @ @ @ @ good . Less than a day ? Spectacular . <p> So I 'm finding that good polypropylene caps are better than the best ( old ) polystyrenes , in terms of soakage or dielectric absorption ( early or late ) and in terms of leakage , early or late . Are Teflons any better ? Not much . I may have to buy a couple to find out . 
@@21004893 @1004893/ <h> 1950s : Transistors Fill The Vacuum : The Digital Age Begins <p> A decade of contradictions : infinite hope for the future coupled with fear of powerful enemies . That is the 1950s , a time of war and then of post-war prosperity . Rock and roll was evolving from rhythm and blues , soon to be heard blaring from transistor radios from Spokane to Baltimore . Crew-cut kids watched across TV dinners as tales of space travel and futuristic dreams flickered across the screens of RCA consoles . Gas was cheap , tailfins were large , and Americans were consummating their love affair with the open road . The future seemed limitless , and as the decade dawned , few even realized why . But as the 1940s drew to a close , a handful of engineers had made a breakthrough that ultimately would change the world . <p> The infant born in 1947 to Bardeen , Brittain , and Shockley " the point-contact transistor " came of age in the 1950s . It matured into Shockley 's junction transistor , which found a home in countless @ @ @ @ @ @ @ @ @ @ , pushing the electronics industry toward modern digital computers and communications . Transistors ran cooler and demanded far less power than the vacuum tubes they would begin replacing , producing smaller , faster , and more powerful electronics . Initially costly to produce , transistors in the fifties began the trend that the electronics industry has continued ever since : ever-lower cost coupled with greater functionality and integration . Transistor process technology was refined throughout the decade , which culminated in the development of the first integrated circuit . <p> Necessity is indeed the mother of invention , and never was necessity greater than during the wars of the 1940s and early fifties . The massive efforts stemming from World War II , the Korean conflict , and the ensuing Cold War resulted in the mobilization of America 's greatest scientific minds . The tense geopolitical faceoff between east and west found the electronics industry being thrust to the battle 's front lines , fervently employing the new solid-state technology in increasingly sophisticated defense and weapons systems . Out of urgent military need came technological marvels that kept the United @ @ @ @ @ @ @ @ @ @ these was the advent of digital computers . <p> It was the digital computer advances in the 1950s that laid the groundwork for the successful commercial mainframe and mini computers that would emerge in the 1960s , and later evolve into the personal computers of the 1970s and 1980s . Digital computer technology that had begun as part of the war effort in the forties was refined and then marketed as a commercial product . <p> In 1957 , J.M. Bridges , the Defense Department 's Director of Electronics , told a group of computer manufacturers that digital computers were destined to replace less reliable analog machines in complex military weapons systems of the future . A hallmark of the development effort , and a sure means of achieving reliability , would be to manufacture standard , modular digital functional blocks that could be combined with little or no change to build complex computing systems . <p> Indeed , even as the Korean War began at the outset of the decade , the concept of the plug-in circuit module had taken form and begun to speed the production of electronic @ @ @ @ @ @ @ @ @ @ areas and then simply connected together . Modularization , combined with a growing reliance on printed circuits , also brought enhanced reliability , repeatability , and easier servicing when things did go awry . <p> The earliest digital computers , beginning in the forties and continuing into the late 1950s , were based on vacuum tubes . They were unreliable and difficult to program , used lots of power , required very large rooms , and were constantly in need of maintenance . Storing information was difficult , and the machines could only solve one problem at a time . <p> A breakthrough in digital computing came in 1951 , when the Eckert and Mauchly Computer Company of Philadelphia sold the first commercial computer , the UNIVAC 1 , to the U.S. Census Bureau . The massive machine retrieved data from memory by transmitting sonic pulses through tubes of mercury . An additional 45 UNIVAC 1 machines would eventually be sold . <p> Other computer advancements came in memory . For example , the invention of ferrite core memories would lead to the Massachusetts Institute of Technology 's development of @ @ @ @ @ @ @ @ @ @ information quick and efficient . Also , the RAMAC disc operating system , introduced by IBM in 1957 , was the first data processing system to use record-like discs to store digital data . Each disc had a storage capacity of about 100,000 characters and could be randomly accessed . <p> Although development of the transistor gave electronic design engineers an important building block for the future , it also spurred development of the tools and infrastructure the industry would require for growth . The 1950s saw a broad array of test and measurement equipment emerge as engineers clamored for ways to quantify the performance of their circuits . As the need for improved test equipment grew , advances in cathode-ray tube ( CRT ) technology were essential for the equipment to evolve . Improved CRTs were put to good use both in test gear and in television sets . <p> The 1953 development of the digital voltmeter ( DVM ) by Non-Linear Systems as a separate instrument was a key innovation in test equipment . The DVM , an instrument that was part of many analog computers , increased @ @ @ @ @ @ @ @ @ @ order of magnitude over the vacuum-tube analog voltmeters that had preceded it . <p> The industry also began looking ahead to how it would produce components in the future . To that end , Bell Labs developed an experimental transistor-making robot that presaged later advances in automated semiconductor manufacturing . The machine , dubbed " Mr. Meticulous , " accurately positioned and welded gold collector and emitter wires to their respective device layers and then automatically tested the finished devices . <p> Automated semiconductor production was pivotal as the technology infiltrated more than military and computer applications . Space represented a new frontier to be conquered , and there was great political and ideological capital at stake for the victor . In 1957 , the Soviet Union startled the world when it launched Sputnik , the first orbital satellite . The United States was caught short with its space program barely off the ground . But the U.S. made a comeback , launching its own first orbital satellite , Explorer I , in 1958 . The space race was on , fueled by an explosion in engineering ingenuity from the @ @ @ @ @ @ @ @ @ @ solar system quickly followed the early orbital satellites . The combined efforts of many companies to make the necessary equipment lighter , more precise , and more efficient made these probes possible . <p> Meanwhile , the newborn that was solid-state electronics was making its presence felt on terra firma in a big way . The transistor radio , introduced in 1954 , became the fastest selling consumer product of the time . By 1955 , car-crazed Americans , fueled by post-war prosperity and cheap gas , were more than ready for a little driving music . RCA 's Sarnoff Research Center answered the call with an experimental nine-transistor car radio . Transistor radios came onto the market in droves , giving America its first taste of its own future : electronics everywhere , packaged to travel and ready for deployment at will whether on the street , in the car , or at home . <p> One of the earliest commercial applications of junction transistors was in hearing aids . As early as January , 1953 , NPN transistors saw use in a hearing-aid circuit that ran for six @ @ @ @ @ @ @ @ @ @ foretold of the advances to come in transistorized circuits by being 25% to 30% smaller than earlier models with twice the output power . <p> Through the 1940s , radio was king and the theater of the mind still ruled in post-war America . But television 's golden age was just beginning in the early fifties and again , electronics led the way . RCA 's experimental solid-state ( except for the picture tube ) TV receiver of 1952 used 37 semiconductor devices , had a five-inch screen , and weighed about 27 pounds . An inauspicious start , perhaps . But as with everything else the electronics industry touched in ensuing decades , the challenge of miniaturizing and improving television sets was ultimately met . <p> Throughout the industry 's history , many technologies found their genesis in the military before trickling down into consumer products . Modularization and miniaturization were an example of this trend . In the beginning , miniaturization was driven by the Soviets ' success with the Sputnik program and was a major objective of government-funded electronics research programs . But through work like RCA @ @ @ @ @ @ @ @ @ @ its mark on consumer products . <p> As always , the basic building block of the transistor formed the underpinnings for all of the advances in consumer goods . For most of the 1950s , germanium was used to make transistors . But after Texas Instruments introduced the first silicon transistors in 1954 , silicon began to replace germanium as a semiconductor material , thereby extending operating temperatures to military ranges . <p> As the decade wound down , the pieces were in place for the crucial next step along the path of integration . Engineers at both Fairchild Semiconductor and Texas Instruments sought to produce a single substrate of silicon carrying not only transistors and diodes , but also resistors and capacitors " and then join all the components to form a complete circuit . <p> In 1958 , Jack Kilby of Texas Instruments and Robert Noyce of Fairchild Semiconductor independently developed just such a device " the integrated circuit ( IC ) . The first monolithic IC was built in 1958 at Texas Instruments when Kilby constructed a phase-shift oscillator from a single silicon bar . The device @ @ @ @ @ @ @ @ @ @ electrical path was through the silicon . TI was also the first company to announce a product line of ICs . <p> By the end of the decade , the transistor had rightfully earned its place in the forefront of technology and , in fact , had begun to fulfill its promise to take the industry much further . Government got into the act in 1958 , when President Dwight D. Eisenhower created the Advanced Research Projects Agency ( ARPA ) to keep the U.S. at the forefront of technology . ARPA would , in the next decade , plant the seeds for one of the greatest technology advances of the century " the Internet . <p> A decade of contradictions , social and political , managed by its close to coalesce into one of great technological advances . The 1950s set the stage for the computer advances that would be seen in the sixties and on into the seventies . And it was the beginning of rapid change in electronics , changes that would heavily impact the way Americans lived their everyday lives . 
@@21004895 @1004895/ <h> Many Technologies Contribute To Miniaturization <p> Gary Pinkerton Dec 22 , 2002 <p> Electronic miniaturization is not simply a process of making everything smaller . Miniaturization of one phase of a product usually reveals limitations and obstacles in other parts of the overall design and manufacturing process . So progress often comes in uneven spurts , as advances in a specific technology " semiconductor fab , pc board , power , manufacturing , and packaging " leapfrog other technologies . Developments in several areas other than integrated-circuit dies are proving critical to the continued progress of miniaturization . <p> In the passive-component area , the introduction of the " 0201 " ( 20- by 10-mil ) form factor for surface-mounted devices ( SMDs ) is one example . These near-microscopic components occupy 25% of the pc-board area and less than 20% of the volume of previous 40- by 20-mil parts . A related development is the use of adhesives in place of solder to mount SMDs . In addition , phasing out lead-based solder will have far-reaching effects on all of the electronics industry . Even developments in @ @ @ @ @ @ @ @ @ @ CMOS IC designs that operate on lower supply voltages will enable even greater miniaturization and longer battery life by downsizing power sources . <p> For some time , the subtractive ( etch ) process for pc-board fabrication has been seen as a barrier to further circuit miniaturization . As feature sizes shrink , maintaining dimensional tolerances and long-term reliability becomes more difficult because etching tends to undercut metal beneath the trace mask . A new additive process uses electroforming to build up metallic traces on a pc-board substrate and supports fabrication of 25-mm diameter holes and 10-mm wide lines/spaces on pc boards as thin as 12.5 mm . These figures represent 75% to 80% reductions versus etched pc boards . Such techniques as chip stacking further conserve board real estate . <p> Thermal management also has been identified as an obstacle to miniaturization , especially as device speeds and packaging densities rise . Heat loads are expected to outpace established cooling techniques sometime in 2003 or 2004 . Now the focus is shifting to localized , active cooling strategies that provide very low thermal resistance , subambient capability , cost-effectiveness @ @ @ @ @ @ @ @ @ @ heat-flux regions on IC dies . <p> The bottom line of most tradeoffs in miniaturization is whether or not the market will support the cost of achieving a given size/performance level . Cutting-edge miniaturization typically becomes more expensive as sizes are reduced . A part of the increased cost results from facilities and placement/bonding machines that can attain higher precision . By some estimates , a yield of at least 98% is necessary to make miniaturized electronic products profitable . More aggressive miniaturization can make such yields more difficult to achieve , driving up cost until manufacturing technology matures . Adding to the problem is the growing impracticality of rework or repair as products shrink . Some miniaturization processes preclude testing until components are committed to final pc-board assembly . <p> Miniaturization is a strong draw in many types of consumer products , but it can be taken too far . For example , cell phones could be shrunk to the point where keypads and displays would be difficult to use . Increasingly , product designers are challenged to provide easy-to-use man-machine interfaces despite higher product complexity and shrinking control-panel @ @ @ @ @ @ @ @ @ @ near optimal form factor . Future miniaturization will focus more and more on increasing a product 's sophistication , performance , and market penetration . <p> Miniaturization typically extracts some cost penalty , so it 's most suitable to less cost-sensitive products . Markets like instrumentation , security , military/aerospace , and especially medical electronics can support the cost , whereas current telecommunications products ca n't . Continued progress now depends on manufacturers and designers solving problems related to electronics and the physics and chemistry of cooling , pc-board production , power distribution , and RF signal transmission . 
@@21004898 @1004898/ <h> Make The Most Of Your USB Functionality <p> The Universal Serial Bus ( USB ) is a proven connectivity system . However , there are still design challenges in producing a USB hardware interface . Prime among these are face layout , power , and interference issues . <p> A USB comprises a host ( traditionally the PC ) and one or more devices , often called the slave or slaves . The physical USB interface is made up of four shielded wires . Pin 1 , which is the VBUS , is used to power any connected peripheral by supplying a +5-V voltage from the USB host . Pin 2 is the negative data terminal denoted as D " ( DM ) , while Pin 3 is the positive data terminal denoted as D+ ( DP ) . These pins make up the differential pair that carries out data transfers . Finally , Pin 4 is the ground connection ( GND ) . <p> To ensure signal integrity , both the DP and the DM signals should travel the same distance . If one trace is longer @ @ @ @ @ @ @ @ @ @ be affected with data errors resulting . It is therefore important to ensure that data trace lengths are matched . The recommended maximum allowed deviation between the DP and DM trace lengths is just 150 mil . <p> Most modern PCB layout software can be configured to route both signals together with these characteristics . The DP and DM signals should be made as short as possible . For very short runs , less than 1 cm , it may not be possible to observe the controlled impedance guidelines described here . But in practice , this is usually acceptable provided the other guidelines are followed . <p> Care should also be taken not to add any stubs when putting voltage protection diodes and capacitors into the design . This will minimize data signal reflections . Also , the DP and DM signals should consistently be routed over a USB signal ground plane . Ideally , there should not be any splits in the plane directly under either DP or DM . <p> Even though it 's called a bus , USB is a point-to-point interconnect . The connection of @ @ @ @ @ @ @ @ @ @ of a USB hub device . Up to 127 slave devices can be connected to a single host via one or more hubs. - <p> Basic circuit layout principles should always be followed , such as routing USB lines away from noisy power signals and clock circuitry components . Designers should also avoid the use of right-angled turns on USB signal traces . Using two 45- turns will prove far more beneficial than a single 90- turn . <p> Power Issues Selecting an appropriate power configuration is another important consideration for USB interface design . Designers should think about how their USB circuitry will be powered and , more importantly , how much current this circuitry will draw . USB peripherals can be USB bus-powered or can draw power from an external source in a self-power configuration . <p> Continue on next page <p> The USB 2.0 specification for bus-powered systems allows a device to draw up to 500 mA from the 5-V VBUS supply . USB bus power is often used to charge batteries or power low-power devices . With USB power , designers need to ensure that the @ @ @ @ @ @ @ @ @ @ to enumeration . <p> The 5-V VBUS supply is not always practical for directly powering ICs and other devices , as not all ICs support 5-V tolerant inputs . A voltage regulator can be used to generate the required voltage levels . That 's why the FT232R USB UART interface IC from FTDI features an integrated 3.3-V regulator ( Fig. 1 ) . <p> This interface can be used to take power directly from the VBUS supply , reducing component costs and simplifying system design . The IC features a UART interface ( Fig. 2 ) that can be used to provide a USB connection to a UART port on a microcontroller or other processing device . <p> It is important to note that the circuit design shown here recommends providing for a capacitor or resistor to remove noise from the shield . This is based on experience when submitting products for electromagnetic compatibility ( EMC ) and radio-frequency interference ( RFI ) testing , despite being contrary to circuit theory . <p> USB bus-powered peripherals also must support power-management features , such as the USB suspend state to save @ @ @ @ @ @ @ @ @ @ from the suspend state , many slave devices have remote wakeup capabilities , allowing them to resume operation as soon as activity is detected . <p> For higher power applications , an external or self-powered configuration can be used . Self-powered configurations have fewer restrictions , but devices must protect against current draw down through the USB bus to the host when the host or the hub is unpowered since this can damage the upstream circuitry . To prevent this potential hazard , connect the VBUS signal ( Fig. 3 ) to a reset pin , forcing the IC to wait in a reset state until the USB host is ready . <p> For USB bus-powered configurations , a ferrite bead should be deployed on the VBUS supply to prevent EMI noise from being radiated down the USB cable to the host . Configurations typically consist of a capacitor and ferrite bead placed as close to the USB connector as possible . Ferrite beads should not be used on either of the USB data signals or the ground signal . <p> Other current-protection techniques include adding circuitry to protect against @ @ @ @ @ @ @ @ @ @ issue in USB bus-powered configurations where excessive current can be drawn from the host during initial plug-in or enumeration or when restarting from a suspended state . <p> ESD protection techniques for USB designs include the use of transient voltage suppression diodes on the data lines , on the VBUS supply pin , and on any other external interface components . These diodes should be placed as the first board-level device next to any external connection point . This will ensure the shortest current path to ground and minimize the possibility of damage elsewhere on the PCB . <p> Another noise suppression technique is the addition of PCB pads for the connection of a resistor or capacitor between the USB connector shield and the connector ground . The quality of the shielding on different types of USB cables can vary quite significantly . As a result , adding a passive device may help limit noise from being transferred to the system ground plane . This technique is also important if manufacturers are seeking to secure CE and Federal Communications Commission ( FCC ) compliance for their USB product . <p> @ @ @ @ @ @ @ @ @ @ Implementers Forum ( USB-IF ) certification , allowing them to use USB compliance logos on their product . The certification process involves testing by the USB-IF to ensure that the interface conforms fully to the electrical and interoperability requirements outlined within USB specifications . During electrical compliance testing , USB signal rise and fall times may require adjustment through the use of capacitors and/or resistors on the DM and DP data lines to account for configuration-specific variations . <p> As part of the enumeration process , a USB host will request configuration and identification details ( known as USB descriptors ) from the peripheral slave device . The descriptors contain information such as vendor I 'd , product I 'd , USB revision , number of USB interfaces , and supported transfer types . The data can either be stored internally within a USB IC , as is the case in the FTDI FT232R , or on an external EEPROM . <p> Although these recommendations relate to directly designing a USB slave interface , many of these practices are also relevant to designing an embedded USB host interface . When designing a @ @ @ @ @ @ @ @ @ @ the power circuitry to ensure that sufficient current can be supplied , and overcurrent conditions detected , for the type of USB slave devices connected to the host . 
@@21004900 @1004900/ <p> This all-analog circuit provides three key waveforms simultaneously and at the same frequency within the audio band . It is useful for evaluating audio systems , transformers , cables , and other electrical installations . <p> This simple , robust , and low-cost signal generator , based on the LM386 power amplifier IC , provides a trio of audio-band signals with three different simultaneous outputs at the same frequency : square/rectangle ( SQW ) , triangle ( TRG ) , and sine ( SS ) . <p> Each output can drive loads such as long cables , transformers , auto-transformers , audio couplers , or active loudspeakers . The amplitude of each output can be adjusted independently . The outputs can be connected to ground , the power supply , or between them for short time without damage . <p> The simplified block circuit shows IC1 operating as a square-wave generator with frequency determined mainly by R1 and C1 ( Fig. 1 ) . The signal in point A is approximately triangular with amplitude of about 0.35 V p-p and a supply rail of +9 V. <p> 1 @ @ @ @ @ @ @ @ @ @ ( LM386 ) are configured to implement a triple-waveform generator at one of two selectable frequencies . <p> The triangular signal goes to amplifier IC2 via potentiometer P1 . It is also routed to the low-pass filter ( LPF ) or a band-pass filter ( BPF ) . The quality of that filter determines the quality of the sinusoidal signal , which IC3 amplifies . <p> The 3-dB frequency of the LPF should be equal to or lower than the frequency of the triangular signal at point A. With a BPF , the central frequency or the resonant frequency should be approximately equal to that of the signal at the same point . In the simplest case , these can be second-order low-pass RC , RC band-pass , LC band-pass , or LC low-pass filters . IC3 amplifies the sinusoidal signal at point B , after potentiometer P2 . <p> IC2 and IC3 are used with a gain of 200 . This may result in trapezoidal-like signals at outputs TRG and SS when the input signals are too large and the amplifiers are saturated . If this is a problem @ @ @ @ @ @ @ @ @ @ set to approximately 50 as described in the IC data sheet . <p> The actual circuit of the generator is built with three LM386 ICs . It produces two frequencies , selectable via double-pole double-throw ( DPDT ) switch S1 ( Fig. 2 ) . When the switch is in position 1 , the frequency is 1 kHz . In position 2 , it is 500 Hz . Trimmer potentiometer P1 is used to fine-adjust the nominal 1-kHz frequency , while the 500-Hz output is not adjustable , for simplicity . <p> 2 . The frequency of the simultaneous square , triangle , and sine waveforms can be switched between two values ( here , 500 Hz and 1 kHz ) via DPDT switch S1 , which selects the capacitor for the resonant LC tank . <p> IC2 amplifies the triangular signal from point A via potentiometer P3 . It also goes to the band-pass LC filter built with C9 ( or C10 ) and L1 . The resonant frequency of L1/C9 is around 500 Hz , while the resonant frequency of L1/C10 is 1 kHz , with C10 implemented @ @ @ @ @ @ @ @ @ @ nF ) . The resonant frequency F of the LC tank can be approximated using the standard formula F = 1/ ( 2- GLC ) . <p> Depending on the position of the wiper of the P3 , output TRG will be triangular or trapezoidal , with the maximum amplitude limited by the power supply . The square-wave signal is available at the outputs SQW1 ( non-adjustable amplitude ) and SQW2 ( adjustable amplitude with the potentiometer P2 ) . The sinusoidal signal at point B is connected via potentiometer P4 to be amplified by IC3 . The amplified signal is available as output SS . <p> The internal noise of the chosen LM386 may not specified , so its gain should be minimized . The values of R1 , R7 , R8 , R9 , P3 , and P4 also should be minimized to minimize noise . The LM386 amplifier is available from different sources with some variations in specifications , such as an operating supply range from 4 to 12 V or 5 to 18 V. Typical and maximum output power is a function of the LM386 chosen @ @ @ @ @ @ @ @ @ @ <p> Petre Tzvetanov Petrov is an electronics engineer with Micro-Engineering , Sofia , Bulgaria . He has worked as a researcher and assistant professor at Technical University , Sofia , and has been an expert lecturer at OFPPT , Casablanca , in the Kingdom of Morocco . - He can be reached at email protected <p> - <p> 1 . The block diagram shows how three low-power audio amplifiers ( LM386 ) are configured to implement a triple-waveform generator at one of two selectable frequencies . <p> - <p> 2 . The frequency of the simultaneous square , triangle , and sine waveforms can be switched between two values ( here , 500 Hz and 1 kHz ) via DPDT switch S1 , which selects the capacitor for the resonant LC tank . 
@@21004902 @1004902/ <p> Designers can sort through these many options by understanding the relative merits and demerits of each technology . Then they will be equipped to make the selection that best fits the need of the device being designed . <h> Periphery Vs . Area-Array Packages <p> Both leadframe-based peripheral interconnect and laminate substrate-based area-array packages are mature technologies . Array packages , as the name suggests , provide contact points in an X , Y array . Escape routing to a package 's periphery can be much simpler than routing to an X , Y array . This often makes for a less complex system PCB for peripheral leaded devices , with fewer routing layers . Area-array configurations , on the other hand , allow for much smaller packages for a given pin count . Most current systems use some combination of area-array substrate and leadframe-based packages . <h> Wire-Bond Interconnect <p> Wire bond , developed in the 1950s and 1960s , turned into a massively efficient , high-volume manufacturing technology that still maintains lots of traction today , years after industry pundits predicted its demise . Wire bonds @ @ @ @ @ @ @ @ @ @ substrate designs , and they often are more cost-effective than flip-chip alternatives . <p> With wire bonds , the same chip can be assembled into different package form factors , giving end users flexibility to fit the package that best suits the system or assembly process technology 's needs . Wire bonds are usually limited to the chip 's periphery . When chips are very small or have a large number of I/O , the wire-bond pitch requirements can grow to the size of a die , pushing up costs . <p> The primary electrical deficit of wire-bond technology involves high wire inductance , which can limit signal speed . The signal speed of wire bonds can increase by placing return current wires in parallel with the signals to get near transmission-line capabilities . A rule of thumb , and rules of thumb never fit all cases , is that wire bond technology can work up to 0.5 to 1 GHz . <p> Other wire-bond technology limitations include difficulty in evenly distributing the power and ground across large die , and ensuring the power and ground is noise-free . In @ @ @ @ @ @ @ @ @ @ due to cost and the fact that copper is more conductive than gold . <h> Flip-Chip Interconnection <p> Flip-chip interconnection eliminates the two primary technical limits of wire bonding " it provides area-array interconnect and reduces interconnect inductance , which enables higher-frequency performance . Current flip-chip devices operate at around 25 GHz and can perform at this frequency across hundreds of differential I/O . <p> How do flip-chip interconnects reduce inductance ? They 're usually no more than 30 to 200 mm long , compared to wire bonds that can be 3 to 4 mm long . Assuming the same inductance per unit length , flip-chip interconnects are easily 100 times less inductive . <p> Flip-chip technology also allows all bonds to be made simultaneously , dramatically decreasing the time required to bond the chip to the substrate for high-pin-count devices . Overall , the flip-chip area-array approach allows for more uniform power and ground distribution across the die compared to wire bonding . <p> So , why has n't flip-chip technology become universal since its introduction in the early 1960s ? Costs and process complexity have been major hindrances @ @ @ @ @ @ @ @ @ @ seems to be matched with an advance in wire bonding . <p> For instance , the cost of bumping a wafer in flip-chip technology remains the same regardless of the yield . On the other hand , with wire bonding , only good die are subject to the wire bonding cost . Flip-chip processes require tight control of device placement , warpage , fluxing , reflow temperature profiles , flux cleanup , and underfill , adding process complexity . Moreover , each flip-chip die typically requires its own custom substrate , compared to the flexibility of a wire-bonded chip on standard leadframes . <p> Differences in the process for copper pillars ( plated on the die ) followed by a thin cap of solder , versus a standard flip-chip solder bump , enable the tighter pitch ( Fig. 1 ) . The tradeoff is a need for tight substrate design pitches and less warpage between the die and substrate to minimize opens with a solder joint that has less collapse height . <h> Embedded Die Or Embedded Package <p> In some instances , it can be advantageous to embed a @ @ @ @ @ @ @ @ @ @ density . Take Texas Instruments ' MicroSiP ( system in package ) solution for a dc-dc converter ( Fig. 2 ) . A controller package is embedded in a substrate that carries the inductor and capacitors required for switching-supply functions , enabling very high density . <p> 2 . Texas Instruments ' TPS82671 MicroSiP contains a power-controller package embedded in an organic substrate with multiple passive components mounted to the surface . It connects to the system PCB via solder balls . <p> Another type of embedded technology is the eWLB or fan-out wafer-level package ( FO-WLP ) ( Fig. 3 ) . The die are mounted face down on a carrier , over-molded , and separated from the carrier , and interconnections are built on the exposed die surfaces . Both package types gain many signal advantages of flip chip without the process complexity of bumping and flip-chip assembly . Of course , process details must be optimized for successful embedding . However , as mass production brings margins of scale , a robust infrastructure is developing . <p> 3 . The FO-WLP is created by mounting multiple die @ @ @ @ @ @ @ @ @ @ them from the carrier , and forming a buildup interconnect on the exposed die side . <h> Multi-Die Interconnects <p> Multichip die packages containing discrete components , originally called hybrid electronics , have also been around since the 1950s and 1960s . From that time , new technologies have steadily improved the interconnection of multiple die within a single package . <p> One of the primary goals of multi-die packaging is to reduce PCB area or system volume . Multiple die can be placed side by side on a single leadframe , bonded together , and bonded to the leadframe . Alternatively , die can be stacked vertically " a controller chip is followed by memory on top , all wire bonded to a substrate ( Fig. 4 ) . <p> 4 . Multiple die can be integrated into a package by stacking and wire bonding them to each other and to the substrate . <p> Side-by-side and stacked die offer many electrical advantages over standard packages mounted on a PCB . Chief among these are reduced parasitic inductance and capacitance , as well as less time delay between the @ @ @ @ @ @ @ @ @ @ . Disadvantages of multichip modules ( MCMs ) include yield hits and process complexity . <p> Higher performance levels are being sought with TSV technology ( Fig. 5 ) . TSVs provide usable conduction paths vertically through the die and can be area-arrayed . <p> TSV technologies have n't permeated the market on a widespread scale as of yet . However , that 's sure to change over the next few years . <h> Package-On-Package <p> A hybrid stacking scheme involves multiple packages stacked on top of each other to achieve the required density ( Fig. 6 ) . Using stacked packages , rather than stacked die , makes it possible to source commodity memory chips from any number of suppliers , enabling market forces to drive down costs . The tradeoff is higher complexity at PCB assembly . 
@@21004904 @1004904/ <h> Understanding HiPot Certification Testing <p> Certifying a new power product to relevant safety standards is an essential part of any design and development process . But faced with a plethora of standards , engineers often need clarification regarding the nature of the specific tests addressing each standard , particularly high-potential ( HiPot ) testing . <p> What types of HiPot tests are there ? Typically , there are two different types of test : design verification ( DVT ) and safety testing , which may take place first , followed by production and customer qualification testing . Confusion can occur sometimes when actual HiPot testing takes place . <p> For instance , misinterpretation of the relevant standard may result in testing a system to higher isolation safety test levels ( 3 kV ac and 4 kV ac ) when the standard only requires production and customer qualification HiPot testing not exceeding 1.5 kV ac or its dc-rectified equivalent of 2121 V dc from input to output or input to ground . <h> HiPot Isolation Safety Testing <p> Isolation and insulation safety testing is among the most critical and @ @ @ @ @ @ @ @ @ @ used to conduct HiPot isolation testing : 3 kV ac and 4 kV ac . For example , standard IEC60950-1 as it applies to ac-dc power supplies found in information technology ( IT ) and industrial equipment requires products to pass an input-to-output isolation test of 3 kV ac . <p> It 's important to know that 3-kV ac and 4-kV ac tests are stress tests for the main transformer only . These tests require the removal of the main transformer from the power supply for testing as a standalone part . Be aware that applying the 3/4-kV ac test voltages to the supply assembly will generate a failure , but it 's not a failure of the transformer as a protection barrier . It will be a failure of the basic insulation parts tied to ground ( Fig. 1 ) . For additional safety verification , running a 1.5-kV ac test checks the system 's two isolation barriers : input to output and input to ground . <p> 1 . A reduced graphic of a typical power supply shows typical insulation points : R is the location of reinforced @ @ @ @ @ @ @ @ @ @ and O represents operational insulation . Tied to ground , points B and O are susceptible to failure under 3/4-kV ac stress tests of the main transformer . <h> A Typical Real-World Example <p> Obviously , end products must meet certain conditions specific to HiPot tests . If they do n't meet these necessary conditions or if an unusual scenario ensues , false failures may appear and possibly damage the power supply . Typical events include damage to input-to-ground and output-to-ground capacitors , primary-side field-effect transistor ( FET ) failures , and surge-protection device failures . <p> A typical real-world example involves a power supply complying with both IEC60950-1 and IEC60601-1 . Under isolation testing from input to output at 4242 V dc ( the rectified equivalent of 3 kV ac ) , a breakdown occurred from the input connection to the chassis . The breakdown happened because the supply 's isolation from the barrier strip to the chassis was specified to withstand a maximum of only 1.5 kV ac ( 2121 V dc ) . <p> The solution , outlined earlier , is to remove the transformer from the @ @ @ @ @ @ @ @ @ @ Alternatively , disconnecting the unit from its chassis and removing its Y capacitors will ensure a passing grade ( Fig. 2 ) . <p> 2 . To avoid a breakdown between the input and chassis during isolation testing at 4242 V dc , it 's necessary to remove the transformer from the supply and test it independently at 3 kV ac . The unit must be disconnected from its chassis , and the C1-4 capacitors must be removed . <p> These test issues are a particular problem in Class I equipment using a protective ground to ensure safe operation . Class II equipment employs double or reinforced insulation to ensure safe operation with no provision for protective ground . Class II supply users are able to test from the input to the output of the unit at 3 kV ac , or 4242 V dc , for IT devices and at 4 kV ac/5656 V dc for medical devices to verify insulation safety . <h> The Unusual Event <p> A not so typical scenario , one that demonstrates the importance of working with a knowledgeable power supply vendor , involves @ @ @ @ @ @ @ @ @ @ testing went very well until it got to the nationally recognized testing laboratory ( NRTL ) . <p> At the NRTL , the unit passed every test except the HiPot test , which was a bit of a surprise since the unit 's power supply carried medical safety approvals along with the necessary ITE approvals . This means the isolation is actually higher than what 's required for HiPot isolation tests . <p> The power-supply vendor verified that the test procedures and power-supply installation were correct . However , although testing was at well above 1.5 kV ac , it was not at 3-kV or 4-kV levels . Neither the vendor nor the OEM understood why the NRTL was testing above 1.5 kV ac , but the lab was quite were adamant that it was required . <p> Further investigation revealed that the test house was testing with such a high voltage because the OEM mistakenly labeled the product as having an input-voltage range from 80 to 264 V ac , the same input indicated on the datasheet for the power supply it was using . As a reaction , @ @ @ @ @ @ @ @ @ @ rather than the standard 240-V ac value . Once realized , the OEM corrected the product label , reran the HiPot test at a standard 1.5-kV ac value , and the product passed . <h> Hindsight <p> In the mislabeling situation , the NRTL should have realized the input was a very non-standard rating and questioned the OEM about it . Unfortunately , the lab did not , costing the OEM a few extra days and a few headaches . But it shows that by working together , the OEM , vendor , and test lab can speed things along nicely to everyone 's satisfaction and safety . 
@@21004915 @1004915/ <h> Passive Intermodulation ( PIM ) : What You Need To Know <p> A : PIM is the generation of interfering signals caused by nonlinearities in the mechanical components of a wireless system . Two signals mix together ( amplitude modulation ) to produce sum and difference signals and products within the same band , causing interference . <p> Q : Where does most PIM occur ? <p> A : PIM is a problem in almost any wireless system but is most noticeable in cellular basestation antennas , transmission lines , and related components . <p> Q : What actually causes PIM ? <p> A : The interaction of mechanical components generally causes the nonlinear elements , especially anywhere that two different metals come together . Junctions of dissimilar materials are a prime cause . PIM occurs in antenna elements , coax connectors , coax cable , and grounds . It is caused by rust , corrosion , loose connections , dirt , oxidation , and any contamination of these factors . Even nearby metal objects such as guy wires and anchors , roof flashings , and pipes can @ @ @ @ @ @ @ @ @ @ makes an excellent mixer . As nonlinearity increases , so does the amplitude of the PIM signals . <p> Q : What conditions are necessary to cause PIM ? <p> A : Typically , two relatively strong RF signals relatively close in frequency are required to trigger PIM effects . The outputs from two or more high-power ( 20 W or so ) transmitters are enough to create the PIM effects . The higher the power used , the greater the PIM signals generated . <p> A : Mixing generally produces the sum and difference frequencies of the two transmit signals f1 and f2 . These signals are f1 + f2 and f1 " f2 . Sum and difference signals are also formed with the harmonics of the transmitter signals . <p> Q : For example ? <p> A : Consider the two cellular frequencies of f1 = 869 MHz and f2 = 894 MHz . Mixing these two signals together produces 894 " 869 = 25 MHz and 894 + 869 = 1763 MHz . These two signals are way out of the cellular bands of interest , so @ @ @ @ @ @ @ @ @ @ the signals that mix with the second harmonic and higher harmonics are the problem . For instance , the second harmonics mixed with the base frequencies produce what we call third-order intermodulation products 2f1 " f2 and 2f2 " f1 . These would be 844 MHz and 919 MHz , respectively , both in the same cellular band . These third-order PIM products are known as IM3 or IP3 . Other harmful signals are the smaller fifth-order signals 3f1 " 2f2 and 3f2 " 2f1 called IM5 . The signals to worry about are mf1 - nf2 where m and n are the harmonic numbers . The figure shows the spectrum generated by PIM . <p> Q : Besides interfering signals , what are the other negative effects on the wireless system ? <p> A : The main effect is on the receiver with its high sensitivity . Interfering signals can raise the noise floor and block desired signals . Interfering signals can also reduce receiver sensitivity . End effects include dropped calls , decreased system capacity , and decreased data rates . <p> Q : What wireless systems are @ @ @ @ @ @ @ @ @ @ methods like CDMA , HSPA , and LTE are the most vulnerable . <p> Q : How do I know if I have a PIM problem ? <p> A : If its effect is minor , you may not know at all . If the problems of receiver sensitivity or interference seem to be present , you may have PIM . To know for sure , you have to test for it . <p> Q : What is the test procedure for PIM ? <p> A : The basic process is to generate two high-power ( typically 20 W or 43 dBm ) RF signals similar to the ones used in the system and apply them to the cable , antenna , or other objects to be tested . If nonlinearity is encountered , PIM will be generated . The PIM signals travel from the cable to the antenna . They also propagate back to the PIM signal source where the test receiver will pick them up and display them . You will need a spectrum analyzer to see the signals . The most problematic signals are the IM3 signals @ @ @ @ @ @ @ @ @ @ made for PIM testing . <p> Q : How is the test procedure conducted ? <p> A : One approach is to try to stress the suspected components involved . For example , you may want to tap on connectors or other components . Flex any suspected cables . You should do this while monitoring the PIM output on the test equipment . Some PIM testers have a feature that can measure and determine the distance to the nonlinear fault . 
@@21004919 @1004919/ <h> The Best of CES 2016 : Day 1 <p> It was a bit of a chore to get to this year 's Consumer Electronics Show , but it was well worth the trouble . The challenge is seeing as much as possible and then writing about it . Here are a few things I saw early on , with a lot more to come . <p> Cima NanoTech 's SANTE ( self-assembling nanoparticle technology ) technology supports very-large-screen capacitive touchscreens ( Fig. 1 ) . It can handle standard displays as large as 85 in. , and the technology can scale to even larger displays . <p> 1 . Cima NanoTech+ ? ? s SANTE technology is a self assembling-nanoparticle approach that can handle this 50-in. display . <p> Capacitive touch is faster and easily handles multitouch supporting dozens of simultaneous contact points , compared to one or two for infrared touchscreens currently used for large displays . The nano particles wind up in a random pattern eliminating the Moire effect that is often seen on more regular touch systems . <p> Automotive technology is getting ever more @ @ @ @ @ @ @ @ @ @ the car ( Fig. 2 ) . The new standard specifies the interface , but the cabling and connectors are likely to be custom for transportation applications . The maximum run length is shorter ( usually 10 to 15 meters ) than regular Ethernet on CAT5 or CAT6 , but the twisted pair cables are a lot smaller and lower cost . It also easily covers most cars and many larger vehicles. - <p> 2 . Marvell+ ? ? s 1000 Base-T1 can handle multiple 4K displays using twisted pair that is not CAT5 or CAT6 . <p> Automotive applications are the initial target for this network interface , and Marvell has a 100 Base-T1 implementation , as well . It would be ideal for other application areas like robotics , where the smaller cabling would be very useful and the more limited connection length would not be an issue . <p> The DragonFly uses an additive approach that builds up each layer . The dielectric ink contains a collection of two tiny particles that contain the two encapsulated parts of an epoxy . The printer deposits the ink , @ @ @ @ @ @ @ @ @ @ . This forms the circuit board , while the silver ink provides the conductive surfaces and via 's . It does not need holes because of the way the way the PCB is created . <p> The system is ideal for prototypes and custom solutions . There were many challenges to overcome because the characteristics of the silver ink are different from copper that would be used in conventional PCB production . Having the same characteristics is important because the prototype needs to replicate the final product . One way this is done is by increasing the vertical ( Z ) height when using the silver ink. - <p> This is all I have time to write about right now , as I am off to see more of what is at CES . So stay tuned : There will be more about each of these and the other products and technologies I get to check out at CES in the near future . 
@@21004921 @1004921/ <h> Understanding Trusted Computing From The Ground Up <p> Donald Palmer , General Micro Systems Nov 12 , 2012 <p> Why is trust related to computing such a big deal ? Imagine if the data on your computer is visible to others . Or , what if others have changed the data on your computer ? Trust does n't only refer to " secrets , " it also encompasses the ability to count on your computer to act the way you expect it to , without unanticipated crashes and appearance of viruses becoming part of your computing routine . These issues have made " trusted computing " the electronics industry 's biggest 21st-century buzzwords . <h> Table of Contents <h> Introduction <p> Along with the exploding interconnectedness among computers and other devices , the issue of cyber security has grown into one of great concern , since all devices are open to attack and compromise whether they are network connected or even offline . It was this concern that brought many of the heavy hitters in the computing world - including AMD , Hewlett-Packard , IBM , Intel and @ @ @ @ @ @ @ @ @ @ known as the Trusted Computing Group . <p> The Trusted Computing Group ( TCG ) formed to improve trustworthiness on information systems by defining , developing and promoting open , vendor-neutral , globally respected industry standards that would support a hardware-based " root of trust " in computing platforms . A root of trust is defined by the TCG as " a component that must behave as expected because misbehavior can not be detected . " The group 's goal came to be the development of an integrated circuit that meets TCG specifications ranging from protecting privacy and backward compatibility ; to technology that is interoperable , and that keeps data portable and accessible . <h> Security Starts With Measurement <p> Some of the concerns relevant to a discussion of trusted computing include whether a trusted system booted the computer , the system is still running on the computer , the running system is approved for the application and whether the system has access to trusted network service . <p> Gathering evidence is the only way to prove that a computer system has not been changed or modified . Once @ @ @ @ @ @ @ @ @ @ , each of the questions above can be answered . In order to do this , a baseline must be established . By comparing a baseline measurement against the measurement taken every time the computer is powered on , the decision of trust becomes an evaluation of the evidence . <p> A baseline measurement does not refer to length , width or weight , but rather what specific devices comprise the computer system . This can include anything from the make and model of keyboard to the fact that the system is powered by a particular processor . For example , General Micro Systems ' SZC91X system incorporate an Intel Westmere processor because it incorporates the necessary security functions : It supports Intel 's second generation Virtualization Technology ( VT-d2 ) ; supports the TPM ; and supports Trusted Execution Technology ( TXT ) for secure system operation . The system has 96 Gbytes of ECC DDR3 1333 MHz RAM , and a hard drive attached to a SATA port housed in a rugged case . <p> Once you have all the configuration data , it can be encrypted , @ @ @ @ @ @ @ @ @ @ encrypted data and the encryption key are stored separately , where no one else except a registered user can find them . This provides a safe and secure measurement of the computer 's hardware that can be used as evidence to prove the computer can be trusted . <p> The same security specifications that are used with hardware are applicable to software , so it too must be measured . There are several different methods to measure the software , each having individual , complex algorithms . As with hardware , the goal is to establish a measurement of the software on the computer , encrypt it and store the data where it is safe . <h> The Trusted Platform Module <p> Several specifications came out with the inception of the Trusted Computing Group . The most important of these are the actualization of its goal related to the Trusted Platform Module ( TPM ) , as well as the related Trusted Software Stack ( TSS ) . Together TPM and TSS provide a new level of security that can be applied to existing applications and can be utilized with @ @ @ @ @ @ @ @ @ @ A TPM ( Fig. 1 ) is a microchip designed to provide basic security-related functions . The TPM is usually installed on the motherboard of a computer or laptop , and communicates with the rest of the system using a hardware bus . <p> Figure 1 . The trust centers around the Trusted Platform Module involve hardware and software to endow a system with the ability to behave as expected . ( General Micro Systems ) <p> Computers that incorporate a TPM have the ability to create cryptographic keys and encrypt them so that they can be decrypted only by the TPM , a process called " wrapping " or " binding . " Each TPM has a root " wrapping " key , called the Storage Root Key ( SRK ) , which is stored within the TPM itself . The private portion of a key created in a TPM is never exposed to any other component , software , process or person . <p> Computers that incorporate a TPM can also create a key that has not only been wrapped , but also tied to certain measurements . @ @ @ @ @ @ @ @ @ @ platform measurements have the same values that they had when the key was created . This process is called " sealing " the key to the TPM . Decrypting it is called " unsealing . " <p> Secure computer operation is made possible by the TPM through three main blocks of operation , starting with the cryptographic processor , whose main function is to generate the encryption keys ( Fig. 2 ) . The TPM processes commands and data from the host system , then specific responses are relayed back to the host system though the hardware bus . <p> Figure 2 . Caption : This block diagram illustrates the encryption keys incorporated in the Trusted Platform Module that together form the heart of the TPM 's capabilities . ( General Micro Systems ) <p> The data stored in Persistent Storage , the second major block , can only be accessed through the use of the encrypted SRK , embedded in the TPM security hardware . This key is required to open up the block for use by application software , and is used to protect TPM keys created by @ @ @ @ @ @ @ @ @ @ the TPM . <p> The third block is the Versatile Storage area , which is used to store keys generated either by the TPM or by others . <h> Booting Up <p> Establishing a root of trust when a computer is powering on is the first step toward cyber security , since this is when measurements are conducted and stored . This process ensures that access to data in a platform could be denied if the boot sequence is not as expected . Because most system " attacks " occur while a computer is running , a " run-time " root of trust must also be established . Created by periodically refreshing , re-evaluating and representing the " evidence , " the run-time root of trust will detect many system attacks . Virtual machine support can extend secure boot support to guest operating systems ( Fig. 3 ) . <p> Figure 3 . This diagram shows how hardware and BIOS are verified using Trusted Execution Technology ( TXT ) , of which TPM is a part , to enhance computer security . ( General Micro Systems ) <p> The sequence @ @ @ @ @ @ @ @ @ @ department of mathematics at the University of London ( March 2010 ) . It notes that when booting up a system containing a TPM , the process begins with the BIOS Boot Block ( BBB ) , also called the Core Root of Trust for Measurement , which measures its own integrity and the integrity of the entire BIOS . It stores the details of the measured components in the Stored Measurement Log ( SML ) , saving the integrity measurements ( hash values of the component measured ) in a TPM Platform Configuration Register ( PCR ) . <p> The BBB then passes control to the BIOS , which contains a Measurement Agent ( MA ) , responsible for measuring the option ROMs , storing the details of the measured components in the SML and the integrity measurements in a TPM PCR . Control is then passed from the BIOS to the option ROMs , which carry out their normal operations and pass control back to the BIOS . The BIOS then measures the OS Loader , and stores the details of the measured component in the SML and @ @ @ @ @ @ @ @ @ @ is then passed to the OS loader , also containing an integrated MA , which carries out its normal functions and then measures the OS , stores the details of the measured component in the SML and the integrity measurements in a TPM PCR . Finally , control is passed to the OS . <h> How Real Is The Need For Trusted Computing ? <p> Trusted Computing with a TPM offers a significant advancement in platform security if all of the features are utilized . It offers assurance related to software-based attacks from malicious code , Trojans , viruses and root kits , as well as providing platform configuration information when requested . Its strength is in its ability to measure components on a platform in a way that can not be bypassed by code running without the knowledge of the core root of trust supported by the system 's various measurements . <p> In the 2007 E-Crime Watch Survey conducted by the U.S. Secret Service , Carnegie Mellon University Software Engineering Institute 's CERT program and Microsoft Corp. , four types of risks were studied to determine the security @ @ @ @ @ @ @ @ @ @ . The risks selected were Compromise of information , Technical failures , Unauthorized Actions and Compromise of functions . <p> It was found that a TPM reduced the risks by 33 percent to 67 percent across most of the risks . The TPM was most effective on risks associated with " Compromise of information " and " Unauthorized actions , " which are especially applicable to all kinds of regulated environments because these risks can invalidate data . Even worse , they could allow a regulator or operator to shut down business operations if compliance can not be demonstrated . <p> Trusted computing has been a necessary and logical outgrowth of our changing world , and goes hand-in-hand with the continued interconnectedness of computing devices , as well as the number and kinds of threats arising . Since threats are always changing , keeping encryption technology current is a constant challenge . Another challenge has been to consistently address the arguments of critics regarding the balance of security and privacy in trusted computing . These issues form the basis of continual study and development by companies that specialize in computing @ @ @ @ @ @ @ @ @ @ both security and privacy are equally important contributors to the trust that people have in computing , and in online services and information systems . It is a belief that computers and computing devices should do what people expect regardless of disruption from environmental sources , user and operator error , or attack by hostile forces . Even though computers are not always recognizable in all their various forms , they are present in our cars , phones , homes , appliances , medical devices and military equipment . And the prevalence is only increasing . It is a certain assumption that , especially in an age of cloud computing , people would prefer a computer absolutely bound by code to their bank account , for example . In that case , the only way they could n't access their money would be if their laptop or computer was actually missing . <p> Since September 2001 and the sophisticated forms of terrorism we have experienced , and because we need increased assurance for our troops that fight overseas , our military is one of the proving grounds for trusted computing @ @ @ @ @ @ @ @ @ @ national security is a necessity that design and make embedded computing systems for military use are pioneers in the field , and their technology reflects the latest hardware and software developments . <p> According to statistics reported by Microsoft , since 2007 and the formation of the Trusted Computing Group , about 300 million PCs alone have been shipped with TPMs . As more users share storage , networks , information and infrastructure , the more we all benefit from the TPM solution . Everyone deserves the added assurance regarding security and privacy afforded by TPM computing , along with the edge of interaction with a more secure network at large . 
@@21004926 @1004926/ <h> Tantalum Is Tantalizing , But Ceramics Are The Real Catch <p> In 1999 , Murata Electronics first began to see industry acceptance of ceramic capacitors as substitutes for hard-to-get tantalum caps . Passive-component producers had adapted to the needs of their customers , producing ceramic capacitors with the same , if not superior , benefits as tantalum . And by 2001 , caps made from ceramics and other materials proved they had enough advantages over their tantalum counterparts to become permanent replacements . While some applications are still better served by a tantalum capacitor , most design engineers now recognize that ceramic caps are the caps of the future . <p> The widespread adoption of ceramic caps represents a milestone in the history of electronics . Tantalum capacitors have always been desired for electronics because of their high density , high melting point , and high capacitance . Plus , tantalum is corrosion-resistant to most acids over a range of temperatures . Such features have made the substance increasingly useful over the years , particularly in miniaturized electrical circuitry . <p> It was n't until after World War @ @ @ @ @ @ @ @ @ @ even then , ceramics were n't as popular as products made with tantalum . In part , this was because ceramics could n't provide the same capacitance values as tantalum . Though tantalum was n't perfect ( it 's nearly as rare as uranium ) , an alternative simply was n't necessary . The mindset of " tantalum equals electronics " was hard to overcome . So , what happened ? <p> A scarcity of tantalum powder converged with the rising demand for passive components , producing shortages of tantalum parts . After years of using tantalum parts , manufacturers suddenly needed other options . Capacitor vendors responded with research and development efforts that led to improved engineering and production methods for ceramic capacitors . <p> Many customers were surprised by the way the resulting improvements in design combined with the inherent characteristics of ceramics . The design modifications led to several advantages , including ease of placement , low equivalent series resistance ( ESR ) , nonpolarization , and high voltage . Lower ESR is particularly important because it let 's designers use lesser-value capacitors without degrading performance . But @ @ @ @ @ @ @ @ @ @ cost-effective . <p> As customers realized the design flexibility offered by ceramics , demand for the material surged . Component development engineers could quickly adjust the design of ceramic caps , allowing for drop-in replacements in decoupling , filtering , by-passing , and smoothing applications . It even became possible to customize the ceramic caps in a timely cost-effective manner . In fact , lead times dropped from 52 weeks for tantalum caps to eight weeks for ceramics . Meanwhile , ceramic replacement caps reached capacitance values close to those of tantalum parts . <p> Although smaller caps ca n't achieve the same capacitance as larger ones , they do require less raw material . And , a reduced demand for raw material lessens the likelihood of a material shortage , which raises cost . Since tantalum capacitors are typically much larger than the ceramic type , using ceramic caps can reduce component cost and size . Another benefit is that nickel , the electrode material used to make ceramics , is easier to find and mine than tantalum . <p> The future of ceramic capacitors is very promising . @ @ @ @ @ @ @ @ @ @ will place greater importance on the design flexibility , size , and cost of capacitors . While tantalum is still a useful material , ceramics have proven their value in the market and will continue to do so . 
@@21004928 @1004928/ <h> Use Flyback Converters To Drive Your LEDs <p> The flyback converter topology includes an electromagentic interference filter and rectifier , a MOSFET switch , a rectifier diode , and an opto-isolator . They provide an inexpensive , efficient , and safe solution for LED drivers . <h> - <p> - <p> These days , LEDs are turning up in backlighting , general illumination , and other innovative applications . They provide many performance advantages over their incandescent counterparts . However , they 're also more expensive . <p> LED drivers based on the flyback power-supply topology are inexpensive . They also can provide an isolated output that complies with UL safety requirements in fixtures that are n't double-insulated . <p> Further , it 's possible to include power factor correction ( PFC ) without adding greatly to the cost while enabling dimming with a standard triac-based dimmer . The flyback driver can meet Energy Star requirements from the U.S. Department of Energy as well , making it a very attractive option for offline LED-based light fixtures under 50 W. <p> Basic Operation <p> The flyback converter is based @ @ @ @ @ @ @ @ @ @ utilizes a single high-voltage switching MOSFET and coupled inductor to provide energy storage and transfer to an isolated secondary and single-diode rectifying output circuit . <p> In an LED application , the power-supply output current is regulated instead of the voltage unlike most power supplies . LEDs should be driven with a constant current for best stability and operating life . It is also essential to include open-load over-voltage limiting at the output since this type of switching power-supply circuit can produce very high output voltages ( see the figure ) . <p> When the MOSFET switches on , the current in the primary of the coupled inductor shown in the figure rises linearly . During this phase a magnetic field builds up in the air gap in the center of the ferrite cores . <p> When the MOSFET switches off , the magnetic field collapses as its stored energy transfers to the load through the rectifier diode . The voltage at the inductor secondary rises to whatever level is required for current to flow and permit energy transfer . <p> A capacitor is included at the output to remove @ @ @ @ @ @ @ @ @ @ signal determines the amount of energy stored per switching cycle , which is controlled by means of an error amplifier that compares the LED current with a reference and either increases or decreases the pulse width to regulate energy transfer . <p> Flyback converters may be designed to operate in continuous or discontinuous modes . For simplicity and to aid PFC , Flyback LED drivers usually operate at the border between the two modes in critical conduction or transition mode . This means the switching cycle begins immediately after all of the energy stored in the inductor has been transferred to the output . <p> Current Regulation Methods <p> The output is isolated , so it 's necessary to include an opto-isolator if the LED output current is to be sensed and fed back to the input to control the pulse-width modulation ( PWM ) duty cycle . Since the opto-isolator adds costs and reduces reliability , some designs eliminate it by sensing the primary current to regulate the power . <p> This method works on the assumption that the input voltage and load do n't change significantly and therefore @ @ @ @ @ @ @ @ @ @ to a fixed voltage load such as a string of LEDs . <p> This method is generally adequate for LED drivers designed to drive a specific load from a fixed supply voltage such as 120 V ac . Designs intended to work over a wide input voltage range or with different loads need a closed loop with an opto-isolator . <p> Over-voltage protection is easily implemented if there is already an opto-isolator providing feedback isolation in the circuit . The output current and voltage information can be OR 'd together and fed back to the PWM control circuitry at the primary . However , where there 's no opto-isolator , the voltage needs to be sensed indirectly at the primary . <p> The primary control IC and circuitry normally requires a third winding of the inductor to provide its VCC supply , which is also useful for providing voltage feedback information since it is proportional to the load voltage . It also can provide zero crossing information to the control IC , enabling it to detect when stored energy has been transferred and initiate the next switching cycle . <p> @ @ @ @ @ @ @ @ @ @ of the basic boost topology widely used in power-factor-correcting front-end stages in many power supplies and electronic ballasts . It is therefore possible to obtain a high power factor without adding additional switching stages and inductors simply by operating the circuit from a full-wave rectified voltage without dc bus smoothing and using a similar control approach . <p> This can be done in flyback configuration in the same way as in a boost . A relatively large capacitance is necessary at the output to remove low-frequency ripple though . A small voltage ripple translates to a large current ripple in an LED load due to its steep voltage to current gradient . <p> High-brightness LEDs operate from low voltage and high current , which means that the output capacitor needs to be on the order of 1000 -F to supply a typical 350-mA LED load with acceptable low-frequency ripple . <p> This necessitates the use of an electrolytic capacitor selected for longest possible life and small dimensions . A 105-C rated capacitor with an 8000-hour operating life rating is a good option . <p> As a general rule of thumb @ @ @ @ @ @ @ @ @ @ . The LED driver operating life , then , does n't have to be restricted by the electrolytic capacitor if the maximum operating temperature is kept at least 20-C below the 105-C limit and voltage and ripple current ratings are higher than the maximum output voltage and ripple current of the LED driver . <p> The regulating control loop speed must be relatively slow , requiring several ac line cycles to adjust the PWM on time so that during a single line half cycle the on time varies by only a very small amount . The ac line input current can maintain a reasonably sinusoidal shape to provide a power factor above 0.9 . <p> Although the on time is effectively constant during the ac line cycle , the off time varies because more energy is stored at higher instantaneous ac line voltages . The stored energy per cycle is given by E = -+ . L.Ipk2 where Ipk = V.Ton/Lpri and Lpri and Ton are constant so the energy stored per cycle is proportional to the square of the instantaneous line voltage . The change in off time during @ @ @ @ @ @ @ @ @ @ a variation in on time would . <p> Efficiency And Power Limits <p> The basic flyback converter can provide efficiencies of above 80% at power levels up to about 50 W. The fact that the boost/flyback circuit uses indirect energy transfer , meaning that energy is stored in the on phase and transferred during the off phase , explains why the flyback topology is not efficient at higher power levels as the inductor would need to be large with inherent losses due to imperfect coupling and parasitic elements . <p> Other switched-mode power-supply ( SMPS ) topologies using direct energy transfer offer higher efficiency and smaller size at higher power levels . A dimmable one-stage high-power-factor flyback LED driver may have an efficiency of 80% at 120-V ac input with 33-V dc output at 350 mA , which is 11.5 W. <p> LED drivers requiring a high output current often use a two-stage topology comprising a boost front end followed by a flyback output stage . Since the first stage produces a regulated high-voltage dc bus , the design of the flyback second stage can be greatly simplified and optimized @ @ @ @ @ @ @ @ @ @ high-frequency ripple . <p> Dimming Methods <p> Almost all dimmers are based on a simple triac-based circuit , and most of them use a very basic input and output connection with no connection back to the neutral line . A simple timing circuit produces a firing pulse to the triac gate at some point during the ac line half cycle , which can be adjusted by a potentiometer , allowing the triac to be fired at almost any point . <p> The triac switches on and conducts only after firing and continues to conduct until the current flowing through it drops behold a fixed threshold known as the holding current , which normally occurs at next zero crossing . This works with purely resistive light bulbs because of the relatively low resistance path back to neutral for the load current , which allows the gate trigger circuit to be referenced to the output . <p> Simply having a high power factor does not enable an LED driver to be dimmable . Connected to capacitive loads such as electronic ballasts and power supplies , dimmers are susceptible to erratic switching on @ @ @ @ @ @ @ @ @ @ inductors and capacitors . This can cause the triac current to drop below the holding current and switch off and then back on again several times during a cycle , resulting in severe flickering . <p> Even a high-power-factor power-supply input circuit represents a capacitive load , but it does have the advantage of drawing current from the ac line for the complete cycle or from the triac firing point until the next zero crossing . For smooth dimming , the challenge is to avoid false triac switching caused by the ringing produced by the large dV/dt that occurs when the triac is initially fired . <p> Conclusion <p> The flyback-based LED driver makes sense at power levels below about 50 W where isolation is a requirement . But since it is less efficient than a buck regulator , it makes little sense for non-isolated designs . With the techniques discussed here , a simple and cost-effective design can be produced with high power factor and dimming capability . The flyback is less suited for drivers required to produce more than 350-mA output since large-output capacitors are needed , and @ @ @ @ @ @ @ @ @ @ 
@@21004929 @1004929/ <h> What 's The Difference Between Bluetooth Low Energy And ANT ? <p> Wireless networks originate from an array of wireless technologies , such as Wi-Fi 802.11 , Bluetooth , ZigBee , Z-Wave , WirelessHART/Dust Networks , ISA 100a , multiple versions of 802.15.4 , and a mix of ISM-band-based ( industrial , scientific , and medical ) proprietary versions . But due to complexity and high power consumption , many are less than ideal for some sensor networks . <p> In applications that emphasize battery power , battery life , and low maintenance , even fewer technologies can pass muster . However , two standards have emerged to address short-range , low-power , low-maintenance networks : Bluetooth Low Energy and ANT . <h> Table Of Contents <h> Wireless Network Topology <p> There are multiple ways to implement a wireless network , depending on the application ( Fig. 1 ) . A wireless node ( each circle in the figure ) may be a transmitter ( TX ) , receiver ( RX ) , or transceiver ( TX/RX ) . Some nodes are just slaves to be monitored or @ @ @ @ @ @ @ @ @ @ to external communications . Some nodes may also serve as repeaters to relay data from one node to another . <p> 1 . The most common topologies for wireless networks are point-to-point ( a ) , star ( b ) , tree ( c ) , and mesh ( d ) . Each node is a transceiver , and each network has a master controller . <p> The point-to-point ( P2P ) link is the simplest form ( Fig. 1a ) . It could be a single transmitter to receiver link , or both nodes could be transceivers . A transmit node would be a sensor . A node connected to an actuator device would be a receiver . <p> Another common topology is the star configuration ( Fig. 1b ) . Multiple nodes connect to a central collection or control node . Thus , it 's called a multipoint-to-point ( M2P ) connection . The nodes do n't talk to one another , just to the central collection point . A star network could work the other way in which the central node broadcasts to all other nodes , @ @ @ @ @ @ @ @ @ @ . <p> A tree network can have many branches ( Fig. 1c ) . This one shows a star network talking to another star network through their central controllers . Another popular configuration for sensor networks , mesh , can be configured into a number of variations ( Fig. 1d ) . The key characteristic is that all nearby nodes can talk to one another . <p> Furthermore , all or most nodes can be repeaters , whereby data may be passed from one to another that 's not directly connected . For example , node F ca n't connect directly to node A because of distance or power limitations , but it can pass the information through other nodes ( e.g. , B or E and C ) . This mesh feature makes it possible to extend the network over a very wide range that 's beyond the normal reach of most nodes . <p> In addition , a mesh network offers great reliability . If one node goes down because of battery or other failure , or a node is temporarily blocked in some way , alternate paths @ @ @ @ @ @ @ @ @ @ Mesh networks tend to be more complex , but the range and reliability they provide may be worth the added expense . <p> All of these networks have a central control or collection node . It could be a laptop computer , a cell phone , or some special router device that connects to a local-area network ( LAN ) or the Internet . This master control point stores and forwards the information to the appropriate destination . <h> Applications <p> Most low-power wireless networks find homes in consumer , medical , health , sports , and fitness applications . These mobile applications require small size and coin-cell power that can function for years without attention . Possible use cases include : <p> Consumer <p> Electronic leash to locate people or things <p> Proximity detection for use in identification , authentication , and wireless locks <p> RFID-like cases <p> Automatic meter reading <p> Toys <p> Automotive applications <p> Home area networks <p> HID ( human interface devices ) peripherals <p> Medical and health care <p> Heart-rate monitor <p> Temperature monitor <p> Other medical instrumentation <p> Body area networks ( BANs @ @ @ @ @ @ @ @ @ @ watches and monitors <p> Heart-rate belts <p> Bike computers <p> Speed and distance monitoring <p> Fitness equipment <p> Other performance monitoring <h> Bluetooth Low Energy <p> Bluetooth Low Energy ( BLE ) , a low-power variation of the original Bluetooth standard that emerged in 1998 . Bluetooth SIG manages , develops , and promotes the standard , as well as certifies products as interoperable . BLE was defined as part of the most recent standard specification Bluetooth v4.0 , which includes the legacy Bluetooth v3.0 and BLE . <p> BLE also is known as Bluetooth Smart " a marketing name for low-power devices . Bluetooth , probably the most widely implemented short-range wireless technology including billions of cell phones ( headsets ) and millions of laptops , will further expand worldwide with the Smart version . <p> Bluetooth Smart uses a different set of technical and radio techniques to ensure very low power consumption . The data protocol was changed to create low-duty-cycle transmissions or a very short transmission burst between long periods . In addition to extremely low-power sleep modes , the low duty cycle allows a Bluetooth Smart @ @ @ @ @ @ @ @ @ @ . <p> BLE still operates in the same ISM , license-free , 2.4- to 2.483-GHz frequency band as standard Bluetooth . However , it uses a different frequency-hopping spread-spectrum ( FHSS ) scheme . Standard Bluetooth hops at a rate of 1600 hops per second over 79 1-MHz-wide channels . BLE FHSS employs 40 2-MHz-wide channels to ensure greater reliability over longer distances . Standard Bluetooth offers gross data rates of 1 , 2 , or 3 Mbits/s , while BLE 's maximum rate is 1 Mbit/s with a net throughput of 260 kbits/s . BLE also uses Gaussian frequency shift keying ( GFSK ) modulation . <p> Other BLE features include a 0-dBm ( 1 mW ) power output and a typical maximum range of 50 meters . Latency measures only 6 ms . The combination of an adaptive frequency-hopping technique ( which avoids interference ) , a 24-bit cyclic redundancy check ( CRC ) , and a 32-bit message integrity check improves link reliability . Security is 128-bit AES . P2P and star are the most common network configurations . <p> One key point must be taken into @ @ @ @ @ @ @ @ @ @ . BLE devices do n't interoperate with classical Bluetooth products . However , implementing a dual-mode device could achieve such interoperability if so desired . <p> A dual-mode device is an integrated circuit that includes both a standard Bluetooth radio and a BLE radio . Each operates separately but not at the same time , though they can share an antenna . Several vendors offer dual-mode chips , such as Broadcom , CSR , EM Microelectronics , Nordic Semiconductor , and Texas Instruments . Complete modules also are available from connectBlue ( Fig. 2 ) . <p> 2 . Complete Bluetooth modules developed by connectBlue include a classic Bluetooth module , a Bluetooth Smart Ready module that supports both standard Bluetooth and BLE , and a Bluetooth Smart module that includes only BLE . <h> ANT <p> ANT represents another ultra-low-power , short-range wireless technology designed for sensor networks and similar applications . It , too , uses the 2.4-GHz ISM band . The proprietary protocol is developed and sold by Canadian company Dynastream Innovations Inc. , a subsidiary of GPS personal navigation firm Garmin . So far , its @ @ @ @ @ @ @ @ @ @ implement personal-area networks for performance and health monitoring . However , it 's applicable to all of the other applications described earlier . <p> ANT also uses the very short duty-cycle technique and deep-sleep modes to ensure very low power consumption . It operates for years on a coin cell , too . Each ANT node can operate as a slave or master and can transmit and receive as well as function as a repeater . <p> The ANT protocol is set up to use a single 1-MHz channel for multiple nodes thanks to a time-division-multiplex technique . Each node transmits in its own time slot . Basic message length is 150 -s , while the message rate " the time between transmissions " will range from 0.5 Hz to 200 Hz with an 8-byte payload per message . A 16-bit CRC is used for error detection . Up to 65,536 time slots can be accommodated per channel . If interference is encountered , the node transceivers can switch channels . Once again , modulation is GFSK . <p> ANT+ is a relatively recent addition to ANT . This software @ @ @ @ @ @ @ @ @ @ the collection , automatic transfer , and tracking of sensor data for monitoring all involved nodes and devices . SensRcore , another ANT feature , is a development system that helps developers create low-power sensor networks . ANT transceiver chips are available from Nordic Semiconductor ( Fig. 3 ) and Texas Instruments . <p> 3 . Nordic Semiconductor makes chips for 2.4-GHz wireless networks . Included in this group are a generic model ( left ) , a chip with an embedded ANT protocol ( center ) , and an IC with an embedded Bluetooth Low Energy protocol ( right ) . <h> Comparing The Technologies <p> A number of similarities exist between ANT and BLE , but their differences are stark ( see the table ) . Both are good choices for very low-power applications . ANT has the simplest protocol with minimum overhead , and it supports more different types of network topologies . BLE is a star-only format , while ANT supports all types including mesh . More vendors offer Bluetooth chips and modules versus ANT , though . 
@@21004932 @1004932/ <h> Voltage Regulator ICs <p> What is the function of a voltage regulator IC ? A voltage regulator generates a fixed output voltage of a preset magnitude that remains constant regardless of changes to its input voltage or load conditions . There are two types of voltage regulators : linear and switching . <p> What is a linear voltage regulator ? A linear regulator employs an active ( bipolar junction transistor ( BJT ) or MOSFET ) pass device ( series or shunt ) controlled by a high-gain differential amplifier . It compares the output voltage with a precise reference voltage and adjusts the pass device to maintain a constant output voltage . <p> What is a switching regulator ? In a switching regulator , the input voltage is applied to an LC filter and is controlled by a power switch ( MOSFET or BJT ) . The output voltage is fed back to the switching regulator controller that varies the length of time the power switch is on ( duty cycle ) to keep the output voltage constant . <p> What are some of the switching regulator topologies @ @ @ @ @ @ @ @ @ @ ) , boost ( stepup ) , and buck-boost ( stepup/step-down ) . Other topologies include flyback , SEPIC , Cuk , push-pull , forward , full-bridge , and half-bridge . <p> How does switching frequency impact regulator designs ? Higher switching frequencies mean the voltage regulator can use smaller inductors and capacitors . They also mean higher switching losses and greater noise in the circuit . <p> What losses occur with the switching regulator ? Power losses occur as a result of the power needed to turn on and off the MOSFET . The MOSFET driver must bear this loss . Also , the MOSFET takes a finite time to switch to/from a conduction state to non-conduction state . Hence , power loss will be associated with this activity in the MOSFET itself . These losses are dominated by the MOSFET gate charge and the capability of the drive , in effect the energy needed to charge and discharge the capacitance of the MOSFET gate between the threshold voltage and gate voltage . <p> What are the usual applications for linear and switching regulators ? The linear regulator 's @ @ @ @ @ @ @ @ @ @ a given input and output voltage , so typical efficiencies can be 50% or even lower . Using the optimum components , a switching regulator can achieve efficiencies in the 90% range . However , the noise output from a linear regulator is much lower than a switching regulator with the same output voltage and current requirements . Typically , the switching regulator can drive higher current loads than a linear regulator. 
@@21004943 @1004943/ <h> What 's The Difference Between IPv4 and IPv6 ? <p> If you are using Internet or almost any computer network you will likely using IPv4 packets . IPv4 uses 32-bit source and destination address fields . We are actually running out of addresses but have not fear , the Internet Engineering Task Force ( IETF ) is here with IPv6 . <p> The IPv6 packet ( Fig. 1 ) does n't look much like its IPv4 ( Fig. 2 ) cousin , except for the leading version field . The IPv6 address fields are 128-bits . The larger address space is one reason to migrate to IPv6 but there are many more differences that give IPv6 an advantage . For example , the header checksum field has been eliminated because transport reliability has gone up and its overhead was unnecessary . <h> - Sponsored Resources : - <p> The movement to IPv6 on a global scale is inevitable . It has been more of an issue of getting the infrastructure in place to make the move to cause the minimal number of problems . It is possible for @ @ @ @ @ @ @ @ @ @ issues that vary depending upon the network configuration and the type of network traffic . <p> Here are some of the major differences between IPv4 and IPv6 . Both standards are extensive and many features are less obvious and important for only some environments . <p> The address space is the main difference between IPv4 ( 32-bit ) and IPv6 ( 64-bit ) . The text representation has also been changed from a 2-digit partitioning for IPv4 to 4-digits for IPv6 . An IPv4 example address is 12:34:56:78 . An IPv6 example address is **39;900;TOOLONG . The IPv6 representation also allows double colons ( : : ) to represent a string of zero entries so 1234:0:9abc:0:0:0:0:def0 could be 1234:0:9abc : : def0 . <p> Packets for both IPv4 and IPv6 are variable and they can be up to 64 Kbytes . The problem is that the protocols can be used over a number transports that may have other limits . This is normally specified by the maximum transmission unit ( MTU ) . Both protocols have a minimum MTU requirement . This is 576 bytes for IPv4 and 1280 bytes @ @ @ @ @ @ @ @ @ @ around the network by breaking the data among multiple packet fragments . This is typically done by the host but in IPv4 this can also be done by routers . IPv6 hosts need to determine the MTU for a path to a destination . This approach simplifies routers but adds complexity at the host end . This is normally not an issue and the IPv6 minimum MTU can always be used with any path . <p> The other big difference between IPv4 and IPv6 is the header . There are changes in the number and type of fields and extensions are handled in a different fashion . The IPv6 header is always 40 bytes and can be followed by any number of extension headers and then the data . This approach is more flexible but harder to process since the number and size of additional headers is variable . <p> The first field for each extension header is the next header code that specifies the type . Header should be ordered although only those necessary headers need be included in a packet . If there is a Hop-by-Hop header then @ @ @ @ @ @ @ @ @ @ that the last next header code specifies the upper layer type of data in the payload or No next header . <h> Header Codes <p> Order <p> Header Type <p> Next Header Code <p> 1 <p> Basic IPv6 Header <p> - <p> 2 <p> Hop-by-Hop Options <p> 0 <p> 3 <p> Destination Options ( with Routing Options ) <p> 60 <p> 4 <p> Routing Header <p> 43 <p> 5 <p> Fragment Header <p> 44 <p> 6 <p> Authentication Header <p> 51 <p> 7 <p> Encapsulation Security Payload Header <p> 50 <p> 8 <p> Destination Options <p> 60 <p> 9 <p> Mobility Header <p> 135 <p> - <p> No next header <p> 59 <p> Upper Layer <p> TCP <p> 6 <p> Upper Layer <p> UDP <p> 17 <p> Upper Layer <p> ICMPv6 <p> 58 <p> Today 's network hardware and software often does deep packet scans since many IPv4 protocols needed to implement this type of approach in the data . IPv4 was more limited and had many fields located at fixed offsets making processing easier but it made extensions much harder to implement . IPv4 has a checksum that needs @ @ @ @ @ @ @ @ @ @ changes . In theory , it provides more reliability . IPv6 does not have a checksum field thereby eliminating the field because transmission is more reliable and other mechanisms are used to provide this reliability . <p> Domain Name System ( DNS ) servers provide a distributed mechanism for resolving domain names to IPv4 or IPv6 address . A DNS server can handle both types of addresses using different DNS database records . The A record provides domain name to IPv4 resolution information . The AAAA record does the same except for an IPv6 address . <p> DNS handles IP address to domain name translation as well . This uses the PTR record for both types of IP addresses . These are prefixed by in-addr.arpa for IPv4 addresses and ip6.arpa for IPv6 addresses . <p> Other than address changes , DNS changes for handling IPv6 are relatively minimal . <p> What most people think of IPv4 and IPv6 addresses are Unicast addresses that specify a particular node . IPv4 also has a single Broadcast address for a subnet while IPv6 has Multicast addresses that specify a group of nodes . @ @ @ @ @ @ @ @ @ @ is like multicast in that it can specify multiple nodes but , in terms of delivery , a packet need only be delivered to one node within the group . <p> IPv4 devices have a fixed IP address or obtain one using a DHCP ( dynamic host configuration protocol ) server . 127.0.0.1 is the IPv4 loopback address . <p> IPv6 devices have a fixed IP address or obtain one using a DHCPv6 server . Nodes can also use stateless address autoconfiguration ( SLAAC ) using Internet Control Message Protocol version 6 ( ICMPv6 ) . SLAAC will be used on networks that do not have a DHCPv6 server . It uses Router Advertisements from routers connected to the local network . <p> I will not get into lots of details on address generation for IPv6 but I did want to mention cryptographically generated addresses ( CGA ) . CGA uses a public key mechanism that allows nodes to generate an address and to uniquely identify itself without requiring an external certifying system . Like many IPv6 features , it is optional but having a standard mechanism means it can @ @ @ @ @ @ @ @ @ @ are also allocated in blocks allowing easy subnet specifications . A netmask is often used to specify the number of bits used in the subnet. 192.168.1.0/24 ( the netmask is 255.255.255.0 ) is the typical home subnet used with many gateways . It has 256 addresses associated with the subnet including the broadcast address that is 192.168.1.255 in this case . <p> IPv4 has three private address space blocks . These include 10.0.0.0/24 , 172.16.0.0/20 and 192.168.0.0/16 of which 192.168.1.0/24 is a subset . Private address blocks will never be used for public IP addresses . <p> There is just one IPv6 private address block . It is fc00 : : /7 , also called a Unique Local Address . The specification works just like the one used with IPv4 . This means the block uses 121-bits for local devices . Other special addresses include the : : 1/128 loopback address ( 127.0.0.1/32 for IPv4 ) , ff00 : : /8 multicast , fec0 : : /10 site-local prefix , and fe80 : : /10 link-local prefix . IPv4 addresses are actually mapped to the lower fields of : : @ @ @ @ @ @ @ @ @ @ Some of the big differences between IPv4 and IPv6 include how extensions like security are implemented . The header extensions mentioned earlier are how these features are incorporated . IPsec is now a standard option rather than a specialized protocol with IPv4 . <p> Quality-of-service ( QoS ) is handled a little differently than extensions . The flow label and priority fields are used to provide QoS support . These are found in all IPv6 packet headers although they may be unused if the subnets in a path do not support them . <p> IPv4 and IPv6 subnets have and will continue to coexist even as the overall Internet moves from IPv4 to IPv6 . There are a number of mechnisms in place that facilitate this . These include Stateless IP/ICMP Translation ( SIIT ) , 6rd , NAT , tunneling and proxy server support . Many of the techniques can be deployed in firewalls and routers between IPv4 and IPv6 subnets . <p> SIIT uses : : /96 address and maps the 32-bit IPv4 to the lower bits of an IPv6 address . This allows direct access of IPv4 @ @ @ @ @ @ @ @ @ @ deployment ) uses IPv6 to bridge IPv4 subnets . It tunnels IPv4 packet over IPv6 . It is sometimes a service provided by ISPs . <p> Proxy servers with dual stacks can operate in either direction providing IPv4 access to an IPv6 server and vice versa . Proxy servers tend to be a stopgap measure since each proxy must be explicity configured . <p> IPv4 NAT gateways provide a mechanism for linking IPv4 devices to the IPv6 Internet . Of course , this assumes that the gateway can connect to an IPv6 network . Most of the latest commercial and consumer devices can do this but older devices are IPv4 only . In this case , an additional gateway is required so the IPv4 to IPv6 translation occurs outside a customer 's premises . <p> Dual stack hosts are likely to be common as well . A network can carry IPv4 and IPv6 traffic at the same time . A dual stack host can communicate with either type of device as well as having its traffic routed to the outside world if appropriate . Dual stack routers can be gateways @ @ @ @ @ @ @ @ @ @ fragile and many of the techniques will not work well together . Combine this with IPv4 extensions such as IPsec and other protocols and there is the possibility that connections might be made but applications will not work . The only likely combinations that will work well will be IPv4-to-IPv4 and IPv6-to-IPv6 . <p> One issue that will have to wait for another article is IPv6 security . Because of the differences and features of IPv6 , firewalls and security software need to address additional security issues that IPv4 did not . For example , tunneling solutions mentioned earlier can bring the more open IPv6 into an IPv4 network . It is possible to prevent or mitigate attacks along these lines but only if proper security configurations are used and if the hardware support this . <p> So what happened to IPv5 ? IPv5 is a designation for a variant of the Internet Stream Protocol ( ST ) that started back in 1979 but abandoned . Many of the features of ST are found in Multiprotocol Label Switching ( MPLS ) standard . IPv6 was based on IPng ( IP @ @ @ @ @ @ @ @ @ @ version 7. 
@@21004948 @1004948/ <h> In Honor of an Electrical Engineer <p> I often interview and write about notable engineers and scientists , but today I wanted to talk about an electrical engineer ( EE ) you probably have not heard about . George Wong ( Fig. 1 ) was my father , who recently passed away at age 87 . He had six children with my mother , who is still with us . Two turned out to be engineers including my brother , who has a chemical engineering degree , and myself , who is also a EE . <p> My father was a graduate of the University of Wisconsin . He started studying to be an electrical engineer at Beloit College in Wisconsin and was a co-op engineer for a year . This was back when motors , relays , and vacuum tubes were in the curriculum . <p> 1 . George Wong was an electrical engineer and great-grandfather to my three grandchildren . <p> After college he became a 1st Lieutenant in the U.S. Army Corps of Engineers . He spent time in Korea during the Korean conflict before @ @ @ @ @ @ @ @ @ @ Morse designing DC electric motors and generators in Beloit , where he grew up . He then worked for Beloit Corporation for the next 36 years moving us around the U.S. to various Beloit facilities . This included work as an engineer and manager building paper machines ( Fig. 2 ) and injection molding systems . He received three patents for paper machine technology that he helped develop while at Beloit . After he retired from Beloit he worked as a consultant . <p> You may be using paper that has been made using Beloit machines , although Beloit Corporation went away many years ago . <p> My father was a hands-on engineer who was also involved with woodworking , metalwork , and electronics . We still have an excellent desk he crafted and a Heathkit receiver/amplifier I helped build . <p> One reason I became an electrical engineer was due to his help and inspiration . I remember doing various projects , including resurrecting a black-and-white television set by cannibalizing the vacuum tubes from an identical unit . He had already taught me basic electrical work , including wiring @ @ @ @ @ @ @ @ @ @ , schematics , and basic electronics . I wound up teaching my children these skills , who are now all engineers . My youngest daughter , who is a mechanical engineer , taught some EEs at the University of Rochester when she was a student there how to use a soldering iron , since they never used one before . I expect her to teach her daughter when she is old enough ( she is a newborn at the moment ) . <p> 2 . Beloit paper making machines were large and complex systems . <p> My father helped hundreds of engineers , students , and friends over the years . He was involved in many activities , including Boy Scouts , resulting in three Eagle Scouts ( myself and my two brothers ) . <p> We would not have cars , buildings , smartphones , or the cloud without millions of engineers . We will probably know only a few of them , but they are all important and do much more than just engineering . 
@@21004950 @1004950/ <h> Analog Voting Circuit Is More Flexible Than Its Digital Version <p> R. Jayapal Dec 03 , 2003 <p> Majority voting systems are used to protect critical plants and processes . Such systems find applications in chemical , power , nuclear , and aerospace industries . Here , multiple sensors monitor a critical parameter , and the readings of , say , two sensors ( which are closely tracking ) are taken as correct . But if one sensor fails , the critical parameter is still monitored . <p> Figure 1 shows a typical majority voting system in which three identical initiators ( A , B , and C ) give 0 or 1 logic signals , depending on whether a process parameter " such as temperature , pressure , or level " is below or above the trip setting . These logic signals are passed to a two-out-of-three voting circuit . The voting circuit sends a trip signal to the trip system only if two or more initiators are in a trip condition . This voting circuit follows the expression : <p> Y = AB + BC + @ @ @ @ @ @ @ @ @ @ with the two-out-of-three voting circuit , following the expression : <p> Y = AB + BC + CD + DA + AC + BD <p> Similarly , for a three-out-of-four voting circuit , the following expression applies : <p> Y = ABC + BCD + CDA <p> In a typical high-pressure , high-temperature liquid-level monitoring application , conductivity probes were kept at various levels . Each probe circuit gives a logical 1 output when the liquid level reaches that probe . In view of how critical this measurement is , two-out-of-three logic for tripping was adopted . That is , if the nth probe is set as a trip point , ( n G 1 ) and ( n + 1 ) probes are also monitored . If any two probes go HIGH , the voting circuitry gives a HIGH output for further action , like a trip , etc . <p> For the same application , some users wanted two-out-of-four voting logic , and others wanted three-out-of-five voting logic , etc . With a microcontroller-based circuit , this meant either rewriting the program each time or writing a program @ @ @ @ @ @ @ @ @ @ <p> To eliminate these difficulties , an analog circuit was designed that simplified the selection of the number of initiators and the voting logic ( Fig. 2 ) . The first op amp of U1 is a buffer for the voltage adjusted by P1 . Potentiometer P1 is adjusted to get 1 V at TP1 . U1 's second op amp is configured as an inverting summer , while U1 's third op amp is an inverter . <p> Every probe output going to logical 1 closes the switch corresponding to it in U2 . Closure of each switch in U2 gives a 1-V increase at TP2 . If a two-out-of-three voting circuit is needed , select the appropriate probes through the DIP switch setting . Voting by two probes gives 2 V at TP2 . Set the reference voltage at TP3 to under 2 V but above 1 V. Output Y will be 1 if two or more probes output a logic 1 . Similarly , if two-out-of-four voting is required , select the four probes with the DIP switch and set the reference voltage at TP3 as 1.5 @ @ @ @ @ @ @ @ @ @ of probes selected , and n out of m voting is necessary , select the m probes with the DIP switch and keep the reference voltage at TP3 slightly less than ( n + 1 ) V , but more than ( n G 1 ) + 1 V. With the circuit of Figure 2 , m has a maximum of eight , and n G m . This circuit can be extended for any voting logic , which can be set or altered even in the field . 
@@21004953 @1004953/ <h> Mixing Work And Leisure : A Blurring Line <p> At the end of the workday , some of your fellow engineers head out the door together , perhaps for dinner , drinks , or even a movie . They used to invite you , but you had family activities or night school after work , and repeatedly declined . After all , they were only your colleagues and you had friends of your own to hang out with . But now you 're wondering if that was such a good idea in the long run . The group e-mails often refer to technical solutions arrived at during the course of a few drinks , and you 're beginning to feel increasingly isolated from the group 's problem-solving process . <p> Many technical professionals face this and similar problems . It 's especially the case in a fast-paced technology environment , where hard work and tight deadlines often bring teams together for long periods of intense effort . The lines between work and leisure blur , leading to more work being done outside of the traditional office environment . @ @ @ @ @ @ @ @ @ @ . You may be very interested in fostering and participating in activities with your colleagues outside of work , only to find that they go their separate ways at 5:00 p.m . Good ideas that could be aired out and refined outside of the formal work environment are instead never heard . <p> Does It Matter To Your Job ? Activities outside of the workplace vary a great deal depending on the company . In some cases , there are few if any opportunities for colleagues to spend any time together outside the office . Everyone simply takes separate paths at closing time . At other companies , project teams might meet for dinner after work , during entertainment events on the weekends , and even on daylong or multiday leisure trips . <p> To a large extent , socializing with colleagues is driven by corporate culture . How much you participate largely depends on your interest in doing so and how much effect it has on your job performance . A lot of times , there 's no requirement to participate , and attendance is neither taken nor noted @ @ @ @ @ @ @ @ @ @ friends outside of work . <p> If the latter is the case , why should you care about whether or not and how much those around you socialize with each other ? First , it may have something to do with how much you enjoy your job . If your socialization goals are substantially different from those of your colleagues , then no matter how good the technical work is , there 's a good chance you will be unhappy or dissatisfied with your job . But , if your social goals are similar to those of the corporate culture , then you will simply have more fun and fit in better . If you do n't , then you could feel like an outsider , even after months or years on the job . <p> Second , it may affect your ability to do your job , or how you 're perceived about performing your job . If you head immediately off to your family or night school at the end of each workday , you might find that your managers question your commitment to the project . Plus @ @ @ @ @ @ @ @ @ @ you 're not present when some critical decisions are made . <p> Only you can gauge your interest in socializing with your colleagues . You may enjoy meeting after hours or on weekends with your colleagues , especially if you 're young and have similar interests . In other situations , you might have a full life outside of work , involved with family , friends , or the community . Even if you do n't have the same social needs as your fellow engineers , you may be comfortable with your job and at the same time be different socially . <p> Socializing that has to do with job performance , however , is something you should understand and address in your career . It can be overt . For example , your group may have an annual " team-building event " involving a daylong or even weekend exercise learning how to function as a team outside of the office . Not participating , even while providing a good excuse , automatically makes you less of a team member . <p> These situations are easy to identify . Plus @ @ @ @ @ @ @ @ @ @ decline to participate , at least the choice and the consequences are easy for you to identify . But that 's not the case when the socialization rules are less formal , yet exist nonetheless . You may be unhappy without knowing why , while your managers and colleagues also are unhappy with you . It 's important to identify the unwritten rules that a company , department , or project group places on socialization , and then determine how you plan to navigate through those rules . <p> You can start finding out what you need to know during the interview process for a new job , if you proceed diplomatically . You could ask questions about how the project team makes decisions , and how management feels about the work-leisure boundaries without appearing overly concerned about whether or not you will arrive at home on time every day . Consider when you make your best technical decisions . Notice how the engineers on the team typically interact with one another . And , ask yourself how to build teamwork in the department . <p> Another thing that you @ @ @ @ @ @ @ @ @ @ the company 's parking lot at the end of the day and observe people leaving the building . If people tend to leave the building alone , and right at the end of the official business day , chances are high that there 's little after-hours interaction among the professional staff . On the other hand , if people leave in small groups , spaced over a period of several hours , they most likely spend some relaxation time together before going home . <p> People already working for the company are your best source of information . Even if they do n't work in the type of job or department in which you are seeking employment , they will be able to tell you something about that company from an inside perspective , especially the way that the staff interacts . <p> Getting To Know Your Colleagues You might wonder how you can meet these people . If the company is a large employer in the general area in which you reside , you probably already know someone working there . Ask around . If one of your friends @ @ @ @ @ @ @ @ @ @ know someone themselves . Otherwise , night school classes and community activities provide good arenas for meeting people who work for the employers that you 're interested in . With a little bit of research , it 's possible to find out about how colleagues in that company work and " play " together . <p> The biggest problems may arise when you 're already in a job , as you gradually find your socialization goals greatly differ from those of your fellow engineers . This actually wo n't be a problem unless it affects your job satisfaction or your perceived performance . <p> Is it possible to attain success in a job under these circumstances ? Yes , but it takes some work on your part . You can do so by being upfront about your after-hours commitments with your colleagues . That way you will keep up-to-date on decisions or technical plans made after hours , and you can maintain your working relationships with your fellow engineers . You may even grow into a new role , becoming the sounding board for ideas that the group developed after @ @ @ @ @ @ @ @ @ @ seek to encourage after-hour activities , start modestly and do n't try to immediately tie it into work . Consider organizing a weekly or even monthly dinner in which people who enjoy talking to one another are given the opportunity . When I was a college professor , I offered my graduate students just that type of gathering . Those who participated had jobs , families , and school responsibilities , but those who attended then still continue eight years later . <p> How about organized , company-wide activities ? Many companies hold company picnics , lunches , holiday parties , and even dances or daylong outings for employees , and sometimes their families as well . In many instances , the company subsidizes some or all of the cost for these events . Often the parties occur on company time , although some may start on company time and extend into the evening hours . <p> These are the types of events that you should consider attending , even if you do n't participate in informal group or departmental gatherings . Rarely are business or technical topics discussed there @ @ @ @ @ @ @ @ @ @ leaving early . Go and eat the food and watch the people . Consider it as inexpensive entertainment , nothing more or less . <p> However you do it , recognize that you need similar socialization attitudes to those you work with in order to be happy in your job . Seeking that out and fitting into the type of culture you 're most comfortable with is one of the keys to a satisfying job and work environment . 
@@21004956 @1004956/ <h> The Dirty Little Secret of Software Pricing <p> Mr. Customer , our price is $13,349 per floating development seat . Larger teams need more support , so we charge an additional 20 percent for maintenance and support . Runtimes start at $800 per core and decline through a series of levels with volume down to a few dollars each . Would you like the optional tool package ? Great , that will be $7,500 . <p> It sounds well thought out and justified . Does n't it ? It is thought out , but sorry , it 's based on fiction . <p> Software pricing has always been controversial . Moreover , as the evidence mounts that open source does not control costs , it has become even more critical . How much is software worth ? Who should pay for it ? What 's fair ? Should vendors charge per floating license , per user , or for support only ? And what about , runtime royalties ? <p> Many business models have evolved over time . Any successful policy must accomplish one key goal : the @ @ @ @ @ @ @ @ @ @ . However , nobody seems to be coming right out and revealing " the dirty little secret of software pricing . " And not understanding that secret costs people , companies , and governments a lot of money . <p> As a long-term vendor of embedded infrastructure software , I feel it 's time everyone knew . You see , the secret is ( shhhhh ! ) : <p> Software pricing today makes no sense . Vendors make it all up . The real goal is to charge in proportion to how much money you have . <p> All the policies are just ways to approximate this rule . The best pricing plans take any metric of a project that correlates to the money involved and charge for that . <p> Why is this ? Partially , it 's because there 's a fundamental business conflict . Software costs a ton of money to produce . Once done , the incremental cost of another customer is very low . Users want to pay that low incremental cost and vendors need to cover the entire cost . This gap must somehow @ @ @ @ @ @ @ @ @ @ ( Fig. 1 ) . The two natural arguments are about cost to the vendor and value to you . <h> Let 's first look at cost . <p> Software is a strange beast . It costs money to develop and maintain . It costs even more money to find and match people to usage ; marketing , sales , and presales support outweigh engineering . It costs nothing to produce and ship . And , it costs nothing to provide to everyone . It does cost , however , to help people use it once they start . And , it takes an ongoing investment to keep it current and on track . Development cost is important , but should not be dominant . <h> Controlling Development Costs <p> Although they are a small part of overall software costs , most cost analyses focus just on engineering development costs . Even within engineering , the biggest cost is actually " maintenance , " or keeping the code base current . " Maintenance " here is in quotes because the line between development and maintenance is vanishingly thin . Good @ @ @ @ @ @ @ @ @ @ that , the real driver of engineering cost is the imperative to keep a single code base . Splitting--copying the source and developing a " branch " -- is orders of magnitude easier than merging . In fact , merging is so hard that an unmanaged branch is almost impossible to merge . Ever . Each branch costs about the same to maintain , so the split doubles costs . Uncontrolled version explosion is death . Any policy that does not recognize that is doomed to failure . <p> This is not always obvious . For instance , government models do n't account for it . Source " repositories " come and go , rights are demanded , open source is encouraged , all in the name of having free access to IP . Yet software costs go up and up and up because cheap software is continuously maintained software . Cheap software has a trained , stable team . And cheap software has a single code base . If you check out the source and modify it , you just bought an expensive branch . Unsupported source with no @ @ @ @ @ @ @ @ @ @ increased engineering hours . Repositories offer only the false economy of letting integrators compete for those hours , thus lowering rates . But , every new team and every new version is very expensive . <p> Simply put , the sole imperative to control software cost is to establish a stable team working on a single code base . Every successful software model has that as its core . More strikingly , this is also the main source of excellence in software . Great , inexpensive software is written by stable teams with controlled code . <p> This fact also explains the unmet promise of open source " community development . " At least for emerging products , there is no stable external team . It can work for mature technologies with huge user bases , or those maintained by users . But coordinating one code base across the diverse team is inefficient . - Long term , efficiency matters . So , the industry ends up with " flavors , " each with a single supporting organization . <h> Real costs and cost justifications <p> - <p> Maintaining an @ @ @ @ @ @ @ @ @ @ develop , telling the world what the code does , and then matching the code 's solution to customers dominate real costs . These responsibilities require a significant ongoing investment in engineering , support , product management , marketing , sales , and services . <p> Unfortunately , you ca n't charge customers for that . Customers demand justification for what their spend . Accountants want countable beans . What 's a vendor to do ? They often strive to bridge the gap by pricing based on some incremental cost metric , but this is fundamentally impossible . Thus , we jump off the real-cost bridge onto the very slippery slope of incremental cost justification . Here are some common explanations : <p> Everyone has to pay for support . This is a common example of questionable cost justification . Companies claim that you pay support fees for everyone because larger teams generate more support load . That sounds reasonable , but it 's not true . In reality , support costs are roughly inversely proportional to the number of people at a site . Large sites develop experts who @ @ @ @ @ @ @ @ @ @ Licenses cost money . Another tactic is to imply there 's a " cost " of providing you a license . Runtime , development , source , and use licenses may carry big price tags , but , let 's be real ; that piece of paper costs nothing . It 's just something to count . <p> We price by what you use to cover our product costs . Bundling is another trick leveraged , often implicitly justified because " more software costs more . " However , since shipping costs are zero , it does n't cost more to ship sixteen pieces of software than it does to ship three . In fact , it costs less . There are no additional support costs for the shelfware the user does n't even open , and you can ship the same package to every customer , an efficiency that does save money . Bundling can help allocate value , but cost justifications are weak . <p> We charge only support and services . The pure-play open-source business model is another example ; the idea is to give away the @ @ @ @ @ @ @ @ @ @ hours . It 's the most straightforward of incremental cost justifications . <p> This sounds good in theory ; you pay only for what you use . In practice , however , it 's often terrible . The user is one entity striving only to solve its own needs as inexpensively as possible . There 's a lot of " the other guy will pay " mentality , resulting in incomplete solutions and their unfortunate consequences . Many users start blindly down the free primrose path , only to run into these issues and find they need far more hours than expected . This surprise can be unwelcomed , to say the least , because many users start without even checking into upgrade or support pricing models . <p> Bottom line : user-paid projects simply do n't reward everything required to support an emerging technology . Following the few of those users who are willing or forced to pay is hardly a way to navigate a dynamic industry . While it works in some cases ( mostly **29;984;TOOLONG or mature technologies ) , revenue hours can be a poor driver @ @ @ @ @ @ @ @ @ @ relationship . <p> Our software is the result of our combined experience with hundreds and hundreds of problems . We 've walked your path before . We have a great team of engineers making sure the product is the best in the world . We professionally track and prioritize requirements of entire markets . We do a very thorough job , through services and sales , of mapping our solution to your problem . We deliver real value , and we do that by reducing your risk , by lowering your development costs , and by guiding your success with the bright light of our experiences . <p> So software delivers very real value . But vendors ca n't list value in this form on a price quote . <p> What do users expect on price quotes ? They expect metrics like developer counts , runtimes , support , and product bundles . Unfortunately , the justifications for these " value " charges are n't usually relevant . Some typical value arguments : <p> Why charge per development seat ? The usual argument is that the software brings value to @ @ @ @ @ @ @ @ @ @ the software , but ( at least for infrastructure software ) the value is really to the project . The software may eliminate an entire expensive and risky team of people from the project , but that one individual working on a GUI display may not even be aware he 's using an underlying commercial product . The system value is more than the sum of the value to individuals . <p> Why charge runtime royalties ? It can work ; enterprise and desktop software is mostly sold by runtimes . Runtimes make sense for quickly-deployed systems , but often not for complex systems with long development cycles . For these systems , the rationale for charging runtime royalties is often " shared risk ; " you only pay if you deploy the code for revenue . But sharing that risk does n't really bring much value . And there are many reasons you may not deploy . For most software , the real risk reduction value is simple : you may get it wrong if you do it yourself . And that is hard to put on a quote @ @ @ @ @ @ @ @ @ @ everyone support gives each engineer the freedom to call . However , as outlined above , that 's often not really valuable at all . <p> And why split the charges into bundles ? So you can select what to buy , even though often that selection is n't ( or should n't ) be optional . You need to get the software that does what you need , period . Bundles are great for helping tune the purchase , but in practice there 's often little real choice . <p> So the rationales are often wrong . Nonetheless , value metrics tend to map reasonably well to how much money you have ( i.e. , projects with more people have more money ) . More runtimes shipped implies more money received . And projects with larger budgets will " see value " and " pay up " for bundles . So , according to the " dirty little secret " values are better metrics than costs . <p> In the end , pricing by a value metric is promising . The real problem is that these metrics get used @ @ @ @ @ @ @ @ @ @ and complex approval chains . That leads to confusion , and confusion leads to surprises . <p> - <h> So what makes sense ? <p> Wellironically , it almost makes sense to charge you based on how much money you have . More precisely , it makes sense to charge in proportion to how much you are investing in your project . If you have a bigger investment , then you face more risk and more pain . You 're thus likely getting more real value , and you should pay for that value . This mapping is n't perfect , but it 's not that bad , either . Seeking this goal drives vendors to " follow the money . " If they do that , then they develop the best product to fit those segments of the market that are in the most pain and will get the most value and therefore deliver the most return . <p> The real message is that this model should be open and fair . That requires striving for simplicity without surprise . There 's little reason to charge against a confusing @ @ @ @ @ @ @ @ @ @ to the size of your project ( e.g. developers or runtimes ) correlates well with value received . It also makes software costs easily modeled . You should be able to choose those few who will interface to support , and only those people should pay . That way , your support interface people can become experts on the technology , thus lowering everyone 's costs . Bundles are fine , but the goal should be to fit the solution to the problem , not just to give the appearance of lower cost . And , if the vendor offers an open source or free version , the cost of discovering the flaws or shortcomings of that free version should be open , easily calculated , and known up front . <p> The burden of making this work does not fall solely on the vendor . Customers must be realistic about software costs . Many of the poor justifications and hidden surprises arise because customers get " sticker shock " when confronted with real costs up front . Customers can ease the process by striving to understand how software companies @ @ @ @ @ @ @ @ @ @ relationship . And , that means paying a fair price for value received . <p> The dirty little secret should not be a secret . It 's just good business . If the pricing is open , fair , simple and without surprise , it all makes perfect sense . 
@@21004959 @1004959/ <p> There are a lot of myths swirling around the home-automation market . In the smart-home arena , connected systems are losing out to point solutions . I talked with Cyril Brignone , Chief Executive Officer of Arrayent , to find out why . <p> Wong : Cyril , you have been involved in the Internet of Things market since 2000 at HP Labs. - What 's changed over the last 15 years ? <p> Brignone : Two changes stand out " the smartphone/tablet and cloud computing . Smartphones appeared and became ubiquitous to the point where nearly half the world 's population owns one . The smartphone is important in a number of ways . First , it has become the volume driver to lower silicon costs . Today you can purchase a Wi-Fi module for less than $5 . That makes it practical to add Wi-Fi into everything you make . Many consumer brands are committed to putting Wi-Fi into everything . Second , it 's a screen that most people carry with them everywhere , so it is essentially a common interface to almost everything . @ @ @ @ @ @ @ @ @ @ no longer have to deal with a crude screen , or non-intuit button/switch interface . <p> Cloud computing is important in that it enables product designers to remove complexity locally and push that complex to the cloud , where computation and memory resources are much more scalable . The cloud is where mobile voice-recognition processing is done for Apple Siri , Google , and Amazon 's Alexa . It is also emerging to be the place where companies can create interoperable systems much more rapidly than was possible before . <p> Wong : And what has stayed the same ? <p> Brignone : The market penetration of traditional central monitored home security , with a $20 to $50 per month subscription , has stayed roughly 20% adopted over this period . And the adoption of DIY home-security systems , with a subscription of $10 a month , remains very small . <p> Wong : Why are n't adoption rates increasing ? <p> Brignone : It 's simple economics : high cost means low adoption . The home-security market is based on a hardware cost subsidized by a subscription contract model @ @ @ @ @ @ @ @ @ @ to install and set up . The upfront cost is too high for any adoption , so the cost is spread across a two- or three-year contract . It 's a business model the wireless carriers borrowed to make $650 smartphones affordable . <p> In the case of DIY security , there is no free lunch . By that I mean that the DIY over-the-top broadband hardware cost might be a little lower than 3G/4G hardware for a monitored security system , but the DIY system still has to be installed . A dirty secret in the consumer IoT space is that things are hard to connect to home networks and hubs . So while there may not be the dollar cost , there is time cost that most consumers today wo n't tolerate. - - <p> Wong : So what 's the solution ? <p> Brignone : First you have to realize that no one wakes up on Saturday morning and says to themselves : " I have a home-automation problem . " Second , recognize what retailers have known for years " consumers go online or drive to @ @ @ @ @ @ @ @ @ @ a point solution to fix their pain . Whether that is to replace a broken or worn-out thing , or buy that cool item that their friend owns . So it is critical to the brand owner to focus on compelling use cases , delivered as point solutions . Essentially , we are seeing a process of one retrofit upgrade at a time . So the smarthome will happen , one point solution at a time . <p> At the same time , it is interesting to note that the home construction industry is looking at making all of their new homes into smarthomes . Just like OSRAM , Whirlpool , and Chamberlain , which are adding connectivity to their products , home-construction companies like KB Homes are building sensing and connectivity capability into their homes . Why ? Early market research shows that the new generation of millennial homebuyers is going to expect that homes just come smart. - <p> Wong : So what 's a consumer-product company to do ? <p> Brignone : For now , be really good at one task/solution to start . Product reviews with @ @ @ @ @ @ @ @ @ @ is only then that you can add more features to your first product . Later add a second and third product that customers will consider buying . Over time , consumers will acquire a number of connected point solutions that are solving problems for them a few times a week . This will take time , of course . <p> And then they will move to stage two , wanting their things to work together . This is the Google Nest strategy . Thermostat first . Smoke detector second ( the Trojan horse is adding more sensors to the home ) , and then the DropCam camera . They have added the Connect to Nest program to grow their ecosystem that already includes products from Whirlpool , Chamberlain , Mercedes , OSRAM , and Philips . These companies can take advantage of Nest 's Home and Away API capabilities for their own products . They are laying the groundwork for connected systems that work the way individuals work. - <p> Wong : What is actionable advice to traditional product manufacturers ? <p> Brignone : The most important thing in a @ @ @ @ @ @ @ @ @ @ you have that , business expansion opportunities open up . People want the product they buy to be compatible with an IoT ecosystem like Nest , Alarm.com , and others . This opens great new sales channels for the product manufacturer . <p> Wong : But not everyone is a Google or Apple with abundant resources to build out a cloud presence . So how can a traditional product company go about getting a cloud presence ? <p> Brignone : We see three approaches : build an IoT cloud yourself ; hire an IT services company like IBM to write one for you ; or buy a commercial IoT platform . In the history of enterprise software , commercial product offerings always end up being cheaper , more fully featured , and more reliable than any one-off software project can be . No one today would imagine writing an accounting , CRM , or ERP system from scratch . This will be the same for IoT platforms , too . 
@@21004960 @1004960/ <h> AC Induction Motors Come In Terminal Boxes <p> The Terminal Box Type AC induction motor family allows the power cable to be fixed with the cable clamp and seal connector to provide greater security for a variety of uses . No terminal crimping is needed as the lead wires are directly inserted into the terminal block . The series includes induction and reversible motor types in 25W , 40W , 60W and 90W output power . Meeting worldwide input power requirements , all single-phase and reversible motors are available in 100 vac , 50/60 Hz , 110/115 vac , 60 Hz , 200 vac , 50/60 Hz , and 230 vac , 60 Hz versions . Three-phase induction motors are available with input power of 200 vac , 50/60 Hz , 220 vac , 60 Hz , and 230 vac , 50/60 Hz . All models are CE Marked and meet UL , CSA and EN standards and are recognized by UL and certified by VDE . Gearheads are available in ratios from 3:1 through 180:1 . The ac reversible motors are used where frequent shaft reversals are @ @ @ @ @ @ @ @ @ @ overrun . 
@@21004961 @1004961/ <h> A Day In The Life Of An Electronics Engineer <p> Richard Gawel Oct 19 , 2006 <p> Based on your submissions , designers everywhere face the same challenges " producing more functionality-while maintaining an elegant design . <p> The latest project at Intelix , the Audisey Series Athena , exemplifies these demands . Available later this year , the Athena provides microphone preamplification , input DSP , true matrix mixing , output DSP , and amplification all in a 3U chassis . It uses a DSP/Class D amplification module , which is the heart of the project . <p> According to Intelix Applications and Hardware Engineer Andrew Kurth , one of the project 's key challenges was providing a cost-effective way to land the module in the company 's existing audio system without a large , costly pc board . To achieve this goal , the engineers designed a board that allows for two modules to be socketed above other surface-mount circuitry , minimizing real estate . The team then used a Freescale MC9S12 microprocessor to control the modules . <p> The following series illustrates a day in @ @ @ @ @ @ @ @ @ @ preproduction Athena . Congratulations to Andrew and the rest of his team , and good luck with Athena and all your future endeavors ! 
@@21004964 @1004964/ <p> is well known for delivering high-performance , system-on-chip solutions . I recently spoke with Kumar Sankaran , Associate Vice President of Software and Platform Engineering at Applied Micro , about their new HeliX 1 family of embedded processors . <p> Wong : During ARM TechCon this year , Applied Micro announced its HeliX 1 family of embedded processors . Can you provide more detail ? <p> Sankaran : The HeliX 1 is the world 's first ARMv8 64-bit system-on-chip solution for the embedded market and is based on the same technology as the X-Gene family , the world 's first server-on-a-chip ( SOC ) solution . While HeliX 1 's and X-Gene 's cores are identical , the input/output ( IO ) mix of the HeliX 1 is different and suited for the embedded market in terms of lower power , fewer cores ( up to four cores ) , lower clock speed for the cores ( from 1.2 to 2 GHz ) , single-channel DDR memory , six PCIe lanes , one/two SATA ports , and multiple USB 3.0 ports . The HeliX 1 also features the @ @ @ @ @ @ @ @ @ @ market segments ( routers and gateways ) , mid-tier storage like NAS , and multi-function printers . <p> Wong : In the coming years , what server markets do you see growing in demand ? <p> Sankaran : In the coming years , the demand for cloud and hyperscale , in-memory databases , and data-analytics markets will grow . In addition , storage , which includes warm and cold storage , will continue to grow at a steady rate . <p> Wong : What do you see as some of the key factors driving ARM in the server space ? <p> Sankaran : ARM-based servers deliver significant cost savings as it relates to total cost of ownership ( TCO ) . TCO is one of the critical factors in data centers today , and decision makers look for TCO savings as the metric to base decisions on . Compared to the competitive landscape , ARM servers provide a significantly reduced TCO in the majority of the workloads used in the cloud hyperscale and high-performance computing markets today . <p> Additionally , ARM has a long-standing history of providing processors that @ @ @ @ @ @ @ @ @ @ power consumption , cooling needs , and physical space require greater capital outlays . With ARM servers , users can achieve not only greater density , but dramatically drive down power and cooling requirements . Coupled with the earlier benefits I discussed , customers utilizing ARM technology can deliver a higher performance-per-watt at a reduced cost point . <p> Wong : As the cloud continues to grow , the demand rises for efficient data-center solutions . How will this shape the competitive landscape and what changes should we expect to see ? <p> Sankaran : As the cloud continues to grow , we will start to see ARM solutions that address all of the market segments mentioned above , including cloud and hyperscale , in-memory databases , data analytics , and warm and cold storage . The embedded community , which has historically used ARM 32-bit cores , will continue to move to ARM 64-bit cores , given the benefits memory bandwidth can deliver and the need for higher performance . Power and performance efficiency will dictate the competitive landscape , and we will see fabrication technology in terms of @ @ @ @ @ @ @ @ @ @ higher performance and lower power in the same die area for a further reduction in TCO . <p> Wong : You recently launched an X-Gene-based development kit . Can you talk a little more about that and the impact ARM in servers has on the developer community ? <p> Sankaran : The X-C1 development kit based on the X-Gene 1 device is in production today and being sold by distributors worldwide . The highly integrated , purpose-built X-Gene solution delivers the highest performance and lowest total cost of ownership for private cloud , public cloud and enterprise applications . <p> The X-Gene development kit includes a hardware reference system and software-development kit featuring production-quality BIOS , compiler , LAMP stack , virtualization and cloud applications ( such as open source search ) , and publishing engines . The bulk of the ARM core infrastructure development is currently being performed using this platform , and we have shipped over 1500 of these platforms to customers and evaluators all over the world . <p> These include the ARMv8 compiler and tool-chain suite for distributors such as Redhat , Canonical , Debian , @ @ @ @ @ @ @ @ @ @ in the ARMv8 community ; BIOS vendors like AMI ; ISVs like Oracle for Java ; and open-source organizations like Linaro . <p> The X-C1 development kit is the first platform in the world to be offered commercially and first to have a real system-on-chip architecture . The platform enables all developers to have access to these key boards , so that every developer can have one on their desk . For instance , the Linaro open-source developer 's community has over 60 boards , and all of its engineers have access to those boards today . <p> Wong : What 's next for APM ? <p> Sankaran : APM will continue advancing the X-Gene family of products , and we will continue to focus on scale-out applications as well as handle scale-up applications in the next-generation products . Our primary focus will be to provide software-as-a-service and optimize applications and infrastructure deployment on the X-Gene SoC solution . Areas of focus include network function virtualization and Openstack , where the features in X-Gene are ideal . <p> Block diagram of the soon-to-be-released HeliX 2 SoC . <p> For our @ @ @ @ @ @ @ @ @ @ will follow the X-Gene train and continue to innovate in specific areas related to the embedded market . Additionally , the HeliX 2 will be announced in the upcoming months . <p> Wong : Anything else to share on the future of the ARM server market for 2015 and beyond ? <p> Sankaran : The ARM server market segment for this year and beyond looks very promising . This is the first year where we will see data centers actually deploying small clusters of ARM servers . Most of our customers have been in evaluations for the past year or more , and we should see the results of these deployments in 2015 . By 2016 , we will see an increase in penetration of ARM 64-bit cores into the server market segment . 
@@21004966 @1004966/ <h> What 's All This Frequency-To-Voltage Converter Stuff , Anyhow ? <p> Download this article and more as part of Electronic Design Library 's new eBook , Focus On : Bob Pease on Analog . <p> Once upon a time " my gosh , it was 30 years ago " a guy asked me if I could show him how to make a Frequency-to-Voltage converter ( FVC ) . Well , at that time , at George A. Philbrick Researches , we knew a lot about analog computers and we figured we could convert almost any signal to any other form or mode . So I designed a charge-dispenser made of a voltage limiter , a capacitor , and diodes . I built it up , and it worked pretty well . <p> And in 1964 we put this into the old Philbrick Applications Manual.1 ( Fig. 1 ) . <p> The first amplifier has a limited output voltage . The p-p voltage across the capacitor is pretty well established : <p> V p-p = 2Vz + 2Vd - 2Vd <p> So , the charge ( Q = C @ @ @ @ @ @ @ @ @ @ the second amplifier . The output voltage will be , on the average : <p> Vout = Rf + C + V p-p + f <p> A few years later , we got into the Voltage-to-Frequency Converter ( VFC ) business . At the same time , I came up with an improved circuit for an FVC ( Fig. 2 ) . The input comparator is set up to accommodate TTL signals , but if you put a resistor from the + input to -15 V , you can accommodate symmetrical signals ; a resistor from the + input to ground will cut down the hysteresis and let you handle small signals . <p> That is what 's required for good linearity " for minimum deviation from the straight line of : <p> Vout = k + Fin + ( error ) <p> Also , note the symmetrical Zener clamp.2 <p> Another cute feature was the adaptive filter at the summing point of the second amplifier . The conductance of the diode is linearly proportional to the current through it , so the 1--F capacitor gives an adaptive time constant @ @ @ @ @ @ @ @ @ @ less at high frequencies . That 's the classical problem with most F-to-V converters : If you want to get low ripple , you get slow response due to the heavy filtering . If you want fast response , it 's hard to get low ripple . <p> After I left Philbrick , I joined National and designed the LM131 voltage-to-frequency converter3 , using completely different ideas than any of the Philbrick circuits . It used Q = I + T , rather than the Q = C + V employed by all of the Philbrick ones . It did n't need -15 V ; it could run on +15 or +30 or +12 or +5 V " much easier to apply . BUT , it still had the same constraint when you used it as an F-to-V converter : If you want low ripple , it 's hard to get fast response . <p> In 1978 , I wrote an application note on how to improve the response time of an FVC " in the Linear Apps Handbook.4 I showed how to cascade two or more fast Sallen-Key filters @ @ @ @ @ @ @ @ @ @ ripple at 24 dB per octave . For example , if you have a frequency in the range 5 to 10 kHz and the frequency suddenly changes , you can get the output voltage to settle to the new level ( within 1% ) in about 40 ms " that 's about 200 cycles " yet the ripple will be less than 5 mV p-p . That 's about a 10:1 improvement over a single R-C filter . Good , but not good enough for some applications . <p> In 1979 , I wrote another App Note5 showing how to use a phase-locked loop to make a quicker F-to-V converter , about 2 ms . That 's about 10 cycles of the new frequency " a further 20:1 improvement . <p> Not bad " but still not fast enough for everybody . For example , in a control loop , you may need a voltage that represents the frequency , and any delay or lag in the information may cause loop instability . So a fast response can be very important . <p> Recently , a guy asked me how @ @ @ @ @ @ @ @ @ @ lag or delay . I told him that the standard procedure is to use a fast clock and a digital counter . But the number of counts collected during one period is linearly proportional to the period of the signal , and you might have to do some digital computations to convert that to a signal representing the frequency . Then I realized that a " multiplying " DAC can be used to divide in a reciprocal mode . <p> I built it up and it worked . This Frequency-to-Voltage converter settles in one cycle of the frequency . Besides that , it uses only a small number of parts ( Fig. 3 ) . <p> The digital logic generates a couple of pulses at the time of each rising edge of the incoming frequency ( you could use some kind of dual one-shot multivibrator , but I did n't have any of those around ) . The first pulse loads the data from the CD4040 into the DAC ( the pulse also disables the path from the clock to the counter to avoid any confusion from rippling in the @ @ @ @ @ @ @ @ @ @ . <p> The MDAC has storage registers built in , so the data from the counter is fed right in to the DAC when the WRITE-2-bar pulse is applied . The MDAC is n't connected in the normal way , with the variable resistance in the input path . The fixed resistor is in the input , and the impedance controlled by the Digital code is connected as the feedback resistor . This permits the multiplying DAC to act as a divider , so the reciprocal function is done neatly " not in the digital realm , and not in the analog world , but on the cusp between them . ( More on this in a few months ) . The LM607BN was chosen for the op amp because you need low offset . It 's cheap , Vos is only 25 -V typical ( 60 -V max. ) , and you do n't need a trimmer pot . <p> The guy who asked me for this function was quite pleased , as he said there are several suppliers who are happy to sell you this function for a @ @ @ @ @ @ @ @ @ @ that big a deal . You can do the whole thing yourself . All it takes is just a few dollars worth of parts and a little labor . <p> The main limitation of this scheme is getting a decent resolution on the output voltage if you must cover a wide range of frequencies . For example , if you have to cover a 10:1 range , let 's say from 20 to 200 Hz , then you can only use a clock frequency of 20 kHz with a 10-bit counter ( or the clock counter would overflow , giving unacceptable false answers ) .6 Then at 60 Hz , the number of counts would be just 333 . The resolution would be only one part out of 333 , or one-third percent . <p> So , if 200 Hz is scaled for 10 V , 60 Hz for 3 V , and 20 Hz for 1 V , then the FVC can only resolve the difference between 60.18 Hz and 60.000 Hz " for example , 3.000 V and 3.009 V. The resolution at 200 Hz would be even @ @ @ @ @ @ @ @ @ @ are so few COUNTS there . <p> If you need to get better resolution , you can get a 4X improvement by using a more expensive 12-bit MDAC and a 80 kHz clock . An 8-bit MDAC , even though the price is right , ca n't give much better than 1% resolution , even if you use it in a dynamic range of just one octave . <p> So , there 's the limitation to this counting method . But you have to admit it is fast and has low ripple ! ( Of course , the other limitation is that if you wanted a fast computation for a 60-kHz frequency , you might need a 20 or 80 MHz clock and counter , not impossible , but not so easy .... ) <p> All for now. /Comments invited ! RAP/Robert A. Pease/Engineer <p> p.s . And in an upcoming column , I plan to write about Voltage-to-Frequency converters , too . <p> How do you like that little Zener bridge circuit that 's inherently symmetrical in its swing ? As near as I can tell , it was @ @ @ @ @ @ @ @ @ @ in Electronic Design , p. 69 , July 5 , 1976 . I sort of invented it about 1971 " has anybody ever seen it before 1976 ? I do n't think I have ever seen any patent on it " and if there had been one , it would have expired by now .... 
@@21004968 @1004968/ <h> What 's The Reach Of Your Wireless Router ? <p> I recently spent some time trying out a Wi-Fi range extender in my home . These devices have been on the market for quite some time . But ever since I purchased a wireless-N router , I 've never felt the need for one . <p> So why did I bother to try the extender ? Two of my relatives recently complained to me that wireless-N is n't serving their needs , and they asked me for suggestions . In one case , a smart TV was the straw that broke the wireless-N signal 's back . In the other , a recent addition of a family room caused the problem . The new room slipped out of the coverage range of the wireless-N router 's signal . <p> In the case of the smart TV , the router was on one side of the house and the TV was on the other side , with lots of rooms in between . I was asked why Netflix did n't work on the new TV . I knew what @ @ @ @ @ @ @ @ @ @ the router to a more centralized location . Among other things , it was in the same room as the cable modem and had a wired connection to both the modem and a PC . <p> With the room addition , the wireless-N router was upstairs and far enough away that it did n't quite cover the new room , so tablets and notebooks could not connect to the Internet from there . The room also seemed to be exhibiting a Faraday cage effect , since wireless worked fine once you stepped out of it . <p> The Wi-Fi extender I tested is the REC10 from Amped Wireless . Released in April , it 's billed as the industry 's most powerful , compact Wi-Fi range extender . As with most Wi-Fi extenders , all you have to do is plug it into an outlet and connect to it with your device . I set up the REC10 completely from my tablet via a Web menu and then used the tablet 's Wi-Fi signal strength indicator to conduct a test . At a location in my house where I usually @ @ @ @ @ @ @ @ @ @ boosted the signal strength to three bars from its more centralized location . <p> The REC10 boasts four amplifiers delivering up to 600 mW power in a 2.75- by 4.0-in. form factor . It is compatible with any brand of router and retails for $79.99 . Actually , the REC10 is probably overkill for my home , but it seems perfect for extending Wi-Fi coverage to the smart TV and devices in the new room . 
@@21004970 @1004970/ <h> Analysis of a Digitally Controlled Wien Bridge Oscillator <p> INTRODUCTION Of all the low-frequency oscillator configurations , the Wien Bridge has to be the friendliest and easiest to get along with . Like a faithful dog , it behaves itself regardless of the weather , is not very temperamental and very rarely chews up newspapers . It uses standard components , gives a good sine wave and is fairly immune to the type of op amp it is designed around . <p> It can , however , be misunderstood , and over simplifications as to its operation can leave the designer thinking that it is not as well trained as originally thought . In pursuit of gaining an understanding of our trusty friend , it is wise to go back to basics . <p> 1 THE CIRCUITThe circuit of a standard Wien Bridge oscillator is shown in Figure 1 . A circuit will oscillate if , at a given frequency , it has greater than unity gain and zero phase shift from input , through the device , through the feedback network and back to the input . @ @ @ @ @ @ @ @ @ @ Figure 1 , R1 and C1 produce a positive phase shifted current with respect to the output voltage . When this current meets R2 and C2 , these components produce a voltage that is phase shifted in a negative direction . At one frequency the phase shift caused by R1 and C1 will be offset by an equal and opposite phase shift caused by R2 and C2 and the net phase shift will be zero . The circuit is now in danger of oscillating . <p> For the mathematically inclined , the transfer function of the network made up by R1 , C1 , R2 , C2 can be considered . Since the output impedance of the op amp will be low and the input impedance of the inputs very high , it is relatively straightforward to derive the transfer function of the Wien Network ( the resistive divider made up of R1 and C1 on the top and R2 and C2 on the bottom ) . One strong cup of coffee and a rainy Sunday afternoon yields the transfer function as : <p> Put simply ( if this is @ @ @ @ @ @ @ @ @ @ 90- phase shift in the transfer function ( either positive or negative ) . The real , non ' j ' terms represent zero phase shift in the transfer function . As the magnitude-of the real and imaginary terms change , so does the resultant phase shift . It can be seen from Equation 1 that at : <p> the real terms in the denominator equate to zero , leaving only imaginary terms in the numerator and denominator . Dividing the numerator and denominator by ' jw ' leaves no imaginary terms and hence no phase shift . We therefore have our condition for zero phase shift at a given frequency . <p> 3 . CONSIDER THE GAINOnce the battle between the real and imaginary terms has ceased and the resonant frequency determined , the transfer function is : <p> Now , to greatly simplify things , it is wise to equate R1 to R2 and C1 to C2 . It can then be seen that at resonance the transfer function from output to input is : <p> To meet the requirements for oscillation ( zero phase shift and unity @ @ @ @ @ @ @ @ @ @ a gain of three to overcome the attenuation resulting from the Wien Bridge network . Looking at this another way , to keep the two inputs of the op amp at the same voltage , the resistor network from the output to the inverting input needs to provide an attenuation of three to match the attenuation of the Wien Network . <p> This is very convenient in theory , but near useless in practice . We can obtain resistors with accurate values but obtaining accurate capacitors is a bit more difficult . Getting capacitors with an accuracy greater than 20% starts to eat into the design budget , so it is now wise to consider the effect of different capacitor values on the performance of the circuit . <p> 4 . CONSIDER CAPACITOR VALUESFigure 2 shows a simple spreadsheet illustrating the values of the Wien Bridge Network and their impact on the gain . Cell B7 is the transfer function represented in Equation 3 , cell B12 is represented by Equation 2 ( with the answer in kHz ) and cell B9 is the reciprocal of cell B7 . If @ @ @ @ @ @ @ @ @ @ = 10K , the circuit will oscillate at 1.59 kHz and the gain of the op amp is 3 . A practical measurement of this circuit backs up this theory . <p> However , the above results were achieved with -10% tolerance capacitors . A quick inspection of a components catalog indicates very similar capacitors designed for general decoupling with a tolerance of -20%/+80% . If this is the case and C1 = 8 nF ( 10 nF - 20% ) and C2 = 18 nF ( 10 nF + 80% ) , then the circuit will need a gain of 4.25 . Inserting these components into the circuit will mean the circuit does not have the required gain ( our circuit only delivers a gain of three ) and the circuit will not oscillate . Alternatively , if C1 is high and C2 is low the circuit will have too much gain and the circuit will oscillate , but with significant distortion . In addition to this , once the circuit is oscillating , the frequency will be incorrect due to the wide tolerance on the capacitor values . @ @ @ @ @ @ @ @ @ @ the point of oscillation . Any less gain and the circuit will stop oscillating ; any more gain and it will start to distort . <p> 5 . ADD A JFET IN THE FEEDBACK NETWORKAs illustrated in Figure 3 , adding a JFET in the feedback network provides a solution to this problem as it can vary the gain over a small range and ensure consistent oscillation . At startup , the FET Gate voltage is at zero , so the Drain " Source impedance is very low . This gives a gain greater than three ( to get the circuit going ) . Once oscillations build up , the diodes rectify the negative transitions of the output , which provides a turn off voltage to the JET 's gate . This reduces the gain and the circuit settles down to stable oscillation . The amplitude of the output is dependent on the voltage drop across the two diodes as well as the turn off voltage of the JFET . Unfortunately , JFETs have a large variation in gate turn-off voltage , meaning the output voltage of the circuit can @ @ @ @ @ @ @ @ @ @ as it has a very low variation in gate turn off voltage , thus guaranteeing a small variation in output voltage from circuit to circuit , but this situation often does not yield the lowest distortion oscillator . The circuit could still oscillate , but with significant distortion and the FET would maintain this oscillation regardless of the distortion . The FET should therefore only be used as a ' tweak ' to keep the circuit going , not to act as a blanket cover of poor circuit design . <p> 6 . INSERT A VARIABLE RESISTOR IN THE FEEDBACK PATHUnless complex circuit design can be tolerated , the simplest way to ensure the circuit starts up and continues to oscillate without distortion ( due to too much gain ) is to insert a variable resistor in the feedback path . The resistor is then adjustedto the point where the circuit just starts to oscillate . This will provide a clean sine wave with the lowest distortion . <p> However , some engineers consider a variable resistor as a simple design solution , but a time-consuming production headache . It @ @ @ @ @ @ @ @ @ @ this makes the circuit difficult and hence expensive to produce . <p> The ideal solution is the insertion of an electronically variable resistor , or digipot . In Figure 3 , replacing VR1 with a digipot provides a low cost , small , simple solution to enable the circuit to be adjusted at production to ensure minimal distortion . It can be used as a single variable resistor , or put in series or parallel with other resistors to provide either coarse or fine tuning of the gain . Once the circuit is oscillating , the JFET takes care of the fine tweaks in gain to keep the circuit going . <p> The circuit of Figure 3 was enhanced with the MAX5467 10K digipot . Since this part has two floating terminals , the part does not have to be ground referenced . Therefore , it can be used to adjust the frequency as well as the gain of the circuit , simply by combining it with either resistor , R1 or R2 , or both . A simple digital interface means the circuit can also be manually adjusted without @ @ @ @ @ @ @ @ @ @ this theory correct . Two 10K digipots were inserted in series with resistors R1 and R2 and , it was observed that the frequency of operation of the circuit could be adjusted from 833 Hz to 1.6 kHz . A digipot was also inserted in place of VR1 and , as expected , the output of the circuit could be adjusted from dc to pure sine wave to distorted sine wave as the gain of the circuit changed . Figure 4 shows the final circuit with the MAX5467 digipots labelled IC2 , IC3 and IC4 . <p> Figure 6 shows a power supply for the circuit . The circuit was powered from 5V . From this a +2.5V and a -2.5V rail were derived using a BC547 transistor . The op amp and digipots were powered from these rails , while the rest of the circuit was referenced to 0V . Figure 7 shows the frequency and gain adjust circuits , respectively . IC2 and IC3 in Figure 4 shared the same digital interface and hence could be incremented and decremented simultaneously . IC4 was used to provide an independent @ @ @ @ @ @ @ @ @ @ round the digipot resistor terminals are connected . <p> CONCLUSIONIn conclusion , the Wien Bridge oscillator is easy to understand in theory , but the practicalities of the circuit can cause the designer frustration . Insertion of a digipot in the three critical areas of the circuit ensures much more stable operation and factory/user adjustability. 
@@21004975 @1004975/ <h> Select The Right Circuit Protection For Switch-Mode Power Supplies <p> Stephen J. Whitney Nov 16 , 2008 <p> Switch-mode power supplies ( SMPS ) continue to replace linear-regulator types in a host of applications . As the need for more efficient electronics accelerates and as a result of their size , weight , and energy-saving advantages , SMPS are being widely used in applications such as LCD TV monitors , PC/ laptop displays , portable electronics chargers , printers , DVD recorders , and even automotive electronics and industrial . <p> Yet because these new SMPS lack the inherent resistance of linear-regulator designs , there 's a growing need for proper circuit protection . Engineering schools generally do not emphasize selection and application of circuit protection devices . As a result , too often many SMPS lack adequate protection . <p> Whether they are external or internal , forward or fly-back conversion units , continuous or discontinuous , each type of SMPS is subject to regulatory requirements . For instance , a power supply for a telecom installation will potentially need to comply with Telcordia or ITU requirements @ @ @ @ @ @ @ @ @ @ the consumer sector , IEC , UL , and CSA standards govern at the equipment level , and a host of other safety testing will be required . There are also IEC , UL , and CSA standards that apply specifically to circuitprotection components . <p> Fuses are ideal candidates for overcurrent protection in SMPS because of their proven safety , reliability , low resistance , small size , and cost effectiveness . Just as there are system-level requirements for the SMPS , there are regulatory requirements for safety and performance at the component level . For example , IEC-60127 gives specific dimensional requirements and also specifies a series of fuse tests . <p> CIRCUIT PARAMETERS OVERVIEWFigure 1 shows the location of a fuse in the ac-mains input of an ac-dc SMPS , such as in a cell-phone charger . The fuse positively interrupts the current flow when a component such as the radio-frequency interference ( RFI ) choke or filter capacitor fails in the short circuit mode . <p> A metal oxide varistor ( MOV ) in the ac-mains input suppresses transient voltages associated with lightning or load switching @ @ @ @ @ @ @ @ @ @ dc bus , further suppress any transients , providing a higher degree of protection for the dcdc converter circuitry . <p> Figure 2 shows an embedded ac-dc SMPS that may be found in a server . In addition to the fuse at the ac mains input , fuses find employment on the high-voltage dc bus and in the housekeeping power supply . <p> Circuit voltage is the source voltage driving the circuit . For safety concerns , it is critical to know because the fuse 's voltage rating must be equal to or greater than the circuit voltage . It is also extremely important that fuses in dc applications have an adequate dc-voltage rating . <p> Maximum normal operating current is the maximum RMS current under full load in normal operation . Maximum potential fault current is the expected maximum current with the source voltage shorted out . Obviously , maximum operating temperature is the anticipated operating temperature of the circuitry near the protection device , under full load , with all shields and covers in place , at maximum ambient temperature . <p> Pulse currents are the transients induced @ @ @ @ @ @ @ @ @ @ those coupled to the ac mains from lightning and load switching . Both the magnitude and duration of the transients and the anticipated number of transients over the lifetime of the equipment need careful consideration . <p> Finally , choosing the mounting method and/or form factor of the fuse comes into play . Options vary to include surface-mount devices , pin-through-hole , pigtail leads , or simply a fuse and a holder . Also critical is the amount of space available for mounting the device . <p> FUSE SELECTION The fuse selection process usually begins by satisfying three basic selection criteria . First , what standards must be satisfied ? For most SMPS products , the answer is a wide variety of international standards , which leads to a fuse that complies with IEC-60127 . Several families of fuses have European , Asian , and North American safety agency approvals to IEC-60127 . <p> Second , what is the maximum operating source voltage ? The most common answer for ac-mains input protection for a SMPS destined for the international market is 250 V ac . Third , what is the @ @ @ @ @ @ @ @ @ @ SMPS is radial or axial lead for direct circuit-board attachment , as small as possible , driven largely by economic and available space concerns . <p> The next step in the selection process is to determine the maximum potential fault current . It is best to do this by analyzing or measuring the path impedance across the input to the SMPS with the SMPS disconnected from the ac mains . This impedance , when added to the estimated impedance of the ac mains , enables one to calculate the maximum potential fault current . <p> Continue to page 2 <p> Let 's assume that this drives the decision to use a **26;1015;TOOLONG 5- by 20-mm fuse with an interrupting rating of 1500 A at 250 V ac . A fast-acting fuse is tentatively the favored component since it is the most economical and provides the closest degree of protection . <p> Once we select a fuse family , we need to estimate the current rating within the family . The initial estimate will involve the calculation or direct measurement of the highest rating that will still provide the required protection @ @ @ @ @ @ @ @ @ @ current waveform with a storage oscilloscope on the line side of the acmains input using a Pearson current probe or a shunt resistor and differential probe . <p> To measure the maximum normal operating current , the SMPS should be operating at full load . Figure 3 shows typical voltage and current levels for a desktop computer SMPS as they would be viewed on the oscilloscope . The yellow waveform ( channel one ) is the voltage across a 0.01-O shunt , which translates into 0.763 ARMS . <p> Since fuses that meet IEC-60127 operate right at their current rating , the next highest rating in the fuse family is 0.8 A. It is important to note that using a fuse meeting UL/CSA standards means a factor of 0.75 would apply since those fuses operate at 75% or less of their rated current , which means that a 1-A fuse would be appropriate . <p> Two additional factors require consideration before one can finalize the fuse 's ampere rating " the effects of pulse cycle withstand and temperature . Referring back to the current waveform in Figure 3 , the @ @ @ @ @ @ @ @ @ @ duration of 2 ms , which can be approximated by a 2-A by 1-ms square pulse with an I2t value of 0.004 A2s . This is approximately 2% of the nominal melting I2t of the chosen fuse , which does not pose a pulse withstand issue . ( Refer here to the manufacturer 's pulse cycle withstand capability information . ) <p> There is also a requirement that the ac input survive five simulated lightning surges of 8 by 20 -s at 1000-A peak with an I2t value of about 5.6 A2s . This drives the fuse selection away from an 0.8-A fastacting fuse to a 3.15-A fast-acting fuse with a nominal melting I2t of 7.9 A2s or a 2-A time lag fuse with a nominal melting I2t of 7A2s . The 2-A time lag fuse is more reliable as it is closer to the normal operating current and will supply better protection in the event of an overload fault . <p> For information on the effects of ambient temperature on current rating , refer to the manufacturer 's temperature de-rating curves . Re-rating based on temperature varies with the @ @ @ @ @ @ @ @ @ @ on the type of fuse selected and the actual measured temperature near the circuit protection device , under full load , with all shields and covers in place , at maximum ambient temperature . <p> TESTING THE APPLICATION Upon fuse selection , one needs to test to prove the concept . One approach is to monitor load current through the application , and the fuse , via a Pearson current probe and simultaneously monitor the voltage across the fuse using a differential probe . <p> While operating the load at maximum current draw , monitor the current to ensure consistent operation and monitor voltage drop across the fuse to ensure a minimal shift . Check the cold resistance of the fuse both before and after testing to ensure the fuse has not opened after testing . <p> While a fuse does not prevent a fault from occurring , it will operate quickly to prevent further damage . By doing so , it maintains the safety of the application and can help to prevent collateral equipment damage . The fuse will also limit the extent of the damage to the application @ @ @ @ @ @ @ @ @ @ making repairs less costly . Proper selection of the fuse is critical . With an understanding of both the application and the fuse , finding a suitable match should be a quick and easy task . 
@@21004978 @1004978/ <h> Troubleshoot A Flyback Supply That Generates Audible Noise <p> While switch-mode power supplies operate at frequencies well above the range of human hearing , they can produce audible noise under certain load conditions . Potential sources of audible noise can vary widely . Noise can be the result of design flaws such as an oscillating output voltage , or it can be generated by noisy components such as capacitors or transformers . In some cases , the high-pitched whine or hissing noise you hear can be something as simple as a cooling fan oscillating at an unusual frequency or the supply 's proximity to an external electromagnetic interference ( EMI ) source such as a fluorescent light or another converter causing a beat frequency due to the interaction of the two . With today 's need for reduced standby power , converters often employ lower average switching frequency modes , which also tend to increase audible noise . <p> Here is an approach to troubleshooting the most common sources of audible noise in flyback power supplies , along with potential solutions to the problem . All of these @ @ @ @ @ @ @ @ @ @ programmable ac source or Variac . Keep in mind that in some cases the audible noise your supply is generating may be so low that it will not present an issue if the power supply is intended for use in a sealed enclosure . <p> Likely Suspects <p> The most common source of audible noise in a flyback supply is a noisy component . Typically , ceramic capacitors or ferrite transformer cores generate this noise . Noise in a ceramic capacitor is usually a product of the reverse piezoelectric effect . When a voltage is applied across a dielectric structure , it can induce a mechanical stress or strain that causes the material to deform . As the material deforms , it displaces the air around it and generates noise . <p> Since the reverse piezoelectric effect occurs during large voltage swings , designers can focus their search on those ceramic capacitors that experience high dV/dt swings . In a typical power supply , they include snubber and clamp capacitors as well as ceramic output capacitors . Do n't overlook auxiliary or bias outputs where low output currents allow ceramic @ @ @ @ @ @ @ @ @ @ if a ceramic capacitor is generating noise , replace it with a metal-film-type capacitor with the same value and appropriate voltage rating . If the noise level declines , you have located a noise source in your circuit . <p> The source of noise may be a clamp capacitor . Try replacing it permanently with a metal-film-type capacitor or a ceramic capacitor using a different dielectric material ( Fig. 1 ) . Another option is to change the type of clamp you are using to , for example , a Zener clamp circuit . If the noise problem lies in a snubber capacitor , consider replacing it with a metal-film type or increasing the value of the resistor in series to reduce dV/dt seen across the capacitor . You can also try to switch to a ceramic capacitor with a different dielectric and see if the noise level goes down . <p> 1 . Noise may be produced by a clamp or snubber capacitor ( circled in red ) . Options include replacing it with a metal film capacitor , increasing series resistance , or using a capacitor with a @ @ @ @ @ @ @ @ @ @ a ceramic output capacitor , try substituting an electrolytic capacitor or changing to a capacitor with a different dielectric . Alternately , try replacing the problem capacitor with multiple ceramic capacitors in parallel . The smaller size of each capacitor reduces surface area and , in the process , changes the mechanical resonance of the capacitors . <p> Transformer-Core Noise <p> Noise generated by transformer cores , on the other hand , typically is caused by magnetostriction , a process similar to the reverse-piezoelectric effect . That is , many ferromagnetic materials change shape when they 're subjected to a magnetic field . As the magnetic field changes the transformer core , it can cause the core to physically vibrate . When this vibration reaches the mechanical resonance frequency of either the transformer core or bobbin , it will be amplified and may become audible . In ac-electrical devices with line frequency transformers that experience 50/60-Hz applied magnetic fields , the maximum length-change happens twice per cycle , producing the familiar 100/120-Hz hum . <p> For switching power supplies , the fundamental frequency is above the audible range . However @ @ @ @ @ @ @ @ @ @ the average frequency and reduce losses . This modulation includes lower-frequency harmonics that similarly create audible noise in the magnetic components . <p> If a new design is experiencing this problem , begin the debug process by ensuring it is not being stressed by an improper design implementation . First , verify that the input voltage and output load the transformer sees match design specifications . If the power supply is run below the specified minimum input voltage or above the specified output load , regulation may be lost for part of the ac cycle . That , in turn , can cause increased flux level swings in the core and generate noise . <p> If input voltage and loading are within specifications , the next step is to verify that the input bulk capacitor value is accurate . An input capacitor that is too small for the application will cause dc-bus voltage to droop too low between ac-refresh cycles , causing a loss of regulation for part of the incoming ac cycle . This will modulate the flux in the magnetic components at twice the line frequency and create @ @ @ @ @ @ @ @ @ @ elements in a transformer includes windings , isolation tape , and bobbins . Each can be a source of audible noise . Current in the coils can produce electromagnetic fields that can generate forces that lead to mechanical vibration in the transformer 's various components . <p> The most effective way to minimize the physical movement of transformer elements is to use an adhesive material or varnish . Dip-varnishing the core , for example , is widely used to prevent the core from vibrating against the bobbin . While vendors offer a variety of varnishing techniques , we recommend using dip rather than vacuum impregnation because vacuum impregnation significantly increases winding capacitance , reduces efficiency , and drives up EMI . <p> If a design calls for a long-core-type transformer , another strategy is to use a standard core length instead . Long-core variant transformers such as EEL- and EERL have much lower mechanical resonant frequencies than long cores . These lower resonant frequencies tend to increase audible noise . Moving to a standard core length with its higher resonant frequencies can mitigate the problem . It is important to @ @ @ @ @ @ @ @ @ @ core may make it necessary to move to a larger core size to supply sufficient winding-window area . <p> Pulse Bunching <p> Pulse bunching is another potential source of audible noise . It occurs when conducted current pulses in a design collect together , followed by an extended number of skipped pulses . This grouping of pulses introduces components into the switching frequency patterns that are often in the audible range . Pulse bunching tends to occur most frequently in power supplies that use on/off or a similar type of control . <p> To determine whether a design is experiencing these phenomena , break the MOSFET drain trace and insert a current loop to monitor the drain current switching pattern . Using a current probe and oscilloscope , capture a set of drain switching pulses on a wide time scale with the supply operating at normal load . Figure 2 compares waveforms showing pulse bunching with normal switching patterns . If the scope displays pulses like the one depicted on the left where a number of pulses in a row are followed by two or more skipped pulses , the @ @ @ @ @ @ @ @ @ @ The drain current pattern on the left illustrates pulse bunching , another source of audible noise . <p> Typically , pulse bunching indicates that the feedback circuit is so slow it is introducing a lag into the controller 's response . Debug this problem by first verifying that all of the component values in the feedback circuit match those specified in the design. - <p> One possible solution is to switch to a D-type optocoupler . D-type devices offer a much higher gain than standard optocouplers . Another strategy would be to add a feedback-loop accelerator circuit to improve response time . This circuit will ensure that the optocoupler transistor always operates in the active region , preventing it from saturating and giving it a faster response ( Fig. 3 ) . <p> While audible noise in a flyback supply can come from a variety of sources , the most common culprits are ceramic capacitors or ferrite transformer cores . If your supply is generating loud audible noise when tested , try these strategies . In most cases you can quickly identify the faulty component and resolve your noise problem. @ @ @ @ @ @ @ @ @ @ Power Integrations . He has been with the company in a variety of senior technology and applications roles since 1996 . He can be reached at email protected . 
@@21004980 @1004980/ <p> Capacitors are used in parallel to provide special performance attributes ; however , it 's difficult to determine critical performance specifics of ESR , high-frequency ripple voltage , and individual RMS currents when they have unequal values . This numerical approach provides a straightforward solution to calculating the values based on published specifications . <p> Capacitors often are connected in parallel in power electronics to decrease high-frequency ripples , current stress , decrease power dissipation , and operating temperature , as well as to shape frequency response and boost reliability . Yet designers have three critical questions about this technique : <p> Cse is directly proportional to the number of capacitors N : Cse = NC , and Rse is inversely proportional to N : Rse =Rs/N. - <p> Ripple voltage V ( RMS value ) is : <p> for a sinusoidal current excitation i(t) = I G2 sin ( 2-ft ) with frequency f , where Xse = 1/ ( 2-fCse ) is the reactance of the equivalent capacitor Cse and RMS value I , and individual RMS currents in the capacitors are identical : Ik = @ @ @ @ @ @ @ @ @ @ are n't identical , with different capacitance Csk and ESR Rsk values , the solution to the problem is n't trivial . The direct approach is to obtain an analytical expression for the input impedance of the parallel connection in the algebraic form Z = Re Z " j ImZ=- Zse Z and use the formulas Rse = Re Z , Xse = I 'm Z , and Cse = 1/ ( 2-f Xse ) . <p> A less complicated approach is based on the conversion of series Csk , Rsk connections to equivalent parallel Cpk , Rpk connections . To obtain relationships between Rpk and Rsk , and also between Cpk and Csk , set the admittance Ypk of the parallel Cpk , Rpk pair and admittance Ysk of the series Csk , Rsk pair connections equal to each other : Ypk = Ysk , Re ( Ypk ) = Re ( Ysk ) , and I 'm ( Ypk ) = I 'm ( Ysk ) . Then : <p> where : <p> is the reactance of the individual capacitor . <p> After individual parallel capacitances Cpk and resistances Rpk are @ @ @ @ @ @ @ @ @ @ capacitance Cpe can be easily found as the sum of Cpk : <p> The real part of equivalent admittance can be found as the sum of admittances 1/Rpk . Rpe can be obtained as a reverse value of that sum : - - - - <p> The system 's equivalent series capacitance Cse and ESR Rse - can be found by conversion of the parallel Cpe , Rpe connection to the equivalent series connection Cse , Rse . To obtain relationships between Cse and Cpe and also between Rse and Rpe , set impedance Zpe of the parallel Cpe , Rpe and impedance Zse of the series Cse , Rse connections equal to each other : Zpe =- Zse , Re Zpe =Re Zse , Im Zpe =- I 'm Zse . Then : <p> where : <p> is the reactance of the equivalent parallel capacitor Cpe ( Equation 5 ) . <p> Based on this analysis , the calculation procedure for equivalent series capacitance Cse , ESR Rse , voltage ripples V , and RMS currents Ik in the capacitors is : <p> Calculate equivalent series capacitance Cse and ESR @ @ @ @ @ @ @ @ @ @ . <p> Obtain RMS ripple voltage V using Equation 1 . <p> Calculate RMS currents Ik in the capacitors based on : <p> Note that ESR values Rsk are strong functions of frequency . A designer should use ESR data specified by capacitor manufacturers at a given frequency of operation , such as the data for ceramic and polymer aluminum electrolytic capacitors from Murata Manufacturing Co . Ltd . ( MMC ) LONG ... <p> To illustrate the calculation procedure , let 's determine equivalent parameters , voltage ripple , and current distribution for a parallel connection of three ceramic capacitors ( GRM21BR60J226ME39L ) and one polymer capacitor ( ESASD40J107M015K00 ) from MMC ( Fig. 2 ) . <p> 2 . This example of four capacitors , with three identical and one different , illustrates how the computation scheme works in practice . <p> This shows the technique can easily determine the parameter values in each of the capacitors . <p> Alexander Asinovski- is principal engineer at Murata Power Solutions Inc. , Mansfield , Mass . He holds BSEE and MSEE degrees from State Technical University , St. Petersburg , @ @ @ @ @ @ @ @ @ @ , St. Petersburg . He can be reached at email protected . 
@@21004981 @1004981/ <h> MEMS Accelerometer Sets Size And Cost Benchmarks <p> Fig 1 . Wafer-level BGA packaging and a patented heated-gas thermal acceleration measurement method combine to produce MEMSIC 's MXC626Xc two-axis digital accelerometer , which is small enough to be threaded into the eye of a sewing needle . It also lends itself to higher integration levels , making it the lowest-cost accelerometer on the market . <p> Fig 2 . The single-chip MXC626Xc integrates all of the necessary signal conditioning and other circuitry . <p> Thanks to its patented thermal heated-gas principle of measuring acceleration and the use of novel ball-grid-array ( BGA ) and wafer-level packaging ( WLP ) , the MEMSIC MXC626Xc breaks records in size and cost . The two-axis , -2-g ( X/Y ) accelerometer produces an 8-bit digital output in a tiny package that measures 1.2 by 1.7 by 1.0 mm at a single-unit OEM price of just 35 cents ( $0.35 ) . <p> The MXC626Xc not only is the smallest and lowest-cost accelerometer in production , according to the company , it 's small enough to literally fit within the eye of @ @ @ @ @ @ @ @ @ @ size , which is approximately 50% smaller than competitive offerings , it can handle a shock of 50,000 g , which is about five times greater than the shock survivability of typical capacitive-type accelerometers . <p> Manufactured on a standard CMOS 0.18--m process , the package integrates all of the necessary signal-conditioning , programming , and processing circuitry including a clock generator and sequencer , a reference voltage and bias-current generator , a control and data register , a PC interface , and a DSP . There 's also a two-axis sensor , an amplifier , an analog-to-digital converter ( ADC ) , and sensitivity , thermal-compensation , and fine-gain adjustment circuitry ( Fig. 2 ) . <p> The MXC626Xc 's small size and low cost suit it well for a number of consumer electronics applications such as mobile phones , digital still cameras , digital video cameras , toys , and MP3/4 players . It is also aimed at home appliances and items like clothes irons , halogen lamps , fan heaters , and cooling fans . <p> The accelerometer detects four-position and shake-detection orientation . Its two-axis acceleration @ @ @ @ @ @ @ @ @ @ coefficient of 0.6 mg/-C . An I2C interface is included for communications with the device , as is an interrupt pin for shake and orientation . <p> The chip operates from a supply of 2.5 to 5.5 V and draws 1 mA of current in the power-up mode . A power-down mode , enabled via the I2C interface , allows a mere 1 -A of maximum current drain . Turn-on time is typically 300 ms , and the operating-temperature range is " 20-C to 70-C. - <p> Since the MXC626Xc uses the heated-gas approach for measuring acceleration , it has no moving parts . It uses resistive heating to heat the gas molecules and thermocouples or other temperature sensors to measure the temperature difference between the two sides of the heater when there is no acceleration and when acceleration is applied . <p> The MXC626Xc is inherently more reliable than capacitance-type accelerometers . It is also amenable to monolithic manufacturing , resulting in lower-cost and higher-reliability solutions Capacitance-type **30;1043;TOOLONG ( MEMS ) accelerometers , meanwhile , use a solid mass structure that measures the capacitance difference between two sets of @ @ @ @ @ @ @ @ @ @ MXC626Xc is available for delivery within eight weeks . Samples are available upon request . 
@@21004983 @1004983/ <h> Synchronous Detection Plays A Role In Better Analog Design <p> Synchronous detection is a measurement method where a stimulus is modulated with some frequency and the response is demodulated to bring the signal back down to base band . Performed when a dc stimulus is not acceptable , it 's widely used in medical and scientific signal conditioning and in capacitive , inductive , or complex impedance measurements . It also allows for the collection of signals in a high-noise environment . Densitydomain signal processing permits inexpensive demodulation , while the averaging of analog-to-digital converters ( ADCs ) enables inexpensive filtering , resulting in a very cost-effective implementation . <p> Although generally seen as a method of AM radio demodulation , synchronous detection is used in test systems to make measurements in some specific narrow frequency band . A synchronous detector consists of a reference value mixed ( multiplied ) with a specific modulation frequency to generate a modulated stimulus signal that is fed to the system under test ( SUT ) ( Fig. 1 ) . The SUT output is again mixed with the same modulation frequency @ @ @ @ @ @ @ @ @ @ around dc and twice the modulation frequency . A low-pass filter is used to remove the higher-frequency components , leaving a demodulated response . <p> If the SUT is a linear system , its response will be a sinusoid with some amplitude VP and some phase delay . Multiplying this output by the modulation signal and also with another reference signal , 90- out of phase , results in Equation 1 . The product of two sinusoids yields the average of two sinusoids , one being the lower frequency difference of the two terms while the other is the higher frequency sum . When it is low-pass filtered , the high-frequency component is removed , leaving only what is shown in Equation 2 . <p> The square root of the sum of these signals squared produces the signal amplitude . Taking the arctangent of the two produces the phase . This is a very straightforward and standard technique for synchronously detecting signals . Its biggest limitation is that it requires two four-quadrant analog multipliers . <p> An alterative method is to use polarity modulators . A polarity modulator has a @ @ @ @ @ @ @ @ @ @ or negative . It 's used to chop a reference voltage ( Fig. 2 ) . This signal is then bandpass filtered to produce a sinusoid of specific amplitude and frequency . It 's in phase with the modulating square wave used to generate it . This is the modulated stimulus , and it is fed to the SUT . The SUT output is again modulated . By exploiting the averaging effect of an integrating ADC , the low-pass filter can be removed . <p> To guarantee complete averaging , the integration time of the ADC must be set to be an integer number of modulator cycles . Fortunately , with a complete system- on-a-chip ( SoC ) , this constraint is easily satisfied . Figure 3 shows the demodulation of a response signal with a 22.5- phase delay . <p> The top waveform is the response with a 22.5- phase delay . The middle waveform is the response signal modulated with the reference square wave . Its average is 59% of the peak . The bottom waveform is the response signal modulated with the reference square wave shifted by @ @ @ @ @ @ @ @ @ @ The arctangent of the ratio of these two averages is 22.5- . Note that the modulated waveform repeats every half cycle . Equation 3 shows the average for a response with a peak amplitude of VP and a phase delay of . <p> With these two equations , it 's possible to isolate the peak voltage and the phase delay of a response signal . Although polarity modulators reduce the cost of synchronous detection , the use of delta-sigma modulation and density-domain signal processing can even further reduce the cost . <p> HOW IT WORKS The density domain allows an analog value to be represented as a digital stream , where logic high represents a positive reference value and logic 0 represents a negative reference value . Density is defined as the percentage of the waveform that is positive . The actual waveform is not important . What matters is the density . Equation 4 shows the relationship between the analog value , reference , and density values . Equation 5 defines the density , given the analog and reference values . With logic high defined as positive and logic @ @ @ @ @ @ @ @ @ @ a density multiplier for two uncorrelated density inputs . Given two analog signals ( A1 , A2 ) and their corresponding density values ( d1 , d2 ) , Equation 6 shows the density output of these XNORed densities . <p> Substituting this value into Equation 4 provides the new analog value as a function of these two densities ( Equation 7 ) . Substituting the density with the analog value defined in Equation 5 into Equation 7 produces the new analog value as a function of the input analog values ( Equation 8 ) . <p> In the density domain , multiplication is performed with an XNOR gate . The delta-sigma modulator ( ? SM ) , which converts an analog input into a digital density output , is commonly coupled with a decimating digital filter to make an ADC . However , the output stream can be mixed digitally to perform a polarity modulation . Figure 4 shows the density output of a ? SM for a sinusoidal analog input . <p> The top digital stream is the ? SM density output . Note that it is mostly @ @ @ @ @ @ @ @ @ @ logiclow for minimum signal . The middle digital stream is the density signal XNORed with the square wave used to make the sinusoid . They are in phase . Note that the output is now high for both the most positive and negative signal amplitudes . The lower logic stream is the density output mixed with a square wave 90- out of phase . Figure 5 shows data with the same setup , only the oscilloscope is set in an averaging mode . This acts as a crude filter on the three logic streams . <p> The top logic stream is reconstructed back to a sinusoid . The middle logic stream is reconstructed to the absolute value of the sinusoid . The lower logic steam is polarity-modulated 90- out of phase . If these two outputs are fed to an integrating ADC that averages for an integer number of cycles , the in-phase result is 2 VP/p , while the one output , 90- out of phase , is zero . Figure 6 shows the more simplified synchronous detector . <p> IMPLEMENTATION We 'll illustrate an implantation of these concepts @ @ @ @ @ @ @ @ @ @ 7 ) . This topology has particular advantages that become apparent in Equation 9 . Taking the difference of two readings removes any offset error , while the ratio of these differences removes any gain error . The accuracy of the reference resister limits the accuracy of the impedance measurement . <p> This particular design is implemented with a Cypress CY8C27443 programmable SoC on a CY3210 PSoC evaluation board . The stimulus signal is a square wave set at 7.8125 kHz . Setting the two pulse-width modulators ( PWMs ) to have a clock of 1 MHz , a 50% duty , and a period of 128 achieves this square wave ( Fig. 8 ) . <p> To guarantee the correct phasing of the two PWMs , both are enabled with an output row ( RO03 ) digital lookup table ( LUT ) . These two PWMs are sequentially started in software but do n't actually start operating until enabled by the LUT to be logic-high in software . These PWM outputs are connected to two adjacent output rows ( RO00 , RO01 ) . The RO00 LUT is used @ @ @ @ @ @ @ @ @ @ ( P0.0 ) . This is the signal used to modulate the unit under test ( UUT ) response . The in-phase PWM is also connected to the broadcast row ( BC0 ) , allowing it to be used to control the band-pass filter 's built-in polarity modulator . <p> Continue to page 2 <p> The analog section contains a band-pass filter designed with a center frequency of 7.8125 kHz and a Q of four . Its output is a 7.8125-kHz sinusoid with an amplitude of 1.15 V and a phase delay of zero . It is connected to the analog output buffer on P0.5 . This is the modulated stimulus . <p> The ADC is set for 14 bits and uses a 4-MHz column clock . This sets the integration time to 16.38 ms or exactly 128 cycles of 7.8125 kHz . The analog part of the ADC is a ? SM . The column 0 analog comparator LUT is set to be an XNOR to modulate this ? SM density stream . A comparator is required to get the modulation signal from P0.0 to the column 1 comparator @ @ @ @ @ @ @ @ @ @ signal MUX to the ADC input . Software is used to connect AGND to the analog output buffer on P0.3 <p> RESULTS For all tests , the reference resister used was measured and found to be 10.02 kO . A Fluke 85 multimeter performed the measurement . For the first impedance test , a 15-kO resistor was measured . The following data was collected for each of the three inputs ( in counts ) : <p> Although this is a purely resistive measurement , there is a slightly out-ofphase component . This is because of delay in the analog path . In a production unit , the phase of the modulation waveforms would be adjusted to compensate for this . Applying this data to Equation 9 results in Equation 10 . <p> This works out to an amplitude of 15.03 kO and a phase shift of 0.6- . When measured with a Fluke 85 multimeter , the test resister value is measured at 14.99 kO . For the second impedance test , a 1000-pF capacitor is measured . The following data is collected for each of the three inputs : @ @ @ @ @ @ @ @ @ @ 11 . This works out to an amplitude of 20.02 kO and 89- phase shift . Equation 12 shows the capacitance value . <p> Delta-sigma modulation easily allows analog signals to be converted to the density domain . Density-domain signal processing and averaging ADCs allow for the inexpensive construction of synchronous detectors in particular and signal multipliers in general . 
@@21004985 @1004985/ <h> Design Balanced Op-Amp Circuits For Performance And Simplicity <p> By cancelling some input errors , balanced ( differential ) analog circuits provide better performance than unbalanced ( single-ended ) circuits , and they also have a simple gain formula . There are several ways to approach the selection of resistors for positive and negative gain in a circuit , especially where the circuit is mixing ( adding ) multiple analog inputs . <p> In a balanced op-amp circuit , the op-amp inputs see equal impedances looking into the circuit . Balanced circuits provide better performance by cancelling some input errors and have a simple RF/RI gain formula that works for all cases , where RF is the feedback resistor that connects from the output to the inverting input and RI is the input resistor that connects the input voltage source to an op-amp input . <p> It 's simple enough . The gain is positive if RI connects to the non-inverting input and negative if RI connects to the inverting input . <p> Alternatively , you can use Daisy 's Theorem to get the balance resistor , which @ @ @ @ @ @ @ @ @ @ circuit must be equal to +1 . The balance resistor adds a ground input to the circuit . Select the ground input gain to satisfy Daisy 's Theorem and you have a balanced circuit . <p> 1 . Analysis begins with a basic differential op-amp circuit with two inputs : a positive one with gain of +5 and a negative one with gain of " 5 . The signal gains sum to zero and need a ground gain of +1 to satisfy Daisy 's Theorem . <p> The procedure works for all combinations of positive and negative inputs . If you have been using the 1 + RF/RI formula , you may have some misconceptions that should be cleared up . <p> For negative gains , the " RF/RI formula is the same as the classical op-amp formula . For a positive gain , the RF/RI gain formula differs from the 1+ RF/RI formula , which only applies to the non-inverting amplifier circuit and only for an input connected to the non-inverting op-amp input . The RF/RI formula applies for all positive inputs in a balanced circuit . <p> A @ @ @ @ @ @ @ @ @ @ the confusion ( Fig. 2 ) . To show that both formulas create the same result , we need to add a balance resistor . The standard circuit has the input connected directly to the non-inverting op-amp input . <p> 2 . In the non-inverting amplifier circuit , balance resistor RB makes the analyses from both perspectives agree and protects the op amp . <p> To protect the op amp and provide a way to balance the circuit , a balance resistor RB has been added . If you select RB = RF in parallel with RI , you will have a balanced circuit , and RB does not affect the circuit gain . Since the non-inverting input impedance is infinite , no current flows through RB , and the non-inverting op-amp input voltage is VIn . <p> The RF and RI labels come from the standard circuit . Note that RI is not a signal input resistor . It is the ground the standard circuit . It has been added above and labeled RB . <p> The results are @ @ @ @ @ @ @ @ @ @ . It comes from how the equations are derived . Classical analysis derives the non-inverting formula using circuit assumptions . If the op-amp gain is large , both op-amp inputs must have the same voltage to create a finite output voltage . This assumption makes the analysis of the circuit simple . <p> In summary , the 1 + RF/RI formula works only for the non-inverting circuit . The RF/RI formula works for all positive inputs in a balanced circuit . There is no conflict . The balanced circuit formula is derived from Plato 's Gain Formula : <p> VOut/VIn = p + ZF/ZI <p> K9 Analysis represents a circuit component as an impedance Z , where Z can be an ideal component , a two-terminal network for a non ideal component , or a resistor . Plato 's Gain Formula is the unified gain formula for a single op-amp circuit . The gain is a constant p times the feedback impedance ( ZF ) divided by the input impedance ZI . <p> For a circuit with equal impedance at the positive ( + ) and negative ( " ) @ @ @ @ @ @ @ @ @ @ or RF/RI for resistors . The gain is positive for inputs connected to the positive op-amp input and negative for inputs connected to negative input . <p> Constant p is equal to " 1 for negative gains and ZP+/ZP " for positive gains . ZPn is K9 notation for the parallel combination of the impedances that connect to node n . ZP+ is the parallel combination of the positive input impedances that connect to the non-inverting op amp input . <p> Since the inputs are ideal sources , this is the impedance seen by the non-inverting op-amp input . ZP " is the parallel impedance of the negative input resistors and the feedback impedance ZF . The ZP terms will vary with the circuit and depend on the number of circuit inputs . For a balanced circuit , the ZP terms cancel and the magnitude of the gain is ZF/ZI . <p> Plato 's Gain Formula is derived via K9 Analysis using nodal analysis . If you 're still skeptical , compare Plato 's Gain Formula to the gain formula in a textbook solution . They should match . If @ @ @ @ @ @ @ @ @ @ input resistor to avoid singularities . ( This may require a bit of algebra . ) <p> The intent of K9 Analysis is to make analog circuit design simple . With the balanced-design technique , op-amp circuit design becomes simple , and you are no longer constrained to existing op-amp circuits . <p> If you are using multiple op amps to implement a linear circuit with a single output , you may be able to reduce the circuit to a circuit with a single op amp . Just get the circuit gains and design a balanced , single op-amp circuit . Keep in mind that one op amp can implement any linear circuit equation . <p> No longer is a single op-amp design with multiple positive and negative gains difficult . You do have to create a balanced design by adding a balance resistor , which determines the ground gain . Since ground is zero voltage , you may think that the ground input does not contribute to the op-amp output . That 's wrong ! Ground is never zero voltage . There is always a little ground noise . @ @ @ @ @ @ @ @ @ @ <p> What 's the ground gain in the inverting mixer circuit ? The inputs add to a gain of " 8 . Daisy 's Theorem has the ground gain at +9 . Since all the gains are negative , the circuit does not need a balance resistor . The non-inverting op amp input can be connected to ground . <p> If you can afford an extra resistor , you can create the balanced design . Two of the inputs are moved from the inverting input to the non-inverting input . What 's the ground gain now ? The input gains add to zero and the ground gain is +1 . This is a big noise reduction . <p> You can even do better by making the sum of the signal gains equal to 1 , in the third variation , where two of the input gains are +2.5 and the other two are " 2 , so the gains add to +1 . The ground gain is 0 and no balance resistor is needed . This circuit adds no ground noise to the output , which is nice . <p> @ @ @ @ @ @ @ @ @ @ and eliminate ground noise by using a balanced design . K9 Analysis uses impedances . If we use a capacitor for ZF , we can build an integrator circuit . Figure 4 shows the textbook integrator circuit on the left . The integrator has a negative gain , but can we design an integrator with positive gain ? <p> 4 . The balanced principles are not restricted only to simple amplification . They can be adapted for use in various integrator circuits , the second most commonly used function ( after amplification , of course ) . <p> In the circuit in the middle , the input has been moved to the non-inverting input . This circuit is not balanced , as the inverting input sees the feedback capacitor , while the non-inverting input sees the input resistor . <p> To balance the circuit , we need to add a resistor equal to the input resistor to the inverting op-amp input and a capacitor equal to the feedback capacitor to the non-inverting input . Thus , both inputs see equal impedances and are balanced . <p> The balance components were @ @ @ @ @ @ @ @ @ @ to a voltage-source input to create a different circuit , such as a differential integrator , by returning the inverting input-balance resistor to a second input , or an ac amplifier by returning the balance capacitor to an input . These circuit techniques allow you to convert inverting textbook circuits to non-inverting circuits , as long as you maintain balance . <p> But there are caveats . The simplified positive-gain formula hides the fact that positive gains are very interactive . Changing any input impedance can change all the positive gains . You need to have a balanced circuit for the simple positive formula to apply . Most changes require a change in the balance impedance . In contrast , negative gains are independent and do n't interact . If all the signal gains are negative , you do not need a balanced circuit . <p> Also , op-amp circuit voltages are limited . You need to verify that inputs do not cause the output to saturate . For positive inputs , you also need to verify that the inputs do not violate the common-mode input range . Note that @ @ @ @ @ @ @ @ @ @ inputs are at ground potential and the common-mode input range is not an issue . You also need to verify that the circuit is stable . The design equations are solutions of circuit equations . Although the solutions are correct , there is no guaranty that the circuit will remain in the solution state . <p> Plato 's Gain Formula is ZF/ZI for balanced circuits . Just pick a feedback impedance and select the input impedances for the desired gains . Connect the input impedance to the non-inverting op-amp input for a positive gain or the negative op-amp input for a negative gain . Create a balanced circuit by adding balance impedances . <p> For amplifier designs , use Daisy 's Theorem to find the ground gain . If the circuits requirements allow , explore changing the gain signs to reduce the ground gain and consider implementing the circuit with a single op amp . <p> Dieter Knollman is a retired member of the technical staff at Bell Labs . He has a PhD from New York University and about a dozen patents . He created K9 Analysis to simplify @ @ @ @ @ @ @ @ @ @ K9 analysis ) and taught circuit design at a state university in the 1980s. 
@@21004986 @1004986/ <h> What 's The Difference Between Voice Coil Actuators And Solenoids ? <p> When it comes to linear motion , engineers often face two choices : voice-coil actuators ( VCAs ) or solenoids . Both are simple electromechanical devices that can accomplish the task . But there are definite differences between the two , and it 's important to select the component most suitable for the task at hand . Comparing the design and capabilities of the two components makes it easy to determine which is more appropriate for a given application. - - <h> Table Of Contents <h> Solenoids <p> Solenoids normally consist of a coil with no magnet attached to a soft magnetic housing , an iron or steel core , and , often , a spring . These on/off components are controllable via simple switches . When current flows through the coil , the electromagnetic field created by the coil attracts the iron core ( Fig. 1 ) . When the coil is de-energized , the spring pushes the iron core back to its original position ( Fig. 2 ) . <p> 1 . When current @ @ @ @ @ @ @ @ @ @ pulled in . <p> 2 . By removing current from the solenoid , also known as de-energizing , the iron core is released and travels back to its original resting place . <p> In some applications , designers employ solenoids without springs to move a common iron core back and forth . In all cases , it 's possible to design solenoids to achieve a certain speed and a certain amount of force . But once set , alterations for making adjustments to the necessary movement are impossible , i.e. , it can not provide any controllable changes in speed , force , or position . <p> Essentially , solenoids meet simple linear-motion requirements at a low cost in a simple on/off control mechanism . Suitable solenoid applications include car starters and ticket machines . If the application requires more than simple on-off control with precise positioning , then consider VCAs . <h> Voice Coil Actuators <p> VCAs come in many shapes and sizes and in two types : VCAs with a moving coil and VCAs with a moving magnet . The first type consists of the usually stationary field @ @ @ @ @ @ @ @ @ @ In contrast , moving magnet VCAs have the coil attached to a stationary soft magnetic housing , which also serves as a conductor of the magnetic flux . The field assembly typically consists of an axially magnetized , permanent cylindrical magnet and two soft magnetic pole pieces attached to both ends of the magnet . <p> Applying a voltage across the terminals causes the VCAs ' moving part , magnet or coil , to travel in a given direction . Reversing the polarity of the applied voltage will change the direction of the moving magnet or coil . The generated force is proportional to the flux crossing the coil and the current that flows through this coil. - <p> By design , VCAs support a specific or set stroke . Typically , for a specific current , the force created by a VCA at mid-stroke is approximately 15% higher than the force created at both ends of the stroke . <p> VCAs shine in applications where more precise control is necessary , primarily because they are available with position feedback devices . Also , with low moving mass , VCAs @ @ @ @ @ @ @ @ @ @ and shaker tables . And because moving magnet VCAs consist of a stationary coil and a moving permanent magnet assembly , as opposed to a coil assembly and a piece of steel in a solenoid , VCAs can typically create more force than solenoids for a specific size , stroke , and input power. - - <p> VCAs with moving coils are ideal for many limited-angle rotary applications that require high acceleration . The fast acceleration capability is achievable by minimizing the moving mass , in this case , the moving coil . Since it is separate from the magnet , it is customizable to be more lightweight than the heavy permanent magnet field assembly , allowing extremely fast speeds. - <p> The physical characteristics of a VCA also make it a first choice in medical , aerospace , and military applications in which size and weight are as important as its functionality. - Many medical equipment applications require high mobility , and every component must meet a specified dimension . A VCA can weigh as little as half a pound , making it a perfect solution for such requirements. @ @ @ @ @ @ @ @ @ @ VCAs and solenoids and , obviously , application requirements will determine which one to employ . Chosen for their technologies and performance , VCAs are high-power-density components . Therefore , in applications with a short stroke or excursion angle , a VCA can do the job where other technologies such as motors or gear motors will be bigger and heavier. - <p> Although solenoids are suitable for on/off linear movement and intermittent duty , VCAs are the obvious choice to control force , speed , travel , and **25;1075;TOOLONG for continuous performance and accurate positioning ( Fig. 3 ) . <p> 3 . VCAs provide high force and acceleration capabilities along with high-speed linear position control . 
@@21004987 @1004987/ <h> What 's All This Noise Gain Stuff , Anyhow ? <p> Download this article and more as part of Electronic Design Library 's new eBook , Focus On : Bob Pease on Analog . <p> On my recent seminar tour , I asked about 4000 engineers , " How many of you use noise gain ? " About 2% of the people held up their hands . Sigh . Noise gain is often not very important or critical . That is one of the reasons why op amps are so popular . They tolerate almost any kind of feedback and any noise gain . You can often see that by inspection . But when it is important , things get interesting pretty fast . <p> Let 's start with a definition of noise gain : Noise gain is the reciprocal of the attenuation from the output of an op amp ( or any feedback loop ) to the input . In Figure 1 , the attenuation is RIN/ ( RIN + RF ) . So the noise gain is ( RF + RIN ) /RIN . Or , @ @ @ @ @ @ @ @ @ @ - <p> As I say in my lecture , it is not a good idea to try to memorize that , because that just ensures that you will forget it . But you ought to recognize the cases where life gets interesting . <p> If RF/RIN is a small number , and the noise gain is not very high , the curve of Figure 2b can apply . Most op amps are happy with any noise gain from 1 to 2000 . But be cautious about any amplifier that is specified for " Gain of 10 minimum . " Such an amplifier has excessive phase shift at high frequencies , and it will surely oscillate if the noise gain is not at least 10 ( or as stated ) . But , refer to NSC 's App Note LB-42 . <p> Reactances : If we add a feedback capacitor across RF , the noise gain can be high at low frequencies , but it will fall to 1 at high frequencies ( Fig. 2c ) . Guess what ? This cuts the output noise " a very popular move ! @ @ @ @ @ @ @ @ @ @ a lot of capacitance on the summing point " which might happen if you had a large photo diode or a lot of cable capacitance " then the noise gain will rise at higher frequencies . This can cause serious problems because when the noise gain rises ( Fig. 2d ) , it tends to cross the op amp 's gain-bandwidth product too steeply . And , the 12-dB per octave slope will cause severe ringing . This ringing or oscillation can usually be cured with a small feedback capacitor . The nominal value for this capacitor will be G2CIN/ ( GBWP + 2-RF ) . For a typical circuit with a summing-point capacitance of 100 pF , the CF may need to be 5 to 10 pF " not too huge . <p> Note , however , that while most of this analysis is computed in the frequency domain looking at Bode plots , the evaluation of loop stability is normally done in the time domain . Hit the input with a little step of current and see how well the output settles without excessive ringing . <p> Often @ @ @ @ @ @ @ @ @ @ " for his feedback resistance to avoid having to buy a large-value resistor . I almost always say that that 's a bad idea . Why ? Because of the noise gain ! Either due to the noise , or the bandwidth , or the drift , any tee network with a factor of more than 2 is usually a terrible idea . A noise gain of 10 or 100 or 1000 is often a terrible idea ! <p> Next time you work with an op amp , think about the noise gain . If it is a simple case , it wo n't require more than a moment . But if it is complicated , it might require more than an hour ! Or if you neglected to study the problem properly , you 're in for days of grief ! 
@@21004990 @1004990/ <h> Bus-Bar Benefits <p> David G. Morrison Nov 18 , 2001 <p> Not every system requires laminated bus bars . In some rack-mounted systems , current levels do n't rise above the capacity of a backplane . In other cases , there are relatively few taps off the power bus , so a wiring harness is the best approach . Also , in applications where only a few cabinets need to be wired , a wiring harness may be sufficient , even when the number of taps off the power bus and wiring complexity are high . But with a complex power distribution in production volumes , the advantages of a bus-bar design are compelling . <p> Laminated bus bars are typically more costly than wiring harnesses because of how they 're made . Their manufacturing process involves cutting strips of copper and insulation to shape and then combining them into a multilayer structure with mounting holes , tabs , or connectors added for interface . <p> As Rick Whistler , national sales manager at bus-bar manufacturer Eldre , Rochester , N.Y. , describes the process , fabricated copper @ @ @ @ @ @ @ @ @ @ fixture and then subjected to pressure and high temperature over time . The insulation " one of several materials such as Mylar , Nomex , Tedlar , or Kapton " has been customized with a b-stage resin . When heated , this material bonds the insulation to the copper . The copper conductors are sized to achieve the required current ratings based on the acceptable temperature rise for the conductors . The Copper Development Association publishes current ratings for various sizes of bus bars at a temperature rise of 30-C , a limit applied in UL safety tests ( see http : **38;1102;TOOLONG , Table 1 , " Ampacities of Copper No. 110 Bus Bars " ) . Whistler notes , though , that Eldre sizes conductors around a more conservative temperature rise of 20-C , in part to account for the presence of insulators on the copper . <p> Although its material cost will likely be higher than that of an equivalent wiring harness , a bus bar 's overall cost may be less after taking assembly , reliability , and field service requirements into account . In the @ @ @ @ @ @ @ @ @ @ with a bus-bar design than with a wiring harness . Moreover , the likelihood of miswiring with bus bars is less . One reason for this is that with bus bars , the location of the interconnects is fixed . They also are readily labeled using a variety of methods , including rubber stamp , silk screen , and adhesive labels . Plus , the benefits of easier assembly translate into faster and easier component repair in the field . <p> Beyond these benefits , bus bars provide a platform for greater mechanical integration at the system level . Advanced designs are exploiting this capability ( see the figure ) . As Whistler says , " The greatest innovations are custom solutions that integrate as many components as possible . " In addition to integrating power connectors , bus-bar designs are taking on other power-related components , including fuses , circuit breakers , filters , and capacitors . Because the bus bar is essentially a custom design , there 's an incentive to exploit its ability to clean up and simplify assembly . Another opportunity for customization lies in the @ @ @ @ @ @ @ @ @ @ that incorporates small wires or flex circuits to route signals . Advanced bus-bar designs , like this one developed by Eldre , distribute power neatly and efficiently and integrate many of the discrete components associated with power distribution . 
@@21004993 @1004993/ <p> Designers can use precision discretes , though practically speaking , this approach is limited to prototyping . For production trimming , the classic choices have been laser-trimming , using either resistors fabricated alongside active devices on an integrated-circuit die or trimmable discrete devices , and digital potentiometers . Recently , a third alternative known as the rejustor has become available . <p> How does laser-trimming work , and what are its pluses and minuses ? <p> As part of the back end of IC manufacturing , trimming is accomplished by burning away part of the resistor structure using a laser beam . As the resistor 's effective cross-section is reduced , resistance increases . The trimming is frequently done in conjunction with wafer probing , so it is n't so much the resistance that is being monitored to control how much material is being removed as it is some characteristic ( e.g. , amplifier gain ) of the circuit being probed that is adjusted . Most of the advantages of laser trimming lie in the decades of experience the technology has accumulated . On the downside , laser @ @ @ @ @ @ @ @ @ @ ? <p> A digital potentiometer is essentially a ladder network whose switches are controlled by a digital input . Some digital pots incorporate nonvolatile memory to maintain their setting when power is removed , and some do not . Digital pots are very handy when a voltage divider is called for . <p> But since they 're digital , their controllability is more granular than what would be possible with the highestprecision laser trimming . Also , designers must deal with a fixed amount of " wiper resistance . " Their maximum allowable current varies with wiper position . And , digital pots often are frequency-limited by their packaging and generate the most thermal and 1/f noise of any adjustable resistor technology . <p> What about rejustors ? <p> As a new technology , rejustors take a little more explanation . Although they can be processed at the IC fab level , the only products that have been announced to date are discretes , packaged in pairs to form voltage dividers . <p> Think of these products as something like digital potentiometers , but with lots of bandwidth ( up @ @ @ @ @ @ @ @ @ @ metal-film resistor . They 're continuously adjustable , like a physical pot , but without any wiper resistance . As with lasers , the object of trimming is usually to adjust some performance characteristic . <p> Each rejustor has two components : a thermally isolated poly film resistor and an adjacent power resistor ( Fig. 2 ) . For trimming , the power resistor is pulsed in a controlled fashion , briefly raising the temperature of the rejustor resistor . The result is an annealing that changes the rejustor 's resistance in a controlled and predictable manner . <p> Why do it that way ? <p> Rejustors make it possible to adjust resistance and temperature coefficient ( TC ) to independent targets . The adjustment software makes it possible to recursively adjust both those characteristics incircuit . In practice , designers pick a nominal value for the rejustor . During production , each circuit is fine tuned not just for trim point , but for TC as well . Also , rejustors have lower capital-equipment costs than trimming lasers . <p> Does n't a resistor that gets set by thermal @ @ @ @ @ @ @ @ @ @ . The rejustors are thermally isolated . During fabrication , one or more dopant implant masks are used to tailor the rejustor resistor-poly film . ( This is in addition to the other masks used to fab the IC . ) At the end of fabrication , the resistive microstructures are released by a bulk-silicon etch process , leaving them suspended over a cavity , providing thermal isolation and low thermal mass. 
@@21004994 @1004994/ <h> On-cell Touch Screen Panel Slims Down Mobile Displays <p> Multitouch interfaces are found on most tablets and smartphones with real buttons and switches disappearing from these devices . Simplifying the multilayer touch interface has been the quest of many vendors in this market . Single layer multitouch technology is available from companies such as Cypress Semiconductor ( see Single Layer Multitouch Cuts Cost In Half ) and IDT ( see Multitouch Using Single Layer Sensor ) . These technologies are designed to be applied on top of conventional displays and normally combined as part of the construction process . <p> Hydis Technologies , a has created a compact , multitouch display ( Fig. 1 ) that employs a single layer sensor that is applied directly to the display . This allows Hydis to deliver a touch display as one compornent rather than combining a touch sensor and an existing display . The on-cell Touch Screen Panel ( TSP ) approach also simplifies construction of multitouch displays and reduces system cost . <p> The on-cell approach allows multitouch functionality to be embedded on top of a thin-film transistor ( @ @ @ @ @ @ @ @ @ @ display . In addition to simplifying construction and reducing costs , the architecture also delivers better optical qualities because there are fewer layers . Hydis eliminates the air gap , shield layer , two ITO film layers and reduces the mask layers from four to one . <p> The reduction in the number of layers also reduces parallax errors providing a superior touch interface . Fewer layers also means backlight intensity can be reduced while providing the same brightness level . The usual multitouch display has an 88% transparency while the Hydis display is 93% . This helps reduce lighting power requirements and extends battery life . <p> Hydis ' on-cell technology can be applied to displays up to 22-in at this point . Most tablet and smartphone multitouch displays are limited to 12-in with a 3mm to 5mm side bezel . The on-cell approach does not need a side bezel . The multitouch support hanles any number of touches although typical implementations are likely to handle 10 touches as do most high end multitouch displays . <p> Hydis Technologies is a subsidiary of of E Ink Holdings , creator @ @ @ @ @ @ @ @ @ @ Fringe Field Switching ( FFS ) LCD technology that is used on many currently available smartphones and tablets . The on-cell technology can be used with these displays . 
@@21004996 @1004996/ <h> 50 Years of BASIC Programming <p> Can you believe it ? The BASIC programming language is 50 years old this month . As you may know , BASIC was created in 1964 by Dartmouth College professors John Kemeny and Tom Kurtz as a system to simplify the teaching of programming . BASIC means Beginners All-Purpose Symbolic Instruction Code . The language was implemented as an interpreter on Dartmouths GE time sharing mainframe where students used ASR-33 Teletype machines as terminals . It was popular from the start as students could learn the language in record time and create useful programs quickly . <p> Back in the 1960s there were few programming languages . Most machines were programmed in assembler but the higher level languages FORTRAN , Algol even LISP were available yet fairly complex and difficult to master . BASIC really opened the door to computing for many because it was easy to learn . <p> Where is BASIC today ? Well , it is still around but not as popular as it once was . Today , the C language and its derivatives seem to dominate programming @ @ @ @ @ @ @ @ @ @ Java very widespread . And today , young millennials anxious to get a job in programming are spending $10,000 to $17,000 for 8 to 12 weeks of coding school where the languages taught are Python and Ruby on Rails . <p> I learned FORTRAN in college . Later , I learned machine code and assembler to program minicomputers like the DEC PDP-8 and PDP-11 . Then when the first personal computer kits became available in the mid-1970s , BASIC became the main language . Microsoft was formed around BASIC and was quickly successful . I ran an early paper tape version of Microsoft BASIC on an ASR-33 Teletype connected to an 8080-based IMSAI computer . It worked well . The process was to load BASIC using the 10 cps paper tape reader then do your coding . Then you stored your program on paper tape again at 10 cps . Back then there was no OS so BASIC was your way to use the computer , unless you wanted to machine code it with the front panel switches . <p> BASIC was the software of early personal computing . Every @ @ @ @ @ @ @ @ @ @ Pet , Radio Shack TRS-80 , Sinclair and most others . I was at Heathkit in the 1970s where we built the H8 and H11 computer kits . We tried to get Microsoft BASIC but they would not sell to us at a reasonable price so we developed our own called HBASIC . We also had BASIC and Focal on the DEC LSI-11 used in the H11 . <p> There were many other versions of BASIC like CBASIC and Tiny BASIC . I can remember programming in QBASIC on an early IBM PC and using the BASIC interpreter embedded in an Intel 8052 microcontroller . More recently I used the Parallax BASIC Stamp computer for some hobby projects . It uses a very simple interpreted BASIC on a PIC microcontroller . And I taught an entry level Visual BASIC course while I was still a professor . I even learned the crazy LISP language during the artificial intelligence craze during the 1980s . <p> So far I have successfully avoided using C. I tried to learn it but it is just not intuitive . It takes time and experience to @ @ @ @ @ @ @ @ @ @ derivative language of the popular Arduino computers but quickly abandoned it in favor of the BASIC Stamp for programming projects . If I have to program a microcontroller I will use BASIC if available otherwise I try to use assembler . I think best at the bit level . <p> Anyway , I still like BASIC and I believe it was one of the main drivers of the PC business . You do n't  see it much today but it is available in many forms and still a great starting point for those interested in computers . <p> We should all silently thank Kemeny and Kurtz for BASIC and the computer revolution it supported . 
@@21004997 @1004997/ <h> Safety in Medical Device Software : Questions and Answers <p> Ben Brosgol Jun 06 , 2011 <p> Software is playing an expanding role in modern medical devices , raising the question of how developers , regulators , medical professionals , and patients can be confident in the devices ' reliability , safety , and security . Software- related errors in medical equipment have caused people 's deaths in the past , so the issue is not simply theoretical . Device manufacturers need to provide safety assurance for complex software that is being developed in a competitive environment where price and time-to-market are critical factors . Further , security issues that previously were not a major concern now need to be anticipated and handled . <p> I recently spoke with Dr. Benjamin Brosgol , senior member of the technical staff at Adacore , about these issues . This includes how some recent Food and Drug Administration ( FDA ) regulations are dealing with such issues , and how programming language and support tool technology can help . <p> Wong : How does the medical device industry differ from other @ @ @ @ @ @ @ @ @ @ control ? <p> Brosgol : Obviously there 's a basic similarity in that a software failure can directly lead to human fatality , but there are also some differences between medical and other domains : <p> If a plane crashes or a nuclear reactor releases deadly radioactive gases , that 's instant news all over the world . On the other hand , one person dying from an insulin overdose caused by faulty infusion pump software does not get the same attention . That 's not to understate its significance , or the importance of having confidence that medical devices " first do no harm " . But historically the requirements for certification in the medical industry have not been as strict as in domains such as commercial avionics . <p> If software problems delay a new aircraft 's flight certification , then airlines can use older planes . This is perhaps an inconvenience for passengers , or an additional cost for the airline or the manufacturer , but the delay is not a safety hazard . On the other hand , if there is a delay in certifying a @ @ @ @ @ @ @ @ @ @ waiting for the device to be approved . That tends to put the onus on the FDA to show that a device is unsafe , versus on the manufacturer to show that it is safe . <p> There are only a few companies in the business of constructing airplanes or nuclear reactors , whereas there are several thousand medical device companies . The large number of vendors of medical devices affects the dynamics of regulation/approval . <p> In most safety-critical domains , equipment is operated only by trained / certified personnel . Medical devices often need to be operated by end users ( patients ) who have no formal training . That places a higher demand on the design of the user interface and the need for hardware- or software-enforced checks on inputs or outputs . <p> Many safety-critical industries see software lifecycles that extend over a decade or more , with the hardware platform remaining stable . In contrast , a medical device manufacturer tends to react more quickly to hardware improvements that will offer a competitive advantage in terms of performance or functionality . That in turn induces @ @ @ @ @ @ @ @ @ @ which can introduce various risks ( regression errors , configuration / version problems , etc . ) . <p> Wong : Give some examples of medical device software safety issues that have been responsible for patients ' deaths . <p> Brosgol : Some of the earliest and most dramatic incidents involved the Therac-25 radiation therapy machine in the mid 1980s , when a software design error caused several patients to be killed from radiation dosages orders of magnitude higher than what had been intended . The immediate cause was a so-called " race condition " where rapidly-entered human input took the machine into an unplanned state . But more fundamentally , a detailed accident analysis cited shortcomings in the development and verification process , including inadequate software engineering practices . <p> Unfortunately , that was not the only case where defective medical device control software has proved fatal . Here 's an excerpt from Total Product Life Cycle : Infusion Pump - Premarket Notification 510(k) Submissions ( Draft Guidance , April 2010 ) : <p> FDA has seen an increase in the number and severity of infusion pump recalls . @ @ @ @ @ @ @ @ @ @ that appear to be a result of faulty design . Between January 1 , 2005 and December 31 , 2009 , FDA received over 56,000 MDRs associated with the use of infusion pumps . Of these reports , approximately 1% were reported as deaths , 34% were reported as serious injuries , and 62% were reported as malfunctions . <p> This translates into a rate of more than 100 deaths and 3500 serious injuries per year , from equipment that is supposed to be helping people . The Draft Guidance goes on to state : <p> The most frequently reported infusion pump device problems are : software error messages , human factors ( which include , but are not limited to , use error ) , broken components , battery failure , alarm failure , over infusion and under infusion . In some reports , the manufacturer was unable to determine or identify the problem and reported the problem as " unknown . " Subsequent root cause analyses revealed that many of these design problems were foreseeable and , therefore , preventable . <p> The FDA has evaluated a broad @ @ @ @ @ @ @ @ @ @ are numerous , systemic problems with device design , manufacturing , and adverse event reporting . FDA has structured this guidance document to address these device problems prior to clearance of the premarket notification and in the postmarket context . <p> Wong : How does the new FDA guidance intend to solve these problems , without making the certification effort unrealistically expensive ? <p> Brosgol : The draft guidance requires the manufacturer to demonstrate safety through " assurance cases " : <p> An assurance case is a formal method for demonstrating the validity of a claim by providing a convincing argument together with supporting evidence . <p> The " formal method " is not necessarily mathematical , it is more a line of reasoning as would be found in a court of law to prove a particular point . <p> An assurance case addressing safety is called a safety case . A top-level claim ( e.g. , " this infusion pump is comparably safe " ) is supported by arguments that demonstrate why and how the evidence ( e.g. , performance data ) supports the top-level claim . The arguments @ @ @ @ @ @ @ @ @ @ fashion with multiple layers of sub-claims , each supported by appropriate evidence . The arguments in a safety case are intended to convince a qualified reviewer or reviewers that the top-level claim is valid . <p> This approach is not new ; it is also found in other safety standards such as the UK 's Defense Standard 00-56 . It is not intrinsically more or less expensive than other methods , but the key is to apply it early in the development process so that potential hazards can be avoided before they get into the product . Building an assurance case after the fact is possible but will require understanding or reverse engineering the requirements and the design , and that is a difficult and costly process . <p> Wong : What 's the difference between process-based certification standards such as DO-178B , and product-based standards such as FDA infusion pump guidance with its safety case requirements ? <p> Brosgol : Process-based certification focuses on the development-related activities and their associated artifacts ( requirements specifications , test plans , configuration management procedures , etc. ) rather than on measurable properties @ @ @ @ @ @ @ @ @ @ testing , versus say formal methods , as the main way to verify that software meets its requirements . <p> The rationale for such an approach in DO-178B was perhaps best summarized by GTrard Ladier ( Airbus ) at the FISA-2003 Conference : <p> It is not feasible to assess the number or kinds of software errors , if any , that may remain after the completion of system design , development , and test . Since dependability can not be guaranteed from an assessment of the software product , it is necessary to have assurance on its development process . You ca n't deliver clean water in a dirty pipe . <p> This technique has worked well in practice . Although there have been some close calls , there has never been a fatal aircraft accident that has been attributed to DO-178B-certified software . <p> But the process-based approach , with its indirect relationship with safety , is not without its critics . For example , John Rushby ( SRI ) offered this observation at the HCSS Aviation Safety Workshop in October 2006 : <p> Because we can not @ @ @ @ @ @ @ @ @ @ how hard we 've tried . <p> In contrast , the product-based approach concentrates on properties of the delivered product rather than on how it was developed . Its relationship with safety is therefore more direct than with the process-based approach . As mentioned above , it is illustrated in " safety case " certification standards , such as the UK 's DEF-STAN 0056 and the FDA infusion pump draft guidance . <p> In point of fact , both approaches are needed . Indeed , DO-178B depicts the System Safety Assessment Process as separate from , but interrelated with , the Software Life Cycle Processes that the standard describes . And an organization that is developing a safety case analysis certainly needs a sound software management process to ensure appropriate configuration management , traceability between requirements and implementation , bug tracking , regression testing , etc . <p> Wong : What about security ? <p> Brosgol : Safety-critical systems need to be accessed by external equipment for various reasons , and for many medical devices such remote access is intrinsic ( e.g. , pacemaker software updates ) . The connectivity @ @ @ @ @ @ @ @ @ @ equipment , the software , and the data are protected from threats to the needed confidentiality , integrity , and availability . <p> As with safety , this is an issue that needs to be considered from the earliest stages of software development . In a sense , it could be treated as a special category of safety ( in order to be safe , a system has to be secure ) but security issues have some inherent differences from safety issues . For example , with safety one may take a probabilistic approach to device failure based on hardware characteristics , but with security one must assume that an adversary who knows about a vulnerability will exploit it . <p> Security issues are not dealt with directly by safety regulations , such as DO-178B or the FDA Draft Guidance , but several other standards are relevant . For example , the Common Criteria , which is basically a catalog of security-related functions and assurance methods , can serve as a reference for specific measures that may be needed ( e.g. data encryption , user authorization ) based on the @ @ @ @ @ @ @ @ @ @ ( ISO/IEC 27005 ) can likewise be adapted so that it applies to the development of medical device software . <p> Wong : What is the role of the programming language in helping produce safe software ? <p> Brosgol : Safety certification standards , whether process- or product-based , tend to be language blind , but that does not mean that the choice of languages is insignificant . Languages differ with respect to their susceptibility to vulnerabilities , and the language choice affects the ease or difficulty of achieving safety certification . <p> For use in developing safety-critical systems , an ideal programming language should meet three main criteria : <p> Reliability . The language should help detect errors early , and should be immune from " traps and pitfalls " that can lead to program bugs . <p> Predictability . The language should not have features whose effect is unspecified or implementation dependent . Such features interfere with portability ( for example the program might have a different effect when compiled with a different compiler ) and may introduce security vulnerabilities . <p> Analyzability . The language should enable @ @ @ @ @ @ @ @ @ @ , such as absence of " buffer overflow " . <p> Unfortunately , no general-purpose programming language achieves this ideal . This is not a surprise , since languages such as C , C++ , Ada , and Java were designed with tradeoffs among a number of goals . The real question is whether it 's possible to define a subset that is sufficiently expressive to be practical for real-world systems while meeting the three criteria mentioned above . <p> A number of candidate subsets are available , including : <p> MISRA C , a C subset intended for safety-critical software . The original focus was on automotive systems , but the subset is not domain specific . <p> MISRA C++ , a C++ subset designed for critical software , not necessarily safety critical . <p> SPARK , an Ada subset augmented with special comments that reflect program " contracts " . SPARK tools can verify various safety- or security-related properties . <p> Each of these subsets has pros and cons . Since C and C++ are widely used in the software industry in general , there is a large @ @ @ @ @ @ @ @ @ @ many vulnerabilities found in the full languages . But the MISRA restrictions are sometimes subject to interpretation , and in any event neither C nor C++ were originally designed with safety or security as a goal . <p> SPARK is reliable , preventing errors such as buffer overrun , and predictable , with completely-defined semantics . It has a proven track record in both safety and security , and is highly analyzable , due to the language restrictions and to Ada 's ability to specify subranges on scalar data . SPARK 's main drawback is its relatively small user / tool provider community . <p> In addition to these existing subsets of C , C++ , and Ada , there is also an on-going effort to define a safety-critical subset of Java . This is intended for applications that need to be certified at the highest levels and may be attractive to a developer who has settled on Java for other parts of the system . However , the safety-critical Java effort is not yet complete , and it remains to be seen whether its approach to memory management without @ @ @ @ @ @ @ @ @ @ developers of safety-critical systems need to consider various tradeoffs . A language technology such as SPARK offers the most technical advantages , while options , such as MISRA C and MISRA C++ , have larger user and vendor communities . <p> Wong : What about static analysis tools ? <p> Brosgol : Static analysis tools are sometimes portrayed as the way to deal with safety and , more especially , security . Feed the source code into the tool , have it detect potential vulnerabilities , and then make the appropriate repair . The reality , however , is different , for several reasons . <p> The best way to deal with errors is to prevent them from being introduced in the first place . So in a sense , a static analyzer that detects , say , a potential buffer overflow , is coming in too late . It 's preferable ( and less expensive ) if the error is detected at the outset , before the bug settles into the delivered code . And here the language makes a difference , as was pointed out in the answer @ @ @ @ @ @ @ @ @ @ checking will prevent a pointer from being treated as an integer . A language with run-time checking will throw an exception if an array index is out of range . <p> Unfortunately , one does not always have the opportunity to deal with security issues at the outset . For example , an existing system might need to be deployed in a networked environment and thus has to be analyzed for potential vulnerabilities . A " retrospective " static analysis tool is the typical approach , but again , the programming language makes a difference . For example , a number of vulnerabilities in C or C++ could not arise in Ada or Java . There are also several practicalities that need to be taken into account : <p> Soundness : Does the tool report all errors in the class of bugs that it is looking for ? <p> Precision : If the tool reports an error , is it a real error as opposed to a " false alarm " ? <p> Efficiency : Does the tool scale up to large systems , perhaps hundreds of thousands of lines @ @ @ @ @ @ @ @ @ @ among these , especially between soundness and precision . If a tool is not sound then it must be complemented with some other analysis in order to ensure that all errors are detected . If a tool is not precise , then developers can easily overlook real errors given the large number of false alarms . And a tool that detects only trivial properties , or that is inefficient , is not useful . <p> Static analysis tools have their place . They are most useful during the software development process , so they can help prevent bugs from being introduced . When used " retrospectively " they can certainly help , but the tradeoffs among the various goals need to be carefully weighed . 
@@21005005 @1005005/ <h> What 's All This Ground Noise Stuff , Anyhow ? <p> Recently I got a letter from a reader , James Hansen in New Boston , NH . He introduced himself as a digital and analog/digital system design engineer , and said a few nice things about what I write , and then said he had a favor to ask . <p> I 'd like to know how you blue-blooded analog types get those marvelously clear and beautiful low-level waveforms on the scope . I 've used everything from crummy scopes through lab-quality scopes , but none of them , regardless of what I 've tried , ever produced the squeaky clean displays like the ones I see in the data books . <p> When I crank up the gain , there 's always noise in my displays - usually common-mode noise - that I do n't think is really there , but I am not always sure . I 'm talking about a lifetime of experience here , in a variety of locations , equipment and breadboards , not just one system that came down the pike @ @ @ @ @ @ @ @ @ @ true , and trusty 465B scope , for which I personally paid Tek some $2600 , years ago . In spite of all the TLC I 've given this scope , the 50 mV scale is useless if there is anything besides battery-powered flashlights running in the building . <p> What I find is damped ringing spikes running at either the clock frequency of whatever is under test , or 60 Hz , with the peaks running typically about 3/4 full scale at 50 mV/division , all mixed on top of the real signal . When the gain is backed down to something like 5 V/div , the visual effect is a thick or slightly fuzzy line . This does n't really bother me much when dealing with large signals , but it is bad news when you need to look at something little . <p> I 've shorted the probes with the shortest ground strap available , and I still see the junk by touching the common ground point - or anywhere else on the chassis . Sometimes I can cut down the amplitude of these dudes a bit @ @ @ @ @ @ @ @ @ @ to eliminating it . I 've tried using the scope differentially , I 've floated it and/or the test bed , played games with various grounding schemes , and a hundred other things , all to no avail . <p> So before I die , just once I 'd like to hook my scope to the output of a 12-bit DAC and see those uncluttered , beautiful , sharp , clear 5 mV stairsteps like those in the databooks . Is this possible ? Do the databook guys cheat , like , touch up the picture ? <p> How does one absolutely , positively know if the junk on the screen is real , or some instrumentation artifact ? I 've chased this kind of noise for days only to discover ( actually , ' proclaim ' is a better choice of words ) that it was n't real . Do other people run into this sort of problem , or am I the only soul on earth cursed in such a way ? <p> If you do n't care to write the story on this - it would be @ @ @ @ @ @ @ @ @ @ hints , and I 'll write it up for publication in the magazine of your choice . <p> Anyhow , this is the challenge . Will you grasp the ring or beg off ? With thanks for your past and future good humor , unknowing help , and encouragement ! I am , sincerely yours , James M. Hansen , Project Engineer . <p> Well , I recognized a guy with a real problem . And it 's not just his problem ; I 'm sure other people have it too . So , remembering the philosophy and the immortal words of LaVerne Baker , " Jim Dandy was the kind of guy , never like to see a pretty girl cry - Jim Dandy to the rescue , " I called up Jim Hansen in his lab . I told him I thought I could help him , but this was going to be one of these Onion Syndrome deals - you peel off a couple layers , and cry ; then you peel off a couple more layers , and cry some more . <p> I told him @ @ @ @ @ @ @ @ @ @ really quiet , was to put a screwdriver across the master clock in his digital section . He said , after thinking a bit , " Bob , that will cut down the noise a lot , but then I wo n't be able to get any signal to feed to the DAC , to exercise it . " I agreed that was surely true , but if it really did cut down a lot of the noise , that was a good clue . NOW , there may be a little more noise buried behind the local noise , but to a certain extent you do have to clean things up , one after another . <p> If you try one experiment to cut down the noise , and you ca n't see any improvement , you may have to do that experiment again later , because it was masked by some other source of noise you cleaned up at an intermediate time . THAT 's the Onion Effect at work . But , specifically , I told him , his noise is caused mostly by 3 main problems @ @ @ @ @ @ @ @ @ @ a receiving antenna . We can improve all 3 of these . <p> Let 's assume that , as an example , we really do want to add a little 12-bit DAC onto an existing digital system , and we want the analog output to be quiet , and we want to be able to SEE that it is quiet , in real-time - not just by the use of some averaging function on a fancy digital scope . <p> The first part of the problem is to recognize that the digital system is generating a lot of noise , some of it at more-or-less clock rate , with voltages moving 5 volts in just a few nanoseconds , and other stuff at various rep rates . Example : a low-duty-cycle pulse might drive a couple hundred milliamperes of current into a load , for a few microseconds every millisecond . Even if the current 's path does not describe a very big loop ( in terms of area ) , there will definitely be a big amount of magnetic flux coupled into the air . If the circuit was @ @ @ @ @ @ @ @ @ @ parallel busses for Drive and Return , or through twisted pairs of wires , that can help a lot , though . <p> Now if you have a bus that is nearby the clock or other fast-rise-time signals , you definitely can get capacitive coupling , and even if you have really good bypass capacitors on your power bus , they will also let the current pulses couple magnetically to your signal . So if you put a scope probe anywhere near the computer , the probe can pick up some noises . The electrostatic ( voltage-related ) part of this noise can be largely eliminated by putting the computer in a sealed metal or copper-clad box . Now you may not want to do that , and you may not be able to , but you may not literally have to do that . Instead , you may be able to just wall the noises out by putting your DAC inside a smaller metal box , so you literally segregate the DAC from the noisy world . The computer 's Digital ground and the DAC 's Analog ground should @ @ @ @ @ @ @ @ @ @ one point - and that point should preferably be right at the DAC . That way , digital noises will not have to flow through the analog ground system , in general , and they will be shielded away from the DAC and the other analog circuits . <p> Unfortunately copper or aluminum will not reject or attenuate magnetic noises . You might try some iron , but it may take 1/4 in. of steel to do the filtering if you have 60 or 120 Hz noises , and even 1/16 in. is not really guaranteed to shield out high-frequency magnetic flux . When you are really serious , you may have to buy some mu-metal foil or thin sheeting . <p> What is the realistic thing to do , then ? Well , one thing that does cause magnetic coupling to fall off rapidly is distance . You may be able to move the DAC to another board , or another quiet area of your system , farther away from the noisiest digital signals . Or , to be more realistic , if this DAC is going to add @ @ @ @ @ @ @ @ @ @ want to bring the DAC right over by the load it will drive . That way , after you get the analog signal coming out clean , the signal will be right where you want it . NOW , maybe the DAC has to be driven from a busy computer bus . How can you put the DAC exactly half-way between the busy bus and the pre-amplifier ? The answer is , layout . You have to plan and lay it out exactly that way , if that is exactly what you want . For best results , you would indeed have to bring in the digital signals on one side of the DAC , and feed the analog signals directly from the DAC over to its load . But that 's still just part of the problem . Let 's say you bring your probe over near the DAC , and the scope display is reasonably quiet . But as soon as you touch the probe 's ground to the signal ground , horrible noises appear . ( This is what I think was Jim 's major problem ) @ @ @ @ @ @ @ @ @ @ coupling . One , as we have discussed , is to try to get the digital signals to not radiate so much noise ; and the SECOND is to try to get less current flowing through the ground path . A majority of scopes have a ground path from their signal grounds , back through the line cord to the ground pin of their power plug . When your scope is plugged in , the ground of the scope is grounded to the building , for safety . But if there is any other source of noise in your building , the noise can couple in through that ground pin . Touching your probe to any other ground enables ground currents to flow through the entire length of the probe , and through the probe 's ground wire - a ground loop . <p> One good thing to do is to use a 3-prong-to-2-prong adapter on the line cord . In some places that might cause trouble or danger , especially if there are high voltages around . But it 's worth a try , and this is probably the @ @ @ @ @ @ @ @ @ @ ground current . " When you do this , hang a fat label on the scope so other users will be warned of this semi-floating condition . Also , be warned that some high-frequency noise currents can still come right in through the power line . Power transformers do n't have zero picofarads of capacitive coupling , even the best ones . So a noisy room can still cause large currents to flow as soon as you touch the probe to a signal or ground . In an extreme case , you will have to give up on the line-powered scope , and use a battery-powered scope . Still , even a battery-powered scope can have some picofarads from its case to the world , so you can NEVER cut that current down to ZERO . Still , it 's worth an effort to see what improvement you can get by this approach . Then we will go on to the best part of the fix . <p> The best part is to get the probe 's ground wire down to zero length . When you buy a scope , @ @ @ @ @ @ @ @ @ @ a 12-inch ground wire , and a whole fistful of funny little pieces of metal and plastic that you quickly shove into the back of a drawer and never look at again . WELL , it 's just about time to dig them out and look at them . They will be helpful . <p> The major problem in this noise test is that the current noises flowing through the scope 's ground wire are generating all the large noises , as they flow through the inductance of the ground wire . Shortening that wire is the main solution . Do n't just swap the 4-inch ground wire for the 12-inch wire ; that 's still bad . Instead , unscrew the plastic ferrule or sheath that protects the tip of the probe . ( Your probes may need to be disassembled a little differently than mine , but they can all get dismantled in a similar way . ) Now you see the metal ground sleeve that is wrapped right around the tip of the probe . Look in the bag of probe accessories and see what kind of @ @ @ @ @ @ @ @ @ @ a 1/4 " path from that ground sleeve to the chassis or groundplane of your system ( Fig. 1 ) . Slap this small clip securely onto the tip of the probe . ( if it falls off into the soup and shorts out and wrecks your circuit , we warned you here .... ) Then connect the tip of that clip to the signal 's ground . The noise will be improved by a factor of 20 or 50 compared to what you had before . The main point is , not only is the inductance of the ground strap reduced by a huge factor , but also the coupling of the current into the loop comprised by the probe tip and its ground . That 's why probes work so well in the first place . <p> If you ca n't find those little probe accessories , you are not in trouble . Form and wrap a piece of bus wire ( #20 or 18 ? ) around the ground sleeve of the probe , say , 3 or 4 turns . Then solder that loop to your @ @ @ @ @ @ @ @ @ @ of thin bus around the small wire of the probe tip , about 3 turns , and tack-solder that to your signal . Then you can slide the probe into those sheaths , and let the weight of the probe hold it there . You will have a very short ground path for the price of a penny - and you can fabricate it yourself in just a few seconds , any time you need one ! <p> When I pointed this out to Jim he said , " Why is n't this written down anywhere ? " I pointed out that I did mention this in my Troubleshooting book* , on page 15 , that if you want to see clean step response with a scope probe , you have to use this VERY SHORT ground path ; and that it is also good for minimizing the pickup of noises in the air , too . Maybe I did not emphasize that as much as I should have ! <p> Now , if you called up the applications engineers at Tektronix or any other good scope company , and @ @ @ @ @ @ @ @ @ @ and give the right answer . But you have to know how to ask the right question . Is it written down anywhere ? Maybe there are some books on how to use your scope wisely . Not very many . <p> Now that you have made this major improvement , you will usually want to go back and try all the other experiments , to see which aspects of layout , scope floating , transmitter loops , guarding , shielding etc. , will now make the biggest improvement on the observed noise . Because things that made no effect before , can make a difference now . <p> These inductively-coupled noises will never match exactly if you use 2 probes , so that explains why you could not run the scope preamp differentially to get the noises to cancel . However , John Christensen in our apps group pointed out that you can usually improve this inductively-coupled noise by a couple more octaves , by running a separate , heavy ground wire from the scope to the system ground . If you can get most of the ground current @ @ @ @ @ @ @ @ @ @ 's ground wire , that 's where you can get an advantage . Nick Johnson suggested also that a high-frequency FET probe is usually designed with very short ground paths and will thus be good at rejecting noises , also . <p> Now , let 's say you can look at the ground and it 's reasonably quiet . Then you look at the DAC output and it is noisy . There are about five new places to look . <p> Does the DAC have a quiet power supply ? Many DACs have a PSRR of 70 or 80 dB - at dc . At 5 or 10 MHz , if the PSRR is as good as 6 or 3 or even 1 dB , it 's a miracle . Look at the noise on that power supply . Are you feeding a +5-V digital- power bus to your DAC , with 87 mV pk-pk of noise on it ? And then complaining because the noise on the output of the DAC looks only a little less bad than the 87 mV ? For shame ! <p> You can try @ @ @ @ @ @ @ @ @ @ capacitors , plus 10 -F of tantalum , plus 220 -F electrolytic , can cut the noise to an acceptable level . ( And remember , only YOU can decide what that is ... " good enough " is not necessarily anywhere near " perfection " ) . If the bypassing alone does not work , then : <p> Try some decoupling resistors , perhaps 33 or 120 ohm , or ? ? even a ferrite bead , in series with the path of the power from the supply to the DAC . If this is not enough improvement , try : <p> A completely separate set of twisted-pair wires from the power supply to the DAC . Put 100 ohm in series with that wire . <p> Try a completely separate power supply for the DAC . Repeat all the bypassing . Maybe one or more of these things will solve the problem ; maybe none of these will help right now , but they may help later . Remember the Onion Syndrome . <p> And finally , sometimes the DAC is fed signals from a noisy set of @ @ @ @ @ @ @ @ @ @ is talk-through from these busses into the DAC output . Do n't be surprised ; there is almost never a spec on that , and this talk-through can be LOUSY . The solution is to make sure the DAC gets its digital signals through a set of drivers or buffers that are running off the same quiet power supplies that the DAC is getting . The bit lines that the DAC sees can get a lot quieter , thus reducing the talk-through effects . <p> One of the things I like to do is to bring the signal right to the scope . It avoids the 10x attenuation and the possibility of bad phase compensation of the 10x probe ; and it avoids the bandwidth limitation of the 1x probe ( most of them have barely 10 MHz of bandwidth , and mediocre settling time ) and it avoids the capacitance of shielded cable . If you can bring your system to the scope , that has some great advantages , and I recommend it . Maybe you can not do that . But , it 's usually not essential @ @ @ @ @ @ @ @ @ @ there is still a little more feedthrough from some systematic noise than you can tolerate ? Maybe after you have done all these things , it 's time to go back and find out exactly WHAT signal is making the noise , and try to figure out how it is coupling in . Is it a current flowing through a big loop ? Maybe that loop can be closed up , or you can use twisted pair or coax cables to get minimum transmitter effect from that signal . Maybe it is capacitive crosstalk from a couple adjacent pc-board runs , and the signals can be shielded or guarded . <p> This is probably a good time to mention a book by John Barnes , " Electronic System Design : Interference and Noise-Control Techniques . " * * It 's quite good , practical , and offers several excellent ideas for many kinds of practical problems . He gives a number of good examples throughout . I am delighted to recommend this book ; in some respects , it can be considered as a companion to my book on Troubleshooting @ @ @ @ @ @ @ @ @ @ there 's still some vexing noise , and you turn off the clock and turn off the power supply , and there 's still that noise there ! Well , that sure gives you a clue , does n't it ? Noises can get conducted into your system by the power supply leads . Maybe you should UNPLUG your power supplies . Certain kinds of noises are brought in by your soldering iron , so , you may unplug THAT , and/or move it several feet away . Transformers for power supplies AND soldering irons can generate a lot of 120/180/360 Hz noise that couples insidiously ( magnetically ) into an otherwise low-noise system . <p> And DVMs are often pretty noisy , whether or not they are connected to your signal , so try turning that off . Is there a computer or terminal nearby ? Turn that off , too . As you can see , this is rapidly turning into a game of , " Is there anything that can not be causing that noise ? " Maybe that flashlight of Jim Hansen 's really is the @ @ @ @ @ @ @ @ @ @ ( And if you shine that on a diode , the light can cause dc currents to flow . ) Anyhow , at least we have shown that it probably is NOT the oscilloscope causing all that high-frequency noise , all by itself . It 's just a matter of , do you want a good antenna , or do you want a minimum antenna that will reject the noises in the air ! <p> Now , did that help , Jim ? Jim says YES . He was enough of a good sport to admit that part of his noise was caused by an oscillator that he had built up several months ago . He had quit using it , but had never disabled or disconnected it from power . He 'd forgotten all about it , until these troubleshooting tips led him to the source of the noise . A second source of noise was a transformer whose flux was coupled into a signal fed to a high-gain preamp . The 180 and 360 Hz waveshapes were a dead give-away. 
@@21005013 @1005013/ <h> Amazing Adaptable AM Radio <p> Do you listen to AM radio ? I do . And as it turns out millions of others do to , despite the growing number of competitors to conventional broadcast radio . AM radio used to be the only entertainment we had and it provided music , ball games , serials ( Lone Ranger , Captain Midnight , etc. ) and drama shows ( The Shadow ) . Amplitude modulation radio is the oldest form of electronics there is . It is not like it used to be but it is still around thanks to an interesting mix of technology and market factors . <p> The first AM radio broadcast was from station KDKA in Pittsburgh in 1920 . The number of stations grew steadily over the years but tapered off when FM became popular in the late 1950s and beyond . Today there are still roughly 4700 U.S. AM stations broadcasting . That number has remained pretty constant over time but it is down 4% from 1992 to 2012 . As for FM stations , there are about 6300 and that does @ @ @ @ @ @ @ @ @ @ the 800+ low power FM stations . FM dominates broadcast radio in the U.S. <p> The question is , why is AM still around ? This ancient analog technology has staying power . It works well , it is simple technically , inexpensive and serves a useful purpose . Besides broadcasting , AM is still used in citizens band radio ( AM and SSB ) and aircraft radio . Marine radio uses FM except for long range marine that uses SSB a derivative of AM . And SSB is still the main transmit mode choice by a huge population of amateur radio operators . And most shortwave ( SW ) broadcasting is still AM . <p> AM radio is talk radio , that is , news , weather , traffic , sports and opinion . There are still some AM music stations around but mostly the music moved to FM . AM and FM radio is primarily listened to in the car or truck . Coverage is predominantly local as the range of most AM and FM stations , during the day , is only a maximum of about 100 @ @ @ @ @ @ @ @ @ @ ( 88 to 108 MHz ) line of sight ( LOS ) and AM is mainly ground wave during the day . At night with the sun down the ionosphere layers come into play . AM signals can travel hundreds even thousands of miles on the AM band ( 530 to 1710 kHz ) because of the skip conditions where signals are refracted from the ionosphere layers . <p> It is amazing what you can hear at night on the AM band with a good radio and a wire antenna . You can hear coast to coast AM stations with ease and even some foreign stations . As for SW ( 3 to 30 MHz ) , broadcasts are worldwide . Most SW stations are in the 5 to 19 MHz range and the coverage varies depending on ionosphere conditions , sun spots , time of day , noise environment , and of course your radio and antenna . <p> Despite the lingering popularity of analog radio , the transition to digital radio is already occurring . In the U.S. , HD Radio now broadcasts simultaneously on the same frequencies @ @ @ @ @ @ @ @ @ @ is a digital version of the analog content overlaid on the same analog carriers . You will hear it referred to as in-band on channel ( IBOC ) . It uses OFDM and voice compression to minimize bandwidth but at the same time give greater fidelity to the audio . Noise and fading are less of a problem as well . <p> Nevertheless , HD Radio has been available for years but it has not become mainstream . Few actually know about it . HD radios are rare devices . Some high-end cars have HD Radio and some table top HD radios are available but they are rare . Furthermore , HD radio quality is less than expected as it is barely a noticeable improvement over the standard quality of FM and AM . There are very few HD AM stations but the majority of FM stations do broadcast in HD . HD offers the benefit of being able to multiplex one or two additional program sources on the same frequency giving stations several additional programming and advertising choices . <p> More popular than HD Radio is digital satellite radio @ @ @ @ @ @ @ @ @ @ back to form Sirius XM . This is a paid subscriber service available in most vehicles today . There are table top satellite radios but generally they are rare as they do require a special antenna that must " see " the satellites to work . <p> Shortwave broadcasting is also going digital , or at least some of it . A new digital technology called Digital Radio Mondiale ( DRM ) is now used in dozens of SW stations . It uses coded OFDM and digital compression to keep the bandwidth down to that required for SW broadcast ( &lt;10 kHz ) . A VHF version is also available now . A special receiver is needed or you can get a generic PC-based software-defined radio ( SDR ) and get the DRM software for demodulation . <p> Other countries have already made the conversion from analog to digital radio broadcast . The UK and most European countries use Digital Audio Broadcast ( DAB ) based on a digital standard called Eureka147 . It usually operates in the 174 to 240 MHz range or the L-band from 1452 to 1492 @ @ @ @ @ @ @ @ @ @ the data rate and bandwidth to a minimum . Japan has a similar digital radio called ISDB-T . <p> And let 's not forget Internet radio . That 's another story . <p> There have been rumors about phasing out AM and eventually FM radio in the U.S. I do n't  see any immediate action on this but keep it in mind . There is still time to enjoy the benefits of AM radio . Get a good receiver like a SW radio or one like those from CC Crane . And add an antenna . Then check out your local stations . You will be amazed at what you can hear at night on AM . A real listening experience . And try SW if you can . <p> Finally , if you have never built and tested a crystal radio , you had better get to it . Once AM broadcast stations go away , the crystal set will be history too . I built one recently just for the fun of it . I used the traditional oatmeal box inductor and a 1N60 germanium diode with ear phones . @ @ @ @ @ @ @ @ @ @ any signal . I tuned only three local AM stations and they were weak but very listenable. 
@@21005019 @1005019/ <p> Logic analyzers and oscilloscopes have coexisted for several decades . The emergence of additional digital inputs on scopes more than 15 years ago gave birth to mixed-signal oscilloscopes ( MSOs ) . Once a niche product category , MSOs now are offered by all major scope vendors . Many of these scopes include mixed-signal capabilities . Logic analyzers continue to be offered by major test and measurement vendors as well . While some engineers regard MSOs as narrow-channel logic analyzers , the difference between the product types is more substantial . <h> Which Instrument Is Home Base ? <p> - <p> After using logic analyzers extensively for 15 years , I 'm extremely comfortable setting up logic analyzers ; acquiring signals and buses from a variety of FPGAs , ASICs , microprocessors , and state machines ; and working with logic analyzer probing . Logic analyzers are great for tracking down functional and timing problems . A job change resulted in me getting my first MSO in 2005 . I became a fan and now have extensively used seven different MSOs from a variety of scope vendors . @ @ @ @ @ @ @ @ @ @ that you can use an MSO simply as a scope , which is how one would use it most of the time ( see the table ) . When needed , MSO digital channels provide just enough logic analysis for users whose home base is a scope . MSO digital channels are an extension to the scope . Digital channels can lie dormant for long periods until the need for them arises . This seems obvious , as the primary value of the MSO is the scope , not the digital channels . Once you have thought this through , your thinking about MSOs and logic analyzers becomes more rational . <p> While logic analyzers are typically used for single-shot applications , MSOs work across both single-shot tasks and applications that require the viewing of repetitive waveforms . MSOs have a simpler use model , as they 're usually limited to 16 channels or less , while logic analyzers come with many more channels . This limits MSO debugging to tasks that can be solved with up to four analog scope channels plus up to 16 digital channels , while @ @ @ @ @ @ @ @ @ @ anywhere from a single channel up to hundreds of channels . That 's why users often think logic analyzers are more complex than MSOs. - <p> While logic analyzers offer up to hundreds of time-aligned channels , the overlap with MSOs is really for users of logic analyzers with 34 or 68 channels . Users often will employ only a fraction of logic channels in debugging . They also can use additional channels to monitor parallel events that require a great number of channels . <h> State And Timing Analysis <p> MSOs and logic analyzers have fundamental architectural differences in how they acquire and display signals . MSOs exclusively use asynchronous sampling , just like an oscilloscope . For many users , this makes setting up an acquisition on digital channels simpler , because it feels like a scope . There is no need to know the difference between timing and state analysis or to specify a clock signal . MSO users get responsive updates when running repetitively . <p> 1 . The digital channels in MSOs add incremental debug capability to scopes , as shown here with Agilent 's @ @ @ @ @ @ @ @ @ @ bus triggering and decode . They also enable triggering across both analog and digital channels . <p> In contrast , logic analyzers offer more extensive acquisition modes with both timing and state analysis . State analysis is a great way to capture data on synchronous buses that have a clock . State captures only occur on valid clock conditions , which eliminate the capture of unimportant transition activity between valid clock signals . They also increase the width of the captured time window by using logic analyzer memory only when valid states occur . Optimized for capturing and displaying single-shot events , logic analyzers suffer from long stretches of dead time between acquisitions when running repetitively . <p> Interestingly , logic analyzer users typically find grouping and naming signals and buses to be much simpler on a logic analyzer than on an MSO . Ironically , MSO users typically find logic analyzer grouping to be more complex . <h> Triggering <p> MSOs and logic analyzers differ greatly in their triggering capabilities . Triggering in an MSO 's digital channels parallels its analog triggering . Most MSOs include both edge and @ @ @ @ @ @ @ @ @ @ these trigger conditions . Additionally , many vendors allow digital channels to be used for pulse-width and other time-based triggers . Triggering typically extends across both MSO digital and analog channels so users can trigger on a bus pattern on digital channels when a clock on an analog channel goes high . <p> As logic analyzers have no scope channels , users must team them with a standalone scope with a more complex cross-triggering setup to come close to triggering and measuring across analog and digital domains . <p> 2 . Logic analyzers uniquely offer both state and timing analysis . State analysis enables the capture of longer time windows and filters out transitions between valid states . Logic analyzers can interact with scopes when cross-triggering capabilities are needed . And , time-aligned scope waveforms can be imported into the logic analyzer viewer as shown here with Agilent 's 16800 logic analysis system . <p> MSOs are generally architected with a single-stage trigger ( one event ) , while logic analyzers incorporate sequential triggering . Logic analyzers allow the specification of a sequence of events that must occur in that @ @ @ @ @ @ @ @ @ @ scopes offer sequential triggering . However , the multiple stages are limited strictly to analog channels and are less capable than logic analyzer trigger sequencers . For example , logic analyzer sequences give users eight or more stages with storage options at each stage . MSO triggering is typically limited to a single pattern or a combination of edges and patterns with none of the logic analyzer trigger sequencing storage options on each level. - <h> Low-Speed Serial Bus Support <p> A key difference between logic analyzers and MSOs is the latter 's ability to trigger on and decode serial buses . Low-speed serial buses are ubiquitous in electronic designs because of their ease and low cost of implementation . It is hard to find a design that does not include at least one I2C or SPI bus , an RS-232 port or another UART standard , CAN , LIN , or USB . <p> MSOs excel at debug that includes low-speed serial buses . All good MSOs come with both triggering and decode options for serial buses . However , logic analyzers have not incorporated similar triggering and decode @ @ @ @ @ @ @ @ @ @ to set up the scope to trigger on specific packets . For example , users can set the MSO to trigger when an I2C read to a certain address with a certain data value happens . Alternatively , users can trigger on a certain SPI data packet or at the start of USB enumeration . <p> Quality MSOs decode packets at the protocol level . Not only does this save time compared with decoding the packets by hand , it also eliminates errors in protocols such as JTAG , USB , and FlexRay that use complex state machines and/or embedded clocks that make hand-decoding impossible . <p> Because MSOs include both analog channels and digital channels , it is important to note that the scope channels also can be used for serial bus triggering and decode . It 's often useful to reserve the analog channels for simultaneous examination of system events , though , or to use a combination of analog and digital channels for serial triggering and decode . <p> For example , one might use an analog channel for monitoring a JTAG clock while connecting four digital @ @ @ @ @ @ @ @ @ @ . Or , for four-wire SPI , a combination of analog and digital channels frees up at least one analog channel to simultaneously view other signals . <h> Probing And Supported Signal Types <p> Most mainstream logic analyzers and MSOs support single-ended signals and have threshold and minimum signal-swing requirements of about 500 mV to differentiate between ones and zeros . Signal access tends to be better thought out for logic-analyzer users due to the increased number of expected channel connections , while digital channel MSO probing tends to be an afterthought with no special built-in connectors . <p> Some MSOs offer Mictor , Samtec , and connectorless probing , but the dominant use mode continues to be connection using flying leads . Mainstream logic analyzers use similar flying-lead technology , as well as connector-based and connectorless probing . <p> 3 . MSOs typically include power options for serial bus triggering and decode . In this example , two analog channels were used to capture and decode I2C while four MSO digital channels were used to capture and decode SPI . <p> To produce affordable MSOs , vendors build MSO @ @ @ @ @ @ @ @ @ @ analog bandwidth ( typically 300 MHz to 500 MHz ) and uniquely offer single-ended signal support . The analog-bandwidth limitation can confuse users who see MSO sample rates ( typically called out as a banner spec ) far in excess of the digital-channel bandwidth ( typically not called out as a banner spec ) , believing that this leads to greater measurement precision . <p> In reality , the upper-frequency components of incoming signals are attenuated and will not make much difference in the accuracy of measurements . More expensive high-end logic analyzers and MSOs incorporate front-end technology and probing to support differential signals and high-bandwidth probes and cables . These tools typically support bandwidths in excess of 2 GHz , allowing these products to better use faster sampling rates . <h> Cost <p> It is extremely rare for a design team to be torn between purchasing a logic analyzer or an MSO . Rather , for an engineer or team needing a new scope , the addition of MSO digital channels can be attractive . Typical incremental cost is $2000 to $4000 on top of the scope . Most @ @ @ @ @ @ @ @ @ @ with a license key , an MSO cable , and probes . Upgrading to an MSO is quick and easy . <p> There are instances , though , when a team has a limited budget and must determine whether a scope or logic analyzer is a bigger need . The MSO really plays a secondary role behind the scope . As expected , 34- and 68-channel logic analyzers tend to be slightly more expensive than 16-channel MSOs , as they 're more capable for issues that require additional channels , state analysis , and easier grouping and naming of signals and buses . <p> While a scope can be upgraded later to add MSO digital signals , logic analyzers do n't offer the ability to upgrade to add scope analog channels . At the very high end , 16-channel MSOs cost in excess of $10,000 , making them more expensive than a mainstream 68-channel logic analyzer , but less expensive than a 68-channel high-speed logic analyzer with differential signal support . <p> MSOs have become widely popular over the last few years . Pioneered and first invented by HP , @ @ @ @ @ @ @ @ @ @ vendor . The value of MSOs over DSOs lies in their complement of 16 digital channels when the need arises to view state machines signals and buses , especially serial buses , where the scope 's four analog channels are n't sufficient . With the continual migration of parallel buses to serial , logic analyzers will remain an important tool for users who need state analysis , sequential triggering , and advanced multi-channel probing connections . 
@@21005023 @1005023/ <h> Skills For A Successful Manager <p> Throughout my career , I 've viewed the management ranks as a territory I could n't quite figure out , and one in which I could never really participate . Although I have held minor management positions , I never felt comfortable in them , and I inevitably reverted back to the working level . But because managers can do very well financially , especially those who move beyond the project level , I always wondered what made them more valuable than me . <p> Some engineers become successful managers , while others flounder . But that 's true of any type of professional moving into a management role . There 's no reason why engineers ca n't make the transition into management . For some , though , it 's a difficult process . Others do it and then decide the role does n't fit very well . <p> So what are the characteristics of a good manager , and do engineers as a group possess these characteristics in enough quantities to carry success beyond engineering and up the chain of @ @ @ @ @ @ @ @ @ @ think would be important , but really are n't . <p> Intelligence : Management success is n't actually highly correlated with intelligence . There are a number of obviously bright managers , but you also will find some who are n't as intelligent . Although it probably helps to be smart , the not-as-sharp managers can become successful as well . <p> Education : While those responsible for hiring managers seem to place a premium on MBA degrees from top schools ( few if any fast-track executives were ever hired from any of my alma maters ) , no degree automatically creates a good manager . In a number of cases , engineers became highly effective managers without any formal education on the subject . Some specialized courses , such as management accounting , can help . But many working engineers at the project level manage budgets pretty well . <p> Organizational Ability : If this is a prerequisite , then it 's clear why I failed . For many years , I 've used a good memory to overcome my lack of organization . Some managers , though , @ @ @ @ @ @ @ @ @ @ they can still achieve positive results . <p> Political Savvy : Decisions and actions in the management ranks are n't at all cut and dried . They require a sense of organizational power and influence , and knowledge about how to use that information to move forward one 's own goals . This too might be my own downfall as a manager . I could never quite figure out which way the political winds were blowing , or if I did , then I could n't make use of that information . Still , everyone would like to believe that managerial skill rather than influence or astuteness is the key to long-term success . An ability to understand the political and cultural climate of your company is essential to knowing what course of action to pursue , yet an excess of this quality decreases management ability . <p> A number of other personal characteristics might be important , but few seem to guarantee or even predict success as a manager . Certainly the attributes already mentioned here do n't guarantee managerial ability or expertise . So , what do managers @ @ @ @ @ @ @ @ @ @ things matter in the making of effective management ? <p> To put the question more succinctly , is it possible to pinpoint precisely how a good engineer can make a good manager ? If there were a formula , most engineers would be able to analyze and follow it . There is n't exactly a formula , but it 's possible to identify the factors that make management better or worse . Then , you decide if you possess these characteristics , or if you want to learn them . Here are a few qualities that should make a difference : <p> Leadership : A critical aspect of management is leadership , or the ability to get others to willingly follow your direction . In one sense this is easy to accomplish , because on an engineering project , most participants will want to follow a common direction to make the project a success . But translating this common direction into a means for completing the project is extraordinarily difficult . <p> In my time in the military service , leadership was based in part on the power of a @ @ @ @ @ @ @ @ @ @ decisiveness of the individual . That 's just one type of leadership . Most engineering organizations do n't have a rigid chain of command , and giving orders is far more difficult without it . In fact , you may have to lead people who do n't report to you and have little inherent reason to listen to you . It 's unlikely that a military style of management will work , at least by itself . There are other ways to get people to follow your direction , although they tend to be subtler and more difficult . <p> Sometimes people will follow you if you 're interesting " that is , if you provoke their curiosity or their ability to think creatively . Another way to lead people is by successfully implementing ideas and completing products . A third method is to remove administrative roadblocks , like procuring components or getting technical information from other parts of the company , so the engineers can press ahead on the project with minimal interruptions . <p> Essentially , these indirect means of leadership involve encouraging people to perform at their @ @ @ @ @ @ @ @ @ @ in high technology is a combination of coaching and setting an example , with no guarantee of the results . The downside to this is that it 's likely to burden you with very necessary duties that seem uninteresting or trivial . <p> To be a manager , engineers must be able to accept and operate with that type of uncertainty and mundane work . The problems are vague rather than well defined , and they rarely have a single good solution . While you can derive some satisfaction from navigating through management problems , you usually wo n't find the correct or best solution as you often would in engineering . <p> Focus : A manager ca n't focus on the details of the implementation . This is possibly the biggest hurdle for engineers to overcome . The urge toward involvement in design decisions and prototyping is very strong in most engineers . <p> A manager has to focus on the process , rather than on the structure . The most successful managers operate similarly to conductors who guide the orchestra while enabling and encouraging improvisation where it enhances @ @ @ @ @ @ @ @ @ @ the issue of delegation . Just as you delegate a power supply to produce a current with a set voltage , you have to delegate the details of the project to your team . The difference is that a power supply produces a known quantity based on physical laws , while your subordinates may produce results that greatly differ in quality and quantity . People tend to react with much less predictability and at widely varying levels of performance than electronic components . Nevertheless , without delegation , there 's no management . <p> Lack of control : Despite many textbook references to management as a controlling function , there frequently is little control in the process . You do n't control the business environment or your development tools , and you control the people least of all . Instead , your goal is to provide the resources and focus to the project so those doing the actual work can do it successfully . <p> Management is n't about moving chess pieces around on a board . The people who work for you move back , and not always in @ @ @ @ @ @ @ @ @ @ the best you can hope for is that people will follow your lead right up until the point you 're wrong , be able to recognize the fact you 're wrong , and continue in the right direction while still accepting your leadership . <p> Whether or not these kinds of activities appeal to you boils down to a personal preference . While there frequently are financial rewards for moving into management , many engineers find that it also has a significant downside . You have to direct the efforts of people who may or may not follow your lead , and operate within an environment over which you have little or no control , to bring about a conclusion that perhaps wo n't even be the one you had in mind when you started . <p> If this sounds appealing , or at least tolerable , then you 're management material today , and there are ways to prepare yourself for that role . I will address some of those tactics in future columns . <p> On the other hand , if it sounds worse than a trip to @ @ @ @ @ @ @ @ @ @ ever enjoy the benefits ( and hazards ) of management . During the course of a career ( which spans about 40 years ) , your interests , skills , and career goals are likely to change . If you desire the financial and power rewards that middle managers and executives seem to have , but your skills do n't appear to match those required for that role , give it a few years . <p> In the meantime , observe the managers you like and enjoy working for , and determine what characteristics make them good managers . Those observations will serve you both when deciding whether or not you have aspirations to management and after you achieve your position there . 
@@21005024 @1005024/ <h> What 's the Difference Between 3G and 4G Cellular Systems ? <p> The G of course means generation . Cell phones and systems are classified by the generation they belong to . Third generation ( 3G ) phones were developed in the late 1990s and 2000s . The goal was to improve the data capability and speed . 3G phones were defined by the Third Generation Partnership Project ( 3GPP ) and later standardized by the ITU-T . Generally known as the Universal Mobile Telecomunications System ( UMTS ) , this 3G system is based on wideband CDMA that operates in 5 MHz of bandwidth and can produce download data rates of typically 384 kb/s under normal conditions and up to 2 Mb/s in some instances . Another 3G standard , cdma2000 , was developed by Qualcomm . It uses 1.25 MHz bands to produce data rates to 2 Mb/s . Another version of cdma2000 is an improved IS-95 version . It is a 3GPP2 standard . It can transmit data at a rate to 153 kb/s and up to 2 Mb/s in some cases . <p> 3G @ @ @ @ @ @ @ @ @ @ data speed and capacity . The WCDMA phones have added high speed packet access ( HSPA ) that use higher level QAM modulation to get speeds up to 21 or 42 Mb/s downlink ( cell site to phone ) and up to 7 and/or 14 Mb/s uplink ( phone to cell site ) . AT&amp;T and T-Mobile use HSPA technology . The cdma2000 phones added 1xRTT as well as Rev. A and Rev B modifications that boost speed as well . Verizon and Sprint use cdma2000 3G standard technology . Virtually all standard and smartphone models and most tablets still use some form of 3G . <p> Long Term Evolution ( LTE ) <p> LTE is what most are calling 4G but in reality it is just an advanced 3G standard that some call 3.9G . LTE uses a completely different radio technology . Instead of CDMA , it uses orthogonal frequency division multiplexing ( OFDM ) and OFDM access . This modulation technique divides a channel usually 5 , 10 or 20 MHz wide into smaller subchannels or subcarriers each 15 kHz wide . Each is modulated with part @ @ @ @ @ @ @ @ @ @ slower streams that modulate the subcarriers with one of several modulation schemes like QPSK or 16QAM . <p> LTE also defines multiple input multiple output ( MIMO ) operation that uses several **29;1142;TOOLONG . The data stream is divided between the antennas to boost speed and to make the link more reliable . Using OFDM and MIMO let 's LTE deliver data at a rate to 100 Mb/s downstream and 50 Mb/s upstream under the best conditions . <p> Verizon and AT&amp;T are using LTE but it is not widespread yet . Sprint and partner Clearwire use WiMAX . They call WiMAX 4G but by definition , WiMAX is also 3G . Sprint and Clearwire have plans to switch to LTE in the future . <p> Incidentally , keep in mind that 3G and 4G technologies are data only . Voice is not carried by this technology . Instead , all voice calls are still via 2G GSM or cdma2000 . All 3G/4G handsets contain multiple radios , some for voice and some for data . Eventually voice will be carried over LTE but it is not there yet . <p> @ @ @ @ @ @ @ @ @ @ 3GPP and ITU-T still call LTE a 3G technology . If that is the case <p> What is 4G ? <p> The fourth generation has been defined but we are not in it , yet . Yes , many if not most of the mobile carriers and the various phone and equipment manufacturers actually advertise 4G now . The formal definition of 4G as declared by the 3GPP and the ITU-T is something called Long Term Evolution-Advanced ( LTE-A ) . The standard has not been fully completed but basically it is an improved and enhanced version of LTE that uses wider bandwidth channels and a greater number of MIMO antennas . The theoretical upper data rate is 1 Gb/s . That remains to be seen in practice . <p> As for what the various companies are calling 4G , Verizon says that their LTE network is 4G . AT&amp;T promotes their LTE and HSPA networks as 4G . T-Mobile indicates that their HSPA+ networks are 4G . Furthermore Sprint and Clearwire say that their WiMAX network is 4G . As mentioned , WiMAX is actually defined as a 3G @ @ @ @ @ @ @ @ @ @ and WiMAX are completely different technologically from previously defined WCDMA/cdma2000 3G , it seems appropriate to say LTE and WiMAX are 4G . Both are a step up in data speed . It all depends on your interpretation and acceptance of what 4G is . If the carriers are calling LTE 4G now , will they call LTE-Advanced 5G . If it is good marketing , they may . 
@@21005025 @1005025/ <p> This article describes the calibration and compensation of piezoresistive pressure sensors . Basic circuit properties of external circuits are calculated as an example of bare C32 pressure dies and pre-housed ASB1200E dies and the advantages and disadvantages of external circuits compared to integrated circuits are discussed , especially considering the restrictions of modern production lines . <p> The offset voltage V0 is part of this equation as ratiometric contribution of the driving voltage : <p> vo = VDD vo <p> Due to the given tolerances of the offset , the sensitivity , and the bridge resistance , the readout of a device deviates from the nominal values . The accuracy of a compensated device is then only limited by the nonlinearity and drift , if not for the fact that important parameters of Equation 1 significantly change with temperature . In fact all piezoresistive pressure sensors show the following inherent characteristics : <p> The decrease in sensitivity with increasing temperature , which is referred to as the negative temperature coefficients of span TCS . <p> With TN being the nominal temperature ( typically 25-C ) , SN and @ @ @ @ @ @ @ @ @ @ , +S , +RSand +Rs are the coefficients for the first and second order of the quadratic approximations . <p> The temperature dependence of the offset voltage is due to thermomechanical stress on the device . This stress is mainly caused by the mounting situation of the chip and is therefore not referred to as an intrinsic temperature dependency . It is often given in the form of the two secants slopes TCV0+ and TCV0- . From these secants the quadratic coefficients can be calculated . A first indication of the temperature impact on the offset can be calculated by the linear approximation i.e. for elevated temperatures : <p> V0 ( TMax ) = VDD ( V0(TN) + TCV0 ( TMax - TN ) ) <p> The change of the output voltage ( 1.1 ) with temperature is given by : <p> ( Equation 1.4 ) - - - - - - - - - - - <p> Continue to next page <p> With , in case of constant driving voltage and , in case of constant current excitation where RS is the total bridge resistance and IDD is the @ @ @ @ @ @ @ @ @ @ one may consider V0 = 0 . Just taking into account the linear contributions in temperature one finds : <p> for constant voltage <p> for constant current <p> Comparing the magnitude of these contributions to the temperature behavior of an ASB1200E at 75-C one finds temperature errors of sensitivity and bridge resistance are typically 10% of the full scale readings and the temperature shift of the offset is one order of magnitude smaller than the contributions of +S , and +RS . Additionally , the contributions of as , and aRs have different signs and compensate each other in case of constant current excitation : TCVO&gt;&gt; ( +RS + +S ) s p <p> Compensation And Calibration Via External Circuits <p> The Compensation of Offset and Sensitivity <p> With open ( half ) bridge devices the compensation of the offset can be done adding a fixed resistor into the bridges circuit . As this procedure is most often the origin of additional temperature shifts closed ( full ) bridge devices are used together with external circuits . An example for such a circuit is shown in figure three . This @ @ @ @ @ @ @ @ @ @ operational amps A and B. The resistor R gain in the resistor network is used to set the gain and compensate the deviations in sensitivity : <p> The offset is compensated by the voltage divider R offset 1 and R offset 2 . <p> To determine the settings for the offset one can start to measure the output at a given pressure p1 at 25-C , <p> with v0N = 0 and sN being the nominal values of the ratiometric offset and sensitivity . The actual reading now differs form the nominal expected reading : <p> Given only this one measurement point ( p1 , VOUT 1 ) , it can not be distinguished how much of the deviation is due to the offset and how much is due to the applied pressure ( sensitivity ) . A second measuring point ( p2 , VOUT 2 ) is needed to adjust offset and sensitivity : <p> One finds the shift of the offset for a specific device : <p> Continue to next page <p> Using these values one can now adjust R offset 1 and R offset 2 until the @ @ @ @ @ @ @ @ @ @ can be adjusted to rotate the curve i.e. by varying R gain at pressure p1 until the desired reading VOUT1N is reached . The following instruction should be carefully respected for each calibration procedure : <p> 1 . Allow the circuit to heat up and stabilize temperature . 2 . Make sure that the sensor temperature is well controlled at 25-C 3 . Applied pressures shall be applied with the highest possible accuracy . The use of calibrated references is recommended . 4 . The adjustment of the offset and gain should be done at the pressure point where highest accuracy is required . 5 . After adjusting the gain the compensation of the offset should be rechecked . 6 . The procedure needs to be performed on every single device <p> The accuracy that can be reached by this method mainly depends on the accuracy of the reference pressures and the stability and robustness of the circuit . If the pressures can only be adjusted with a limited accuracy of + " p also the compensation will show limitations . <p> Temperature Compensation With External Circuits The calibration of @ @ @ @ @ @ @ @ @ @ well as elimination of the temperature influences . During the design of the circuit one not only needs to take measures to calibrate the inherent temperature behavior of the sensor , but also needs to consider additional temperature effects added by the external circuit . <p> In a circuit such as figure three , the temperature impact is not only limited to +s , +s , aRs , +Rsand TCV0 as discussed earlier , but also has contributions of the temperature dependence of Roffset1 , Roffset2 , Rgain and from the other components in the circuit . <p> One also needs to consider that the temperature of the pressure die is not necessarily the same as the temperature of the circuit . In extreme cases a separate determination and calibration of the circuits and the chips temperatures need to be applied. - - <p> The most important temperature effect of the pressure die is the decrease of sensitivity at elevated temperatures . As we have seen before , this effect is typically one order of magnitude higher than the temperature dependence of the offset TCV0 or the quadratic contributions +s. @ @ @ @ @ @ @ @ @ @ ( Equation 2.5a for constant voltage ) - - - - - - - - - - - - - <p> ( Equation 2.5b for constant current ) - - - - - - - - - - - - - - <p> To deal with the decreasing sensitivity two basic methods can be applied : <p> Using thermistors or other temperature dependent devices in combination with a constant voltage supply . <p> Using internal chip characteristics " like the temperature behavior of the bridge resistance " in combination with constant current source . <p> Calibration With A Constant Voltage Supply Equation 2.5a is a ratiometric dependency in VDD . The idea behind constant voltage supply calibration with thermistor networks is to make VDD temperature dependent . Figure four sketches this basic idea. - According to equation 1.1 with compensated offset and neglecting all second order effects : <p> With VN being the voltage drop over the thermistor network RN. - With the condition of proper temperature compensation one finds : <p> ( Equation 2.7 ) - - - - - - - - - - - - <p> Continue @ @ @ @ @ @ @ @ @ @ temperature behavior of s and Rs equation ( 2.7 ) can be rearranged to a condition for the temperature coefficient of RN : - <p> ( Equation 2.8 ) - - - - - - - - - - - - <p> With RNN and RSN as resistance values at the reference temperature , the given characteristic has a negative temperature coefficient . The bridge supply voltage VDD rises when RN decreases with temperature , the drop in sensitivity is then compensated by the increase of the bridge output . <p> Temperature Compensation With A Thermistor Already indicated in figure four , the resistor network can be realized with a thermistor RT and a fixed parallel resistor RP. - The rate of rise of this linearized characteristic is <p> ( Equation 2.9 ) - - - - - - - - - - - <p> with B the B-Value of the thermistor , TM the middle temperature in the measuring range , and RT the thermistors resistance at TM . . Setting 2.8 equal to 2.9 , one finds an equation for the parallel resistor . The easiest way to @ @ @ @ @ @ @ @ @ @ and B and than solve the equation in RNN first : <p> ( Equation 2.10 ) - - - - - - - - - - <p> In this example , it is assumed that the application temperature range is between 0-C to +80-C with the bridge resistance of ASB1200E- being 3.5 k ? at +40-C ( TM = 313 K ) . The compensation is via an NTC B57881S212F , which has the following parameters at 40-C : B = 3560 K and RT = 1.2 k ? <p> Using 2.10 one finds as solution <p> - = 0.5 k ? <p> and therefore RP = 0.86 k ? . <p> - <p> With the parameters given it is possible to reduce the temperature impact of sensitivity from 2.2 10-3K-1 by a factor 5 to 0.410-3K-1 . <p> - <p> Calibration With A Constant Current Source <p> Figure five shows the configuration used in case of constant current source configuration . Similar to the previous analysis we start again with Equation 1.1 , assuming again the offset to be compensated and neglecting all second order effects : <p> ( @ @ @ @ @ @ @ @ @ @ - - <p> With the condition of proper temperature compensation , one finds after the same procedure as above as compensation condition : <p> ( Equation 2.12 ) - - - - - - - - - <p> - <p> Continue to next page <p> On Temperature Compensation The response curve of piezoresistive pressure sensors show linear and quadratic dependencies in pressure and temperature . A useful sensor needs to be compensated and calibrated . The simple compensation and calibration techniques previously described can reduce the linear impacts of temperature and improve the typical accuracy within the temperature range to 3% to 5% full scale or reading whatever the higher value is . Further more sophisticated circuit ideas are shown in figures six and eight . <p> Very often users of pressure dies however see certain drawbacks : <p> 1 . The calibration procedure needs to be done for each single device and the sensors need to be matched with selected resistors individually . 2 . For the calibration procedure measurements at two pressure points and at two temperatures are needed as minimum requirement . The integration of the measurement @ @ @ @ @ @ @ @ @ @ sensor chip 's technical parameters are altered by the assembly and mounting of the chip . The use of pre-measured chips is not possible. - 4 . A/D conversion or amplification of the signal needs to be done separately . <p> Therefore external circuits are more and more replaced by integrated signal processors , i.e. , DSPs , ASSPs , or ASICs , especially for new designs and higher volume applications . By using ICs it is possible to completely separate the mechanical assembly of a sensor device from the calibration and compensation step . Ready packaged sensors can be calibrated by software measures . <p> Calibration Using ICsFigure seven shows a typical circuit and architecture of a calibration circuit with Signal Processor . As indicated by the ASIC 's architecture the IC provides power management , a communication interface , EEPROM storage block for calibration parameters , signal transmission with multiplexing and ADC/DAC , amplification in case of analog outputs , an option DSP , optional temperature reference or temperature signal input , and an optional VDD regulator . <p> Simple low cost ASICs are designed for the use @ @ @ @ @ @ @ @ @ @ processor , and VDD regulator . They primarily offer three functions : storage of calibration parameters , conversion and transmission of sensor parameters , and the communication with an external signal processing or control unit . If the ASIC does not provide VDD regulation , this has to be provided by an external circuit . <p> It is not recommended to use the internal temperature reference of an ASIC for the calibration and compensation of a pressure sensor . The chip 's temperature is more important and can deviate from the ASIC 's temperature . <p> Calibration Procedure Whether the signal processing is done using an internal or an external signal processor does not matter for the general calibration procedure . The five free parameters sN , +s , +s , roff(TN) , and TCV0 in equation 1.1 to1.4 need to be implemented in a model . The calibration is based on the following general equation which describes a quadratic dependency of temperature and pressure <p> ( Equation 3.1 ) - - - - - - - - - - - <p> with a , b , c , d @ @ @ @ @ @ @ @ @ @ the raw output of the resistance bridge. - This equation is implemented in the signal processing unit and can also be given in different forms , for example <p> ( Equation 3.2a ) - - - - - - - - - ( Equation 3.2a ) - - - - - - - - - <p> with F , G , H , J , and K being another set of five calibration parameters . <p> Continue to next page <p> One can easily show that equation 3.1 and 3.2 are similar if all contributions of higher , non-quadratic orders are ignored. - The parameters g and g ' are fixed gain factors to map the desired pressure range to a specific output signal range . To determine all five calibration parameters of equation 1.1-1.4 or 3.1 or 3.2 one needs to measure five points of the transfer characteristic : ( pi , Ti , Vouti ) with i = 1.5 <p> The number of measuring points can be reduced if the temperature dependency in the application is small or the quadratic impact of output voltage shall be ignored . @ @ @ @ @ @ @ @ @ @ as 0 or 1 . i.e. d=e=0 in equation 3.1 leads to a similar calibration problem as G=1 and K=0 in equation 3.2 with 3 free parameters each . <p> The actual calculation of the calibration parameters and the storage of the parameters in the EEPROM of the ASIC is an easy software task and does not require any physical changes of the device itself . Therefore the calibration can be completely separated from the rest of the assembly line which allows a more efficient set up and usage of the production equipment . <p> Accuracy And Resolution The terminology of accuracy and resolution of a device often causes confusion , both refer to completely different properties of the transmitter . Some more refined definitions might be useful for a deeper understanding , such as accuracy refers to the reading of a sensor compared to a well known reference pressure , resolution is the smallest short term pressure change that can be detected by the sensitive device , and resolution is not a property of the sensitive chip or calibration but of the signal processor . <p> As an example @ @ @ @ @ @ @ @ @ @ signal ASIC with a minimum output resolution of 11 bits . The remaining nonlinearity L is in the order of magnitude of the temperature and pressure hysteresis HT and Hp and equals 0.1% full scale . The remaining temperature dependencies of sensitivity and offset TCVFS and TCVAO equal 0.015% FS/K . The accuracy therefore can be estimated as per : <p> The resolution however can be estimated as - , which equals 0.6 h Pa . <p> Conclusion Pressure sensitive elements , i.e. , silicon MEMS chips , show variations of offset and sensitivity as well as cross sensitivities to temperature and thermomechanical stress . The aim of compensation and calibration is to eliminate the sensitivity variations as well as reduce the cross sensitivities . <p> Compensation and calibration can be done by either external passive circuits or ICs , especially ICs as they 've become more popular in recent years as the availability of standard ICs for sensor purposes increases . Packaging is an important issue related to calibration for two reasons : a major part of the thermomechanical stresses originate from the packaging of the sensitive elements and @ @ @ @ @ @ @ @ @ @ . Pressure ports must be installed on the device . <p> As a consequence , the calibration needs to be done after the packaging is complete . The use of prepackaged devices like the ASB1200E can be very useful as the prepackage already protects the sensitive element in production . However , the decision of which calibration concept to use requires a detailed analysis of more factors such as the application , design , and production . <p> In terms of the application , temperature and pressure measuring range and accuracy requirements of the sensitive device itself need attention . A number of factors influence the design including the electrical environment ( availability of a stabilized power supply and an external signal processor ) , necessary output ( analog current , analog voltage , digital interface , etc. ) , packaging concept and accessibility of variable components , and the availability of temperature signals . <p> Production entails the availability of pressure measuring equipment , integration of calibration procedures in the production line , and in-house or external calibration . Especially for high volume productions , it is most often @ @ @ @ @ @ @ @ @ @ calibration and testing . In this case , integrated signal processing units or an ASIC seem to be the best choices . <p> Very often the calibration equipment does not fit into a highly optimized pick and place production . In such cases , the use of ready calibrated devices like ASB1200V ( see fig. 8 ) may be the way to go . <p> Dr. Bernhard Ostrick is head of marketing of temperature and pressure sensors systems for the Sensors Business Group of TDK EPC . He joined the company , then EPCOS , in 2002 . Dr. Ostrick can be contacted via e-mail at email protected . 
@@21005028 @1005028/ <h> Does Anyone Still Use An Analog Oscilloscope ? <p> In my recent technology report " The Ultimate Test Drive : High-Octane Oscilloscopes " , I got a chance to write about digital sampling oscilloscopes ( DSOs ) . These instruments are truly amazing today because they not only make all the basic measurements , but also perform all sorts of other useful test , troubleshooting , and measuring functions , thanks mainly to the amazing analysis software available . <p> After I wrote the report , however , it dawned on me that I forgot to mention analog oscilloscopes . It is probably just as well , as I suspect that most of you only use digital scopes and that analog scopes are history . But digging around in the analog scope world recently convinced me that these scopes , while they may be in the minority , are still alive and well . There are more than a few of them around in labs and shops everywhere . Here is what I found out : <p> There is something to be said about looking at a signal @ @ @ @ @ @ @ @ @ @ what is really there . In a digital scope , the signal is sampled , stored , processed , and then reconstructed on an LCD screen for viewing . What you see is a highly modified version of the actual input . So just how close is the actual signal to what you are seeing ? <p> I realize that if the input bandwidth , sampling rate , ADC resolution , and processor speeds are great enough , then what you see is pretty close to the actual . If it were not , we would not be using these instruments . But such a process seems to be a great deal of signal processing just to look at a signal . It is expensive to do it this way , and for many routine applications , a digital scope is probably overkill . DSOs are also very expensive . If you are just doing basic troubleshooting , you probably do not need as much scope horsepower in the modern DSO . <p> Where analog scopes really still shine is in looking at mostly analog signals . If you are @ @ @ @ @ @ @ @ @ @ probably still tell you all you need to know . Modulated signals also show up better on an analog scope . Low speed digital signals are also OK on an analog scope . But if you are working in the realm of all digital signals , especially at very high data rates , digital is the only way to go . You probably need a logic analyzer . If you are using complex modulation and communications protocols , DSOs are a must . <p> In asking around about analog scopes , the following opinions emerged : <p> Analog scopes are easier to use : I tend to agree with this opinion , but then again , maybe because I am just used to using an analog scope . DSOs , especially the older ones , are a bear to use . Like most digital devices , you end up spending lots of time playing with buttons and menus . I hate that . But I do have to say that the newer DSOs are a bit easier to use than the old ones . But they are still a challenge @ @ @ @ @ @ @ @ @ @ with a DSO you are dealing more with software than hardware . <p> Analog signals display better on a crt : I also agree with this . They are clear and crisp , thanks to fine focus on the crt . You can really see the details better . <p> Digital scopes can give false readings : Aliasing can sometimes be a problem . You really need to know what you are looking for and looking at on a DSO . With practice , you get used to the DSOs . <p> The dynamic range of an analog scope is greater : This is probably true . The digital resolution of the typical DSO is 8 bits , and that does limit the range . For some analog analyses , the analog scope is better . <p> I am used to analog and do n't really need to change This is an old way thinking , but it is also so very common . I would have to say , do n't knock it ( a DSO ) until you have tried it " especially the newer models . Yet @ @ @ @ @ @ @ @ @ @ justify the magnificence of a DSO . Old analog scopes do just fine , thank you . <p> Analog scopes are cheaper : Boy , is that ever true . You can get a 100 MHz dual trace scope for less than $1000 . There are no DSOs that cheap . A good DSO will set you back mucho thousands of dollars . Most wide bandwidth , fast sampling DSOs are over $10,000 . And there are really high-end models over $100,000 . But in defense of the DSO , these things do so much more . You really do get what you pay for . But if you really do n't need it , why do it ? <p> As for me , I still do a bit of design and use an analog scope . It is an old Tektronix 100 MHz unit I got used . It works great . I did have to buy a new set of probes from Tektronix , and those cost me more than the scope . But you ca n't not have the right probes and expect the scope to work @ @ @ @ @ @ @ @ @ @ it is fine for the work I do . I also experienced the fussiness of the early digital scopes when I bought 16 of them from Tektronix for my employer back in the mid-1990s . I hated these things . But I must say that after many hours of use , you do get used to the arcane menus and other control idiosyncrasies . These units had a bandwidth of 100 MHz and had the FFT feature , which I learned to love for certain measurements . The new DSOs are much better and do so much more . But , you really need to be able to justify their sky-high prices . <p> Incidentally , there are quite a few companies making analog scopes . The big U.S. manufacturers , like Agilent , Lecroy and Tektronix , retired their analog scope lines a while back . But you can still get many of them on the used market . Tons of used instruments are available " even on eBay . New analog scope makers include B&amp;K Precision , EZ Digital , Instek , Iwatsu , Kenwood , Leader , @ @ @ @ @ @ @ @ @ @ they are out there if you are still interested . <p> So how do you feel about analog scopes ? Send me a note at email protected And do answer the simple question below . <p> Which of the following best describes how you feel about oscilloscopes ? <p> I prefer analog scopes , they are adequate for my needs , and I will never change . <p> When digital scopes come down in price , I will buy one . <p> Use one of the newer DSOs with deep memory , color LCD , and analysis software , and you will never go back . 
@@21005031 @1005031/ <h> Microcontroller Handles LED Brightness Control <p> Evgeniy Freidlin Dec 07 , 2004 <p> Usually , an MCU is considered a digital device . By default , its output voltage level can be either high or low and nothing in between . With the requirement to create an LED brightness control , the first idea that comes to mind is using a standard digital-to-analog converter , or design a controlled resistor network . Luckily , most modern MCUs have built-in pulse-width modulation ( PWM ) , and this leads to the easiest and cheapest way to solve the problem . <p> According to our project requirements , the brightness of two LEDs has to be gradually changed from minimum to maximum and back , in the opposite phase and in a time of about several seconds . Also , the several seconds of delay between the ramps should be as shown in Figure 1 . During Ramp 1 time , the PWM signal 's pulse width is incremented for LED 1 and decremented for LED 2 . For example , let 's have the ramp time equal 2 seconds @ @ @ @ @ @ @ @ @ @ step lasts about 16 ms . Note that the pulse-width change should occur only once during the PWM period . Hence , the PWM period should also equal 16 ms . <p> The low-end 8-bit Motorola MC68HC908-QT2 flash MCU with built-in oscillator is used . Its oscillation frequency equals 12.8 MHz , together with the prescaler programmed to a selection of 1:64 , and supplies a timer clock period of 0.02 ms . Then , to generate a PWM with a 16-ms period , the number of clocks to be loaded into Timer Counter Modulo Register ( Tmod ) should equal 16/0.02 = 800 , or $0320 in hexadecimal . <p> The maximum pulse width ( PWMAX ) can be less than or equal to the PWM period . Consider PWmax to be equal to about 15 ms . To get this maximum value from zero , for 128 steps , each step should have a value of 15/128 = 0.117 ms . By rounding it to 0.12 ms , we get PWMAX = 15.36 ms , i.e. , 96% of the PWM period . Thus , in each step @ @ @ @ @ @ @ @ @ @ equal to 0.12/0.02 = 6 timer clocks . <p> Any type of MCU with PWM and any timing consideration can be used to implement this technique . Resistors R1 and R2 should be chosen according to the LEDs used . Pin pA2 is used to activate ( pA2 =1 ) or deactivate ( pA2=0 ) the brightness control . 
@@21005032 @1005032/ <h> The Future Of Wi-Fi , UWB , And The Less Known Wireless Technologies <p> As the cellular generations evolve , so do other wireless technologies . Wi-Fi and Ultra-Wideband ( UWB ) are well known wireless technologies that are also continuously changing along with the cellular standards as semiconductor and antenna technologies advance . <p> The most widely used wireless technology Wi-Fi , also known as the IEEE 's 802.11 wireless local-area network ( LAN ) standard , has changed significantly . When the initial standard 802.11 was introduced in 1997 , the maximum data rate was 2 Mbits/s . In 1999 , the 802.11b standard emerged to provide up to 11 Mbits/s and launch the first successful WLAN wave . <p> Since then , the modulation/access has changed from direct sequence spread spectrum ( DSSS ) to orthogonal frequency-division multiplexing ( OFDM ) . Subsequent versions of the standard have used various configurations of OFDM. 802.11a was the first to use it in the 5-GHz band , boosting rates to 54 Gbits/s. 802.11g came next with 54 Gbits/s in the 2.4-GHz band . The most recent version @ @ @ @ @ @ @ @ @ @ using up to four multiple-input multiple-output ( MIMO ) streams and wider bandwidth ( 40 MHz ) channels in both the 2.4- and 5-GHz bands . <p> Already , the next generation of standards is being finalized " 802.11ac and 802.11ad . The next logical extension of the standard beyond the popular 802.11n is 802.11ac . It is expected to use the 5-GHz band to achieve data rates to 1 Gbit/s using the same basic media access control ( MAC ) and physical layer ( PHY ) configurations but with some modifications to achieve the higher data rates . <p> 802.11ac does this by using wider-bandwidth channels of 80 or 160 MHz , whereas the maximum for 802.11n is 40 MHz . This standard also supports up to eight spatial streams of MIMO , whereas 802.11n has a maximum of four . Multi-user MIMO or MU-MIMO is introduced to further boost speeds . The modulation is 256-phase quadrature amplitude modulation ( 256QAM ) instead of the 64-phase quadrature amplitude modulation ( 64QAM ) used by 802.11n . <p> Using single antennas and 80-MHz bandwidth , a user could expect a @ @ @ @ @ @ @ @ @ @ to 867 Mbits/s with a 2x2 MIMO in an 80-MHz channel . Using a 160-MHz channel and single antennas , a maximum rate of 867 Mbits/s could be achieved . With 2x2 MIMO in 160 MHz , the theoretical rate jumps to 1.73 Gbits/s . Even higher speeds are expected with higher MIMO configurations using the MU-MIMO arrangements . <p> The 802.11ad standard is another high-speed variation using the 60-GHz millimeter-wave band . Data rates up to 7 Gbits/s can be expected . Neither the 802.11ac nor the 802.11ad standard has been finalized as work continues toward a potential ratification in 2012 . <p> Considerable effort was put into developing a UWB wireless standard . While the IEEE standards group 802.15.3a failed to agree on one approach to UWB , several companies developed the OFDM version and have sold chipsets over the past several years . <p> Only a few viable UWB chip companies still exist , such as Alereon and Wisair . Both produce chips that are used primarily for transmitting compressed video to video monitors , HDTV sets , and other video products . More recently it is @ @ @ @ @ @ @ @ @ @ docking stations . <p> UWB uses the 3.1- to 10.6-GHz band and can achieve data rates from 53.3 Gbits/s to as much as 480 Gbits/s at a range of up to 10 meters . The WiMedia Alliance , which defined the standard for UWB , provided for higher data rates in its most recent version 1.5 . It supports data rates to 1.024 Gbits/s with simple modifications to the modulation and coding . Eric Boockman , CEO of leading UWB chip supplier Alereon , sees an increasing adoption of the technology where it simplifies video transmissions over short distances . <p> Some other lesser-known wireless efforts do exist , with their futures unknown . Streaming video wirelessly is the focus . For example , WiDi is a software option from Intel that uses Wi-Fi ( 802.11n ) to stream video to HDTV sets that have an appropriate compatible accessory receiver . <p> ECMA-387 is the European 60-GHz wireless LAN standard . It offers a single-carrier mode with speeds to 6.35 Gbits/s and an OFDM mode that can generate speeds to 4.032 Gbits/s . Its unique MAC conforms to the Open @ @ @ @ @ @ @ @ @ @ the Wireless Home Digital Interface ( WHDI ) is a unique standard for streaming video from computers to HDTV sets . It uses 40-MHz wide channels in the 5-GHz unlicensed band . It also uses OFDM in a version of 802.11a with a unique compression scheme and 5x4 MIMO to achieve a reliable 3-Gbit/s data rate . 
@@21005033 @1005033/ <p> The most common method for measuring currents in electronic circuits is to place low-value sense resistors in series with the load and measure the voltage drop across them . These voltage drops are very low , so their outputs are applied to precision instrumentation amplifiers with high input impedances . The high impedance minimizes loading on the sense resistor , and the instrumentation amplifiers are engineered to have a very linear transfer characteristic . <p> For what 's called low-side sensing , the sense resistor can be placed between the load and the common ground and used with a single-ended amplifier ( Fig. 1a ) . Alternatively , the sense resistor can be placed between the load and the power supply , and a differential amplifier measures the current ( Fig. 1b ) . This is the preferred configuration for several reasons . <p> 1 . High-side and low-side current sensing refers to the placement of the current-sense resistor : between the positive supply and the load , or between the load and ground . With a single load to monitor , the only drawback to low-side sensing @ @ @ @ @ @ @ @ @ @ a fault that shorts the top of the sense resistor to ground . <h> The Trouble With Low-Side Sensing <p> One problem with low-side current measurements is that the current sense circuitry will not detect a fault if it shorts the top of the sense resistor to ground . <p> There is a more serious problem when low-side sensing is used to monitor multiple loads that can be switched on and off independently . In Figure 2 , the current-sense resistors are labeled RS1 and RS2 . The voltages at nodes VCOM1 and VCOM2 depend on the current flowing through those sense resistors . Therefore , the common voltage for loads 1 to 4 and loads 5 to 7 is potentially noisy . The difference can range from a few tens of millivolts to 1 V or even 2 V. <p> 2 . Monitoring multiple loads powered by a common supply strongly favors high-side sensing . The common-mode voltage is stable , and the potential for ground loops is reduced . <p> There are also potential ground loop problems . The voltage at VCOM2 could be higher or lower than @ @ @ @ @ @ @ @ @ @ flow between them , causing errors in the current measurements in RS1 and RS2 . <p> Finally , parasitic resistance RP makes the ground-loop problem even more sinister . The voltages at VN1 and VN2 are negative with respect to VCOM1 and VCOM2 . That means that , depending on its reference point , the amplifier used to buffer and amplify voltage across the sense resistor could see a negative common-mode voltage . <p> Appling high-side sensing , with a differential amplifier , to the multiple-load situation solves all those problems . The common nodes have a much smaller voltage difference between them and the low side of the voltage source , so potential ground loops are minimized ( Fig. 2b ) . <p> A few special considerations must be taken into account when using high-side current measurement . For one , the precision amplifier across the sense resistors must be able to deal with the supply voltage as a common-mode voltage . 
@@21005038 @1005038/ <h> What 's All This Common-Centroid Stuff , Anyhow ? <p> Once upon a time , we designers of op amps used to locate as many of the critical transistors as we could along the axis of symmetry . We put the input transistors right along the Center Line ( CL ) of the chip , or on a pc board along the CL of the board . We tried to put the output transistors on the CL , too , down at the far end of the layout . We realized that any heating from the output stage could cause significant , serious input errors . For my discrete layouts , I designed " ISIS Clips " and " Omega Clips " to keep the input transistors at the same temperature ( Fig. 1 ) . <p> ISIS , the old Egyptian Goddess , was George Philbrick 's inspiration . The K7-A6R array of op amps was called the " ISIS " computer . The symbol S with an I across it was a neat symbol for ISIS . Look at it again , and it 's the @ @ @ @ @ @ @ @ @ @ you are a fan of Positive Feedback , George Philbrick used to say that ISIS was her own mother . So I designed some little clips made of soft aluminum , with green paint for insulation all over them , in the shape of S " an ISIS clip . This clip has rotational symmetry . <p> Conversely , an " Omega Clip " has mirror symmetry , like the Greek letter for omega ( see Figure 1 ) . We made these of the same soft aluminum , and the same green paint . Walter Kern made them up . <p> When monolithic op amps came along , there were some influences to " keep it simple , stupid " . I designed a T52AH " also labelled as Amelco 's 809BE " with just 10 transistors , which worked pretty well . But op amps with 20 or 30 transistors soon had just as good a yield . And they offered more features . So , we kept learning how to add more transistors for better performance . <p> But when the Fairchild -A725 came along , we @ @ @ @ @ @ @ @ @ @ input transistors ? What the heck was George Erdi smoking ? If you set up a diff amp with two transistors in parallel at the plus input and two transistors paralleled on the minus input , why would that give an advantage ? But the specs showed real superiority " low offset voltages , good bias currents , and low offset current . Hey , this was about 1971 . Not many engineers were climbing inside their suppliers ' ICs and studying the layouts . If you did n't , though , you could be stuck with a lousy layout . I know . <p> The basic feature of the -A725 was the common-centroid layout of the input transistor " pair " ( Fig. 2 ) . <p> If you took those four input transistors and laid them out in an X pattern , it would be denoted by : <p> AB BA <p> Connecting them properly in parallel , you can get the linear gradients of Vos , to cancel . And the gradients in beta to cancel . Gradients caused by heating from the output stage " and @ @ @ @ @ @ @ @ @ @ cancel . Any linear gradients caused by imperfect die attach tend to cancel . ( Nonlinear gradients do NOT get cancelled , of course , but these are usually small . ) And these cancellations all happen thanks to a common-centroid layout , which is just another way to say that the " Center of Gravity " ( CG ) of one input " transistor " is at the same place as the CG of the other transistor . ( I bet you can figure out that any geometry that is connected to metal labelled " Bl " is a base " if something is connected to " C2 , " that must be a collector ... ) <p> There are many kinds of common-centroid layout , in addition to cross-coupling . You could lay out a " pair " of npns as ABBA . The " B " transistors in the middle not only reject gradients , but they can have smaller output capacitance , since they only need one tub . And in some cases , this long , skinny circuit ( Fig. 3 ) may fit in @ @ @ @ @ @ @ @ @ @ this example , the transistors are still connected as an ordinary differential pair . But if you connect the transistors to act as a current reflector by shorting Cl , Bl , and B2 together , and merging that metal , the interconnections become very simple . <p> Recently , I saw a technical article by some engineers ? , claiming that they had a computer program that automatically provided good interdigitated and cross-coupled common-centroid layouts . " ALAS ! " was what they called the program . I looked at their results . All I could say was , " Alas ! ! " The authors appeared to think that a layout of ABAB or AABBAABB or ABABABAB or even : <p> ABAB BABA ABAB <p> makes a " common centroid " . When I apprised them of their error , they tried to argue that the magazine 's computers had misrepresented their results . Uh-uh . They did not understand that their computers were clueless . Not only was it a bad program that generated poor layouts , but they did not even recognize that it was a @ @ @ @ @ @ @ @ @ @ need a fancy computer to set up pairs or groups of transistors with common centroids . I do it all the time with groups of resistors , using just pencil and paper " and lots of symmetry . <p> The Editor at the Journal of Solid State Circuits was a good sport , and gave me space for my criticism of that paper2 ; and the authors ' efforts to rebut my criticism3 . <p> Often , there are significant matching errors when using transistors , or resistors , or capacitors , if common-centroid layout is n't used . There are always more-or-less linear gradients across a die . Bipolar transistors have gradients of Vbe and beta . If there 's any temperature gradient caused by output device dissipation , that 's going to hurt the Vbe matching by 2mV/-C , if the input transistors are n't at identical temperatures . MOSFETs are afflicted by gradients in etching , in Vt , and in oxide thickness . Adjacent resistors can have poor matching due to gradients in etching and in sheet rho . If you want your capacitor sets to @ @ @ @ @ @ @ @ @ @ and oxide thickness . Die stresses cause shifts that relate to linear gradients . Proper understanding of cross-coupling or other forms of " common-centroid " layout can be very valuable to help reject linear gradients across your die . An improper understanding of " common-centroid " layout can be amusing " or pathetic . If you insist on cross-coupling components that are not critical , you can waste lots of die space . <p> Back in 1972 , on Jim Pastoriza 's AD550 Quad Current Switch , I observed some of the limitations of laying out a DAC 's transistors all in a linear row . When some bits were switched ON or OFF , there were significant thermal tails . Linear mismatches also occurred , due to linear gradients in Vbe and beta . <p> I made my own layout for a monolithic Quad Current switch , with good common-centroid layout . It had 8,4,2 , and 1 emitters " and 2 emitters for the reference . What was the Patent number ? 3,995,304 ? You can tell that it 's an old number " the patent has expired @ @ @ @ @ @ @ @ @ @ Significant Bit ( MSB ) emitters being A , the LSB as D , and the reference as R : <p> AAAA BBCR - - - - - - D RCBB AAAA <p> I was able to convince myself that the Vbe matching of this kind of layout was adequate for at least an 8-bit DAC " without any emitter resistors . It may be as good as 10 bits , if I did some trimming . And much better , if emitter resistors were used . Heck , the first DAC I ever built was 15 bits plus sign . <p> If you use resistors , you should be aware that resistors made in a batch process tend to have linear gradients . So if you have four resistors in a row , and you want a good ratio , such as 1:1 ( or 4:1 ) , choose the two resistors in the MIDDLE . Put them in series , and take the resistors on the ends , and put them in series ( or in parallel ) and the ratio will tend to be more accurate . @ @ @ @ @ @ @ @ @ @ hold true for thick-film , thin-film , or monolithic resistors . If you have eight resistors , the matching can get even better ( Fig. 4 ) . Back in ' 86 , Dennis Monticelli asked me which layout I would recommend for the input of his LMC660 op amp : 
@@21005039 @1005039/ <h> Thermal Analysis and Other Simulation Types <p> Fig 1 . This image shows the temperature distribution on the top surface of a USB memory stick PCB . <p> Fig 2 . Shown is an isolated view of thermal bottleneck distribution in the top layer of the memory stick PCB shown in Fig. 1 . White and yellow areas indicate areas in which heat flows are most constrained . <p> Fig 3 . Shown is a typical neck-down area on a power distribution net . The net in this view is color-graded by current density . <p> Fig 4 . Shown is a typical heat sink geometry for a power amplifier module . The large heat sink can mechanically stress the board and its connections . <p> The primary function of thermal analysis is to predict the temperatures of components and parts within a product . By visualizing heat fluxes , thermal bottlenecks , and missed shortcut opportunities , thermal analysis seeks to eliminate any detected thermal compliance issues . <p> These temperature predictions are important to other analysis disciplines as well , as many real world engineering materials @ @ @ @ @ @ @ @ @ @ can be critically important , especially in power distribution , signal integrity , and timing signals . Copper 's impedance increases with increased temperature even within common design temperature ranges . Moreover , there may be tradeoffs when deciding what is good for thermal performance and what is good for the rest of the design . This article will discuss how thermal analysis results can influence other forms of analysis and the design tradeoffs that may result . <p> Thermal Analysis Moves Ahead <p> For the past 20 years , computational fluid dynamics ( CFD ) techniques have provided 3D conjugate thermal simulation results that predict and display temperatures in and around electronic product designs . Thermal designers routinely use predicted temperatures to judge thermal compliance , simply by comparing the simulated temperatures to maximum rated operating temperatures . If the operating temperature exceeds the maximum rated value there will be at least a potential degradation in the performance of the packaged IC , and at worst an unacceptable risk of thermo-mechanical failure . These techniques are commonplace today , with widespread adoption all across the electronics sector including heavy @ @ @ @ @ @ @ @ @ @ and consumer products . <p> Frequently the variance in thermo-physical properties for a substance is large enough across the expected temperature range to be a first-order design effect . A common example is the thermal conductivity of silicon , which decreases by approximately 20% as temperature increases from 350-K ( 77 -C ) to 400-K ( 127 -C ) . This of course has the tendency to exacerbate thermal problems at the die level . The hotter the die becomes , the more difficulty heat has in exiting the die due to the lower thermal conductivity value . This effect is often described as a thermal runaway ' scenario . <p> Copper is used extensively in the electronics industry of course , and it too can have significant thermo-physical property changes over the expected range of operating temperatures . For example , the electrical resistivity of copper increases approximately 4% for every 10-C temperature rise within typical temperature ranges . That equates roughly to a 32% variation in resistivity over an 80-C span of temperatures . This has a substantial effect on the DC resistance of the copper in the @ @ @ @ @ @ @ @ @ @ within the board . As joule heating effects are directly caused by current density and resistivity , temperature impacts the power distribution , and the power distribution impacts temperature . <p> This strong interaction is one of the greatest design challenges in modern PCB design , as it adds complexity to any attempt to provide enough metal on the board for DC current needs . Neck-downs ' in the power distribution network will cause locally increased current density and will induce large joule heating terms , elevated temperatures , and associated changes in electrical resistivity . <p> Consider a typical neck-down ( Figure 3 ) on a power distribution plane . A neck-down may be a narrow section of a plane , a via that is connecting the power supply to the plane or two planes together , or a narrow trace that is expected to carry tens of amperes . Such neck-downs can , in severe cases , act like fuses which can lead to disconnected power situations and even mechanical failures . At the very least , these neck-downs cause a rise in temperature on the board . @ @ @ @ @ @ @ @ @ @ is connected . Prediction of the rise requires a detailed thermal simulation of the board . <p> Both power and temperature affect transistor operation . In fact , transistor performance is usually partitioned into PVT corner cases that map variations in process , voltage , and temperature . Voltage and temperature are greatly affected by the PCB design . Standard I/O buffer models known as IBIS models are used in system simulations to characterize buffers by using I-V ( current-voltage ) and V-t ( voltage-time ) tables for each of the different PVT corners . For example , a CMOS buffer has a maximum corner with I-V and V-t tables for fast process , high voltage , and low temperature , respectively . It is important to consider all these factors to properly account for the many I/O buffer performance variations that can arise . <p> At IC process technologies of 90 nm and below , leakage currents begin to cause appreciable additional heat sources . These leakage currents have a non-linear , increasing relationship with temperature . At these process scales , the temperature is required to evaluate the @ @ @ @ @ @ @ @ @ @ of this relationship in the thermal management scheme a necessity . <p> Temperature also has a powerful effect on mechanical stress and strain . Most materials experience a significant decrease in Young 's modulus ( e.g. , a drop of approximately 20% from 50-C to 100-C for Sn-3.5Ag solder ) and an increase in yield stress with an increase in temperature , as well as an associated rise in the coefficient of thermal expansion for that material . Including temperature effects during stress analysis simulation is critical to properly predict thermo-mechanical failure and reliability metrics . <p> It 's essential to be aware of these temperature effects throughout the design process . The temperature dependence of physical properties in common electronic materials means thermal design must be coordinated with the power distribution , signal integrity , and mechanical failure analyses . In addition there are many thermal issues that stem from the temperature dependency of material properties in other analysis and design disciplines . <p> Electrical and Thermal Tradeoffs <p> Component placement commonly involves tradeoffs between thermal and electrical disciplines . Often the ideal placement from an electrical perspective is @ @ @ @ @ @ @ @ @ @ A prime example is the placement of components as closely together as possible for purely electrical reasons . Shorter connections from pin to pin are generally good from a signal integrity standpoint . It is common practice to constrain routing with maximum allowable distances for particular connection " a direct result of prioritizing electrical considerations . <p> But this placement strategy may be in direct conflict with the thermal management ideal . Placing components close together results in increased power density locally and invariably leads to elevated temperatures among all the components in a group . When components are grouped tightly to improve electrical performance , the thermal victim ' effect may appear in components that would not otherwise pose a thermal challenge . <p> A second example is the thermal rule of thumb which claims that components with the largest thermal management issues ( high powers and power density ) should be placed as the near the leading edge of the board as possible , to receive to the coolest possible air in a forced convection cooling system . But this may be impractical from an electrical perspective when @ @ @ @ @ @ @ @ @ @ of routing , timing , and signal considerations . <p> In the field of IC packaging , there is the design problem of hot spots ( zones of elevated power density ) aligned vertically in stacked-die devices . This can have a drastic effect on the peak silicon temperature as well as the temperature gradients present across the dice . Moving the hot spots so they do not stack vertically is a sound approach , but it can add electrical and manufacturing difficulties in packaging . Moreover , it requires careful planning in the functional partitioning of the active surfaces . <p> Electromagnetic Compliance and Thermal Tradeoffs <p> There are further design tradeoffs to be considered in the field of electromagnetic ( EM ) compliance and its relationship to thermal issues . Here too , design proposals aimed at improved EM containment can detract from thermal performance . <p> The concern applies to many aspects of EM design . Consider a vent or perforated plate design . From the perspective of EM compliance , each cooling vent in the chassis should have as small a free-area ratio as feasible ; @ @ @ @ @ @ @ @ @ @ altogether . But any reduction in the free-area ratio of a cooling vent will likely decrease the thermal performance of the design . A less open vent will impose additional flow resistance through the system , reducing the amount of air that moves through the chassis , whether the air movement is mechanical ( fans or blowers ) or buoyancy driven . A design compromise must be found that is acceptable to both design disciplines . <p> A second example is the use of shielding cans . Shielding cans are metallic enclosures that envelope noisy ' components that pose particular difficulty for the EM design . While these cans can effectively attenuate the emissions from the components , they pose additional challenges to the thermal design . By placing a solid obstruction over a component , we are effectively removing a heat transfer avenue by reducing the convective heat transfer ability on the top of the component . This forces most of the heat to reach the ambient via the PCB , and changes to the local copper content and distribution in the form of fills and thermal vias may @ @ @ @ @ @ @ @ @ @ third example is found in heat sink design . Considering the thermal design only , a heat sink with more fins and more surface area is generally better at allowing heat to escape from a component . This is n't always true of course , as heat sink geometry imposes an obstruction to air flow that must be considered , but for the purposes of this argument we 'll allow it . However , the EM compliance design may very well suffer as larger and larger heat sinks are proposed , as the heat sink may begin to serve as an emissions antenna ' and exacerbate EMC problems . The best heat sink for the thermal design may not be ideal for the EMC design . <p> Stress and Thermal Tradeoffs <p> The design of heat sinks can have further tradeoffs when considering mechanical stress as well . One common example of this is the size ( and therefore the mass ) of a heat sink design . Usually a bigger and heavier heat sink will yield better thermal performance than a smaller , lighter one ( again , ignoring @ @ @ @ @ @ @ @ @ @ cost effectiveness ) . However , the increased mass will cause additional mechanical stress concerns . If a heavier heat sink is attached to a component it may require additional mounting attachments . In the case of a vertically mounted heat sink , the heat sink may act as a cantilever ' with increased stress effects being observed at the heat sink attachment points . An example of such a heat sink design ( Figure 4 ) is shown . <p> Further , the selection of materials can have important effects . Copper has excellent heat conduction characteristics ( k 400 W/mK ) and is often used when thermal management is the foremost concern . However , use of copper may have drawbacks on the stress design . Copper 's coefficient of thermal expansion is approximately six times larger than that of silicon , which imposes additional challenges in some cooling strategies ( through-silicon vias are one example ) , as the materials will tend to strain at greatly differing rates . <p> Summary <p> Temperature predictions within electronic systems are still used primarily to compare the thermal performance of @ @ @ @ @ @ @ @ @ @ vital to acknowledge the secondary effects of temperature on other design disciplines . Very often a design change targeted at improving thermal performance will have negative impacts on another aspect of the design because the properties of copper , silicon and other common materials have important " and differing " dependencies on temperature . These can complicate the design of power distribution , signal integrity , electrical timing , and mechanical stress solutions and should be built into the design as early as possible by utilizing thermal simulation techniques in parallel with other design flows . 
@@21005041 @1005041/ <h> What Are Intelligent Building Technologies ? <p> Rawlson O'Neil King Jun 28 , 2006 <p> Property managers can substantially boost the efficiency of their real-estate portfolios by installing intelligent building technologies . Intelligent-building technologies seek to enhance the building environment for occupants while controlling costs . These systems are designed to improve end user security , control , and accessibility , with the aim of increasing worker productivity and user comfort levels . <p> Such technologies are defined as integrated communication and control systems that provide both the building operator and occupant with an environment that is flexible , effective , comfortable , and secure . By using such systems , building operators can enjoy a single interface that can control a network of disparate building automation systems , which typically comprise electronic equipment that automatically performs specific facility functions . <p> The commonly accepted definition of a building automation system ( BAS ) includes the comprehensive automatic control of one or more major building system functions required in a facility , such as heating , ventilating , and air-conditioning systems . Automated systems include a collection of @ @ @ @ @ @ @ @ @ @ be controlled , such as temperature , relative humidity , and pressure . Similarly , output devices impart electronic signals or physical action to the control devices , which may be electric relays or damper and valve actuators . The sensors and output devices are connected either to a unitary controller or to a distributed processor . <p> Unitary controllers are limited to the needs of an intended function and , thus , have limited capabilities , such as memory size . Distributed processors can accommodate the requirements of several unitary controllers , as well as connect directly to input and output devices . Intelligent-building technologies revolve around the use of distributed processors that constitute " integrated systems . " <p> Integrated systems bring a modicum of centralized and simultaneous control over lighting , security , heating , ventilating , air conditioning , fire suppression , and other building systems that form the crux of any intelligent building system . <p> Using such advanced intelligent-building technology provides both property managers and tenants with a comprehensive access and security system that can effectively and efficiently exchange information with other building systems @ @ @ @ @ @ @ @ @ @ , notify responsible staff of unwanted intrusions , and ensure that lighting , fire , and other building-management systems are informed of personnel that enter or leave the building . This information then can be used to manage the local environment and resulting energy usage . Most intelligent-building systems are characterized by : <p> standardized building wiring systems that permit full building control over a single infrastructure <p> Increasingly , intelligent-building technologies are noted for their capacity to concurrently carry both a tenant 's voice and data communications over the same wiring infrastructure that carries building control data . Many industry insiders say that an intelligent building should have high-speed wiring , real-time communications , real-time information , real-time services , and real-time integration . Generally , an intelligent building also should be flexible . <p> " A good intelligent design should incorporate flexibility to allow for easy change , " notes Ehrlich . " Examples of this type of design characteristic include CLA ( communications , life safety , automation ) structured cabling design , and open space with movable or demountable partitions . An intelligent building needs to @ @ @ @ @ @ @ @ @ @ be flexible to meet the needs of future occupants . " <p> For detailed guidelines on what constitutes an intelligent building or information on the latest intelligent building technologies , contact the Continental Automated Buildings Association . CABA is a not-for-profit industry association that promotes advanced technologies for the automation of homes and buildings in North America . The organization has published an in-depth examination of intelligent building technologies . The report , entitled Technology Roadmap for Intelligent Buildings , is freely available online at www.caba.org/trm. 
@@21005043 @1005043/ <h> A Simple DC Motor Controller Optimizes Battery Life <p> Many cordless tools use NiCd battery packs as a source of power . These battery packs typically consist of four to six NiCd cells . Some of the tools also have more than one speed . This is achieved by tapping a fraction of the battery pack ( Fig. 1 ) . <p> The problem with this scheme is that when slower speeds are used , cells B1 to B3 are discharged while cells B4 and B5 remain fully charged . Once cells B1 t o B3 are discharged , the user may try to get the tool to run a bit longer by switching to high speed . Because cells B3 and B4 still have plenty of charge , the tool will indeed run a bit longer . While this is happening , cells B1 to B3 become completely discharged and eventually the voltage across them will reverse . <p> When the tool has stopped operating , the user will try recharging the batteries . Cells B4 and B5 may be only partially discharged and will need less @ @ @ @ @ @ @ @ @ @ and B5 will never be fully discharged and will develop memory effects , resulting in loss of charge capacity . <p> If we leave the charger on until cells B1 to B3 are fully charged , cells B4 and B5 will be overcharged and heat up . Damage to the battery pack will happen very rapidly under these conditions . Cells B1 to B3 will suffer from deep discharges , while cells B4 to B5 will be damaged by overcharging and lose capacity due to memory effect . To prevent this problem with rechargeable batteries , an electronic motor controller is needed . The motorcontroller circuit in Figure 2 solves the problem of uneven charging and discharging of batteries while keeping the component cost down and adding current-limiting . Numerous motor controllers exist that could be used in this application , but these dedicated circuits may be too complex for simple motor-control applications , such as cordless drills , vacuum cleaners , power windows in cars , or other tools . <p> To keep component count to a minimum , the dc motor is driven directly by a PWM controller @ @ @ @ @ @ @ @ @ @ PWM controller U1 operates at 200 kHz . At this frequency , most small dc motors will have sufficient inductance to maintain continuous current through the motor windings , so there 's no need to filter the output of Q1 . The dc motor will see an average voltage at the source of Q1 that 's proportional to the duty cycle : <p> VM = VIN * D <p> where VM is the average motor voltage , VIN is the input voltage coming from the battery pack , and D is the duty cycle set by the PWM controller U1 . <p> The average motor voltage VM is adjusted by potentiometer R2 : <p> where VR is the reference voltage of U1 , which is equal to 1.19 V. With the value of R1 equal to 1.19k , the average motor voltage can be expressed as : <p> VM = R2 + 1.19 <p> where the value of R2 is in kilohms and VM is in volts . Therefore , increasing R2 by 1k will increase the output voltage by 1 V. For example , an R2 value of 3k @ @ @ @ @ @ @ @ @ @ <p> where IM is the motor current , VB is the open-circuit battery voltage , RM is the motor winding resistance , and RB is the battery internal resistance . To handle the stalled condition , the motor windings , the switch , and the battery pack must be able to handle 26 A , even though the normal operating current is only 5 A ( a 5:1 ratio ) . In terms of power dissipation , that 's a 25:1 ratio . The current of 26 A will produce 67 W of power dissipation in the battery pack and 87 W of power dissipation in the motor . It 's obvious that these small components ca n't withstand this kind of dissipation for very long . <p> If the circuit in Figure 2 is used to control the motor , the peak current can be limited to the value set by the resistor RSENSE . The peak motor current will be limited to : <p> The maximum battery current will be limited as well . The battery current may reach 95% of IM-PEAK because U1 can reach duty cycles @ @ @ @ @ @ @ @ @ @ stalled conditions will be lower than the IM-PEAK . This is due to the average output voltage dropping to a low value in the stalled condition . The average motor voltage in the stalled condition will be : <p> VM-STALL = IM-PEAK * RM <p> In the case of the HC663-LGAD-10-A motor , the average motor voltage VM-STALL will be 1.15 V , and the input current will drop to : <p> IM-STALL = ( IM-PEAK * VM-STALL ) /VIN <p> For this HC663-LGAD-10A motor , the input current under stalled conditions will be only 0.9 A. This property is extremely beneficial because it prevents damage to the motor and batteries by high currents under stalled conditions . <p> The circuit in Figure 2 also is very efficient , requiring only a small amount of heat sinking . The motor control circuit for the dc motor used in our tests did not require heat sinks . Heat sinking provided by the printed circuit board was sufficient for currents up to 5 A. If much higher currents are required , the entire circuit could be implemented on Thermal-Clad material from Bergquist @ @ @ @ @ @ @ @ @ @ with a heat sink could be used . The MOSFET needs to be a logiclevel type with the RDS(ON) specified at 4.5 V or less . 
@@21005056 @1005056/ <p> DDS " a data-centric , publish-subscribe system " tends to be more robust and extensive than that found in some operating systems . The standard , which provides interoperability between DDS systems , is designed to be a distributed system without a single point of failure . It works equally well in application environments like the Internet of Things ( IoT ) . <p> Because DDS middleware allows decoupling of data from communication , applications can focus on the processing of data . It handles details like data and service discovery . The data-centric architecture simplifies collaboration between developers and suppliers . Distribution of applications is easier , too , and it can support duplication of services for redundancy . <p> Real-Time Innovations ' Connext DDS can be applied in a range of applications , including self-driving cars . <p> Real-Time Innovations ' ( RTI ) Connext DDS ( see figure ) is capable of delivering microsecond latency . It can be used to tie together sensors and control for complex systems like advanced driver-assistance systems ( ADAS ) through self-driving cars . Connext DDS also supports ISO @ @ @ @ @ @ @ @ @ @ that require DO-178C certification . Furthermore , it 's possible to partition a system so that certification can be done on a subset of a system , where critical operations and data are utilized while linking to non-critical , non-certified system components . <p> Connext DDS builds on standard protocols like TCP/IP and UDP . The system , which can use UDP broadcasts to efficiently distribute data to multiple devices , supports quality-of-service ( QoS ) for guaranteed latency . In addition , it can be employed to integrate data from a CAN bus , such as high-bandwidth LIDAR and radar sensors . Connext even supports Time-Sensitive Networking ( TSN ) . <p> The middleware now includes fine-grained security that 's part of the DDS standard . Encryption or authentication can be applied to published data versus simply using an encrypted link in many IoT applications . This can reduce encryption overhead , since it only needs to be applied to data that must be encrypted or authenticated rather than all information . For example , security may only be needed on control information , but not status information . @ @ @ @ @ @ @ @ @ @ systems and many real-time operating systems ( RTOSs ) . It integrates with tools such as MATLAB , Simulink , and UML . And clients can be lightweight enough to run on microcontrollers. 
@@21005057 @1005057/ <h> Enhanced Bluetooth 4.1 Targets the Internet of Things <p> The Bluetooth Special Interest Group ( SIG ) recently announced an updated 4.1 version of the Bluetooth standard . The 4.0 standard was released in July of 2010 and added the Bluetooth Smart feature which is a low power version of Bluetooth for use in medical , fitness and other consumer products . This latest enhancement further improves the standard making in more useable by consumers and easier to work with by product developers . <p> Bluetooth is probably the most widely used short range wireless technology . With its incorporation into cell phones , wireless headsets , smart watches , wireless keyboards and mice , wireless speakers , and other devices ; over 2 billion devices are shipped each year . Now with the new features in version 4.1 , Bluetooth can be more easily incorporated into devices falling under the Internet of Things ( IoT ) category , billions more devices will be forthcoming . Projections of 20 to 50 billion of IoT devices by 2020 have been made . While cellular , Wi-Fi , ZigBee and @ @ @ @ @ @ @ @ @ @ of Bluetooth should make it a popular choice of developers . <p> The new features include improvements in coexistence , connections , and data transfer . For example the latest update provides for improved coexistence between Bluetooth and the dominant cellular technology Long Term Evolution ( LTE ) . This ensures that Bluetooth and LTE radios can communicate to ensure transmissions are coordinated to reduce the possibility of interference . This coordination will happen automatically . <p> The connection process is also improved by making the reconnection time interval flexible and variable . This allows devices to reconnect automatically when they are in proximity of one another . There will be less frequent manual intervention in establishing a connection . The new version also implements a dual mode capability that , for example , permits a device like a smartphone to serve as a Bluetooth Smart hub or peripheral at the same time . An example is a smartwatch that that uses Bluetooth for a peripheral and a hub in a smartphone . Furthermore , the new version incorporates a way to create a dedicated channel for IPv6 communications essential @ @ @ @ @ @ @ @ @ @ a great choice for sensor IoT applications using IPv6 identifiers . <p> The data transfer process is also improved . It allows bulk data transfers of data gathered during some remote activity to be more efficiently transferred when the user gets near a PC or other device . <p> Some additional features include support for 802.11n protocol adaption layer , accommodation of a new wide band speech codec , upgraded encryption to 128-bit AES , and several support features for 3D TV glasses that use Bluetooth. 
@@21005058 @1005058/ <p> The platform comprises two major components . The MAX17710 evaluation kit ( MAX17710EVKIT ) includes all the components to evaluate the performance of Maxim 's energy-harvesting charger and protector . This kit plugs directly into the EFM32 Tiny Gecko Starter Kit from Energy Micro and powers the EFM32TG840F32 Gecko microcontroller . <p> The MAX17710 is the first IC to integrate all of the power-management functions for ambient energy harvesting , as well as the functions for charging and protecting the Thinergy Micro-Energy Cell ( MEC ) from Infinite Power Solutions ( IPS ) , which is embedded on the kit . <p> Operating at an ultra-low current level , the MAX17710 accepts energy from a variety of poorly regulated energy-harvesting sources with output levels ranging from 1 -W to 100 mW . A boost regulator circuit charges the energy-storing cell from a source as low as 0.75 V ( typical ) . An internal regulator protects the cell from overcharging . <p> Output voltages supplied to the target applications are regulated using an efficient adjustable low-dropout ( LDO ) linear regulator with selectable voltages of 3.3 V , @ @ @ @ @ @ @ @ @ @ in a selectable high-power or low-power mode to minimize drain on the MEC . Internal voltage protection prevents the MEC from over-discharging. 
@@21005059 @1005059/ <h> Can Security Be A Single Point Of Failure <p> The cloud is supposed to offer users a number of features including accessibility from almost anywhere . It , in theory , offers more storage and compute power than might normally be available if you have the electronic cash to pay for it . It is typically touted as being secure and there are any number of methodologies employed to make that true . Unfortunately there can be problems . <p> Microsofts issues with its Azure cloud services is just one example and this particular outage is different than what happened earlier with a portion of Amazons cloud services . In the latter case , it was a hardware issue . In Azures case , it was an expired SSL security certificate . <p> For those that do n't  know , most web security is based on sets of keys and certificates that are used to encrypt and authenticate data . This prevents unwanted access and control of devices . The public key digital certificate system employs a hierarchical approach with root certificate authorities guaranteeing certificates they sign . @ @ @ @ @ @ @ @ @ @ theory , trust certificates signed by the root or possibly anywhere down the chain . I wont get into those details but essentially you can wind up with a certificate that let 's your users know that communication with you will be secure . <p> The certificates also have an expiration date . There is also supposed to be a revocation list from a root that includes certificates that should expire prior to this date . Unfortunately , access to this list is not always possible and its update is typically something the root needs to handle . The expiration dates allow the system to work most of the time because someone must renew a certificate ( actually they must a acquire a new certificate ) before it expires . <p> What happened with Azure was its certificate expired before a new one was put in place with a later expiration date . Administrators could not access their applications . It was an administrative issue but it highlights a single point of failure within the system because the rest of Azure was based on it . <p> I 've taken a few @ @ @ @ @ @ @ @ @ @ it is an issue that everyone must be concerned with because these same techniques are employed with embedded and consumer applications . The same problem that Azure had can arise in other environments . This can have implications on features such as updates and even regular operation of a device Something that works today may not work tomorrow and determining why might be a challenge especially if the method of secure communication is the problem area . 
@@21005062 @1005062/ <h> Is Your Security Testing Soft and Fuzzy ? <p> The latest spate of ransomware highlights the need for security testing . One technique for doing this is called fuzz testing , or fuzzing . It is an automated test methodology that uses large amounts of invalid or random data for the input to the application . The application is tested in the usual fashion for errors such as memory leaks and invalid pointers . This approach works best with applications that have structured inputs , such as packets for a protocol or file formats . <p> Automatically generating test vectors is not a new approach , and has been used in other test environments " including unit testing . The trick is to generate examples that are semi-valid so as to expose corner cases , parsing errors , and errors in general . It can also be used to test security to see if trust boundaries are breached . <p> There are toolchains available to generate the test cases . Some provide automated input minimization support that is designed to reduce the number of test cases and help @ @ @ @ @ @ @ @ @ @ , totally random input may cause a difficult-to-identify bug . A minimization tool will minimize the input stream to the point where the error still occurs , making the task of identifying the problem easier. - Delta debugging is an approach that can reduce a test case to a minimal failure-inducing case . <p> Fuzzing can also be used to detect differential bugs , or bugs detected by comparing results using the same inputs with different application implementations . This might be an incrementally improved application or two different applications that perform the same function , such as an encryption algorithm or a communication protocol stack . Different results using the same input indicate a case that should be investigated . <p> Google's- OSS-Fuzz program found more than 1,000 bugs in 47 open-source projects. - Of course , this type of testing is not limited to open-source projects , but these do provide easy access to large amounts of code . Top errors included heap buffer overflows , global buffer overflows , and stack overflows . Many of these were caught as part of regression testing of new versions . @ @ @ @ @ @ @ @ @ @ , but it may not be one that you are already using . While it 's not applicable to all applications , it can be quite useful and automated for many applications . 
@@21005063 @1005063/ <h> Puerto Rico " A Shining Star Of Aerospace Engineering <p> Even as Congress debates immigration reform and Homeland Security looks to erect a virtual fence on our southern border , the populace of the U.S. is inexorably changing . More than 12% of our residents are foreign-born , the highest percentage in nearly 100 years . Latin American culture in particular is favoring the mainstream culture , fueling growth in many local economies around the country . <p> Latinos are also making their mark in engineering . I recently visited the University of Puerto Rico ( UPR ) along with several of the new engineering services companies setting up shop there , forming the foundation of a budding aerospace and defense contracting workforce . Puerto Rico offers tax advantages and a lower-cost labor force while allowing work on International Traffic in Arms Regulations ( ITAR ) contracts without restrictions . <p> These cost-saving advantages appeal to U.S. tech companies . But the most impressive draw is the commonwealth 's engineering talent , underpinned by a great enthusiasm and respect for the profession . This atmosphere creates an extremely @ @ @ @ @ @ @ @ @ @ make up 40% of the graduating class of UPR , with 606 degrees awarded in 2006 , ranking it 24th in the number of engineering graduates compared with U.S. schools . It also ranked 17th in the number of EE degrees awarded ( 129 ) in 2006 . The school stresses bilingual studies , with all textbooks in English , while classes are taught in Spanish . <p> RESPECT FOR THE CAREER Being an engineer in Puerto Rico means having a titled position , like being a doctor or a minister . It 's highly regarded , seen by both women and men as the key to getting ahead . Part of this has to do with Puerto Rico 's still-vibrant manufacturing economy , with 40% of the GDP provided by manufacturing jobs . Still , the island is planning ahead to a service-based economy and has targeted engineering jobs as a vital part of that growth . <p> Ramon Vasquez Espinosa , an EE and dean of the College of Engineering at UPR , Mayaguez , explained some of the secrets of the university 's success : an extremely @ @ @ @ @ @ @ @ @ @ undergrad program now enhanced by expanding graduate research programs . Espinosa noted some of the school 's current research projects : <p> The Center for Subsurface Sensing and Imaging Systems ( CenSSIS ) is developing imaging technologies to view objects underground , underwater , or inside the human body . The Tropical Center for Earth and Space Studies is focused on image and signal processing for bio-optical oceanography and biosystems engineering . The Collaborative Adaptive Sensing of the Atmosphere ( CASA ) program is creating a distributed , adaptive sensor network to sample the atmosphere via a network of low-power radars that overcome curvature blockage . <p> UPR professors Domingo Rodriguez and Nayda Santiago are directing a space-based digital imaging research project sponsored by Lockheed Martin and General Electric . The research involves new algorithms for on-craft signal processing to analyze images of terrain and ground conditions . Rodriguez notes that halfway through the one-year project , GE/Lockheed managers have been " very happy and surprised " at how quickly the students understood and got into the programming . <p> TAKING OFF IN AEROSPACE Infotech is a Pratt &amp; Whitney @ @ @ @ @ @ @ @ @ @ to 500 employees , mainly degreed engineers . While the company 's current work is largely from Pratt and other United Technologies ( Pratt 's parent corporation ) siblings , Infotech 's charter includes contract-engineering work for outside companies as well . <p> Current projects include work on UTC Power fuel cells and Pratt 's F-35 Lightning II Joint Strike Fighter , with electronic design work including signal processing and aircraft communications . Rita Peralta , Infotech 's president and general manager , and Scott Leslie , chief engineer , recalled that their unit 's first project was finished in half the estimated time . <p> Steve Witalis , a former Pratt engineer who has helped train staff in Puerto Rico , feels the energy and enthusiasm of the young engineers is a tremendous plus . But the real secret , he says , is the partnership with senior Pratt engineers as these " discipline chiefs " share their decades of experience . <p> Essig PR , which does much contract work for GE , has 15 open positions and plans to have 40 engineers by the end of the @ @ @ @ @ @ @ @ @ @ Martin and Honeywell may be heading to Puerto Rico , as GE and others sniff the tropical air . <p> Essig president Joseph Daly says that when 1500 engineers are working in aerospace in Puerto Rico , a critical mass will be reached , creating an aerospace engineering hub . The new opportunities are also drawing Puerto Ricans who left the island years ago back to their homeland . While previously more than 80% of graduating engineers would have left the island , many are now staying and creating a vibrant engineering community . 
@@21005066 @1005066/ <p> Electronic isolation is a means of preventing the transfer of direct current ( dc ) and unwanted alternating current ( ac ) between two parts of a system while still enabling signal and power transfer between those two parts . This kind of isolation is required in a number of instances , such as : <p> Protecting industrial operators from high voltage . <p> Protecting expensive processors and related circuits from high voltage . <p> Preventing ground loops in communications networks . <p> Improving noise immunity . <p> Communicating with high-side devices in a motor drive or power-converter systems . <p> There 's a need for an efficient , affordable , and compact isolation solution for industrial equipment . A fully integrated signal and power isolation product that 's now available brings a number of benefits to system design , including reduced board space , ease of certification , and simpler design . This article introduces isolation methods and a modern integrated approach . <p> Isolation Methods <p> One rather obvious method of electrical isolation is to use a transformer . The primary and secondary windings are electrically @ @ @ @ @ @ @ @ @ @ magnetic induction rather than current flow . A transformer is still a key part of isolation methods , and is the approach of choice for dc power isolation . <p> While transformers can be used for signal transfer , they 're limited in speed , and are bulky and expensive . Other choices are available , though . One isolation method that 's been around for years is optical isolation , and it involves an integrated circuit called an optocoupler . It 's made up of an infrared LED and phototransistor , usually a BJT with an open collector . In some devices , a separate photodiode detector is used ( Fig. 1 ) . <p> 1 . An optocoupler uses an IR LED and a phototransistor to provide a signal path , but with high-voltage isolation . <p> With no input signal , the LED is dark and the phototransistor is off , so the external pull-up resistor produces a high output . - When an input signal is applied , the LED turns on , the base of the phototransistor is illuminated , and it produces the bias @ @ @ @ @ @ @ @ @ @ to go low. - <p> Optocouplers work well and provide good high-voltage isolation up to 5 to 10 kV . Their main disadvantage is speed of operation in some digital systems . Today , a newer form of isolator using capacitive connectivity is now available . <p> Digital isolators use silicon-dioxide dielectric capacitors as the isolation method . However , because the capacitance is restricted by the physical limitations of an integrated circuit , special techniques are used to ensure the fast transfer of energy . One technique is edge-based and the other employs on-off keying ( OOK ) modulation . <p> 2 . The edge-based method of isolation uses two paths , one for slow data and the other for high-speed data . ( Source : Texas Instruments ) <p> A typical digital isolator is made up of a transmitter ( TX ) section and a receiver ( RX ) section . They 're isolated by the capacitive coupling . Figure 2 shows the edge-based method . A single-ended input signal to be transmitted is first converted into a balanced signal that then passes through the isolation capacitors . @ @ @ @ @ @ @ @ @ @ into narrow pulses . Comparators and a flip-flop process these pulses into pulses that are applied to a multiplexer ( MUX ) , which provides the output. - <p> Note that the input signal is also sent to the upper low-speed path , where it pulse-width modulates a higher-frequency oscillator . The pulse-width-modulation ( PWM ) signal is converted to a balanced signal and passed through the isolation capacitors , where it 's processed back into pulses . A low-pass filter ( LPF ) filters out the high-frequency PWM and recovers the original signal . If the input signal is too low in frequency , a decision logic circuit ( DLC ) detects the situation and switches the multiplexer to the low-frequency path . <p> Figure 3 shows the OOK method . The single-ended signal is sent to an AND gate along with an oscillator using spread-spectrum techniques to modulate the input . The resulting higher-frequency signal is converted to balanced form and passed through the isolation capacitors . On the receive side of the IC , the signal is conditioned and amplified . Then an envelope detector extracts the @ @ @ @ @ @ @ @ @ @ a need for isolation is that of a PLC in a factory-automation setup . PLCs are widely used in industry to monitor and control a variety of machines . The PLC gets its inputs from sensors that measure temperature , pressure , position , and other physical characteristics . These sensors are commonly remote from the PLC itself , meaning long cable runs . This situation usually creates ground potential differences that can skew sensor data and introduce errors . Some form of isolation is needed to ensure accuracy . <p> Figure 4 shows how isolation is achieved . The sensor signal is usually conditioned by filters , protection circuits , and an amplifier . The resulting analog signal is digitized by the ADC . This is the data signal that 's needed by the PLC processor to make its decisions . Note that a capacitive-coupled digital isolator is used to eliminate any errors due to ground loops . <p> The other part of the isolation is the dc power to signal conditioning circuits . The dc power for the signal conditioning circuits and ADC is derived from the 24-V @ @ @ @ @ @ @ @ @ @ into 5 V that operates a dc-dc converter , producing pulses that are transferred by an isolation transformer to a dc supply and LDO that furnishes the voltage for the signal-conditioning circuits . Note that the isolation circuits within the dashed lines are those that can be packaged as an integrated solution . <p> Another application example is the need to isolate one system from another while providing communications between the two . PLCs , computers , special controllers , and other equipment are required to talk to one another for automation purposes . The RS-485 interface standard is widely used for such communications . <p> This application uses a differential twisted-pair cable in runs that can be as long as 4000 feet . Such long runs are subject to all sorts of noise pickup and can interfere with operations . The differential signals help mitigate noise , but it 's still a problem . Ground loops are another issue . The solution is digital and power isolation of the RS-485 interface shields the processors from any possible noise and high-voltage signals . <p> Figure 5 shows how a digital @ @ @ @ @ @ @ @ @ @ the dc power to supply the RS-485 interface circuits . This configuration , available as a reference design from Texas Instruments , provides a compact solution capable of generating isolated dc power while supporting isolated RS-485 communication . The design consists of the ISOW7841 reinforced digital isolator with integrated power combined with an RS-485 communication transceiver ( SN65HVD1473 ) . <p> As the demands increase for industrial applications , it generally means that more features to the system need to be added . This puts more pressure on the power-management system to power the various circuits for optimum performance without raising equipment temperatures . Many of these industrial applications also require data and power isolation to protect the low-voltage side from the high-voltage side of a system . 
@@21005068 @1005068/ <h> Intelligent BOM Management for Today 's Product Innovators <p> In the world of product design and manufacturing , the bill of materials ( BOM ) is a critical product information record for both the engineering and manufacturing teams . Managing BOMs with the wrong tools can cause product errors , delays and compliance failures . BOMs define everything necessary to manufacture products and comprise the core building blocks of the product record . <p> Jul 17 , 2017 <p> Brought to you by <p> Too often BOMs are managed across multiple systems by engineering and manufacturing teams . This leads to disconnected development processes resulting in product launch delays , quality issues , manufacturing mistakes , and costly scrap and rework to correct product issues . In this whitepaper , we outline the problems with manual BOM management tools like spreadsheets and email and compare them to a dedicated BOM management system . 
@@21005069 @1005069/ <h> Building Support for Bluetooth 5 <p> luetooth is ubiquitous and it has moved well past the personal area network ( PAN ) model for headsets and keyboards . Bluetooth 5 is the latest standard and vendors are working to deliver support for this standard " for example , Texas Instruments ' ( TI ) new SimpleLink CC2640R2F . <p> The new standard ups wireless throughput to 2 Mbit/s and uses Forward Error Correction ( FEC ) code . That is five times the speed of Bluetooth 4.0 . It also has an improved coding system that provides longer range using the same amount of power . In theory this range is enough to cover the average house without the need for repeaters . The CC2640R2F also supports a proprietary protocol that runs up to 5 Mbits/s . Its long-range mode goes up to 1.5 km using less than 10 mA . <p> The chip is designed to operate for many years off a standard coin cell . It uses only 15 -A in shutdown mode . The Cortex-M3 uses only 61 -A/MHz . The EEMBC ULP Benchmark- rating @ @ @ @ @ @ @ @ @ @ , voice over BLE , and full-beacon iBeacon/Eddystone support . The Bluetooth 5 advertisement extension , ADVEXTIND , allows up to a 248 byte ADV payload by offloading payload to data channels . This reduced traffic on ADV channels . The standard uses a random frequency hopping approach that provides a more robust connection . <p> The system has 275 Kbytes of Non Volative Memory and up to 28 Kbytes of RAM . It has part of the Bluetooth stack support in ROM along with TI RTOS . There is sufficient headroom to support applications in addition to the Bluetooth support. - The chip has a range of peripherals including 32 DMA channels , AES hardware encryption support , a 200 Ksamples/s 12-bit ADC as well as serial , parallel , and timer interfaces . The chip can act as host in standalone mode or it can be linked to a host via a serial or SPI port . <p> The CC2640R2F is available in a number of package options from QFN to a 2.7-mm2 WCSP . The CC2640R2F-Q1 is automotive qualified 