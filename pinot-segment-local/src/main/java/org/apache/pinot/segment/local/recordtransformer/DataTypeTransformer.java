/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */
package org.apache.pinot.segment.local.recordtransformer;

import com.google.common.annotations.VisibleForTesting;
import com.google.common.base.Preconditions;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.HashMap;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import javax.annotation.Nullable;
import org.apache.pinot.common.utils.PinotDataType;
import org.apache.pinot.spi.data.FieldSpec;
import org.apache.pinot.spi.data.Schema;
import org.apache.pinot.spi.data.readers.GenericRow;
import org.apache.pinot.spi.utils.Pair;


/**
 * The {@code DataTypeTransformer} class will convert the values to follow the data types in {@link FieldSpec}.
 * <p>NOTE: should put this after all the values has been generated by other transformers (such as
 * {@link ExpressionTransformer}). After this, all values should be of the desired data types.
 */
@SuppressWarnings("rawtypes")
public class DataTypeTransformer implements RecordTransformer {
  private final Map<String, PinotDataType> _dataTypes;
  private final Pair[] _mapping;

  public DataTypeTransformer(Collection<FieldSpec> fieldSpecs) {
    _dataTypes = new HashMap<>(fieldSpecs.size());
    for (FieldSpec fieldSpec : fieldSpecs) {
      if (!fieldSpec.isVirtualColumn()) {
        _dataTypes.put(fieldSpec.getName(), PinotDataType.getPinotDataTypeForIngestion(fieldSpec));
      }
    }
    _mapping = new Pair[fieldSpecs.size()];
  }

  public DataTypeTransformer(Schema schema) {
    this(schema.getAllFieldSpecs());
  }

  @Override
  public GenericRow transform(GenericRow record) {
    Iterator<Map.Entry<String, Object>> recordIterator = record.iterator();
    int i = 0;
    while (recordIterator.hasNext() && i < _mapping.length) {
      Map.Entry<String, Object> columnValue = recordIterator.next();
      try {
        String column = columnValue.getKey();
        PinotDataType dest = getPinotDataType(i, column);
        if (dest == null) {
          columnValue.setValue(null);
          continue;
        }
        i++;
        Object value = columnValue.getValue();
        if (value == null) {
          columnValue.setValue(null);
          continue;
        }
        value = standardize(column, value, dest.isSingleValue());
        if (value == null) {
          columnValue.setValue(null);
          continue;
        }
        // Convert data type if necessary
        PinotDataType source;
        if (value instanceof Object[]) {
          // Multi-value column
          Object[] values = (Object[]) value;
          source = PinotDataType.getMultiValueType(values[0].getClass());
        } else {
          // Single-value column
          source = PinotDataType.getSingleValueType(value.getClass());
        }
        // Skipping conversion when srcType!=destType is speculative, and can be unsafe when
        // the array for MV column contains values of mixing types. Mixing types can lead
        // to ClassCastException during conversion, often aborting data ingestion jobs.
        //
        // So now, calling convert() unconditionally for safety. Perf impact is negligible:
        // 1. for SV column, when srcType=destType, the conversion is simply pass through.
        // 2. for MV column, when srcType=destType, the conversion is simply pass through
        // if the source type is not Object[] (but sth like Integer[], Double[]). For Object[],
        // the conversion loops through values in the array like before, but can catch the
        // ClassCastException if it happens and continue the conversion now.
        value = dest.convert(value, source);
        value = dest.toInternal(value);

        columnValue.setValue(value);
      } catch (Exception e) {
        throw new RuntimeException("Caught exception while transforming data type for column: " + columnValue.getKey(),
            e);
      }
    }
    return record;
  }

  @SuppressWarnings("unchecked")
  private PinotDataType getPinotDataType(int index, String column) {
    // try to memoize the iteration order of the input
    Pair<String, PinotDataType> pair = (Pair<String, PinotDataType>) _mapping[index];
    if (pair == null) {
      return createMapping(index, column);
    }
    if (pair.getFirst().equals(column)) {
      return pair.getSecond();
    }
    return createMapping(index, column);
  }

  private PinotDataType createMapping(int index, String column) {
    PinotDataType dataType = _dataTypes.get(column);
    if (dataType != null) {
      _mapping[index] = new Pair<>(column, dataType);
    }
    return dataType;
  }

  /**
   * Standardize the value into supported types.
   * <ul>
   *   <li>Empty Collection/Map/Object[] will be standardized to null</li>
   *   <li>Single-entry Collection/Map/Object[] will be standardized to single value (map key is ignored)</li>
   *   <li>Multi-entries Collection/Map/Object[] will be standardized to Object[] (map key is ignored)</li>
   * </ul>
   */
  @VisibleForTesting
  @Nullable
  static Object standardize(String column, @Nullable Object value, boolean isSingleValue) {
    if (value instanceof Collection) {
      return standardizeCollection(column, (Collection) value, isSingleValue);
    }
    if (value instanceof Map) {
      return standardizeCollection(column, ((Map) value).values(), isSingleValue);
    }
    if (value instanceof Object[]) {
      Object[] values = (Object[]) value;
      int numValues = values.length;
      if (numValues == 0) {
        return null;
      }
      if (numValues == 1) {
        return standardize(column, values[0], isSingleValue);
      }
      List<Object> standardizedValues = new ArrayList<>(numValues);
      for (Object singleValue : values) {
        Object standardizedValue = standardize(column, singleValue, true);
        if (standardizedValue != null) {
          standardizedValues.add(standardizedValue);
        }
      }
      int numStandardizedValues = standardizedValues.size();
      if (numStandardizedValues == 0) {
        return null;
      }
      if (numStandardizedValues == 1) {
        return standardizedValues.get(0);
      }
      if (isSingleValue) {
        throw new IllegalArgumentException("Cannot read single-value from Object[]: " + Arrays.toString(values)
            + " for column: " + column);
      }
      return standardizedValues.toArray();
    }
    return value;
  }

  private static Object standardizeCollection(String column, Collection collection, boolean isSingleValue) {
    int numValues = collection.size();
    if (numValues == 0) {
      return null;
    }
    if (numValues == 1) {
      return standardize(column, collection.iterator().next(), isSingleValue);
    }
    List<Object> standardizedValues = new ArrayList<>(numValues);
    for (Object singleValue : collection) {
      Object standardizedValue = standardize(column, singleValue, true);
      if (standardizedValue != null) {
        standardizedValues.add(standardizedValue);
      }
    }
    int numStandardizedValues = standardizedValues.size();
    if (numStandardizedValues == 0) {
      return null;
    }
    if (numStandardizedValues == 1) {
      return standardizedValues.get(0);
    }
    Preconditions
        .checkState(!isSingleValue, "Cannot read single-value from Collection: %s for column: %s", collection, column);
    return standardizedValues.toArray();
  }
}
