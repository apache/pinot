/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */
package org.apache.pinot.integration.tests.udf;

import com.fasterxml.jackson.annotation.JsonCreator;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.databind.MapperFeature;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.fasterxml.jackson.databind.json.JsonMapper;
import com.fasterxml.jackson.dataformat.yaml.YAMLFactory;
import java.io.File;
import java.io.FileWriter;
import java.io.IOException;
import java.io.Writer;
import java.nio.file.Files;
import java.nio.file.Path;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.TreeMap;
import java.util.TreeSet;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.stream.Collectors;
import javax.annotation.Nullable;
import org.apache.commons.io.output.StringBuilderWriter;
import org.apache.hadoop.util.Sets;
import org.apache.pinot.common.function.FunctionRegistry;
import org.apache.pinot.common.function.PinotScalarFunction;
import org.apache.pinot.core.operator.transform.function.TransformFunction;
import org.apache.pinot.core.operator.transform.function.TransformFunctionFactory;
import org.apache.pinot.core.udf.Udf;
import org.apache.pinot.udf.test.UdfReporter;
import org.apache.pinot.udf.test.UdfTestFramework;
import org.apache.pinot.udf.test.UdfTestResult;
import org.assertj.core.api.Assertions;
import org.assertj.core.util.diff.DiffUtils;
import org.assertj.core.util.diff.Patch;
import org.testcontainers.shaded.com.google.common.util.concurrent.MoreExecutors;
import org.testng.Assert;
import org.testng.annotations.AfterClass;
import org.testng.annotations.BeforeClass;
import org.testng.annotations.DataProvider;
import org.testng.annotations.Test;

/// A TestNG test class that uses snapshot files to verify the results of the UDF test framework.
///
/// Snapshots are stored in the `src/test/resources/udf-test-results` directory and can be regenerated by running the
/// main method of this class.
///
/// There are different test that use these snapshots. Read their documentation for more details.
public class UdfTest {
  private static final ObjectMapper MAPPER = JsonMapper.builder(new YAMLFactory())
      .configure(MapperFeature.SORT_PROPERTIES_ALPHABETICALLY, true)
      .build();
  public static final String ALL_FUNCTIONS_YAML = "all-functions.yaml";
  private IntegrationUdfTestCluster _cluster;
  private UdfTestFramework _framework;
  private ExecutorService _executorService;


  @BeforeClass
  public void setUp() {
    _cluster = new IntegrationUdfTestCluster();
    _cluster.start();

    _executorService = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors());

    _framework = UdfTestFramework.fromServiceLoader(_cluster, _executorService);
    _framework.startUp();
  }

  @AfterClass
  public void tearDown() {
    if (_cluster != null) {
      _cluster.close();
    }
    if (_executorService != null) {
      MoreExecutors.shutdownAndAwaitTermination(_executorService, 10, java.util.concurrent.TimeUnit.SECONDS);
    }
  }

  @DataProvider
  public Object[][] udfDataProvider() {
    return _framework.getUdfs().stream()
        .map(udf -> new Object[]{udf})
        .toArray(Object[][]::new);
  }

  /// For each UDF, this test runs the UDF test framework and compares the results with the snapshot file.
  ///
  /// This test may fail in different situations:
  /// 1. A new UDF was added, but the snapshot file was not updated. In this case, the test will fail saying that you
  ///    need to run the snapshot generation first.
  /// 2. The function implementation was changed. In case the semantic change was intentional, you can regenerate
  ///    the snapshots by running the main method of this class, but you should indicate that the change is breaking
  ///    change in the pull request and probably also in the commit message.
  @Test(dataProvider = "udfDataProvider")
  public void testUdf(Udf udf)
      throws IOException, InterruptedException {
    File snapshotDir = Path.of("src", "test", "resources", "udf-test-results").toFile();
    File snapshotFile = new File(snapshotDir, udf.getMainCanonicalName() + ".yaml");
    if (!snapshotFile.exists()) {
      Assert.fail("Snapshot file for UDF " + udf.getMainName() + " does not exist. "
          + "Please run the snapshot generation first.");
    }

    UdfTestResult.ByScenario actualResult = _framework.execute(udf);

    // Diff failed with an error. Maybe diff CLI is not available. Lets compare the content directly.
    List<String> snapshotLines = Files.readAllLines(snapshotFile.toPath());
    List<String> actualLines;
    try (StringBuilderWriter writer = new StringBuilderWriter()) {
      serializeScenario(writer, actualResult);
      actualLines = Arrays.asList(writer.toString().split("\n"));
    }
    Patch<String> diff = DiffUtils.diff(snapshotLines, actualLines);

    Assertions.assertThat(diff.getDeltas())
        .describedAs("Differences found between the actual and expected UDF test results for %s. "
                + "Expected version was %s. "
                + "If you think the new solution is correct, please regenerate the examples and add them to the "
                + "repository",
            udf.getMainName(), snapshotFile.getAbsoluteFile())
        .isEmpty();
  }

  /// This test checks that the snapshot directory does not contain any files that are not used by the UDF test.
  /// This could happen if a UDF was removed or renamed, but the snapshot file was not updated.
  @Test
  public void failWhenSnapshotNotUsed() {
    File snapshotDir = Path.of("src", "test", "resources", "udf-test-results").toFile();
    if (!snapshotDir.exists()) {
      Assert.fail("Snapshot directory does not exist. Please run the snapshot generation first.");
    }

    // Check if the snapshot directory is empty
    File[] files = getSnapshotFiles(snapshotDir);
    if (files.length == 0) {
      return;
    }
    Set<String> udfNames = _framework.getUdfs().stream()
        .map(Udf::getMainCanonicalName)
        .collect(Collectors.toSet());

    List<File> orphanedFiles = new ArrayList<>();
    for (File file : files) {
      String udfName = file.getName().replace(".yaml", "");
      if (!udfNames.contains(udfName)) {
        orphanedFiles.add(file);
      }
    }
    Assertions.assertThat(orphanedFiles)
        .describedAs("The snapshot directory %s contains files that are not used by the UDF test framework. "
            + "Please remove them or regenerate the snapshots.",
            snapshotDir.getAbsolutePath())
        .isEmpty();
  }

  /// This test checks that the all-functions.yaml file is updated with the latest UDFs.
  /// This file keeps track of all the functions that are registered in the system, including scalar and transform
  /// functions, and their corresponding UDFs.
  ///
  /// This could fail if a new function was added to the system, but the all-functions.yaml file was not updated or
  /// if a UDF was removed or renamed, but the all-functions.yaml file was not updated.
  @Test
  public void failWhenAllFunctionsYamlNotUpdated()
      throws IOException {
    File snapshotDir = Path.of("src", "test", "resources", "udf-test-results").toFile();
    if (!snapshotDir.exists()) {
      Assert.fail("Snapshot directory " + snapshotDir.getAbsolutePath() + " does not exist. "
          + "Please run the snapshot generation first.");
    }

    File allFunctionsFile = new File(snapshotDir, ALL_FUNCTIONS_YAML);
    if (!allFunctionsFile.exists()) {
      Assert.fail("The all-functions.yaml file " + allFunctionsFile.getAbsolutePath() + " does not exist in the "
          + "snapshot directory. Please run the snapshot generation first.");
    }

    List<String> expectedAllFunctionsLines = Files.readAllLines(allFunctionsFile.toPath());
    List<String> actualAllFunctionsLines;
    try (StringBuilderWriter writer = new StringBuilderWriter()) {
      generateAllFunctionsYaml(writer);
      actualAllFunctionsLines = Arrays.asList(writer.toString().split("\n"));
    }

    Patch<String> diff = DiffUtils.diff(actualAllFunctionsLines, expectedAllFunctionsLines);
    Assertions.assertThat(diff.getDeltas())
        .describedAs("Differences found between the actual and expected all-functions.yaml file. "
                + "If you think the new solution is correct, please regenerate the examples and add them to the "
                + "repository",
            allFunctionsFile.getAbsolutePath())
        .isEmpty();
  }

  private File[] getSnapshotFiles(File snapshotDir) {
    File[] files = snapshotDir.listFiles(file -> file.isFile()
        && file.getName().endsWith(".yaml")
        && !file.getName().equals(ALL_FUNCTIONS_YAML));
    if (files == null) {
      return new File[0];
    }
    return files;
  }

  /// Returns a map whose keys are all the function names (including scalar and transform functions) and values are the
  /// Udf of that function, or null if the function is not UDF registered.
  private TreeMap<String, AllFunctionsValue> generateUdfMapForAllFunctions() {
    Map<String, PinotScalarFunction> scalarFunctions = FunctionRegistry.getFunctions();
    Map<String, Class<? extends TransformFunction>> transformFunctions = TransformFunctionFactory.getAllFunctions();

    TreeMap<String, AllFunctionsValue> udfMap = new TreeMap<>();
    for (Udf udf : _framework.getUdfs()) {
      for (String name : udf.getAllCanonicalNames()) {
        AllFunctionsValue funValue = new AllFunctionsValue(udf.getClass(), transformFunctions.get(name),
            scalarFunctions.get(name));
        udfMap.put(name, funValue);
      }
    }

    Set<String> allFunctions = new TreeSet<>(Sets.union(scalarFunctions.keySet(), transformFunctions.keySet()));
    for (String function : allFunctions) {
      if (!udfMap.containsKey(function)) {
        AllFunctionsValue funValue = new AllFunctionsValue(null, transformFunctions.get(function),
            scalarFunctions.get(function));
        udfMap.put(function, funValue);
      }
    }
    return udfMap;
  }

  public static class AllFunctionsValue {
    @Nullable
    private final Class<? extends Udf> _udf;
    @Nullable
    private final String _transform;
    @Nullable
    private final String _scalar;

    public AllFunctionsValue(
        @Nullable Class<? extends Udf> udf,
        @Nullable Class<? extends TransformFunction> transform,
        @Nullable PinotScalarFunction scalarFunction
    ) {
      _udf = udf;
      _transform = transform == null ? null : transform.getCanonicalName();
      _scalar = scalarFunction == null ? null : scalarFunction.getScalarFunctionId();
    }

    @JsonCreator
    public AllFunctionsValue(
        @Nullable @JsonProperty("udf") Class<? extends Udf> udf,
        @Nullable @JsonProperty("transform") String transform,
        @Nullable @JsonProperty("scalar") String scalar) {
      _udf = udf;
      _transform = transform;
      _scalar = scalar;
    }

    public Class<? extends Udf> getUdf() {
      return _udf;
    }

    @Nullable
    public String getTransform() {
      return _transform;
    }

    @Nullable
    public String getScalar() {
      return _scalar;
    }
  }

  /// Runs the framework and creates one file for each UDF with the results of the test.
  ///
  /// The file will be stored in the given outputDir and will be named as the UDF main function name
  /// with the .yaml extension. The content of the file will be a YAML representation of the test results, serialized
  /// as defined in [UdfTestResult].
  private void generateSnapshots(File snapshotDir) {
    try {
      UdfTestResult result = _framework.execute();
      Map<Udf, UdfTestResult.ByScenario> results = result.getResults();

      if (!snapshotDir.exists() && !snapshotDir.mkdirs()) {
        throw new IOException("Failed to create output directory: " + snapshotDir.getAbsolutePath());
      }

      // Delete all existing YAML files in the snapshot directory
      Arrays.stream(getSnapshotFiles(snapshotDir))
          .forEach(File::delete);

      for (Map.Entry<Udf, UdfTestResult.ByScenario> entry : results.entrySet()) {
        Udf udf = entry.getKey();
        String udfName = udf.getMainCanonicalName();
        File outFile = new File(snapshotDir, udfName + ".yaml");

        // Serialize only the DTO for this UDF
        UdfTestResult.ByScenario byScenario = entry.getValue();

        try (FileWriter writer = new FileWriter(outFile)) {
          serializeScenario(writer, byScenario);
        }

        try (FileWriter writer = new FileWriter(new File(snapshotDir, udfName + ".md"))) {
          writer.write(getMdLicenseHeader());
          UdfReporter.reportAsMarkdown(udf, byScenario, writer);
        }
      }
      // Write the map to a file named all-functions.yaml
      File allFunctionsFile = new File(snapshotDir, ALL_FUNCTIONS_YAML);
      try (FileWriter writer = new FileWriter(allFunctionsFile)) {
        generateAllFunctionsYaml(writer);
      }
    } catch (Exception e) {
      throw new RuntimeException("Failed to generate UDF snapshots", e);
    }
  }

  private void generateAllFunctionsYaml(Writer writer)
      throws IOException {
    TreeMap<String, AllFunctionsValue> udfMap = generateUdfMapForAllFunctions();

    // Write the license header
    writer.write(getYamlLicenseHeader());
    writer.write("# This is a map between actual functions and their optional UDFs.\n"
        + "# This file has two purposes:\n"
        + "# 1. It is used to have a list of UDFs we should create.\n"
        + "# 2. It is used to have a test that fails if a new function is added to the system without a UDF.\n"
        + "\n");
    // Serialize the map as a DTO
    MAPPER.writeValue(writer, udfMap);
  }

  private void serializeScenario(Writer writer, UdfTestResult.ByScenario scenario)
      throws IOException {
    // Write the license header
    writer.write(getYamlLicenseHeader());
    MAPPER.writeValue(writer, scenario.asDto());
  }

  private String getYamlLicenseHeader() {
    return "#\n"
        + "# Licensed to the Apache Software Foundation (ASF) under one\n"
        + "# or more contributor license agreements.  See the NOTICE file\n"
        + "# distributed with this work for additional information\n"
        + "# regarding copyright ownership.  The ASF licenses this file\n"
        + "# to you under the Apache License, Version 2.0 (the\n"
        + "# \"License\"); you may not use this file except in compliance\n"
        + "# with the License.  You may obtain a copy of the License at\n"
        + "#\n"
        + "#   http://www.apache.org/licenses/LICENSE-2.0\n"
        + "#\n"
        + "# Unless required by applicable law or agreed to in writing,\n"
        + "# software distributed under the License is distributed on an\n"
        + "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n"
        + "# KIND, either express or implied.  See the License for the\n"
        + "# specific language governing permissions and limitations\n"
        + "# under the License.\n"
        + "#\n"
        + "\n"
        + "# This file is auto-generated by the UDF test framework. Do not edit it manually.\n"
        + "# Use the org.apache.pinot.integration.tests.udfUdfTest.generateSnapshots() method to regenerate it.\n"
        + "\n";
  }

  private String getMdLicenseHeader() {
    return "<!--\n"
        + "  ~ Licensed to the Apache Software Foundation (ASF) under one\n"
        + "  ~ or more contributor license agreements.  See the NOTICE file\n"
        + "  ~ distributed with this work for additional information\n"
        + "  ~ regarding copyright ownership.  The ASF licenses this file\n"
        + "  ~ to you under the Apache License, Version 2.0 (the\n"
        + "  ~ \"License\"); you may not use this file except in compliance\n"
        + "  ~ with the License.  You may obtain a copy of the License at\n"
        + "  ~\n"
        + "  ~   http://www.apache.org/licenses/LICENSE-2.0\n"
        + "  ~\n"
        + "  ~ Unless required by applicable law or agreed to in writing,\n"
        + "  ~ software distributed under the License is distributed on an\n"
        + "  ~ \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n"
        + "  ~ KIND, either express or implied.  See the License for the\n"
        + "  ~ specific language governing permissions and limitations\n"
        + "  ~ under the License.\n"
        + "  -->\n"
        + "\n";
  }

  /// Generates the snapshots used to verify results of the UDF test framework.
  ///
  /// If an argument is provided, it will be used as the output directory for the snapshots.
  /// If no argument is provided, it will try to determine the output directory based on the current working directory.
  /// If the current working directory is recognized as the root of the Apache Pinot repository or the
  /// pinot-integration-tests folder, it will use the `pinot-integration-tests/src/test/resources/udf-test-results`
  /// directory (where the test expects snapshots to be stored).
  /// If the current working directory is not recognized, it will throw an exception.
  public static void main(String[] args) {
    File snapshotDir;
    if (args.length == 0) {
      Path currentDir = Path.of(System.getProperty("user.dir"));
      if (currentDir.endsWith(Path.of("pinot", "pinot-integration-tests"))) {
        snapshotDir = Path.of("src", "test", "resources", "udf-test-results").toFile();
      } else if (currentDir.endsWith(Path.of("pinot"))) {
        snapshotDir = Path.of("pinot-integration-tests", "src", "test", "resources", "udf-test-results").toFile();
      } else {
        throw new IllegalStateException("Cannot determine the snapshot directory. "
            + "Please provide the path to the snapshot directory as an argument or execute this process either on "
            + "the root of the Apache Pinot directory or on the pinot-integration-tests folder.");
      }
    } else {
      snapshotDir = new File(args[0]);
    }

    UdfTest test = new UdfTest();
    test.setUp();
    try {
      test.generateSnapshots(snapshotDir);
    } finally {
      test.tearDown();
    }
    // TODO: ClusterTestBasePinotFunctionTestCluster uses BaseClusterIntegrationTest, which leak some threads
    //  non demon on shutdown, which prevents the JVM from exiting. As a workaround, we call System.exit(0) here.
    System.exit(0);
  }
}
