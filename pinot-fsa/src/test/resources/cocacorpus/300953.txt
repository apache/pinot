
@@100664153 @4864153/ <p> Returns an angle whose sine is x . The range of values returned by this function is -PI/2 , PI/2 . Results are undefined if x &gt; 1 . ( From GLSL 1.30.08 specification , section 8.1 ) <p> genType glm : : core : : function : : trigonometric : : asinh <p> ( 45962 @qwx905962 <p> x <p> ) <p> Arc hyperbolic sine ; returns the inverse of sinh . <p> ( From GLSL 1.30.08 specification , section 8.1 ) <p> genType glm : : core : : function : : trigonometric : : atan <p> ( 45962 @qwx905962 <p> y , 45962 @qwx905962 <p> x <p> ) <p> Arc tangent . <p> Returns an angle whose tangent is y/x . The signs of x and y are used to determine what quadrant the angle is in . The range of values returned by this function is -PI , PI . Results are undefined if x and y are both 0 . ( From GLSL 1.30.08 specification , section 8.1 ) 
@@100664154 @4864154/ <h> Library Structure <p> GLM is arranged in 2 distinct segments . These are the GLM features based on the GLSL specification and a set of extensions . Some extensions are stable and backward compatible ( GTC Extensions ( Stable ) GTC VIRTREV Extensions VIRTREV ) but some are experimental ( GTX Extensions ( Experimental ) GTX ) which means that they are not guarantee to be backward compatible from version to version . <p> The GLM represents only what GLSL 's core provides in terms of types and functions ( to the best of GLM 's ability to replicate them ) . All that is needed to use the core is to include &lt;glm/glm.hpp&gt; . <p> GTC extensions are functions and types that add onto the core . These are considered reasonably stable , with their APIs not changing much between versions . Each core extension is included with a separated header file include . All of the core extensions are in the " glm/gtc " directory . <p> GTX extensions are functions and types that add onto the core . Unlike GTC extensions , their APIs are @ @ @ @ @ @ @ @ @ @ marked " experimental " . Like GTC extensions , each experimental extension is included with a separate header file . <p> All the extensions can be included at once by default by including &lt;glm/ext.hpp&gt; but this is not recommanded as it will reduce compilation speed for many unused features . <p> All of GLM is defined as direct children of the glm namespace , including extensions . <p> To use a particular extension , simply include the extension header file . All extension features are added to the glm namespace automatically . <h> Dependencies <p> When &lt;glm/glm.hpp&gt; is included , GLM provides all the GLSL features it implements in C++ . <p> When an extension is included , all the dependent extensions will be included as well . All the extensions depend on GLM core . ( &lt;glm/glm.hpp&gt; ) <p> There is no dependence with external libraries or external headers like gl.h , gl3.h , glu.h or windows.h . However , if **30;0;TOOLONG is included , Boost static assert will be used throughout GLM code to provide compiled time errors . <h> OpenGL Interoperability <p> It is often useful to @ @ @ @ @ @ @ @ @ @ type . For example , the OpenGL function glUniform3fv() takes an array instead of 3 individual values . If the vector and matrix types were simple arrays , then one could pass them to the function like so : glUniform3fv ( loc , 1 , glm : : vec3(0) ) . However , this is not the case ; the vector and matrix types are C++ classes , not arrays . <p> This method requires dereferencing the very first basic type of the object , not merely the first element . The operator on the matrix type returns a column vector ; one must then access the first element of that column vector to get a pointer to the basic type . <p> Note : <p> This operation could have been built into the base vector and matrix types and performed with a cast operator . However , this has some downsides . Implicit casts can cause unexpected and unwanted behavior . <h> GLM for CUDA <p> GLM 0.9.2 introduces CUDA compiler support allowing programmer to use GLM inside a CUDA Kernel . To make GLM compatible with CUDA , @ @ @ @ @ @ @ @ @ @ 
@@100664156 @4864156/ <p> Splits x into a floating-point significand in the range 0.5 , 1.0 ) and an integral exponent of two , such that : x = significand * exp ( 2 , exponent ) <p> The significand is returned by the function and the exponent is returned in the parameter exp . For a floating-point value of zero , the significant and exponent are both zero . For a floating-point value that is an infinity or is not a number , the results are undefined . <p> If genTypeU is a floating scalar or vector : Returns x * ( 1.0 - a ) + y * a , i.e. , the linear blend of x and y using the floating-point value a . The value for a is not restricted to the range 0 , 1 . <p> If genTypeU is a boolean scalar or vector : Selects which vector each returned component comes from . For a component of a that is false , the corresponding component of x is returned . For a component of a that is true , the corresponding component of y is @ @ @ @ @ @ @ @ @ @ selected are allowed to be invalid floating point values and will have no effect on the results . Thus , this provides different functionality than genType mix ( genType x , genType y , genType(a) ) where a is a Boolean vector . <p> The fraction 0.5 will round in a direction chosen by the implementation , presumably the direction that is fastest . This includes the possibility that round(x) returns the same value as roundEven(x) for all values of x. 
@@100664161 @4864161/ 45959 @qwx905959 <p> These functions do not operate component-wise , rather as described in each case . <h> Function Documentation <p> GLMFUNCDECL double glm : : packDouble2x32 <p> ( <p> uvec2 const &amp; <p> v <p> ) <p> Returns a double-precision value obtained by packing the components of v into a 64-bit value . <p> If an IEEE 754 Inf or NaN is created , it will not signal , and the resulting floating point value is unspecified . Otherwise , the bit- level representation of v is preserved . The first vector component specifies the 32 least significant bits ; the second component specifies the 32 most significant bits . <p> Returns an unsigned integer obtained by converting the components of a two-component floating-point vector to the 16-bit floating-point representation found in the OpenGL Specification , and then packing these two 16- bit integers into a 32-bit unsigned integer . <p> The first vector component specifies the 16 least-significant bits of the result ; the second component specifies the 16 most-significant bits . <p> Returns a two-component floating-point vector with components obtained by unpacking a 32-bit unsigned integer @ @ @ @ @ @ @ @ @ @ as 16-bit floating-point numbers according to the OpenGL Specification , and converting them to 32-bit floating-point values . <p> The first component of the vector is obtained from the 16 least-significant bits of v ; the second component is obtained from the 16 most-significant bits of v. 
@@100664163 @4864163/ <p> In listing 3 , arg may look like an implicitly size array but actually , it 's just a pointer . Hence , when we call countof on arg we divide the size of a pointer ( 32 bits or 64 bits depending on the system ) by the size of an element in this array which is indeed not what we expect . <p> The idea is to return the size of an array of char , declared using the template argument size ( N ) of the array we want to know the number of elements from . <p> This countof implementation still particularly relevant and work well on all static use cases . I find only two minor draw backs . First , it 's still a macro so overloading for containers will be challenging . Second , old GCC compilers does n't support this construct . <h> Visual C++ built-in macro <p> Visual C++ supports a built-in macro called countof to detect invalid inputs at compilation time but this solution is not standard . <h> Alternative C++ 11 implementation <p> Fortunately , C++ 11 @ @ @ @ @ @ @ @ @ @ are resolved at compilation time . This allows us to write a function for countof in listing 5 which provides type safety , namespace capability and compile time resolution . <p> Listing 5 : Implementation of countof using a C++11 constant expression : <p> template &lt;typename T , std : : sizet N&gt; <p> constexpr std : : sizet countof ( T const ( &amp; ) N ) noexcept <p> <p> return N ; <p> <p> Listing 6 : Usage examples of constant expression countof : <p> static const std : : sizet values = 42 , 76 , 16 , 11 , 31 ; <p> void foo() <p> <p> for ( std : : sizet i = 0 ; i &lt; countof(values) ; ++i ) <p> bar(valuesi) ; <p> <p> void foo ( const std : : sizet arg ) <p> <p> for ( std : : sizet i = 0 ; i &lt; countof(arg) ; ++i ) // Compilation error ! <p> bar(argi) ; <p> <h> Scalable implementation for old compilers support <p> countof implementation based on constant expressions is a great improvement over the macro implementation . @ @ @ @ @ @ @ @ @ @ constant expressions . For example , Visual Studio 2015 only introduced a subset of constant expressions support and previous versions had absolutly no support of this C++ 11 feature . <p> Hence , listing 7 proposes a more scalable implementation to manage the transition period until C++11 support bacomes universal . 
@@100664164 @4864164/ <h> FAQ <h> Why does GLM follow GLSL specification and conventions ? <p> Following GLSL conventions is a really strict policy of GLM . GLM has been designed according to the idea that everyone writes their own math library with their own conventions . The idea is that brilliant developers ( the OpenGL ARB ) worked together and agreed to make GLSL . Following GLSL conventions is a way to find consensus . Moreover , basically when a developer knows GLSL , he knows GLM . <h> Does GLM run GLSL programs ? <p> No , GLM is a C++ implementation of a subset of GLSL . <h> Does a GLSL compiler build GLM codes ? <p> No , this is not what GLM intends to do ! <h> Should I use GTX extensions ? <p> GTX Extensions ( Experimental ) are experimental . In GLM this means that these extensions might change from version to version without restriction . In practice , it does n't really change except time to time . GTC extensions are stabled , tested and perfectly reliable in time . Many GTX extensions extend @ @ @ @ @ @ @ @ @ @ implementations before becoming stable by a promotion as GTC extensions . This is similar to how OpenGL extensions can be EXT or ARB extensions before becoming core functionality . <p> In short , if you use a GTX extension , the API is much more likely to change from version to version than if you do n't . But you should not feel too uncomfortable about using them . <h> Where can I ask my questions ? <h> Where can I find the documentation of extensions ? <p> The Doxygen generated documentation includes a complete list of all extensions available . Explore this documentation to get a complete view of all GLM capabilities ! http : **32;32;TOOLONG <h> Should I use ' using namespace glm ; ' ? <p> This is unwise . Chances are that if ' using namespace glm ; ' is called , name collisions will happen . GLSL names for functions are fairly generic , so it is entirely likely that there is another function called , for example , sqrt . <p> For frequent use of particular types , they can be brough into the @ @ @ @ @ @ @ @ @ @ : <p> /code using glm : : mat4 ; <p> mat4 someVariable(3.0f) ; /endcode <h> Is GLM fast ? <p> GLM is mainly designed to be convenient ; that 's why it is written against GLSL specification . <p> The 80-20 rule suggests that 80% of a program 's performance comes from 20% of its code . Therefore , one should first identify which 20% of the code is impacting the performance . <p> In general , if one identifies certain math code to be a performance bottleneck , the only way to solve this is to write specialized code for those particular math needs . So no canned library solution would be suitable . <p> That being said , GLM can provides some descent performances alternatives based on approximations or SIMD instructions . 
@@100664165 @4864165/ <p> Another aspect of this release is the change for 2 design policy : A semantics location approach instead of a query location approach and a generalized use of VAOs . Am I not the developer who think VAOs are evils ? Well , I am but thanks to Graham Sellers , AMD OpenGL manager , I have a better idea of how good VAOs are . Again , such a demonstration of the good will toward OpenGL , my feeling for a shiny OpenGL future keep increasing : GOOD ! <p> Let 's say that you can espect about +20% with VAO if your bottleneck in on the draw call and if you draw less than 2000 different VAOs ( / meshes ) with enough attributes . It is already something and we ca n't say anymore that VAOs are evil . On nVidia the limit is about 200 different VAOs ( / meshes ) which is seriously an issue from nVidia implementation . With an appropriate manager , glDrawElementsBaseVertex and changing the element array buffer , we can put several meshes per VAOs and actually reduce the @ @ @ @ @ @ @ @ @ @ a bit of software design and feels an bit odd ( half-mutable VAOs ) but it 's possible to make this VAOs count limit not a problem . <p> For a while I thought ( and I believe most of the community members ) that VAOs were optionals . Most of us ignore it because we did n't see any improvement and VAO brings a software design constrain if we rely on something like immunable VAOs . Well , VAOs are REQUIRED with OpenGL core profile and as I discovered it , it 's not so bad if we know these limits . ( 2000 VAOs on AMD and 200 VAOs on nVidia ) . <p> I hope to find some time to write something about that topic including a dedicated test , including a possible improvement with ' bindless graphics ' which might lead to about +100% efficiency when/if available in future OpenGL specification . 
@@100664169 @4864169/ <p> sRGB is a non-linear color space that can be directly displayed by computer display devices . Another very popular color space is Adobe RGB often used in photography for its higher precision . sRGB and Adobe RGB color spaces define what actual color is a color code so that on all compatible outputs or supports , the color will look the same . <p> OpenGL defines sRGB textures ( OpenGL 2.1 ) and sRGB framebuffers ( OpenGL 3.0 ) to take advantage of the sRGB color space . sRGB provides an optimized use of each value of the storage range so that these values become more relevant for our eyes perception . A quality gain for zero extra storage . <p> OpenGL provides sRGB with 8 bits components and compressed sRGB data only . These formats are identified with GLSRGB , GLSRGB8 , GLSRGBALPHA , GLSRGB8ALPHA8 , GLCOMPRESSEDSRGB and GLCOMPRESSEDSRGBALPHA . When the extension **27;66;TOOLONG is supported , the following format are supported : **27;95;TOOLONG , **32;124;TOOLONG , **32;158;TOOLONG and **32;192;TOOLONG . These formats are absolutely similar to the usual DXTC1 , DXTC3 and DXTC5 but with sRGB @ @ @ @ @ @ @ @ @ @ 8 bits per pixel is not enough precision to make a non linear color space relevant for storage . The ARB has also considered that more than 8 bits per pixel is so much precision than sRGB is n't really useful . Another way to see this , is that less than 8 bits per pixel is not used anymore and more than 8 bits per pixels conversion to linear space would be too expensive to do on the hardware . Currently , we can expect the conversion to be implemented in GPUs with a lookup table of 256 values so that this conversion is almost free to perform . However , a table with 65536 values is a lot higher transistors cost . I would not be surprised to see sRGB16 OpenGL extension in the future . <p> With OpenGL 3.2 core profile , there is no 1 or 2 components sRGB textures . With OpenGL 3.2 compatibility profile we have some extra formats : GLSLUMINANCE , GLSLUMINANCE8ALPHA8 , GLCOMPRESSEDSLUMINANCE and **27;226;TOOLONG . One example where nVidia is right about " some deprecated OpenGL features might be useful " @ @ @ @ @ @ @ @ @ @ linear color space . If we have 2 sRGB pixels A and B then A + B is not a valid operation . Each time a sRGB value is used for an operation , the value need to be converted to a linear color space value . To convert a 8 bits sRGB pixel to a linear RGB pixel , the graphics card might need 16 bits per channel to be lossless . <p> On the OpenGL pipeline we will find these conversions for three tasks : texel sampling , multisample resolution and blending . OpenGL gives control of these conversions only at blending stage with the calls **27;255;TOOLONG and **28;284;TOOLONG . When enabled , the values are linearized prior to their use for blending . A lack of conversions will generally darken the framebuffer . <p> For texel fetch and multisample resolution , these conversions are performed automatically but the way it 's performed is just a recommandation . For texel fetch , the recommantation is to perform the conversions to a linear space before the filtering . For the multisample resolution , the recommanration is to perform the @ @ @ @ @ @ @ @ @ @ from GeForce 6 and Radeon 9***. sRGB framebuffers require a GeForce 8 or a Radeon HD 2*** . Apple drivers does n't support OpenGL 3.0 yet ( in MacOS X 10.6.2 ) but supports GLEXTtexturesRGB and GLEXTframebuffersRGB for all cards that support sRGB color space . Intel drivers are also suposed to support both sRGB textures and framebuffers ... I 'm so sure either about S3 . Chrome 4** supports sRGB textures and are suposed to support sRGB framebuffers because S3 claims that Chrome 4** are OpenGL 3 cards but GLEXT/ARBframebuffersRGB is n't in the extension list of the card . 
@@100664175 @4864175/ <h> Swizzle Operators <p> A common feature of shader languages like GLSL is components swizzling . This involves being able to select which components of a vector are used and in what order . For example , " variable.x " , " variable.xxy " , " variable.zxyy " are examples of swizzling . <p> This functionally turns out to be really complicated to implement in C++ using the exact GLSL conventions . GLM provides 2 implementions this feature . <h> Macro implementation <p> The first implementation follows the GLSL convensions accurately . It uses macros to achieve this , which might generates name conflicts with system headers or third party libraries . Therefore , it is disabled by default . To enable this implementation , GLMSWIZZLE must be defined before any inclusion of &lt;glm/glm.hpp&gt; . <p> #define GLMSWIZZLE #include &lt;glm/glm.hpp&gt; <p> This implementation can be partially enabled by defining GLMSWIZZLEXYZW , GLMSWIZZLERGBA or GLMSWIZZLESTQP . Each macro only enable a set of swizzling operators . For example we can only enable x , y , z , w and s , t , q , p operators using : @ @ @ @ @ @ @ @ @ @ is to use the **27;314;TOOLONG extension . This extension provides the GLSL functionality , but uses a different syntax for it . Moreover , the swizzle extension also provides dynamic swizzling . <p> Static swizzling is resovled at compile-time . The swizzle mask " . xzyy " is as fixed as the type of a particular variable . Dynamic swizzling is resolved at runtime via function calls . Dynamic swizzling is more flexible , since one can choose the swizzle mask at runtime , but it runs slower . This performance issue is enhanced when SIMD instructions are used . <h> Notification System <p> GLM includes a notification system which can display some information at build time : <p> Compiler <p> Build model : 32bits or 64 bits <p> C++ version <p> Architecture : x86 , SSE , AVX , etc . <p> Included extensions <p> etc . <p> This system is disable by default . To enable this system , define GLMMESSAGES before any inclusion of &lt;glm/glm.hpp&gt; . <p> #define GLMMESSAGES#include &lt;glm/glm.hpp&gt; <h> Force Inline <p> GLM 's functions are defined in headers , so they are defined with @ @ @ @ @ @ @ @ @ @ require the compiler to inline them , however . To force the compiler to inline the function , using whatever capabilities that the compiler provides to do so , GLMFORCEINLINE can be defined before any inclusion of &lt;glm/glm.hpp&gt; . <p> A programmer can restrict or force instruction sets used for these optimizations using GLMFORCESSE2 or GLMFORCEAVX . <p> A programmer can discard the use of intrinsics by defining GLMFORCEPURE before any inclusion of &lt;glm/glm.hpp&gt; . If GLMFORCEPURE is defined , then including a SIMD extension will generate a build error . <p> #define GLMFORCEPURE#include &lt;glm/glm.hpp&gt; <h> Compatibility <p> Compilers have some language extensions that GLM will automatically take advantage of them when they are enabled . GLMFORCECXX98 can switch off these extensions , forcing GLM to operate on pure C++98. 
@@100664177 @4864177/ <p> In a world at its birth relativily to others sciences , everything remain to be done in computer graphics and it will take everyone to develop it . OpenGL being based on a community , what benefit to one benefit to everyone and this is true at the level of every one of us , members of The OpenGL Community . <p> What anyone who cares can do at its level is to report bugs , either from implementations or even from the specifications . The OpenGL implementers and the ARB are unfortunately but realisticcally limited in time this is why to contribute , an OpenGL Community member is required to back it up so that bug reports will raise interest and effectively be useful to fix an eventual problem . <h> Report your drivers bugs <h> Quick guidelines <p> When sending a bug report , " it does n't work " does n't give to much chance for a bug to reach interest of the people which will fixe them : Screenshots , platform , drivers version , a description to reproduce the bug and ultimately a @ @ @ @ @ @ @ @ @ @ . <h> On AMD <p> On AMD , the best approach is to post a message on the AMD Graphics Programming sub-forum . Many OpenGL team members are monitoring this forum . There is also an unofficial bugzilla maintained by the Linux guys at AMD . It is still possible to file Windows bugs on this Bugzilla , they will reach the OpenGL team . <h> On NVIDIA <p> On NVIDIA to report a bug , one must become an NVIDIA registered developer LONG ... The place looks pretty much dead but it is still possible to submit bug reports . <h> OpenGL.org and Khornos.org forums <p> Two others fine place to report the bugs are the OpenGL.org forums and Khornos.org forums . Many OpenGL teams of IHV are monitoring these forums and your bugs should be notified . <h> Report to the Khronos Group <p> Not only IHV needs bug reports , also the Khronos Group does . For this purpose , the Khronos Group provides a public Bugzilla which can be used to report specification bugs or even man pages issues . For man pages issues , there @ @ @ @ @ @ @ @ @ @ opengl dot org " . <p> When reporting a specification bug on Bugzilla , I think it is necessary to understand the process implied by a bug report . If it is just a typo , the bug could be really quickly fixed ( even is released only at the next release ) . However , if the bug involves a proper bug , this bug will need to be discuss by the ARB but before that the bug will have to raise the interest of someone who will suggest it for discussion : Submitting a specification bug better have to be done seriously . <p> Moreover , we are living with a 20 years old specification and the least we could say is that the specification is complex . What could be seen as a bug might be just specify or clarify somewhere else . It is necessary to search beyond the expected scope for a language description and include both OpenGL and GLSL specification . <p> When reporting a bug I think it is mandatory to " quote " the specification , the parts of the language that @ @ @ @ @ @ @ @ @ @ I personnaly use a bug report strategy which looks like this : 1 . Sumarize the problem ; 2 . Detail and quote the specification ; 3 . Submit a solution or multiple options . <p> A typo error . <p> A language clarification . <p> Contradictory language . <p> Missing commands , values in a table . <p> Unspecified OpenGL error . <p> And many more ! <h> Conclusion <p> Getting OpenGL implementations better is not only the duties of implementers but also of the one of the OpenGL programmers . There is something worse than a bug : there is an unknowned bug . Contribute to the OpenGL community and report your bugs ! 
@@100664187 @4864187/ <h> Following a surprizing amount of feedbacks , I have updated the entire post accordingly . Thanks for contributing ! <p> There is a lot of reasons for OpenGL ES 2.0 on desktop but I especially like to picture it by " for the purpose of convergence " . This includes computers , tablets and mobile phones but also the web through WebGL which is pretty much a Javascript binding of OpenGL ES 2.0 . In practice we can imagine that it would be a great to be able to port directly a mobile phone game to a desktop platform and minimized code changes , the gap between between mobile phone performances and ultra-book laptop being not that large for example . We can also imagine authoring and prototyping GLSL shaders or even applications on desktop before using them on mobile devices . <p> EGL , WGL and GLX ? What 's the way forward ? When EGL was originally announced , it brought be a lot of hopes , hopes that we will finally have a unified API across all platforms to handle the OpenGL contexts . That @ @ @ @ @ @ @ @ @ @ " hapenned when Sony announced that the PS3 would run OpenGL ES 1 + ES 2 level of extensions and EGL . Unfortunately , OpenGL ES 2 has basically never been used on the PS3 , Apple created it 's own flavour of EGL ( EAGL ) and only AMD exposes EGL on desktop . <h> OpenGL ES 2.0 on Windows 7 <p> On AMD side , OpenGL ES 2 is brought to desktop thanks to EGL and a dedicated SDK is provided which makes it significantly different from using OpenGL on desktop . A dedicated OpenGL ES 2 DLL for the implementation is provided and I believe distributed with the AMD Catalyst drivers . <p> On NVIDIA side , the strategy is different because OpenGL ES 2 is exposed through WGL . The idea was to make OpenGL ES 2 an OpenGL " profile " . When I first had a look at it , the implementation would expose all the OpenGL extensions which made me think something like " Not that joke all over again ? ! " and I did n't waste any time with it . @ @ @ @ @ @ @ @ @ @ OpenGL ES 2 context , only the OpenGL ES extensions are exposed and the drivers is even trying to report all the not ES compliant requests as errors . I expect this to be a challenging work in progress so once again report your bugs ! <p> A last option on Windows is Angle which brings support for both OpenGL ES 2.0 and EGL 1.4 on Windows by translating OpenGL calls to Direct3D 9 calls . It is used by both Firefox and Chrome on Windows . Angle might be the only way to get OpenGL ES 2 running on Intel hardware . There is no news from Intel about OpenGL ES 2 or EGL support but our experiences tell us that they are most likely going to be last at the party . <h> OpenGL ES 2.0 on Linux <p> It looks like that Mesa is currently providing the best implementation : Not only Mesa supports EGL 1.4 but the implementation can load OpenGL , OpenGL ES , OpenGL ES 2 and even OpenVG . However , it 's not clear to me whether it can load the proprierary @ @ @ @ @ @ @ @ @ @ 1.4 and OpenGL ES 2.0 implementations through the its SDK . <p> The Linux world is turning its back on X.org to adopt Wayland which uses exclusively EGL making its support not only desirable but required by proprietary drivers to run their OpenGL ES 2.0 or even an OpenGL implementation . <h> OpenGL ES 2.0 on Windows 8 <p> Windows 8 x86 follows the same behavours than Windows 7 however Microsoft did a large cleaning of APIs on Windows 8 for ARM which implies currently no WGL or EGL . The cleaning , or actually the not ported yet , is so drastic that even XNA is n't supported on Windows 8 for ARM . Considering that Windows 8 for ARM target tablets and I guess ultra-book kind of laptop it seems unresonnable for Microsoft to avoid the Adreno , Mali , PowerVR and Tegra chips which software stacks have mainly mature over the years with OpenGL ES 2.0 . In such case , implementing EGL sounds to me like the most reasonnable option for Microsoft . Another possibility would to use Angle on Windows 8 ARM to get the @ @ @ @ @ @ @ @ @ @ <p> Apple is definetely moving toward the convergence of MacOS X ( renamed OS X for Mountain Lion ) and iOS . However , beside development tools there is no OpenGL ES 2.0 on MacOS X. For EGL , Apple only supports it 's own flavour , EAGL , which is basiccaly EGL in Objective C with no access to the framebuffer as we much render to a colorbuffer . <h> Libraries <p> On the library point of view , only GLFW supports OpenGL ES 2 on desktop through the **29;343;TOOLONG and **29;374;TOOLONG extensions in the version 3 work in progress . EGL supports is on the todo list and I certainly hope it will include desktop support . FreeGLUT 2.8.0 released less than two months ago does n't support OpenGL ES 2 in any way but I hacked it to add the ES2 profile approach ... It tooks literrally 15 mins to add it to say how easy it was to do ! <h> Conclusions <p> So what the future of OpenGL ES on desktop ? First of all , it mainly passed by WebGL because this is how @ @ @ @ @ @ @ @ @ @ interested in games or specific graphics software . GLX and WGL looks nearly dead as the last version of GLX , GLX 1.4 was released in 2005 , and Microsoft is certainly not going to move WGL forward . Do we really need updates of these APIs ? On other end , the Khronos Group seems to be still actively working on EGL as version 1.4 was released less than a year ago and a quick reference card is available without forgetting that the embedded market , where EGL is everywhere , is fast growing . 
@@100664209 @4864209/ <p> At work I have to integrate my C++ code in a large C code ... an opportunity for my to test for the first time an experience of writing a C wrapper of my C++ code ... which turns out to be really easy ! <p> Everything is based on extern " C " qualifier , #ifdef cplusplus and a proper API design . Actually , I have been really suprized how versatile the code can become between C and C++ . Use either one of the other , with a good and simple design , that 's fine . <p> header.h <p> #ifndef cplusplus <p> extern " C " <p> #endif //cplusplus <p> void func() ; <p> source.cpp <p> #include " header.h " <p> #include &lt;iostream&gt; <p> extern " C " void func() <p> <p> std : : cout &lt;&lt; " This is C++ code ! " &lt;&lt; std : : endl ; <p> <p> source.c <p> #include " header.h " <p> int main() <p> <p> func() ; <p> <p> On the design area , I like to create C structures that contain a void pointeur to @ @ @ @ @ @ @ @ @ @ and object oriented approached to C which fit well with C++ code . For each operation , I call the C function with the right ' object ' to modify It follows the " direct state access " way of OpenGL if you want as opposed to the " bind and edit " classic way of OpenGL . <p> The C++ Experiments set of tests has been updated with this C wrapper experiment . 
@@100664210 @4864210/ <p> Introduced by the GLAPPLEvertexarrayrange extension , OpenGL 3.0 introduces a very interesting feature called " mapped buffer range " . It can lead to performance improvement and some software design changes . <p> OpenGL 1.5 included the concept of " buffer " from GLARBvertexbufferobject and a way to access to the buffer memory with glMapBuffer function . It leads to the possibility to load a buffer directly using the graphics driver memory with skip one buffer copy so that people were expected some speed up . <p> However , the results were no really convincing because even if a copy is skipped , the bottleneck is n't really in the copy but in the memory bandwise . By anyway the driver memory needs to be transfer to the graphics card which basically means that whether we use glMapBuffer or glBufferSubData , data are sent to the GPU memory when the software have finished to edit the whole buffer . This implies a serialization of the CPU and GPU works but to reach 100% efficiency we want the CPU and the GPU in parallel . <p> One solution used @ @ @ @ @ @ @ @ @ @ size of buffers . The idea is : Step 1 : edit a buffer on CPU ; Step 2 : send the first buffer and edit a second buffer during this time . By this way , we introduce asynchrony work in our solution . A good side effect of buffer size limitation is the ability to use 16 bits element buffers . <p> A new solution is mapped buffer range . The idea is to edit a range of data instead of the whole buffer . This is now possible thanks to glMapBufferRange function of OpenGL 3.0 . It does n't really deprecate buffer size limitation because of advantages like 16 bits element buffers but it increases the modification granularity . <p> Direct3D 10 changed the balanced cost of the API so that all the checking is done an object creation and not during the rendering . One of these aspects was the creation of the common buffer which does something like grouping the uniform variables in one or several buffer object . This concept has been added to OpenGL through GLEXTbindableuniform extension= " " and uniform buffers which @ @ @ @ @ @ @ @ @ @ OpenGL 3.1 core . <p> A good use of these common/uniform buffers can imply some good performance improvements simply because in most shader oriented softwares , glUniform* called numbers is more than 50% of the overall function calls However , common and uniform buffers need to be updated carefully because usually when updated , the whole buffer need to be send to the graphics card memory . A solution is to group the uniform data , per pass , per program , per object , etc . Mapped buffer ranged provides the ultimate solution because of the fine granularity it allows . A single variable can be updated ; all per pass data ( eg ) can be changed and only then , they and only they will be sent . <p> For me , there is no doubt for me that this feature is going to be really useful in the feature and will find a lot of application beyond what I have just commented . 
@@100664211 @4864211/ <p> GLM 0.9.5 will show warning messages at compilation each time a function taking degrees is used . <p> GLM : rotate function taking degrees as a parameter is deprecated. #define GLMFORCERADIANS before including GLM headers to remove this message . <p> If you are using a version of GLM older than GLM 0.9.5.1 , update to GLM 0.9.5.4 before transitioning to GLM 0.9.6 to get this help in that process . <p> Make sure to build and run successfully your application with GLM 0.9.5 with GLMFORCERADIANS , before transistioning to GLM 0.9.6 <p> Finally , here is a list of all the functions that could use degrees in GLM 0.9.5.4 that requires radians in GLM 0.9.6 : rotate ( matrices and quaternions ) , perspective , perspectiveFov , infinitePerspective , **26;405;TOOLONG , roll , pitch , yaw , angle , angleAxis , polar , euclidean , rotateNormalizedAxis , rotateX , rotateY , rotateZ and orientedAngle . <h> Using GLM template types <p> There are a lot of reasons for using template types : Writing new template classes and functions or defining new types . Unfortunately , until GLM @ @ @ @ @ @ @ @ @ @ namespace indicating there are implementation details that may changed . <p> With GLM 0.9.6 , template types are accessible from the GLM namespace and guarantee to be stable onward . <h> Optimizations <p> With GLM 0.9.5 , the library started to tackle the issue of compilation time by introducing forward declarations through &lt;glm/fwd.hpp&gt; but also by providing an alternative to the monolithic &lt;glm/glm.hpp&gt; headers with &lt;glm/vec2.hpp&gt; , &lt;glm/mat3x2.hpp&gt; and &lt;glm/common.hpp&gt; , etc . <p> With GLM 0.9.6 , the library took advantage of dropping old compilers to replace preprocessor instantiation of the code by template instantiation . The issue of preprocessor instantiation ( among them ! ) is that all the code is generated even if it is never used resulting in building and compiling much bigger header files . <p> Furthermore , a lot of code optimizations have been done to provide better performance at run time by leveraging integer bitfield tricks and compiler intrinsics . The test framework has been extended to include performance tests . The total code size of the tests is now 50% of the library code which is still not enough but pretty solid @ @ @ @ @ @ @ @ @ @ a lot of old compiler versions . If you are really insisting in using an older compiler , you are welcome to keep using GLM 0.9.5. <h> 11/01/2013 - GLM 0.9.5.1 released <p> One of the annoying aspect of GLM is that sometime angles are expressed in degrees and sometime angles are expressed in radians . Angles expressed in radians are features coming from GLSL where all the angles are expressed in radians and angles expressed in degrees are features coming from OpenGL compatibility profile . <p> GLM provides the define GLMFORCERADIANS to enfore all the angles to be radians . GLM 0.9.5 deprecates degrees so that in GLM 0.9.6 those will be removed . Starting with GLM 0.9.5.1 , warnings will be prompt for each instance of usage degrees . This is designed to help transitioning user code . Defining GLMFORCERADIANS will quiet these messages . <h> 25/12/2013 - GLM 0.9.5.0 released <p> First , in previous version GLM switched from including &lt;glm/ext.hpp&gt; to include individual extensions . Just like we can still use &lt;glm/ext.hpp&gt; for global inclusion , with GLM 0.9.5 we can use individual headers to include @ @ @ @ @ @ @ @ @ @ for glm : : vec3 , &lt;glm/mat4x4.hpp&gt; for glm : : mat4 or &lt;glm/geometry.hpp&gt; for all the version of the geometry section of the GLSL specifications . <p> Futhermore , GLM has a new forward declaration header &lt;glm/fwd.hpp&gt; to help reducing dependecies to GLM code . <p> As a result and for experimentation , a simple raytracer can be compile in less than half the time with GLM 0.9.5 than GLM 0.9.4 . <p> Second , the definition of the precision qualifier ( lowp , mediump and highp ) has changed and now express computation precision in term of ULPs . As a conscequence for example sizeof ( glm : : lowpvec2 ) , sizeof ( glm : : mediumpvec2 ) and sizeof ( glm : : highpvec2 ) return the same values . However , the effective computation can be different . For example , the implementation of inversesqrt uses fast inverse square root for lowp . <p> Finally , some efforts have be put into increasing reliability with a larger coverage of assert and staticassert to give more informative compiler error messages . Also , all the half @ @ @ @ @ @ @ @ @ @ used just like any float of double types but such usage were bad usages requiring a lot of conversions from half to float and float to half , hence very slow performances . Instead , GLM 0.9.5 provides a extensive set of packing and unpacking functions ( glm/gtc/packing.hpp ) so that we have to perform arithmetics in float and when it 's done we pack it in half data . <p> For more details , see the changelog following , enjoy ! <p> Changelog : <p> Added forward declarations ( glm/fwd.hpp ) for faster compilations <p> Added per feature headers <p> Minimized GLM internal dependencies <p> Improved Intel Compiler detection <p> Added bitfieldInterleave and mmbitinterleavesi128 functions <p> Added GTXscalarrelational <p> Added GTXdualquaternion <p> Added rotation function to GTXquaternion ( #22 ) <p> Added precision variation of each type <p> Added quaternion comparison functions <p> Fixed GTXmultiple for negative value <p> Removed GTXocltype extension <p> Fixed post increment and decrement operators <p> Fixed perspective with zNear == 0 ( #71 ) <p> Removed l-value swizzle operators <p> Cleaned up compiler detection code for unsupported compilers <p> Replaced C cast by C++ @ @ @ @ @ @ @ @ @ @ and not a sizet <p> Added GLMFORCESIZETLENGTH and glm : : lengtht <p> Removed unnecessary conversions <p> Optimized packing and unpacking functions <p> Removed the normalization of the up argument of lookAt function ( #114 ) <h> 22/12/2012 - GLM 0.9.4.1 released <p> GLM 0.9.4.1 fixes various bugs and clarifies quaternion interpolations . There are now three different functions now : mix , slerp and lerp . <p> lerp performs a linear interpolation between two quaternions . This operation is only defined with interpolation factors between 0 , 1 and does n't perform the rotation at constant speed . slerp perform a spherical linear interpolation between two quaternion . It always takes the short rotation path and it is performed at constant speed for interpolation factors between -inf , +inf . This function is similar to the old shortMix function . mix is an oriented spherical linear interpolation between two quaternion . It is performed at constant speed for interpolation factors between -inf , +inf. <h> 10/05/2012 - GLM 0.9.3.3 released <p> Nearly two months since the previous release of a GLM revision gave enough time to fix few things @ @ @ @ @ @ @ @ @ @ better compatibility with Intel C++ compiler . <h> 15/03/2012 - GLM 0.9.3.2 released <h> 10/03/2012 - GLM on GitHub <p> After years of using SourceForge.net , GLM is moving to GitHub , as least for its repository . GitHub provides easy ways to clone the repository and submit pull requests which seems a definity advantage for the community contribution . It also allows to download snapshots of every branches . <h> 25/01/2012 - GLM 0.9.3.1 released <h> 09/01/2012 - GLM 0.9.3.0 released <p> GLM 0.9.3.0 is finally released . Since the branch 0.9.2 , the test bench and the Doxygen API documentation has been expended significantly leading to an even more reliable implementation and hopefully an even smoother development experience . <p> For the feature set , the GLSL noise functions are added , based on the implementation of webgl-noise . Some users might prefer the promoted GLMGTCnoise extension also based on webgl-noise but with a different interface and three noise methods : Perlin noise , periodic noise and simplex noise . <p> 2D simplex noise with GLMGTCnoise <p> Additionally , the random number generation functions ( GLMGTCrandom ) which @ @ @ @ @ @ @ @ @ @ GLM tool box , the new experimental extension GLMGTXconstants provides a set of constants . <p> Spherical random distribution with GLMGTCrandom <p> Finally , swizzle operators are a challenging task to implement but thanks to the effort of many contributors , GLM 0.9.3.0 provides something interesting , but admittably not perfect . The new implementation is a great improvement considering the incompatibilities with some external libraries in GLM 0.9.2.7 . GLM 0.9.3 provides two implemetanations , one for C++ 98 compilers and one for C++ 11 compilers providing an implemetnation closer to what GLSL does . Indeed the C++ 98 implementation is compatible with C++ 11 compilers . <p> Implementation for C++ 98 compilers : <p> // To declare before including glm.hpp , to use the swizzle operators <p> #define GLMSWIZZLE <p> #include &lt;glm/glm.hpp&gt; <p> void examplecpp98() <p> <p> glm : : vec4 a = glm : : vec4 ( 2 , 0 , 0 , 0 ) ; <p> glm : : vec4 b = glm : : vec4 ( 0 , 2 , 0 , 0 ) ; <p> glm : : vec3 c = vec4 ( ( @ @ @ @ @ @ @ @ @ @ ) ; <p> glm : : vec2 d = glm : : normalize ( glm : : vec2 ( c.yz ( ) ) ) ; <p> a.xyzw() = d.xyxy() ; <p> <p> Implementation for C++ 11 compilers : <p> // To declare before including glm.hpp , to use the swizzle operators <p> #define GLMSWIZZLE <p> #include &lt;glm/glm.hpp&gt; <p> void examplecpp11() <p> <p> glm : : vec4 a = glm : : vec4 ( 2 , 0 , 0 , 0 ) ; <p> glm : : vec4 b = glm : : vec4 ( 0 , 2 , 0 , 0 ) ; <p> glm : : vec4 c = glm : : vec4 ( ( a.zyx() + b.xyz() ) . xyz * 0.5f , 1.0f ) ; <p> // Before being pasted to a function , a swizzle operator needs to be cast into <h> 08/06/2011 - GLM 0.9.2.3 released <h> 02/06/2011 - GLM 0.9.2.2 released <p> The main improvement of this version comes from the extended number of matrix constructors so that a programmer can used different scalar types for each parameter . <p> #include &lt;glm/glm.hpp&gt; <p> // @ @ @ @ @ @ @ @ @ @ ( <p> 1 , 0.0 , 0 , <p> 0.0 , 1.0 , 0.0f , <p> 0 , 0.0 , 1.0f ) ; <p> The quaternion implementation has been updated as well , fixing the various slerp implementation flavours ( mix , shortMix and fastMix ) and providing more completeness : Added interaction with GLMGTXepsilon and missing lowpquat , mediumpquat and highpquat but also none square matrix equivalents . <p> Finally , some efforts have been put to remove warnings across all supported compilers . <h> 24/05/2011 - GLM 0.9.2.1 released <p> GLM 0.9.2.1 significantly improves compiler detection which allows CUDA to be automatically recognized when GLM is used inside a CUDA kernel . By conscequence , GLMFORCECUDA is no longer required to be declared . <p> It fixed a couple of bugs , including Visual C++ supprot when Visual C++ extensions are disabled and fixed implementations of GLMGTXvectorangle and GLMGTXrotatevector extensions . <h> 09/05/2011 - GLM 0.9.2.0 released <p> GLM 0.9.2.0 provides many exciting features which first of all is the CUDA copiler support so that GLM can be used within a CUDA kernel . This is possible only @ @ @ @ @ @ @ @ @ @ source code . <p> New experimental extensions are also available . GLMGTXnoise is based on the work by Stefan Gustavson and Ashima Arts on WebGL-noise which adds perlin and simplex noise functions in a pure computational way . If everything goes well , this extension will be promoted to GLM core as implementation of the GLSL noise functions . <p> GLMGTXulp provides functions to evaluate the number of ULPs between two floating-point values which gives a way to mesure the accuracy of a function compare to a reference function . In the future , this extension could be used to update the documentation of function and gives the level of accuracy they provide . <p> Finally , **25;433;TOOLONG is an extension developed by Ghenadii Ursachi to extract axis and angle of a 4 by 4 matrix but also directly interpolate between two matrices . This extension works only on linear transformed matrices . <p> Last but not least : with the version 0.9.2 , GLM supports CTest to manage GLM test suite which makes tests much easier to maintain . The number of tests have significantly increase , even if @ @ @ @ @ @ @ @ @ @ is not backward compatible with GLM 0.9.1 with only one point : Quaternion SLERP interpolation ! In GLM 0.9.1 the function ' mix ' always interpolate using the short rotation path but it 's no longer the case . The function ' shortMix ' has to be called for short path interpolation. ' fastMix ' will interpolate two quaternions using a normalized linear quaternion interpolation with non-constant rotation speed . <h> 03/03/2011 - GLM 0.9.1.0 final released <p> Finally , GLM 0.9.1 branch is reaching the status of stable with GLM 0.9.1.0 . <p> From GLM 0.9.1 beta , mainly bugs has been fixed . GLM has evolved on many sides since GLM 0.9.0 : Improved documentation ( manual and doxygen ) , better test framework , simplified **26;460;TOOLONG of GLM and new experimental SIMD API . <p> GLM 0.9.1.0 is not 100% backward compatile with GLM 0.9.0.8 but mainly advanced usages should be affected by the differencies . Have a look at the GLM manual for more information on how to use GLM 0.9.1. <h> 13/02/2011 - GLM 0.9.0.8 and GLM 0.9.1 beta released <p> The stable version , @ @ @ @ @ @ @ @ @ @ and deprecated the cross function previously used for the same purpose . Also , it clarifies that GLM is a header only library when a user try to build it . Once more , there is nothing to build . <h> 31/01/2011 - GLM 0.9.1 alpha released <p> This new version of GLM is bringing a lot of improvements and maybe too many considering the development time it has required : API exposing SIMD implementation but also some new , safe and feature complet swizzling functions and a new setup API . All this is described in the largely updated GLM manual . <p> With the new setup system , GLM detects automatically the compiler settings to adapt its implementation to the flag set at build time . It will automatically enable C++0x features , SSE optimizations and the display configuration informations at build-time . The automatic setup can be overdrive by the GLM user . <p> The SIMD API maintly focus on vec4 and mat4 implementations that are embodied by the types simdVec4 and simdMat4 . The implemention cover most of the common functions , the geometry functions and @ @ @ @ @ @ @ @ @ @ Because it is hight inefficient to access individual components of a SIMD register , the simdVec4 does n't allow it . To reflect this constraint , the simdVec4 has to be converted to vec4 first which would be effectively handle by the compiler thank to the function simdCast . Furthermore , GLM provides some specials functions like simdDot4 that returns a simdVec4 instead of a float with the duplicated dot product value in each components and ensure that no unnecessary component manipulations are performed ( typically m128 to float and float to m128 ) . This implementation can probably be improve in many ways so do n't hesitate to send me some feedbacks . <p> GLM 0.9.1 is not 100% backward compatible with GLM 0.9.0 but mostly advanced usages should be concerned by this compatibility issues . <h> 01/11/2010 - GLM 0.9.0.5 released <h> 04/10/2010 - GLM 0.9.0.4 released <p> GLM 0.9.0.4 revision mainly fixes bugs . It also contains a contribution by Arnaud Masserann , a autoexp.dat file to make GLM looks nicer in Visual Studio debugger . To take advantage of this file , edit LONG ... file @ @ @ @ @ @ @ @ @ @ GLM 0.9.0.4. <h> 21/06/2010 - GLM 0.9.0.1 released <h> 25/05/2010 - GLM 0.9.0.0 released <p> GLM 0.9.0.0 is finally available ! It brings various API changes from GLM 0.8.4 . X branch which makes it not backward compatible . GLM is now compatible with Objective C++ to be used for MacOS X and iPhone projects . <p> To continue making GLM a better library , 2 mailing lists have been created for users and developers . <h> 03/04/2010 - GLM 0.9 Beta 1 released <p> A new development version of GLM 0.9 is available . <p> This version is based on GLSL 4.0 and supports the new common and integer functions . Also a long and frequently asked feature has been implemented : inplicit conversions . However , the rules defining implicit conversions by GLSL 4.0 are quite weaked and ca n't really be apply in C++ . <p> Reaching the beta status , this new features close the feature list of GLM 0.9 . Further development releases may happen before the final release . <h> 20/02/2010 - GLM 0.9 Alpha 2 released <h> 09/02/2010 - GLM 0.9 Alpha 1 @ @ @ @ @ @ @ @ @ @ with this first alpha of GLM 0.9 . <p> This version brings a large internal redesign to improve the library reliability and optimized some parts . It removed the deprecated features and API which implies that GLM 0.9 is n't backward compatible . <p> For most users the build issues when upgrading to GLM 0.9 should be reduced especially if they follow the deprecation policy . <p> This release is still UNSTABLE and not recommanded for commertial products . <h> 16/11/2009 - GLM 0.8.4.3 released <p> This version fixed half scalars and half vectors arithmetics . This is a really slow practice that should be avoid . Half floating point value should be use only to store GPU data . GPUs have native support for half values , not x86 CPUs. <h> 21/05/2009 - GLM 0.8.3.1 released <h> 06/05/2009 - GLM 0.8.3.0 released <p> This version brings to main changed : Stable extensions and a new extension system . <p> The first stable GLM extensions are : GLMGTCdoublefloat and GLMGTChalffloat for higher and lower vectors and matrices floating point precision . GLMGTCmatrixoperation provides determinant and inverse matrix calculation . GLMGTCmatrixtransform @ @ @ @ @ @ @ @ @ @ GLMGTCmatrixprojection provides varius functions to build projection matrices . Few stable extensions yet but the number is going to grow with the next release ! <p> Both GLM 0.8.2. x extensions use method are deprecated ( but still working ) and replace by a new one . If you wnat to use GLMGTChalffloat just include " glm/gtc/halffloat.hpp " and it is going to be included in GLM namespace . <p> Finally , quite some file have been renamed , using " hpp " instead of " . h " . Old file have been deprecated but are still available so that GLM 0.8.3.0 is fully compatible with GLM 0.8.2. x. <h> 30/10/2008 - GLM 0.8.1 released <h> 23/10/2008 - GLM 0.8.0 final released <p> GLM 0.8.0 is released . This new version is now based on GLSL 1.30 specification which provided new functions and precision qualifiers . <p> Beyond this , lot of changes have been done to make GLM easier to use , easier to develop , more reliable , more conform to C++ ISO98 standard and GLSL specifications . <p> It involves that GLM 0.8. x is not @ @ @ @ @ @ @ @ @ @ application port from GLM 0.7. x to GLM 0.8. x is n't a huge work and actually for some , it wont be work at all . <p> On GLM core side , based on GLSL features , vector types ca n't be automatically cast to pointer anymore for code safety purposes . Vector constructors require a single scalar parameter of the exact number of components . <p> On GLM extension side , the mechanism to use them has changed . The old ***GTX way does n't exist anymore . Have a look on the manual for more information . <p> Have a look on the manual and the changelog for more information . Do n't forget to send your feedback and enjoy ! <h> 04/10/2008 - GLM 0.8.0 beta 2 released <p> This release mainly improves half float vectors support . By default the low precission vectors are based on float numbers not on half numbers <p> It also provides new setup options . GLMUSEONLYXYZW to disable multiple names to access to a single vector component . GLMUSEANONYMOUSUNION to allow multiple component names on half vectors with Visual C++ @ @ @ @ @ @ @ @ @ @ done too . Final release is coming ... <h> 26/09/2008 - GLM 0.8.0 beta 1 released <p> GLM have been updated to support GLSL 1.30 . API documentation had significant improvements to make easier finding of GLSL functions and types . <p> GLM 0.8. x is NOT backward compatible with GLM 0.7. x . Upgrade to GLM 0.8. x could involve build errors for the following cases : A lot of improvements have been made to increase the conformance with GLSL specification . Lot of GLSL 1.30 features were already exposed in extensions that have been deleted . The extension syntaxe based on ARB convension is no long used . <p> Due to the number of changes GLM 0.8.0 is release as beta first . The final release is schedule for october . <h> 08/08/2008 - GLM 0.7.6 released <p> GLM 0.7.6 provides a better C++ conformance so that you can build GLM with pedantic G++ parameter or without Visual Studio extensions . To make GLM more reliable , BOOSTSTATICASSERT are used according developer wishes . <h> 05/07/2008 - GLM 0.7.5 released <p> GLM 0.7.5 is available and introduces a @ @ @ @ @ @ @ @ @ @ configuration with Visual Studio . This mechanism is documented in section 6 of GLM manual . Also , GLM can be built with GCC pedantic options . <h> 24/03/2008 - GLM 0.7.1 released <h> 22/03/2008 - GLM 0.7.0 released <p> GLM 0.7.0 is available under MIT license . LGPL lisence have been discard due to an issue of use for console development . This release contains a lot better documentation based on Doxygen . Lot of bugs have been fixed and the documentation completed . Thanks to all people that has contributed thought bug reports and ideas to make this version a lot better ! <h> 07/10/2007 - GLM 0.6.1 released <h> 16/09/2007 - GLM 0.6.0 released <p> GLM 0.6.0 is available . For this release , work focus on extensions . A new mecanisum allows to integrate GLM extensions as it is actually done for GLSL extension by vendors . Lot of new extensions have been added . <h> 06/01/2007 - GLM 0.5.0 released <p> This release include GLSL 1.2 new feature in the core implementation . Also , it includes swizzle read and write operators and a custom @ @ @ @ @ @ @ @ @ @ new extensions to extend GLSL features but they remain experimental . The next release should provide the first stable extensions . <p> The GLM 0.5.0 packages contain some basic samples and some documentation . The ray tracer sample has been updated to GLM 0.5.0 . Except for specific cases , especially with extensions , GLM 0.5 is backward compatible . <h> 22/05/2006 - GLM 0.4.1 released <p> A GLM update is available . It simply includes some examples for a sweet start with GLM . <p> The examples show how to use GLM with OpenGL intermediate mode and OpenGL vertex arrays . Also , they show how to use GLM extensions to replace GLU and OpenGL function witch could slightly increase performances by decreasing the number of OpenGL states changes . <h> 17/05/2006 - GLM 0.4.0 released <p> This release introduces first GLSL 1.2 features as planed . Also , various new extensions have been added and updated . Finally , it 's not anymore required to include windows.h before glm.h when windows.h is required . <p> The number of features of GLM , including extensions , start to really @ @ @ @ @ @ @ @ @ @ recommended to use precompiled headers. <h> 23/04/2006 - Roadmap for the years <p> Version 0.4 will complete matrices and vectors operators and will add GLSL 1.2 features . First , conversions simplifications will be integrated . Then , 4 per 3 matrices and outer product will be available from extensions . The transpose function is already available from extension . <h> 28/03/2006 - GLM 0.3.1 released <h> 19/02/2006 - GLM 0.3 released <p> A new release of GLM is now available . It improves GLSL data type conversion and construction compliance . Also , It 's adds extensions like some to manage double-precision and half-precision float numbers . Finally a Doxygen documentation has been added . <p> To demo the features of this new version , a sample program is included . It is a simple Ray Tracer supporting reflected and refracted rays , three lights types ( point , directionnal and spot ) , two objects types ( sphere , plan ) , using all of the GLM possibilities . <h> 04/05/2005 - English pages <p> The english section of this site is now available . <h> 21/02/2005 - @ @ @ @ @ @ @ @ @ @ availability of GLM . This library supports a part of GLSL specification : All vector , matrice types , the operators and associated functions . <p> For now , there is n't a detailed documentation , but you can have a look on GLSL specifications . Consider any mismatch between GLSL and GLM as a bug . Keep in mind the library is included in the namespace " glm " . <p> This project is multi-platform and was successfully tested under Visual C++ 7.1 , MinGW 3.4 and GCC 3.4. 
@@100664213 @4864213/ <p> Returns the insertion the bits least-significant bits of insert into base . <p> The result will have bits offset , offset + bits - 1 taken from bits 0 , bits 1 of insert , and all other bits taken directly from the corresponding bits of base . If bits is zero , the result will simply be base . The result will be undefined if offset or bits is negative , or if the sum of offset and bits is greater than the number of bits used to store the operand . <p> Returns the bit number of the most significant bit in the binary representation of value . <p> For positive integers , the result will be the bit number of the most significant bit set to 1 . For negative integers , the result will be the bit number of the most significant bit set to 0 . For a value of zero or negative one , -1 will be returned . 
@@100664214 @4864214/ <p> " I invite the subject to the camera . I began to search for an attitude , and then begin to expose film . I follow my plan through to hwat may be a dead end or to success ... I have found that for me it is fatal to change directions radically in the middle of a sitting . I lose the subject . " Irving Penn <p> For some reasons , usual , I do n't fell connected with famious photographer 's works . I can see why it 's good or not , it 's just that emotionnally , I 'm not touched . Irving Penn is one of the few exceptions . I like his creation process , I like his view on photography and actually I share these . <p> Irving Penn , 1917 - 2009 , was an American photographer acknowledged for his portrait and fashion photography who starts his career for Harper 's Bazard but works for many years for Vogue Magazine . <p> " In portrait photography there is something more profound we seek inside a person , while being @ @ @ @ @ @ @ @ @ @ the inside is recordable only in so far as it is apparent on the outside . " Irving Penn <p> The exhibition is on until the 6th of June for -10 . <p> Salvador Dali , 1947 <p> Truman Capote , 1948 <p> Pablo Picasso , 1957 <p> Jasper Johns , 2006 <p> " Sensitive people faced with the prospect of a camera portrait put on a face they think is one they would like to show the world . ... Very often what lies behind the facade is rare and more wonderful than the subject knows or dares to believe . " Irving Penn , 1975 <p> Nice , now I have a great explanation for what I call " True beauty " ! : ) 
@@100664217 @4864217/ <p> My equipment starts to look like very nice even if I 'm still dreaming of a Canon 5D MKII . By now , I have 6 lenses for every use and I do n't plan to buy some more soon ... the next target is the 5D MKII ! <p> My first lens is a Canon EF-S 18-55mm F/3.5-5.6 IS . It 's an ok lens sold as a kit with my Canon 450D . I do n't think that I 'm going to use it anymore actually because my others lenses overlap its uses with higher quality . <p> My second lens is a Canon EF 70-300mm F/4.0-5.6 USM IS . Very good price for the quality , I 'm using it mainly for animal pictures , portrait when far from the subject . I bought it right after I bought my camera and did my first macro pictures because of the nice depth of field but require to be at 1.5m minimum to take the pictures . <p> My third lens is a Canon EF 50mm F/1.4 USM . I become in love with fixed focal @ @ @ @ @ @ @ @ @ @ lenses bring life to picture because it implies that the protographer need to be more dynamic . The large aperture brings such a nice depth of field blur . Very nice for low light . <p> My forth lens is a Canon EF 28mm F/1.8 USM . I use it for full portrait pictures or two persons portraits pictures . The apperture is very nice for low light and the focal makes it great in house lens . <p> My fifth is a Canon EF 100mm F/2.8 USM . My macro lens ... 100mm at F/2.8 , that a crazy beautyful depth of field ! Despite the USM motor , autofocus is quite slow so the subject better not to move too much . Pictures are very sharped with a minimum focus distance at 31cm , perfect for great macro pictures ! <p> Mu sixth is a Canon EF-S 10-22mm F/3.5-4.5 USM . My very wide angle lens , many for landscapes ! It can be used for fish-eyes portrait . The only issue with this lens is that it ca n't be used on full frame camera like every @ @ @ @ @ @ @ @ @ @ , an Opteka Battery Pack Grip and other accessories , it makes me a happy photographer ! <p> I did a little experiment using all my lenses taking pictures for the same positions to show the effect of the focal distance . <p> 50 000 pictures later , my passion for experimenting with photography is still on and lot of new projects are on they way ! There is never enought photography projects so if you have some ideas and topics for me , just let me know ! 
@@100664219 @4864219/ <p> Small triangles is bad for performance and this is not something new . In this post , we are just looking at some numbers to quantity these bad performance . <p> We are using a simple scenario where the framebuffer is filled with tiles of variable sizes , each tile being composed of two triangles and no tile is overlapping another . The vertex shader only transform the vertices and the fragment shader is a pass through shader . This scenario could be seen as a best case scenario , if not best , it 's close to a best case . Nevertheless , the results show horrifying performances on small triangles . <p> Following , two images showing examples of rendering used for these tests . <p> Example of rendering test using 8*8 tiles <p> Example of rendering test using 1*1 tiles <h> First test with squared tile sizes and a full frame tile <p> In a first test , we are filling a 1080p framebuffer using tiles from 1 by 1 to 128 by 128 and even using a single pair of triangle to fill the @ @ @ @ @ @ @ @ @ @ triangle makes better sense for the hardware but it was enough for illustrate our scenario ) . <p> Filling a 1080p framebuffer with tiles using a triangle pair to cover each tile . Relative rendering time to 128*128 tile sizes . <p> The first conclusion is that filling the framebuffer with anything larger than 16 by 16 tiles have no effect on the GPU performance for any desktop vendors at least for the primitive rasterization/fixed function point of view . <p> The primitive minimum size in pixels is pretty much the same for all vendors . Covering 8 by 8 pixels with two triangles starts to have a significant impact on performances but it 's still acceptable as not a performance cliff . <p> Haswell behaves the best with small triangles . " The best " is still a performance cliff as basically Haswell , Kepler and Southern Islands are about 10x , 15x , 20x slower than optimal performance respectively . <h> Does the shape of the triangles really matters ? <p> Filling a 1080p framebuffer with non squared 256 pixel tiles using a triangle pair to cover each @ @ @ @ @ @ @ @ @ @ good new is that equilateral triangles is generally better for all vendors . <p> It 's funny how different are the performance characteristics between 256 by 1 and 1 by 256 for example . However , this is nothing really surprising considering the rasterization patterns of the GPU architectures that is obviously not designed to be somewhat anisotropic . <p> Example of rendering using 32*2 tiles for non squared tiles <h> What about sub-pixel triangles ? <p> Filling a 320*240 framebuffer with sub-pixel tiles . <p> It 's only getting worse ! In this test the framebuffer size is only 320 by 240 because at 1080p implementations would all time out at 0.25 by 0.25 or 0.125 * 0.125 tile sizes . <h> The performance cliff is exponential <p> Filling a 640x480 framebuffer with tiles using a triangle pair to cover each tile . X : Tile sizes , Y : Relative log10 rendering time to 128*128 tile size <p> This last drawing is to highlight that the performance cliff is about exponential . <h> Conclusion <p> Why such performance cliff ? Because GPUs work at varius granularities that is @ @ @ @ @ @ @ @ @ @ is the quadpixels ( block of 2 by 2 pixels ) that are used to compute the derivatives . The derivatives are used for the explicit fragment shader derivatives but also to select the correct mipmaps while filtering as shown in the following code that can be wired in the texture units . <p> Calculating texture lod with derivatives : <p> float textureLevel ( in sampler2D Sampler , in vec2 Texcoord ) <p> <p> vec2 TextureSize = vec2 ( textureSize ( Sampler , 0 ) ) ; <p> float LevelCount = max ( log2 ( TextureSize.x ) , log2(TextureSize.y) ) ; <p> // Access neighbour values within the quadpixels to return the derivative <p> vec2 dx = dFdx ( Texcoord * TextureSize ) ; <p> // Access neighbour values within the quadpixels to return the derivative <p> vec2 dy = dFdy ( Texcoord * TextureSize ) ; <p> float d = max ( dot ( dx , dx ) , dot ( dy , dy ) ) ; <p> d = clamp ( d , 1.0 , pow ( 2 , ( LevelCount - 1 ) * 2 ) ) @ @ @ @ @ @ @ @ @ @ important or even more important : the primitive rate . For example , Tahiti is capable to process two triangles per clock . However , each triangle is effectively sliced into multiple primitives within 8 by 8 pixel tiles . If a triangle overlap two tiles , the triangle requires two primitives . If a triangle overlap only a single pixel , then the budget for the other pixels in the 8 by 8 tile is wasted as only a single primitive can be scanned per cycle per tile . <p> A triangle is contained with a 8 by 8 pixels block , it consumes 1 primitive <p> A triangle covers only a single pixel , it still consumes 1 primitive <p> Two triangles are contained without the 8 by 8 pixels blocks , they consume 1 primitive each <p> A triangle overlaps two 8 by 8 pixels blocks , it consumes 2 primitives <p> A triangle overlaps four 8 by 8 pixels blocks , it consumes 4 primitives <p> Considering these numbers , the felling that tessellation is the biggest waste of GPU area space since the geometry shader @ @ @ @ @ @ @ @ @ @ waste because engines do n't really use tessellation however it provides an effective way to control the size of the primitives on screen . Is the current OpenGL 4 / D3D11 hardware tessellation good enough ? I do n't have that answer . <p> In the meantime , if we want some good primitive performances , let 's set the minimum target to about 8 by 8 pixels per triangles on screen . <p> The source for these tests in available in the staging of the OpenGL Samples Pack 4.4.3 branch . 
@@100664220 @4864220/ <p> After a long 8 months pause , once again , I tested my OpenGL samples on available OpenGL desktop drivers . This post is a report on whether these samples ran successfully . My OpenGL samples are not a conformance test , only a set of 212 OpenGL code samples I accumulated over time . I have n't updated MacOSX or Linux results . <h> Focus on sRGB framebuffer conversion with OpenGL and OpenGL ES <p> sRGB conversions is typically a pretty buggy area particularly on MacOSX . On Windows , it looks like that every hardware vendors got it somewhat wrong with OpenGL core and compatibility profile . How to explain this ? AMD and Intel have followed NVIDIA behaviors which dominates the OpenGL desktop ecosystem . <p> This is attitude of following NVIDIA behaviors is pretty striking considering for example that Intel behaviors used to make the most sense and used to follow the specification . <p> However , NVIDIA behavior is not correct to my understanding build from reading the OpenGL specification and many experiments . Not following the specification is not necessary a bad @ @ @ @ @ @ @ @ @ @ , however on the framebuffer sRGB conversion case , NVIDIA behavior only implies rendering garbage as shown in figure 3 . So , what the OpenGL core profile specification says ? <p> If FRAMEBUFFERSRGB is enabled and the value of **34;488;TOOLONG for the framebuffer attachment corresponding to the destination buffer is SRGB ( see section 6.1.3 ) , the R , G , and B values after blending are converted into the non-linear sRGB color space . OpenGL core framebuffer sRGB conversion rules <p> OpenGL ES is slightly different : GLFRAMEBUFFERSRGB does n't exist so that framebuffer sRGB conversion only depends on the **36;524;TOOLONG . <p> If the value of **34;562;TOOLONG for the framebuffer attachment corresponding to the destination buffer is SRGB ( see section 9.2.3 ) , the R , G , and B values after blending are converted into the non-linear sRGB color space . OpenGL ES framebuffer sRGB conversion rules <p> This hightlight a OpenGL core and OpenGL ES incompatibility : OpenGL ES behaves as if GLFRAMEBUFFERSRGB was already enabled where on desktop GLFRAMEBUFFERSRGB is disabled by default . <p> Following this reasonning a quick interpretation would @ @ @ @ @ @ @ @ @ @ enable GLFRAMEBUFFERSRGB at initialization on desktop . Unfortunately , this is not working in practice as shown in figure 3 . <p> As a result , a default behavior on ES profile ( 4 ) results in a completely wrong output on core profile ( 3 ) . <p> Intel ( with only new drivers ) and AMD behave just like NVIDIA except regarding the **36;598;TOOLONG query on the default framebuffer : Intel and AMD returns GLSRGB and NVIDIA returns GLLINEAR . <p> IF FRAMEBUFFERBINDING is 0 then if FRAMEBUFFERSRGB is enabled , the R , G , and B values after blending are converted into the non-linear sRGB color space . Otherwise , follow the specification . Observed NVIDIA framebuffer sRGB conversion rule on OpenGL core <p> Where NVIDIA behavior has obviously a bug , Intel and AMD behavior might be the result of a specification bug : WGLframebuffersRGB despite being ratified in 2008 , never had the luxury to get it 's specification written . <p> 21 ) Where 's the specification language for the GLX and WGL pixel format selection interface ? TO BE DONE . The @ @ @ @ @ @ @ @ @ @ default framebuffers which are sRGB-capable in the fairly obvious way , but this language was missing in the original EXTframebuffersRGB and needs to be added here . framebuffersRGB : issue 21 <p> With Windows 7 , all the default framebuffers are sRGB capable however there is no way to explicitly request a linear or sRGB color encoding . Additionally , maybe the default framebuffer is effectively sRGB however Windows compositor interprets sRGB values as linear RGB values anyway hence producing the result in figure 3 and 5 . This would mean that Windows effectively does n't support sRGB framebuffer natively which would be shocking but not impossible . If someone has information at OS level , I 'll enjoy to get some inputs ! <p> In any case , we need a proper WGLframebuffersRGB specification allowing to create a linear RGB or sRGB default framebuffer explicitly but also defining sRGB conversions on the default framebuffer . <p> Unfortunately , on MacOSX and at least some AMD drivers there are more problematic cases . For example , it may happen that we must disable framebuffer sRGB conversion on framebuffer object if @ @ @ @ @ @ @ @ @ @ , sRGB conversions are performed on none or all framebuffer attachments for multiple framebuffer attachments case so that all attachments must use the same color space . <p> Considering formats such as RGB10AUNORM or RGBD we might wonder if it 's worth bothering with sRGB framebuffers. 
@@100664224 @4864224/ <p> This is my last series post resulting of GDC 2010 event : OpenGL 3.3 and OpenGL 4.0 release ! This article is so long that I decided to split it into 4 posts . I could have actually make it longer as I did n't even spoke about all the features I read or thought about . Let 's say it 's just a quite introduction of OpenGL future ! <p> DSA is an alternative to the traditional ' bind and edit ' way of OpenGL . How someone like me who value traditions could want to get ride of an old concept ? Because this ' bind and edit ' is a pain for software design , could be inefficient especially with multithreaded drivers and it makes really hard to port an OpenGL software to Direct3D when this port have n't been take care from the ground up . <p> When I 'm writting a code I find it to be a great practice to design an API that tell me how to use it even without documentation . This is hardly possible but I see it @ @ @ @ @ @ @ @ @ @ to tend . ' bind and edit ' is just not anything close to this idea especially because it is decorated with ' selectors ' link glActiveTexture <p> The current bound sampler for each supported texture target ( OpenGL 3.3 ) <p> The current transform feedback object ( OpenGL 4.0 ) <p> Chances are that this number of selectors will increase in the future ( immutable state object ? blend object ? ) . The ' bind and edit ' model asks the question of object use cases ( object edits / call draws ) . Do we really need to affect the binded objects for the draw call when we want to edit an object ? How do we want to manage the current states of the renderer ? <p> At draw call , we just want to draw but with the ' bind and edit ' model we might need to check current states just to make sure that edit code side of the software did n't perturbe one or another state . We might end up with just checking everything which is a massive CPU overload . @ @ @ @ @ @ @ @ @ @ might think of a using glGet* functions to request the current state but this is such a bad idea for effectiveness . <p> The way I decide to resolve this problem is by using macro state objects ( a set of states of similar semantics ) assign a unique identifier for each , an compiling the state into an OpenGL display list . When I bind the macro object , I just execute the display list which change all the states and probably more than what I need . Simple and efficient ( on nVidia , I never made tests on AMD ) . However , display lists are ' deprecated ' ... <p> I am lucky . I wrote a multithreaded OpenGL renderer where one thread was dedicated to the OpenGL renderer and use to process all the commands given by as many threads as possible which each of them add a lot to do already : the application with user event handling , procedural geometry updates , procedural texture generations , etc . One thread to feed them all . <p> The design allows with one frame of @ @ @ @ @ @ @ @ @ @ frame to swap message sender / recipient lists ) for the message manager ( to communicate from all the threads to the OpenGL thread ) to handle the scenario , maximizing macro task multithreading . One problem with this design was the management of feedbacks from the OpenGL thread to the other threads . All the communications between threads required to use the message manager to be safe . With this design , if you need to read a single value , you need to pass by the message system , wait until the message is processed ( up to 1 frame latency ! ) before getting the result ... We need to stall the rendering pipeline for 1 frame ! <p> I 'm sure AMD and nVidia design clever solutions to hide this multithreading latency but still it remains somewhere where glGet* is n't an optimal scenario . <p> We really do n't want to call this setTexture2DParameter function . In a real and complex software , it 's actually quite tempting from time to time to write that kind of hack ... Moreover , we are changing the @ @ @ @ @ @ @ @ @ @ one it is . Even if the current texture object is restaured , in a debugging perspective ... it 's odd ! <p> DSA way , no state checking required with possible under-layered one direction thread communication : <p> Now : scenario ! This sampler is used for a chunked terrain renderer and for some reasons on the configuration , the software is too slow and we want to reduce the texture filtering quality . A sampler object is shared and used already by a set of chunks . We do n't have to mess the texture unit were it is binded or we do n't have to mess with current binded sampler . ' Edit ' and ' draw ' cases are independant . Bonus of the new sampler object , we do n't have to browse all the chucks to find the onces who uses this sampler ! <p> Sampler objects , even if we could complain for some things , as the first DSA API , succeeds and calls for more DSA . <p> From time to time during development , selectors become bugs prone . What @ @ @ @ @ @ @ @ @ @ developers knowlegde of it ? It can just completely mess up the complete rendered image without any OpenGL error . This is actually why I never call glBindTexture without glActireTexture just the line before : to be sure that I am actually binding the texture where I expect to bind it . With DSA , we would simply have a function like glBindNamedTexture ( uint unit , enum target , uint texture ) which garanties the correct behavior . On top of this , the API itself tell us how to use it : wonderful and no rick that some developers would n't be aware of the glActireTexture selector or simply forgot it by mistake . <p> When generalized to the whole API , we notice that the DSA API tell you more about how to use the API , which function needs to be called before one function , each function calling for more functions to be called before itself . By this way , DSA is a better self documented API . <p> The current GLEXTdirectstateaccess extension has few part I do n't really like . For example @ @ @ @ @ @ @ @ @ @ it also allows to edit binding point values like the fonction glMultiTexParameterivEXT function that allows to edit a texture unit binding point . It fells to me that it is messing around with the ' draw ' case and for debugging purpose , I prefer to check at an object level rather than at each parameter value level . <p> The idea of immutable objects at draw fells more reliable at software development level and maybe more efficient at drivers development level . It 's likely that an object might be create and edit at one place but use for drawing at multiple places and multiple combinaison orders . <p> The super awful function : glMultiTexImage2DEXT changes the data of a texture from where it is binded but which you do n't know what is it name if we do n't keep track of the object name or query it ... Odd and scary ! <p> The OpenGL API has few others clues related on the DSA direction took by OpenGL . The OpenGL 4.0 function glDrawTransformFeedback which second parameter takes a transform feedback object . Following the ' edit @ @ @ @ @ @ @ @ @ @ a dedicated binding point GLDRAWTRANSFORMFEEDBACK just like they did for framebuffer blit with the binding point GLREADFRAMEBUFFER and GLDRAWFRAMEBUFFER . More obvious , the OpenGL 3.2 function glUniformBlockBinding which takes as first parameter a ' program ' name where all the others glUniform* functions affect the current binded program . <p> Well , you understand it : I really but I mean really hope to see DSA in OpenGL 3.4 and OpenGL 4.1 ! Number 1 in my wishlist . Would it really be in OpenGL 3.4 and OpenGL 4.1 ? From my understanding and what I read here and there nVidia is really up for DSA but some ARB members are not . Well ... some might be AMD . At OpenGL 3.3 release the lack of DSA was the main cloud in a sky of congratulations . I really like the always constructive contribution of a former Bizzard developer but now working for Valve ( Thanks for the update Rob ! ) who said at OpenGL 3.3 and OpenGL 4.0 release : <p> " If a dozen separate developers all shout loudly for DSA for example , this @ @ @ @ @ @ @ @ @ @ Rob Barris 
@@100664226 @4864226/ <p> Returns an unsigned integer obtained by converting the components of a floating-point scalar to the 16-bit floating-point representation found in the OpenGL Specification , and then packing this 16-bit value into a 16-bit unsigned integer . <p> Returns an unsigned integer obtained by converting the components of a four-component floating-point vector to the 16-bit floating-point representation found in the OpenGL Specification , and then packing these four 16-bit values into a 64-bit unsigned integer . <p> The first vector component specifies the 16 least-significant bits of the result ; the forth component specifies the 16 most-significant bits . <p> Returns an unsigned integer obtained by converting the components of a four-component signed integer vector to the 10-10-10-2-bit signed integer representation found in the OpenGL Specification , and then packing these four values into a 32-bit unsigned integer . <p> The first vector component specifies the 10 least-significant bits of the result ; the forth component specifies the 2 most-significant bits . <p> Returns an unsigned integer obtained by converting the components of a four-component unsigned integer vector to the 10-10-10-2-bit unsigned integer representation found in the OpenGL Specification @ @ @ @ @ @ @ @ @ @ unsigned integer . <p> The first vector component specifies the 10 least-significant bits of the result ; the forth component specifies the 2 most-significant bits . <p> Returns a floating-point scalar with components obtained by unpacking a 16-bit unsigned integer into a 16-bit value , interpreted as a 16-bit floating-point number according to the OpenGL Specification , and converting it to 32-bit floating-point values . <p> Returns a four-component floating-point vector with components obtained by unpacking a 64-bit unsigned integer into four 16-bit values , interpreting those values as 16-bit floating-point numbers according to the OpenGL Specification , and converting them to 32-bit floating-point values . <p> The first component of the vector is obtained from the 16 least-significant bits of v ; the forth component is obtained from the 16 most-significant bits of v. 
@@100664227 @4864227/ <p> During the first years of GLM development , I raised my interest for the efficiency of the generated code by the compiler to answer this simple question : Is writing SSE code using intrinsics worth the effort ? Understand , while that give a performance gain ? For a long time the answer was easy , yes because the compiler does a poor job . Today 's compilers do a much better job however there are still incapable of vectorizing the code ... <p> One of the interest of the SSE or AVX instruction sets is a provide SIMD instructions allowing to process in a Single Instruction Multiple Data . However , this is only a subset of the SEE or AVS instructions as all the Multiple Data instructions also come with Single Data equivalent . This is these Single Data instructions that the compilers are actually generating . Following , here is a code sample that we will use to generate the ASM code for GCC 4.4 , GCC 4.8 , ICC13 , VC12 , Clang 3.0 and Clang 3.2 . <p> Reading these codes , we @ @ @ @ @ @ @ @ @ @ intructions . <p> We can notice some useless mov instructions generated by some compilers . Also , Clang tries to interleave different instructions while ICC is regrouping identical instructions . Others compilers more or less interleave or regroup the identical instructions but in any case each compiler is capable to massively reorder the instructions to the point that GCC 4.8 is capable to generate exactly the same assembly code for both mulcpp and mulinstlike but it is still incapable of vectorizing a code . <p> It seems to me that being capable of such reording shows how compiler optimizations have been focus on the result and the dependances to this result . With such strategy based on ASTs , the compilers can remove dead code and useless operations like sequence of mov instructions . However , today CPU performances are more bound to the usage of memory , how we maximize the cache usage and how we reduce the data movement and transfer . Two conscequences : There is still a lot of room for compiler optimizations and hand writing code with intrinsic remains relevants . <p> There are some @ @ @ @ @ @ @ @ @ @ ISPC seems inspired by GPU architechtures and it generates C++ source code using on demand SIMD instruction sets . Then Polly is a compiler optimizer that directly tackles the issues of memory access pattern . Finally , LLVM is going to integrate in LLVM 3.3 a new optimizer called SLP Vectorizer <p> For GLM , what I would enjoy is to figure out an approach where I could avoid writing intrinsic code but still write my C++ code in a way that the compiler would generate the SSE code I expect it to be generated . Even if , I have to look at the assembler code , such approach would allow me to have a single code for each operation making it easier to maintain . <p> So far GLM provides dedicated simdVec4 and simdMat4 classes for SIMD optimiations . David Reid even contributed a simd version of GLM quaternions for GLM 0.9.5 . It is obivous that using GLM to write very fast code is not a good idea but this is not a reason why GLM should n't be as fast as possible and ideally it should @ @ @ @ @ @ @ @ @ @ to do a better job . <h> Viewing x86 assembly with XCode <p> Since XCode 4.1 , we can display the assembly of a file using the menu " Product/Generate Output/Assembly File " . However , with Clang the IDE will show the LLVM IR which might be great for the compiler to use but I find it harder to read than old-fashion CPU or GPU instructions . Fortunately we can enable x86 assembly generation using the argument " -no-integrated-as " . This argument can be set using the menu " Product/Scheme/Manage Schemes " . Also , " -integrated-as " can explicitly request LLVM IR . <h> Online C++ compilers <p> I discovered few months ago that many compilers can be used online . This is very convenient idea that allows to quickly test a code on different compilers . Is n't it nice to be able to use VC12 on MacOS X ? My favourite website is gcc.godbolt.org which support many versions of GCC but also Clang 3.0 and ICC 13 . A great feature is that this website display the ASM code generated . For Visual C++ 12 @ @ @ @ @ @ @ @ @ @ ASM code but only the compiler errors . 
@@100664230 @4864230/ <p> As part of GLM 0.9 development , I am rewriting the manual which include a FAQ . This is what I currently get , if you have more ideas do n't hesitate to submit ! <p> 1 . Why GLM follows GLSL specification and conventions ? <p> Following GLSL conventions is a really strict policy of GLM . GLM has been designed following the idea that everyone does its own math library with his own conventions . The idea is that brilliant developers ( the OpenGL ARB ) worked together and agreed to make GLSL . Following GLSL conventions is a way to find consensus . Moreover , basically when a developer knows GLSL , he knows GLM . <p> 2 . Why vec4(x) * y does n't build ? <p> GLM follows GLSL semantic conventions and features . Indeed , a vector by a scalar product is supported . However , GLSL defines for example a vector of float by a float scalar but does n't  support for example a vector of float by a double scalar . Value types must match . <p> vec4 v1 ; @ @ @ @ @ @ @ @ @ @ s1 ; <p> double s2 ; <p> ... <p> v2 = v1 * s1 ; // OK <p> v2 = v1 * s2 ; // ERROR <p> v3 = v3 * s2 ; // OK <p> v2 = v1 * 2.0f ; // OK <p> v2 = v1 * 2.0 ; // ERROR <p> v2 = v1 * 2 ; // ERROR <p> 3.3 . Would it be possible to add my feature ? <p> YES . Every feature request could be added by submitting it here : LONG ... <p> These requests would mainly take the form of extensions and if you provide an implementation , the feature will be added automatically in GLM release . <p> 3.4 . Does GLM run GLSL program ? <p> No , GLM is a C++ implementation of a subset of GLSL . <p> 3.5 . Does a GLSL compiler build GLM codes ? <p> Not directly but it can be easy to port . However , the difference between a shader and C++ program at software design level will probably make this idea unlikely or impossible . <p> 3.6 . Should I @ @ @ @ @ @ @ @ @ @ be experimental extensions . In GLM this means that these extensions might change from version to version without restriction . In practice , it does n't  really change except time to time . GTC extensions are stabled , tested and perfectly reliable in time . Many GTX extensions extend GTC extensions and provide a way to explore features and implementations before becoming stable by a promotion as GTC extensions . This is fairly the way OpenGL features are developed through extensions . <p> 3.7 . Would it be possible to change GLM to do glVertex3fv ( glm : : vec3(0) ) ? <p> It 's possible to implement such thing in C++ with the implementation of the appropriate cast operator . In this example it 's likely because it would result as a transparent cast . However , most of the time , it 's really unlikely resulting of build with no error and programs running with unexpected behaviors . <p> GLMGTXtypeptr extension provide a safe solution : <p> glm : : vec4 v(0) ; <p> glm : : mat4 m(0) ; <p> glVertex3fv ( glm : : valueptr(v) ) @ @ @ @ @ @ @ @ @ @ <p> Another solution inspired by STL : <p> glm : : vec4 v(0) ; <p> glm : : mat4 m(0) ; <p> glVertex3fv(&amp;v0) ; <p> glLoadMatrixfv(&amp;m00) ; <p> 3.8 . Where can I ask my questions ? <p> A good place is the OpenGL Toolkits forum on OpenGL.org : LONG ... <p> The Doxygen generated documentation includes a complete list of all extensions available . Explore this documentation to get a complete view of all GLM capabilities ! http : **32;695;TOOLONG 
@@100664232 @4864232/ <p> Splits x into a floating-point significand in the range 0.5 , 1.0 ) and an integral exponent of two , such that : x = significand * exp ( 2 , exponent ) The significand is returned by the function and the exponent is returned in the parameter exp . <p> Builds a floating-point number from x and the corresponding integral exponent of two in exp , returning : significand * exp ( 2 , exponent ) If this product is too large to be represented in the floating-point type , the result is undefined . <p> Returns a value equal to the nearest integer that is less then or equal to x . <p> ( From GLSL 1.30.08 specification , section 8.3 ) <p> genType glm : : core : : function : : common : : fma <p> ( 45962 @qwx905962 <p> a , 45962 @qwx905962 <p> b , 45962 @qwx905962 <p> c <p> ) <p> Computes and returns a * b + c . <p> ( From GLSL 4.00.08 specification , section 8.3 ) <p> genType glm : : core : : function : : @ @ @ @ @ @ @ @ @ @ <p> ) <p> Return x - floor(x) . <p> ( From GLSL 1.30.08 specification , section 8.3 ) <p> genType glm : : core : : function : : common : : frexp <p> ( 45962 @qwx905962 <p> x , <p> genIType &amp; <p> exp <p> ) <p> Splits x into a floating-point significand in the range 0.5 , 1.0 ) and an integral exponent of two , such that : x = significand * exp ( 2 , exponent ) The significand is returned by the function and the exponent is returned in the parameter exp . <p> For a floating-point value of zero , the significant and exponent are both zero . For a floating-point value that is an infinity or is not a number , the results are undefined . ( From GLSL 4.00.08 specification , section 8.3 ) <p> genType glm : : core : : function : : common : : intBitsToFloat <p> ( <p> genIUType const &amp; <p> value <p> ) <p> Returns a floating-point value corresponding to a signed or unsigned integer encoding of a floating-point value . <p> If an inf or @ @ @ @ @ @ @ @ @ @ and the resulting floating point value is unspecified . Otherwise , the bit-level representation is preserved . ( From GLSL 4.00.08 specification , section 8.3 ) <p> genType : : booltype glm : : core : : function : : common : : isinf <p> ( 45962 @qwx905962 <p> x <p> ) <p> Returns true if x holds a positive infinity or negative infinity representation in the underlying implementation 's set of floating point representations . <p> Builds a floating-point number from x and the corresponding integral exponent of two in exp , returning : significand * exp ( 2 , exponent ) If this product is too large to be represented in the floating-point type , the result is undefined . <p> ( From GLSL 4.00.08 specification , section 8.3 ) <p> genType glm : : core : : function : : common : : max <p> ( 45962 @qwx905962 <p> x , 45962 @qwx905962 <p> y <p> ) <p> Returns y if x &lt; y ; otherwise , it returns x . <p> ( From GLSL 1.30.08 specification , section 8.3 ) <p> genType glm : : core @ @ @ @ @ @ @ @ @ @ ( 45962 @qwx905962 <p> x , 45962 @qwx905962 <p> y <p> ) <p> Returns y if y &lt; x ; otherwise , it returns x . <p> ( From GLSL 1.30.08 specification , section 8.3 ) <p> genTypeT glm : : core : : function : : common : : mix <p> ( <p> genTypeT const &amp; <p> x , <p> genTypeT const &amp; <p> y , <p> genTypeU const &amp; <p> a <p> ) <p> Returns : <p> If genTypeU is a floating scalar or vector : Returns x * ( 1.0 - a ) + y * a , i.e. , the linear blend of x and y using the floating-point value a . The value for a is not restricted to the range 0 , 1 . <p> If genTypeU is a boolean scalar or vector : Selects which vector each returned component comes from . For a component of a that is false , the corresponding component of x is returned . For a component of a that is true , the corresponding component of y is returned . Components of x and y that are @ @ @ @ @ @ @ @ @ @ and will have no effect on the results . Thus , this provides different functionality than genType mix ( genType x , genType y , genType(a) ) where a is a Boolean vector . <p> Returns the fractional part of x and sets i to the integer part ( as a whole number floating point value ) . <p> Both the return value and the output parameter will have the same sign as x . ( From GLSL 1.30.08 specification , section 8.3 ) <p> genType glm : : core : : function : : common : : round <p> ( 45962 @qwx905962 <p> x <p> ) <p> Returns a value equal to the nearest integer to x . <p> The fraction 0.5 will round in a direction chosen by the implementation , presumably the direction that is fastest . This includes the possibility that round(x) returns the same value as roundEven(x) for all values of x . ( From GLSL 1.30.08 specification , section 8.3 ) <p> genType glm : : core : : function : : common : : roundEven <p> ( 45962 @qwx905962 <p> x <p> ) @ @ @ @ @ @ @ @ @ @ x . <p> A fractional part of 0.5 will round toward the nearest even integer . ( Both 3.5 and 4.5 for x will return 4.0 . ) ( From GLSL 1.30.08 specification , section 8.3 ) 
@@100664235 @4864235/ <p> I spend my time to say it : " It 's all about bandwidth ! " A renderer ca n't be efficient without taking good care of the bandwidth and probably the first step is to use compressed textures . <p> Direct3D and OpenGL provide a lot of texture formats to make the best use of the bandwidth . However , its a bit difficult to follow what format name correspond to what kind of data . Direct3D 9 and Direct3D 10 use different and OpenGL is based on an inconsistent naming convention following more or less Direct3D conventions but not really . <p> All the GPU compressed texture formats work on 4 by 4 pixel blocks and are saved in memory as fixed size compressed blocks which make possible to arbitrary access any block of a texture . Each block has to be fetch as 1 continue memory block but each pixel can be decoded on fly . Because of the proximity of block pixels , each block makes the best usage of the GPU caches . These basic characteristics make compressed texture very convenient to implement @ @ @ @ @ @ @ @ @ @ uncompressed textures . <p> First note : I do n't really know how BC7 and BC6H format work but this is something I will explore later on . It 's quite a shame than Direct3D 11 documentation does n't describe them properly . As far as I have understood , these formats use block shape patterns to decode the block instead of interpolated values to reduce the block artefacts . BC7 is 8 bits like BC3 what are the use cases for BC7 over BC3 ? <p> On the regard of BC1 to BC5 , every formats use 2 pixels that are interpolated to generate each pixel of the block . These 2 pixels are saved as 16 bits colors ( R5G6B5 ) and the number of interpolated values can change depending on the order of the 2 pixels in the block . Typically , if pixel 0 is bigger than pixel 1 then we use the set of interpolation values with more interpolation values . <p> In the following table , the compressed formats for OpenGL textures and the equivalent format for different versions of Direct3D . <p> On @ @ @ @ @ @ @ @ @ @ still pretty unsupported . GLI still only support Direct3D 9 DDS files and formats . Obviously , the support for all the formats are really high in my development list for GLI ! My favorite texture tool , AMD The Compressonator , have n't been updated and neither the nVidia Texture Tools . The only thing I found to generate BC6H and BC7 is a code sample in the Direct3D SDK and 2 independant exporters in the nVidia Texture Tools repository for BC6H and BC7 
@@100664237 @4864237/ <p> Few months ago , I got annoy that we had some code that translate API independent enumerations to OpenGL enumerations , back and forth , with basically no consideration at what happens when we add a new enumeration value in the API independent enumerations and no consideration of how this translation would perform within the rendering loop , where performance is critical and it 's typically going to be called . Considering the high number of translations per frame , probably it starts to matter . <p> It 's pretty common to read some stipulations about how the compilers are supposed to optimize the code . On cross-compiler environments , the following charts from the article are wishing us good luck with such ideas ! The four implementation methods are described in the full article . 
@@100664239 @4864239/ <p> AMDmultidrawindirect is a functionality that Direct3D 11 programmers can be particularly jealous as it reached OpenGL 4.3 specification but this great feature is still missing in the Direct3D 11 world . Direct3D 11 and OpenGL 4.0 introduced the draw indirect functionality to submit a draw using parameters stored in a buffer object . AMDmultidrawindirect extends this feature by allowing multiple draw submissions in a single call . This approach moves a CPU loop to a GPU command processor loop , hence potentially significantly reducing the CPU overhead and the possible number of draws per frame . Unfortunately , unlike instanced draw , OpenGL does n't provide a unique identifier per draw ( let 's call it glDrawID ) for each draw ... <p> A first approach we could thought of is to use an atomic counter and increment each draw its value when glVertexID and glInstanceID are equal to 0 . Unfortunately , this idea is not working because of the GPU architecture so that OpenGL does n't provide guarantee on the order of excutions so that we ca n't be sure with this method that the first @ @ @ @ @ @ @ @ @ @ AMD hardware this behavior is almost possible but not all the time . On NVIDIA hardware atomic counter are asynchronously executed which nearly guarantee that we will never have the right identifier for a draw . <p> Fortunately , there is one method we can use using a vertex attribute with a divisor and base instance . <p> With a divisor equal to 1 , all the vertices of a draw will access to the same buffer value . Then , for each draw we use the base instance parameter as an offset to set where in the buffer we are reading the DrawID value . The base instance value act here as an indirection value which increases the execution latency but allow to set a specific value for each DrawID , providing a behavior more advanced than a simple increase of the value for each draw . This behavior allows to maximize the usage of each draws by the application . When each draw is associated with a specific mesh , for a specific frame a lot of draws will be useless for the rendering . This behavior would @ @ @ @ @ @ @ @ @ @ it is n't on both Kepler and Southern Islands architectures . By being able to assign a specific DrawID to each draw we can assign a specific mesh for each draw allowing to build the needed list of meshes for each draw . <p> Content of the DrawID buffer for three draws <p> GLsizei const DrawDataCount(3) ; <p> GLsizeiptr const DrawSize = DrawDataCount * sizeof ( glm : : uint ) ; <p> glm : : uint const DrawIDDataDrawDataCount = <p> 76 , 64 , 321 Each value is the identifier of a specific mesh . <p> ; <p> This DrawID gives an interesting functional quality to the multi draw indirect approach however adding an application specific semantic could increase the flexibility and even the change the application performance balance . This DrawID is useful because it allows indexing resources in the shader . Typically , we would like to use it to index material in the fragment shader stage . We can even imagine that multiple resources will be indexed thanks this this DrawID . Hence , we need an indirection table that per draw and this table will @ @ @ @ @ @ @ @ @ @ access each resource per draw . Unfortunately indirections imply latencies and potentially performance ... <p> A possible improvement for this DrawID is to add to itself some semantics to skip one level of indirection . Hence , we can create multiple DrawIDs using both a divisor equal to 1 and BaseInstance and call them " MaterialID " , " VertexFormatID " or whatever an OpenGL application needs . <p> A scenario with multi draw indirect is to pack multiple meshes of different objects into a single set of buffers and manually fetch each vertex for each draw so that each draw can have different vertex format . One tricky issue with this approach is that each the BaseVertex and the BaseInstance parameters are not exposed into the vertex shader stage as input variable . Using the divisor equal to 1 and BaseInstance is also an approach to expose these variables in the vertex shader stage . People used to ridiculously optimized code ( If you do VHDL you will understand me ! : p ) could even naturally pack the BaseVertex and the VertexFormat ids into a single integer by @ @ @ @ @ @ @ @ @ @ VertexFormat relying on the limitations given by **27;729;TOOLONG and **36;758;TOOLONG . <p> The divisor by 1 and BaseInstance method provides a lot of opportunities to the multi draw indirect approach . However , we can question the problem of optimal performances . Even if a single value for a vertex attribute is fetched for all the vertex invocations of a draw , there are little reasons to think that this value wo n't be fetched each time for each vertex shader invocations . Chances are that the latency and bandwidth impact will be small as we can expect a good cache reuse hoping that many vertex shader invocations will be triggered at the same time . <p> A question remains , how fast an automatically increased glDrawID would be compare to the proposed solution ? No immediate bandwidth and latency impact but this approach would require an indirection table ( uniform block ) to identify which actual resource to access which may not do a better cache reuse than the divisor . Another approach would be to add another draw parameter alongside with BaseVertex and BaseInstance where the user could @ @ @ @ @ @ @ @ @ @ could even imagine multiple of those parameters . However , what garantee us that those parameters would not have to be fetched for each vertex shader invocation ? As a result , this approach could perform equally than using vertex attribute with divisors . <p> Vertex attributes with divisor equal to one and base instance to set a specific value to this attribute . ( OpenGL 4.3 ) 
@@100664242 @4864242/ <p> With GLI 0.3.0.0 , the library adds support to DDS 10 files ( loading and saving ) including all Direct3D 11 compression formats : BC1 , BC2 , BC3 , BC4 , BC5 , BC6H and BC7 . The library still contains DDS 9 and TGA loaders . The support of BC6H and BC7 should be considered experimental as I have n't been able to double check with neither AMD nor nVidia drivers . AMD drivers does n't report support for **27;796;TOOLONG and nVidia drivers seem buggy and display a black screen . <p> The API has changed so that GLI 0.3 . X is not backward compatible with GLI 0.2 . X branch . The API better follows OpenGL convensions and introduces some sort of extension system ( like GLM ) . Its reduces the number of headers included because GLI is still a header only library which , despite being very convenient , can significantly slow down the compilation. 
@@100664250 @4864250/ <p> When targeting a large amount of platform , by coincidence OpenGL 3.2 to 4.5 , OpenGL ES 2.0 to ES 3.1+ and WebGL 1.0 and 2.0 , it takes quite some investigations to implement a feature optimally . The difference between doing this investigation and not doing it is basically shipping a buggy engine . As an example , let 's study texture swizzle and how it 's exposed in OpenGL , OpenGL ES and WebGL . <p> However , such functionnality is n't available with OpenGL ES . While , it 's not useful for OpenGL ES 3.0 that has texture swizzling support , OpenGL ES 2.0 relies on some extensions to expose this feature but it does it differently than OpenGL. <h> 3 . Texture alpha swizzling <p> In this section , we call a texture alpha , a texture we using the alpha channel ( . a , . w , . q ) in a shader . With OpenGL ES and WebGL , this can be done by creating a texture with an alpha format as shown with the following code samples . <p> @ @ @ @ @ @ @ @ @ @ and WebGL but was removed in OpenGL core profile . An alternative is to rely on texture red format and texture swizzle as shown with the following code samples . <p> Unfortunately , OpenGL 3.2 core profile does n't support either texture alpha format or texture swizzling . A possible workaround is to expend the source data to RGBA8 which consumes 4 times the memory which might be necessary to support texture alpha on MacOSX 10.7. 
@@100664251 @4864251/ <p> I am Fellini ! I send a small advertissement to the newspapers which says more or less : " federico fellini is ready to meet all those people who wish to see him ' every idiot in Rome turns up to see me , including the police . ... I may see a thousand in order to pick two , but I assimilate them all . It 's as if they were saying to me , " take a good look at us , each of us is a bit of the mosaic you are now building up Federico Fellini <p> Sometime exhibitions are so good that their designs feel like art itself . It 's exactly what I felt visiting the exhibition about Fellini ( 1920 - 1993 ) at Jeu de Paume , Federico Fellini , the artist behind the legendary La Dolce Vita or 8-+ . Movies , quotes , drawing , photographs and even slide films are used to present his inspirations but also his vision as movie writter and director . <p> It presents the history of his work through his experience of @ @ @ @ @ @ @ @ @ @ the circus , the church , miracles , the youth tastes , etc . <p> This exhibition is displayed until the 17th January 2010 for 7 euros and is one of this exhibition that tackle a fascinating topic with a fantastic display . <p> Federico Fellini portrait <p> The circus : immedially I saw it I felt ecstatic , totally committed to that noise and music , to those monstrous apparitions , to those threats of death . I saw the big top as a miracle factory where things were done that were impossible for most men . This kind of show , based on wonder and fantasy , on jokes and nonsense , and on the lack of any coldly intellectual meaning , is just the thing for me . Federico Fellini <p> Dinners : everything here belongs to the belly , becomes belly . A spectacle to be devoured with the eyes , but also the menace of all those eyes , mouths , faces and overflowing bodies , eager to swallow . Federico Fellini <p> Behind the camera : I am incapable of looking at things in @ @ @ @ @ @ @ @ @ @ I do n't give a fig for objectivity . I need to be in the thick of things . I need to know everything about everyone , to make love with everything around me . Federico Fellini <p> Count up to six , slowly and bitterly , then continues up to twenty nine , but with a hint of contempt as well . I put dialogue into the film after I made it . Federico Fellini 
@@100664254 @4864254/ <p> GLM 0.9.5 is a pretty disruptive new branch due to ideas aiming at making GLM more robust . GLM being largely used by now , the purpose of this provisional release is to ensure that it wo n't be too disruptive for the community when comes the final release . <h> Replacing half based types by packing functions <p> First , GLM 0.9.5 removes the hvec* and the hmat* types . Half floats are useful but those types are the wrong abstraction because they let use believe that half floats are native types while they are not . For example , we can perform an addition between two hvec4 but the underlying implementation will simply convert each component to float , do the addition and convert back to half . There is probably better approach to do this addition , there is just none that will be as fast as if that instruction what supported by the CPUs . As a replacement , GLM 0.9.5 provides functions to explicitly perform the conversion from float to half and half to float with the functions packHalf1x16 , unpackHalf1x16 , packHalf4x16 @ @ @ @ @ @ @ @ @ @ packHalf2x16 , unpackHalf2x16 already available in the GLM 0.9.4 core implementation . <h> Faster projects build using forward declaration <p> The problem with header only library is that they increase the compilation time of a program . One of the reason for not enabling the swizzle operators by default is that it generates a lot of code . A good strategy to avoid running in compilation time issues is to ensure that the code is n't a spaghetti plate , and relying on forward declarations . GLM 0.9.5 provides glm/fwd.hpp with a complete set of GLM types forward declarations . <p> // In a header file using GLM types <p> #include &lt;glm/fwd.hpp&gt; <p> // In a source file using GLM types <p> #include &lt;glm/glm.hpp&gt; <p> Furthermore , in previous version GLM switched from including &lt;glm/ext.hpp&gt; to include individual extensions . With GLM 0.9.5 we can use individual headers to include only the features we need . For example : &lt;glm/vec3.hpp&gt; for glm : : vec3 , &lt;glm/mat4x4.hpp&gt; for glm : : mat4 or &lt;glm/geometry.hpp&gt; for all the functions of the geometry section of the GLSL specifications . <p> #include &lt;glm/vec3.hpp&gt;// @ @ @ @ @ @ @ @ @ @ cross , glm : : normalize <p> void computeNormal ( triangle &amp; Triangle ) <p> <p> glm : : vec3 const &amp; a = Triangle.Position0 ; <p> glm : : vec3 const &amp; b = Triangle.Position1 ; <p> glm : : vec3 const &amp; c = Triangle.Position2 ; <p> Triangle.Normal = glm : : normalize ( glm : : cross ( c - a , b - a ) ) ; <p> <p> Updating my simple raytracer from GLM 0.9.4 to GLM 0.9.5 , the project can be compiled in less than half the time . <h> Redefinition of the precision qualifier <p> GLM 0.9.4 exposes GLSL precision qualifiers by using different native types . For example mediumpfloat is actually a float type and highpfloat is actually a double . <p> in GLM 0.9.5 the precision qualifier ( lowp , mediump and highp ) has been redefined and now express computation precision in term of ULPs . As a conscequence for example sizeof ( glm : : lowpvec2 ) , sizeof ( glm : : mediumpvec2 ) and sizeof ( glm : : highpvec2 ) will always return the same @ @ @ @ @ @ @ @ @ @ . For example , the implementation of inversesqrt uses fast inverse square root for lowp . <p> Changelog : <p> Added forward declarations ( glm/fwd.hpp ) for faster compilations <p> Added per feature headers <p> Minimized GLM internal dependencies <p> Improved Intel Compiler detection <p> Added bitfieldInterleave and mmbitinterleavesi128 functions <p> Added GTXscalarrelational <p> Added GTXdualquaternion <p> Added rotation function to GTXquaternion ( #22 ) <p> Added precision variation of each type <p> Added quaternion comparison functions <p> Fixed GTXmultiple for negative value <p> Removed GTXocltype extension <p> Fixed post increment and decrement operators <p> Fixed perspective with zNear == 0 ( #71 ) <p> Removed l-value swizzle operators <p> Cleaned up compiler detection code for unsupported compilers <p> Replaced C cast by C++ casts <p> Fixed . length() that should return a int and not a sizet <p> Added GLMFORCESIZETLENGTH and glm : : lengtht <p> Removed unnecessary conversions <p> Optimized packing and unpacking functions <p> Removed the normalization of the up argument of lookAt function ( #114 ) 
@@100664255 @4864255/ <p> My reading and study of the new specifications is almost done . I decided to write 3 posts about these huge releases . <p> 1 - OpenGL 3.3 review ( &lt;- here we are ! ) <p> 2 - OpenGL 4.0 review <p> 3 - OpenGL future . <h> RGB10A2 format for vertex attributes and textures . <p> I keep saying : " It 's all about bandwidth ! " A GPU is so much computional power , it need to be feed . <p> Usually , for normals and tangents attributes we use floating point data . It is a lot of precision but a big cost in memory bandwidth . **25;853;TOOLONG provide RGB10A2 format for vertex attribute . The bandwidth is reduced by 2 or 3 times and it keep a really good precision , actually higher than most normal maps . <h> Sampler object <p> Finally ! The OpenGL community has debated a lot about this feature before the release . OpenGL texture objects is a conceptual non sens which blend data and operations on a single object . It results in a lot of @ @ @ @ @ @ @ @ @ @ sampling a single image with multiple different filters and sampling multiple images with the same filter . This could be a huge benefice both in texture memory ( no data copy ) and texture filtering processing thanks to an adaptative filtering per-fragment . Why using an amazing filtering method when the fragment is in a blurred part of the image ? <p> This extension still rely on the " texture unit " semantic . Many developers ( include me ) wished to see this extension but in a form that avoid avoid texture unit . To be fair , I would say that GLARBsamplerobjects provides a simple solution for a complex problem . I ca n't be against sure approach . Moreover , this extension is the first one to use ' direct state access ' instead of ' bind to edit ' API . <p> More important feature and actually I think it 's quite a great improvement : **27;880;TOOLONG . This extension allows setting the location of the input variables inside the vertex shader and the output variables inside the fragment shader . This is actually a great @ @ @ @ @ @ @ @ @ @ GLSL . <p> This location idea is such a main feature for me . However , that 's not enough to be really a great one . I would like to see some kind of **28;909;TOOLONG to set the uniform variable locations and extend the concept for ' varying ' variables which will fix all the complaint I have against seperate shader objects ( to make each stage independent ) before promoting this extension to core ( in OpenGL 3.4 ... ) . <p> Wait a minute ? From where come this ' index ' of blend equation parameter ? I would say from GLARBblendfuncextended extension , a community request and also it seems to be a Direct3D 10 feature ( Anyone has some documentation on that ? ) . To use the second index , new values can be used in glBlendEquation and glBlendEquationSeparate : GLSRC1COLOR , GLSRC1ALPHA , GLONEMINUSSRC1COLOR , GLONEMINUSSRC1ALPHA . <h> Occlusion query refinement <p> GLARBocclusionquery2 is the one extension that 's made me laught . It 's a nice extension that adds a new occlusion query : GLANYSAMPLESPASSED . The difference with GLSAMPLESPASSED ? GLSAMPLESPASSED @ @ @ @ @ @ @ @ @ @ boolean value that returns not null is any sample pass . Just like the super old GLHPocclusiontest extension behave ! An example in this extension shows some conditional rendering using GLANYSAMPLESPASSED without using the OpenGL conditional rendering funtions ... <p> Ok , this extension is a why not ... but I do n't think this extension improves anything . It 's nice and will of course work as well as GLSAMPLESPASSED with conditional rendering and maybe slighty faster . <h> Promoted extensions to OpenGL core specification <p> Texture swizzle provides some new texture sampler states to swizzle the texture components which provides a great freedom to interpret texture format . <p> Instanced arrays provides an alternative to the current OpenGL instancing techniques . We can already use uniform buffer and texture buffer to store the per instance data , GLARBintancedarrays proposed to use array buffers for per instance data . Using the function glVertexAttribDivisor for each per-instance array buffer , we specify that the draw call must use the first attribute for N vertices where N should be the count of instances vertices . This extension allows to draw multiples @ @ @ @ @ @ @ @ @ @ the same number of vertices . Using attributes for instance data is likely to avoid the latency of a texture buffer fetch but might fill up the attribute data flow if the size of per instance data is quite large . Probably the fastest instancing method for small per instance data rendering and huge number of instance . <p> Instanced arrays is an extension that came along with OpenGL 3.0 release without being promoted to core until now . This extension have been widely supported by ATI but lacks on nVidia drivers , being part of the core specification will hopefully brings this feature on nVidia hardware . <p> Finally , GLARBtimerquery usse the query object to request the time in nanosecond spend by OpenGL calls without stalling the graphics pipeline . A great extension for optimisations and maybe for dynamically adjusting the quality level to keep a good enough frame rate . <h> GLSL #include directive extension <p> **27;939;TOOLONG is an extension that provides an #include directive to GLSL but it has n't been promoted to OpenGL 3.3 specifications . GLSL 3.30 specification shows that initially , this extension @ @ @ @ @ @ @ @ @ @ <p> The goal of this #include directive is to reuse the same shader text in multiple shader across multiple contexts . The way **27;968;TOOLONG allows this , it introduces ' named strings ' to create some kind of paths in the GLSL compiler space that contains the shader texts . These name strings are created and deleted by glNamedStringARB and glDeleteNamedStringARB . From these name strings , the shader text can be compiled with the function **25;997;TOOLONG of glCompileShader . <p> This extension is an interesting step on the topic of GLSL build management . Developpers are asking for improvements on that side , #include but also shader binaries ( blobs ) . I 'm not completely convinced by this extension . It might require just few improvements . Direct loading from OS filesystem have been considered but involved portability issues . <h> Until the next series post <p> And this is absolutely all for OpenGL 3.3 ? Yes , it 's not so much ! The others extensions are weither Direct3D 10.1 and Direct3D 11 hardware extensions . OpenGL 3.3 is a small update of OpenGL 3.2 which provides @ @ @ @ @ @ @ @ @ @ expect an OpenGL 3.4 release because some subsets of OpenGL 4.0 features seem to be perfectly compatible with OpenGL 3. x hardware . Moreover , GLSL 3.3 and GLSL 4.0 suffer of imcompabilities independant from the hardware . 
@@100664258 @4864258/ <h> Is OpenGL faster than Direct3D ? <p> Last summer we had a quite stunning news coming from Valve saying that Left 4 Dead 2 is almost 20% faster on Linux than on Windows . Quickly this news has been interpreted by " OpenGL is faster than DirectX " . <p> I really ca n't believe this claim and I do n't believe the days where this will happen are near . Direct3D mainly has to support an ecosystem mades of games which is very restricted context . Furthermore , we can expect that these programmers are relatively good or at least better than the average OpenGL programmer who sometime use OpenGL to display something but with no care at all about how efficient is the code because rendering is not the purpose of the program . <p> Supporting these inefficient programs efficiently results in slower OpenGL implementations which ca n't just focus on making fast code running faster . Afterall , optimization is about making slow code run faster . Making these optimizations result in making the " fast path " go slower . If we really want @ @ @ @ @ @ @ @ @ @ write better OpenGL programs . This is one way to explain why the OpenGL core profile has been created but considering the low adoption of the core profile , I guess the OpenGL ecosystem does n't care too much about writing fast OpenGL code . Then the only real Core Profile implementation is Apple OpenGL 3.2 implementation , others are just compatibility profile with extra error checking . How could we expect better performance ? The chicken and the egg ... <p> The case of Left 4 Dead 2 is interesting because it was a major title but this game is built on an old engine design for Direct3D 9 . Chances are that IVHs are more interested in optimizing Direct3D 11 implementations but also Direct3D 11 reflects better how today 's hardware works . The release of Unigine Heaven 4 and Unigine Valley 1 is another opportunity to evalute the performance difference between OpenGL and Direct3D especially considering that the engine is designed for Direct3D 11 hardware and support Direct3D 9 and OpenGL 4 . We can still argue that Unigine is using OpenGL 4.0 which remain a significant @ @ @ @ @ @ @ @ @ @ but this is the best we curently have . <p> In these charts we do n't care about the absolute level of performance , we only consider the relative level of performance , arbitrary based on the results given using the Direct3D9 version of Unigine engine . <p> Generally speaking , the Direct3D 11 version is faster for every vendors , especially on Heaven benchmark . Considering that Heaven has been around for a while , this difference might only be due to IHVs drivers optimizations . The OpenGL drivers seem to be particularly optimized for Heaven on Intel and NVIDIA implementations . On Heaven , the OpenGL renderer performs better than the Direct3D 9 renderer but not on Valley . I can personally expect that no vendor will care too much about optimizing the Direct3D 9 renderer of these benchmarks <p> NVIDIA OpenGL implementation performs quite badly on Valley , being about 33.7% slower than the Direct3D 11 implementation . If we assume that the performance drop we see on Valley is not present on Heaven is due to drivers optimizations by NVIDIA , it means that the implementation @ @ @ @ @ @ @ @ @ @ NVIDIA wo n't care about our program performances and we will be stuck with very bad performances . <p> The minimum FPS is probably the most important number . If this number is too low , the user experience will be jaepodized . <p> Here , the shiny Direct3D 11 performances fade a little has the minimum framerate is lower on Direct3D 11 than Direct3D 9 . On NVIDIA is seem that there is a specific performance bug on Direct3D 11 drivers . <p> Sadly the OpenGL implementations are again not performing well , especially on Valley where AMD and NVIDIA OpenGL drivers are 22% slower than the Direct3D 9 drivers . <p> Intel implementation seems to be the most balance here . <p> The maximum FPS does n't matter much except that it 's better when it is as close as possible to the average FPS . Having huge difference is just a waste of performance that bias the average FPS making it looks better without giving the user experience that should come with it . <h> Unigine at low resolution and quality , more CPU limited <p> Now @ @ @ @ @ @ @ @ @ @ resolution hoping that the CPU becomes the bottleneck to see how the implementation behaves . <p> Looking at these results is seems that the level of performance of Intel drivers is very stable across APIs . It is possible that the HD4000 is simply too slow for these benchmarks for not hitting a specific GPU bottleneck . Our maybe the drivers are very optimise but I have a doubt about that . Considering optimizations of HD4000 drivers , picture the dream : A driver written for a Intel HD4000 can assume that the CPU will be an Ivy Bridge which means that the drivers can use AVX2 intrincis code or compile with AVX2 optimization enable . ? ? <p> The most striking results is that NVIDIA OpenGL implementation turns out to be particularly slow but this is not really a surprized . NVIDIA OpenGL implementation is about 25% and 32% slower than Direct3D 9 implementation , 30% and 33% slower than Direct3D 11 implementation on respectively Valley and Heaven . NVIDIA implementation is supposed to be the most robust which means that it is also probably the one which has @ @ @ @ @ @ @ @ @ @ strange behaviours . It is very likely that NVIDIA implementation is the one doing the most work behind our back which affects our nicely crafted code . <p> AMD OpenGL implementation is about 7% and 9% slower than Direct3D 9 implementation , 8% and 13% slower than Direct3D 11 implementation on respectively Valley and Heaven . <p> For all ISVs , Direct3D 9 or Direct3D 11 makes very little differences , when it comes to CPU usage different API design does n't seem to matter too much how maybe their design is too similar . <p> Here Intel performs best but actually all vendors performs very badly . We see that keeping a stable framerate with OpenGL is really hard . A possible explanation for that is OpenGL memory model which prevent OpenGL programmers and applications to control memory transactions . With OpenGL , we only provide " hints " hoping that the drivers will interpret them appropriately and do the transfers when it 's the most wise to do them . Good luck with that ! My first request for OpenGL remains Direct State Access , 4 years after @ @ @ @ @ @ @ @ @ @ new memory model where the application , which is the only one to know what to do with the memory , will be able to manage itself the memory ( allocation , transfer , access ) . Then , my hypothesis for this performance issue might be just wrong but what close to sure is that this issue conscerns every vendors so this is an OpenGL design issue , not a vendor specific issue . <p> Speaking of vendor specific issues , Intel seems to have a performance bug on its Direct3D 11 drivers . <h> Conclusion on performance <p> Building a conclusion without access to the code is quite challenging so I really do n't want any of this post being seen as truth but instead as axis of thoughts . There are some different behaviours across vendors which makes me believe that Heaven is particularly optimized by the hardware vendors but not Valley . It is also possible that others factors are involved in these differences but I have n't seen them . For example , I can imagine that all the assets in Heaven can be store @ @ @ @ @ @ @ @ @ @ any data streaming during the program execusion . In Valley , the terrain is pretty large its geometry rendering is performed using a CPU based CLOD method which let me believe that there is a significant amount of data streaming . <p> Hence , either because the OpenGL implementations are generally slow or because streaming assets is slower with OpenGL , rendering with OpenGL is significantly slower than rendering with Direct3D 11 even with nicely crafted code like I expect Unigine to be . However , it appears that Intel OpenGL implementation is the one performing best or should I say the less badly . <p> When reducing resolution and quality , we see that NVIDIA OpenGL implementation seems to be the one that suffers the most of CPU overhead . NVIDIA has the reputation to provide the most robust implementation which I guess implies that they are making more work on the CPU side to make sure that applications are not using OpenGL the " funny " way . <p> Intel comes as a good surprized when it comes to performance . Obviously , the overall performance is not @ @ @ @ @ @ @ @ @ @ but the performance differences with Direct3D 11 and OpenGL implementation is roughly 10% for Intel against about 20% for AMD and 30% for NVIDIA. 
@@100664261 @4864261/ <p> I prefer static language typing for many of the same reasons I prefer static linking -- find as many things as possible before execution . John Carmack <p> It 's always a pleasure to quote our heroes expecially when it 's so true ! Across the years , I became an addict of asserts and static asserts because it allows to find as many bugs as possible as early as possible which is particularly time saving . <p> I use a lot of indirection tables for a lot of different cases where from a value A , I want a value B. An indirection table is almost as fast as it can get and I think it should be considered before any other strategy . <p> A code is alive and one of the main problem with indirection table is to be sure that the size of the table match the number of input values along its life . If the input number of input value changes , the table size must match ! <p> Unfortunatly , when with create an array , C++ does n't require that @ @ @ @ @ @ @ @ @ @ <p> A convenient wait to handle this problem is to make sure that when the number of input value changes , we get an error message when we build the code : " find as many things as possible before execution " . <p> My solution is to use a static assert and an array of the size of element is countains . The static assert compare the number of element of the input format and the actual count of elements of the array . <p> With the upcoming C++0x , staticassert are nativement supported within the language and allows to customize the error message . <p> staticassert with C++0x : <p> staticassert ( <p> sizeof(Cast) / sizeof(GLenum) == FORMATMAX , <p> " Indirection table and enum size mismatch " ) ; <p> One could ask : Why not a direct mapping , giving for example the value **27;1024;TOOLONG to DXT1 ? A direct mapping it even more efficient but I think that an indirection table provides a way to index something else directly with the format value . For example , I want to know about the block size @ @ @ @ @ @ @ @ @ @ API independant because actually I might simply want to get the Direct3D value of these formats too . 
@@100664265 @4864265/ <p> GLM 0.9.3.0 is finally released . Since the branch 0.9.2 , the test bench and the Doxygen API documentation has been expended significantly leading to an even more reliable implementation and hopefully an even smoother development experience . <p> For the feature set , the GLSL noise functions are added , based on the implementation of webgl-noise . Some users might prefer the promoted GLMGTCnoise extension also based on webgl-noise but with a different interface and three noise methods : Perlin noise , periodic noise and simplex noise . <p> 2D simplex noise with GLMGTCnoise <p> Additionally , the random number generation functions ( GLMGTCrandom ) which provides various interesting distributions as illustrated below . Also reaching GLM tool box , the new experimental extension GLMGTXconstants provides a set of constants . <p> Spherical random distribution with GLMGTCrandom <p> Finally , swizzle operators are a challenging task to implement but thanks to the effort of many contributors , GLM 0.9.3.0 provides something interesting , but admittably not perfect . The new implementation is a great improvement considering the incompatibilities with some external libraries in GLM 0.9.2.7 . GLM @ @ @ @ @ @ @ @ @ @ and one for C++ 11 compilers providing an implemetnation closer to what GLSL does . Indeed the C++ 98 implementation is compatible with C++ 11 compilers . <p> Implementation for C++ 98 compilers : <p> // To declare before including glm.hpp , to use the swizzle operators <p> #define GLMSWIZZLE <p> #include &lt;glm/glm.hpp&gt; <p> void examplecpp98() <p> <p> glm : : vec4 a = glm : : vec4 ( 2 , 0 , 0 , 0 ) ; <p> glm : : vec4 b = glm : : vec4 ( 0 , 2 , 0 , 0 ) ; <p> glm : : vec3 c = vec4 ( ( a.zyx() + b.xyz() ) . xyz() * 0.5f , 1.0f ) ; <p> glm : : vec2 d = glm : : normalize ( glm : : vec2 ( c.yz ( ) ) ) ; <p> a.xyzw() = d.xyxy() ; <p> <p> Implementation for C++ 11 compilers : <p> // To declare before including glm.hpp , to use the swizzle operators <p> #define GLMSWIZZLE <p> #include &lt;glm/glm.hpp&gt; <p> void examplecpp11() <p> <p> glm : : vec4 a = glm : : @ @ @ @ @ @ @ @ @ @ ; <p> glm : : vec4 b = glm : : vec4 ( 0 , 2 , 0 , 0 ) ; <p> glm : : vec4 c = glm : : vec4 ( ( a.zyx() + b.xyz() ) . xyz * 0.5f , 1.0f ) ; <p> // Before being pasted to a function , a swizzle operator needs to be cast into 
@@100664266 @4864266/ <h> A C++ mathematics library for graphics programming <p> This library provides classes and functions designed and implemented following as strictly as possible the GLSL conventions and functionalities so that when a programmer knows GLSL , he knows GLM as well , making it really easy to use . <p> GLM ensures interoperability with third party libraries , SDKs and OpenGL ; replacing advantageously the deprecated matrix functions . It is a good candidate for software rendering ( Raytracing / Rasterisation ) , image processing , physic simulations and any context that requires a simple and convenient mathematics library . <p> It is a platform independent library with no dependence to external libraries even OpenGL . GLM is written in C++98 but can take advantage of C++11 when available . It supports the following compilers : 
@@100664267 @4864267/ <p> The OpenGL Samples Pack is a collection of OpenGL samples based on the OpenGL " core profile " specifications . <p> The project aims to promote the new OpenGL features making easier version transitions for OpenGL programmers with a complementary documentation for the OpenGL specification . Despite the fact that the OpenGL Samples Pack provides as simple ( and dumb ) as possible samples , it 's not a tutorial for beginner but a project for programmers already familiar with OpenGL . The OpenGL Samples Pack is also a good OpenGL drivers feature test . <p> These samples use FreeGLUT to create window and an OpenGL context , GLEW to load OpenGL implementations , GLM as math library and to replace OpenGL fixed pipeline functions and GLI to load images . 
@@100664269 @4864269/ <p> Through the years OpenGL has seen three different methods to generate mipmaps . Now days mipmaps are absolutely common and should be used it most of the cases , even bi-linear filtering because it provides both higher performance and higher visual quality for just 1/3 of image memory cost . <p> The first method is available since OpenGL 1.1 and used to be gluBuild2DMipmaps . It generates mipmaps on the CPU side and automatically calls glTexImage2D for each level just like if the programmer was generating them himself or loading a S3TC texture . A good feature at that time was the capability of gluBuild2DMipmaps to use NPOT textures and convert them to power of two ( POT ) mipmaps . Until OpenGL 2.0 , graphics card did n't had POT 2D textures support beside rectangular textures ... <p> gluBuild2DMipmaps is the solution for convenience but is n't efficient and out dated feature wise . POT can be useful but ca n't be used anymore and mipmaps generation on FrameBuffer Object is really complicated and inefficient . It would involve copying the texture data from the graphics memory @ @ @ @ @ @ @ @ @ @ graphics memory ... I do n't like so much this method but I must admit that it is a really good method for some compatibilities issues with old hardware or OpenGL implementation that does n't support NPOT textures or does n't provide other mipmaps generation method . Moreover , at texture loading , this method feats well in a compatibility code path . <p> OpenGL 1.4 brings the second method with the extention GLSGISgeneratemipmap . This method is " hardware accelerated " ; the OpenGL API is simple but completely weard because based on a state change using glTexParameter* . <p> glTexParameteri ( Target , GLGENERATEMIPMAP , GLTRUE ) ; <p> A state change for an operation ... sound awkward ? It is ! This call will NOT generate any mipmap . It only says that when a modification to the base level mipmap is done , the lower mipmaps of the base level mipmap shoud be generated . For example , when loading a texture , it means that this previous call should be done before glTexImage2D . <p> GLGENERATEMIPMAP does n't provide a fine control of when the @ @ @ @ @ @ @ @ @ @ , is disable GLGENERATEMIPMAP , update several parts of the texture and enable it just before the last update ... awkward . <p> This function does actually two things which is maybe the only issue with it : It allocates the mipmaps memory and generate the mipmaps . This is very important to notice for framebuffer object texture mipmaps generation because it might reduce render to texture efficiency or simply crash depending if you are using nVidia or ATI OpenGL implementation . <p> On the software design point of view , glGenerateMipmap will make programmers happy as generating mipmaps with it is completely independent from texture modifications . <p> " Hardware acceleration " . <p> Mipmaps generation of Framebuffer Object textures . <p> A fine control of when mipmaps are generated . <p> A great API to use within the OpenGL program . <p> Finally , OpenGL provides the function call **27;1053;TOOLONG , Hint ) ; where ' hint ' could be GLFASTEST , GLNICEST or GLDONTCARE to indicate the quality of filtering when generating mipmaps . <p> My personal advice would be to use glGenerateMipmap but is need to @ @ @ @ @ @ @ @ @ @ and Radeon 9*** you will have support for GLEXTframebufferobject or GLARBframebufferobject with updated drivers . S3 supports GLEXTframebufferobject and OpenGL 3 with its Chrome 430 . Apple supports glGenerateMipmap from MacOS X 10.2 and even Intel claims a support . ( I would not confirm that one without a test ! ) If you really need compatibility with old platform , gluBuild2DMipmaps is a great and solid choice . 
@@100664270 @4864270/ <p> Graphics programmers use ' batching ' as a common performance guide line . ' Batching ' is often understood as regrouping multiple draw calls into a single draw call . This is supposed to imply that a draw call is expensive and by reducing the numbers of draw call we linearly increase the performance . This vision is not correct and it does n't reflect how GPUs work . <p> Batching has a performance benefit essentially because of the regrouping of buffers and textures data into larger resources . What 's expensive about a draw call is the possible driver validation that a draw call may trigger but validation will happen only if states have changed . By regrouping resources we can avoid as many driver validations . <p> In this post , we are looking at the GPU draw call performance . We are studying the minimum number of triangles per draw call that can be submitted before we reach a different and lower performing hardware bottleneck . We are working using a tight loop ( a draw call loop without state changes ) so that we @ @ @ @ @ @ @ @ @ @ Using a tight loop , we can slice the rendering of a mesh and add fine grain culling in the draw calls loop without triggering any driver work . As usual with culling , we are improving the GPU efficiency by avoiding GPU overhead of not visible triangles . <h> Minimum triangle count per draw call per graphics card <p> Identify the minimum number of triangle per draw per GPU . X : Number of triangles per draw call . Y : Relative rendering time to 1024 per draw case . <p> It is very important not to jump too quickly into conclusions with the previous graph . We should not compare the lines against each others as the given results are relative to each card . <p> First , the minimum number of triangles per draw on NVIDIA GPU is 16 triangles per draw since Fermi ( GTX 470 ) and it was 8 triangles per draw on GeForce 8 . Second on Intel , reducing the minimum number of triangles per draw start to have an impact from lower than 256 triangles per draw . However , the @ @ @ @ @ @ @ @ @ @ on Ivy Bridge ( HD 4000 ) and 16 triangles per draw on Haswell ( HD 4600 ) . On AMD , at first it appears to be a little more random : 256 triangles per draw is a good number to keep in the back of the head but on HD 7750 we can go as far as 64 triangles per draw . On a HD 4550 , it 's 16 triangles per draw . <p> To make sure that we are not CPU bound , I made an experiment with the HD 4000 , the R7 260X and the GTX 750 on an Ivy Bridge 3770K running at 2.8 GHz and 3.8 GHz . On both cases , I had the same performance results . In these tests , we are GPU bound somewhere . <p> Next we are having a closer look at the results using the absolute numbers per vendor as we can expect some correlation between GPU generations per vendor . <h> AMD architectures behavior against small triangle count per draw call <p> Triangles per draw per AMD GPU absolute performance . X : Number @ @ @ @ @ @ @ @ @ @ time to 1024 per draw case in s . <p> First , either AMD made significant hardware changes between the Radeon HD 4000 series to the Radeon HD 5000 series or we are observing a drivers bug . Either way , the effective draw call performance of the Radeon HD 4000 series is particularly bad even compared with the older GeForce 8 series . <p> The results between the Radeon HD 7750 and the Radeon R7 260X are particularly interesting . They follow nearly the same curve except that the R7 260X is faster . First , it can be partially explained by the fact that the HD 7750 is clocked at 800 MHz and the R7 260X is clocked at 1100 MHz which is a 137% relative different in frequency . Interestingly , this performance difference is the same difference we observe between the two chips at 32 and 64 triangles per draw . Then , between 16 to 2 triangles per draw , the performance gap is reducing which either means that we are under-utilizing a parallelized hardware block which might be the same or a different one @ @ @ @ @ @ @ @ @ @ the range between 128 to 1024 shows a nearly constant performance difference of 265% between the cards that is twice 137% . This can be explained by an architecture difference : The Radeon HD 7750 ( S.I . Verde ) produces 1 triangle per clock where the Radeon R7 260X ( C.I . Bonaire ) produces 2 triangles per clock . <p> We can conclude that on Bonaire , Pitcain and Tahiti , chips that all supports 2 triangles per clock , we can benefit of the higher primitive rate only if we submit more triangles per draw . Hawaii supports 4 triangles per clock but it 's a V.I . chip so hopefully AMD fixed that behavior in the hardware design . Unfortunately , I do n't have access to a Hawaii chip . <p> AMD has significantly improved the primitive rate on its GPUs , however they have n't changed sibling blocks which results in pretty bad triangles per draw performance compared with other desktop vendors . <p> We can reach the primitive rate on AMD architectures from 256 triangles per draw call as a worse case . @ @ @ @ @ @ @ @ @ @ call <p> Triangles per draw per NVIDIA GPU absolute performance . X : Number of triangles per draw call . Y : Absolute rendering time to 1024 per draw case in s . <p> When it comes to draw call performance , NVIDIA GPUs are very pleasing . 16 triangles per draw is just fine . On old GeForce 8 architecture , 8 triangles per draw is fine too but this might only be because the primitive rate was a lot lower than on current hardware . Just like for AMD GPUs , we observe the convergence of performance between GPUs when the triangles per draw call count is getting too small . <p> The performance from 16 to 1024 triangles per draw can be explained by the primitive rate performance of each GPU : 4 triangles per cycle on the GTX 680 and 1.67 triangles per cycle on the GTX 750 . I have n't find a source for it , however it seems that the GeForce GTX 470 supports 2 triangles per cycle . It looks like the GeForce 8 was capable of less than a triangle per @ @ @ @ @ @ @ @ @ @ 8800 GT . <p> We can reach the primitive rate on NVIDIA architectures from 16 triangles per draw call on all GPUs . <h> Intel architectures behavior against small triangle count per draw call <p> Triangles per draw per Intel GPU absolute performance . X : Number of triangles per draw call . Y : Absolute rendering time to 1024 per draw case in s . <p> Intel GPUs primitive rate performance are pretty low despite Ivy Bridge being clocked at 1150 MHz and Haswell being clocked at 1250 MHz . It looks like that Haswell primitive rate is lower than Ivy Bridge so that I expect that the primitive rates for Ivy Bridge and Haswell is respectively 0.5 and 0.33 . <p> The lower primitive rate performance of Haswell compared with Ivy Bridge remains quite suspicious to me . This could be a case where the GPU is not running full speed because the performance states have n't been triggered for it . Without any feedback in the OpenGL API to detect these cases , I ca n't confirm or not this hypothesis . <p> The primitive rate is @ @ @ @ @ @ @ @ @ @ have been improved as Haswell is more efficient for low triangles counts per draw case than Ivy Bridge . <p> We can reach the primitive rate on Intel architectures from 32 triangles per draw call as a worse case . On Haswell , we can use 16 triangles per draw call . <h> Conclusions <p> Minimum triangles per draw : <p> 32 triangles per draw on Intel architectures <p> 16 triangles per draw on NVIDIA architectures <p> 256 triangles per draw on AMD architectures <p> On my previous study on small triangles , I concluded that a good target per triangle is to cover at least 8 by 8 pixels . Thanks to the results on the minimum number of triangles per draw and the minimum number of pixels per draw , we can conclude on the minimum tile size that a draw needs to cover . This could be useful to do efficient coherent screenspace rendering . <p> Minimum tile size per draw : <p> 64*32 tiles per draw on Intel architectures <p> 32*32 tiles per draw on NVIDIA architectures <p> 128*128 tiles per draw on AMD architectures <p> @ @ @ @ @ @ @ @ @ @ compare these results between GPUs . <p> Comparing the primitive rate of different GPUs using 1024 triangle per draw call . Absolute rendering time in s . <p> The source for these tests ( testdrawcall ) in available in the master branch staging of the OpenGL Samples Pack in the ' micro ' project . 
@@100664272 @4864272/ <p> First , let 's clear out something : SPIR-V has nothing to do with SPIR . It 's built from scratch with marketing thinking it was a good idea to name two products with different version values . Ohhh , I ca n't wait to battle against the confusions this idea will lead to . SPIR-V is not tied to LLVM , it 's a fully specified and self-contained specification . It can represent both graphics code and compute code for any API , including Vulcan , OpenCL , OpenGL , OpenGL ES , WebGL , etc . <p> If we trust the industry is interested in solving actual developers ' problems , it will eventually be used outside the Khronos Group , for Direct3D , Metal , consoles and beyond ! <h> A current shader cross-compilation pipeline <p> Engines will typically use a meta-HLSL or meta shading languages for their shader code . Historically , HLSL on desktop and consoles but GLSL on mobile and CAD/DCC/professional stuff because of markets differences and reality . An engine that wants to address multiple markets is quickly confronted to the @ @ @ @ @ @ @ @ @ @ to HLSL for example with game engines . Alternatively , in the off-line rendering ecosystem , we could also imagine the issue happenning between Open Shading Language and RenderMan . <p> To match the reality of the ecosystem , we have to cross compile the shading languages but this is always a painful process as illustrated in figure 1 . <p> Figure 1 : Shader compilation pipeline in Unity 5+ <p> Is this crazy and insane ? Yes . However , it addresses the reality of the market which is complex and fragmented with a lot of legacy hardware and software . If there are reasons to use an engine , this is one . This pipeline is particularly complex but still GLSL remains a second class shading language in the sense that this pipeline does n't allow to run GLSL code on Direct3D for example . <h> Issues with HLSL11 IL and D3D11 compiler <p> In this pipeline HLSL and HLSL11 IL have a central place but HLSL11 IL is not specified and it 's produced by a closed source Windows only compiler . Additionally , the D3D11 compiler @ @ @ @ @ @ @ @ @ @ was designed for legacy vec4 GPUs which implies wasting 50% of registers on vec2 and %25% on vec3 . Considering that most GPUs hide memory access latencies by launching as many wavefronts as possible , GPUs can only launch new wavefronts when there is still space available in the register file . Thus , D3D11 compiler cost a great deal of performance by wasting registers . <p> 2 HLSL11 does n't expose many hardware features ( glDrawID , pixel local storage , framebuffer fetch ) . How to express these features in HLSL when we want to use them in GLSL where they are available ? Well , it 's hard and at best possible through ugly hacks ! <p> 3 D3D11 compiler performs destructive " optimizations " on the input shaders . Maybe , these " optimizations " where ok at some points in history but they prevent GPU vendors to properly optimize the shaders because source information gets lost . From where comes from these massive performance gains from hotfix drivers on new AAA released games ? At least , part of it from shaders replacements . If @ @ @ @ @ @ @ @ @ @ binary . This process is probably ok for hardware vendors that can afford it but this process wo n't scale beyond some flagship AAA games . Hence , the rest of us , the 99% , are paying the price of a poor compiler . <h> Easier and more robust cross compilation with SPIR-V <p> SPIR-V is a fully specified , cross APIs , binary intermediate language which is easy to read , to extend or to ignore unknown instructions without destructing the source in a tool chain . <p> Figure 2 : A more desiable shader compilation pipeline to match the market reality <p> In figure 2 shows how SPIR-V could be used as a center piece of the compilation pipeline allowing multiple front-ends / languages to produce the SPIR-V IL . On platforms supporting SPIR-V , we could directly feed APIs with SPIR-V . The reality is that it will take a lot of time to transform the ecosystem and we need a solution for others platforms ( eg : shipped mobiles which will never get new drivers ) . Hence , in a market real shader compilation @ @ @ @ @ @ @ @ @ @ IL , HLSL11 IL , GLSL , Metal , etc . <p> This is a lot of work but SPIR-V provides a simpler and more robust approach to cross compile to others ILs and languages . HLSLcc is a great tool that demonstrated that cross compilation at IL level is a good direction . Another example is IL2CPP used by Unity to cross compile C# to C++ . However , HLSL11 IL has many issues , as expressed previously . With SPIR-V , the source IL is fully specified and extendable making the translation from SPIR-V to HLSL11 IL easier ( or even possible ) than HLSL11 IL to SPIR-V for example . <p> I am glade to see that some frameworks are already investigating about SPIR-V : Jogamp is a Java binding for multiple APIs including OpenGL and OpenCL . SPIR-V will allow the framework users to target independently OpenGL compute of OpenCL depending framework users needs for example . <p> Figure 3 : Dreaming of a large market adoption , wish : that 's the plan 5 years down this line <p> In figure 3 , we show @ @ @ @ @ @ @ @ @ @ massive adoption of the shading intermediate language so that we only have focus on innovations in the source language world . Great time to start a PHD on shading language ! <p> In the current ecosystem , we have to generate N shaders per source because Direct3D 9 , Direct3D 11 , OpenGL and OpenGL ES accept different syntaxes . In many cases , only the syntax sugar is different but the functionality is exactly the same from API to API . The multiplication of generated shaders has a production cost in iteration time and latency until we get the results that SPIR-V could ultimately avoid . One SPIR-V =&gt; N platforms . Ideally , only hardware feature levels would condition the generation of multiple shader outputs . <h> Building bridges between ecosystems <p> Supporting multiple source languages as first class citizen is valuable for many reasons : The user case choice the shading language he like best but also to build bridges between ecosystem : off-line rendering and real-time rendering ; Mobile and desktop ; Simulation and rendering , ; etc ! <p> Let 's take a common real-time @ @ @ @ @ @ @ @ @ @ games it might be valuable to do the skinning using a computer shader so that this work will be done on the GPU . However , some games might be GPU bound so to get better performance , it 's probably a good idea to rely on the CPU . Let 's imagine that ISPC decides to support SPIR-V just like it supports NVIDIA PTX for example . In such case an engine could create a single parallel friendly and optimized code and a game could choose either a GPU or CPU target for skinning depending on its needs . <p> Futhermore , SPIR-V allows to decouple the tools from the shipping software . There is no reason to ship a SPIR-V compiler such as ISPC or LLVM in a final game . It would increase export time and take a lot of space which is not desiable on mobile or WebGL platforms where memory is critical . <h> Better matching of the engine reality : custom shading languages ! <p> If we consider engine shading languages , most are actually meta-HLSL using custom syntax to expose built-in shaders , @ @ @ @ @ @ @ @ @ @ compilation and platform targeting or offering a more natural way to expose shaders to technical shader artists . Unity shading language is a good example of such meta-HLSL approach . <p> SPIR-V is offering us the opportunity to officialize these languages and even build the custom engine functionalities in their hearts through extended instruction sets . SPIR-V is built around a model where unrecognized blocks are just ignored and preserved , allowing interactions with SPIR-V tools unaware of these extensions . <p> Going crazier , we could imagine in the future storing OpenGL states in SPIR-V or describing rendering passes with off-line tools capable to filter redundant states changes . Many opportunities to run our imagination wild ! <h> NOT resolved by SPIR V : " Ohoho , on line shader compilation time is too long . " <p> Some game developers would say that we need an IL for better online compilation performance . I think this is misunderstanding the cause of this issue . The slow part of the GLSL compilation is n't the translation from GLSL to IHVs IL ( eg NVIDIA PTX or AMD IL ) @ @ @ @ @ @ @ @ @ @ register allocation and scheduling transformation . These operations are fully dependent of GPU architectures hence should be performed by a targeted platform hardware vendor compiler . <p> Parsing GLSL / HLSL and performing non destruction optimizations have a cost and moving these off-line will give us some online performance gains . However , following the 80-20 rule , we should expect only 20% performance gain . Compilation is a finer art than just parsing languages . <p> A lot of issues with current GLSL compilers is that all of them support invalid syntaxes but hardware vendors do n't want to fix them because it could break some applications . Removing the language syntax avoid potential errors but if tools generate invalid SPIR-V code , chances are that drivers will still do whatever it takes to garantee the IL works on their implementations . From an IHVs point of view , the worse is an application that does n't work on their platforms by run fine else where . <p> By design , SPIR-V does n't prevent IHVs to run invalid code so something else would need to be done to @ @ @ @ @ @ @ @ @ @ I think that the simplicity of SPIR-V brings us to a much better state but the larger potential SPIR-V ecosystem than GLSL makes it required to ensure SPIR-V code quality . <p> The other issue is that some shader compilers are terrible at performance trivial optimizations hence we will probably need to have a shader pipeline path to do this job . <h> Better integration of the shading language in modern graphics APIs : <p> Figure 4 : Integration of SPIR-V in an explict graphics API such as Vulkan <p> Figure 4 shows a potential integration of SPIR-V in Vulkan . Basically , with OpenGL and GLSL , all the cross compilation can be done off-line but the rest , including the actual shader compilations , needs to happen in the rendering thread . With Vulkan , we can decouple the tasks and guarantee that the rendering loop never compile shaders because of shader patching , play with shader cache or validate states . Additionally , we have a full control other the threaded shader compilations . With OpenGL , if we do n't query the compilation results right after @ @ @ @ @ @ @ @ @ @ the compilation time but this behavior is not specified : Would the drivers actually thread the compilation ? How many compilations can happen in parallel ? Vulkan is an explict API , hence we have control for each step , when , where and how these steps should be performed . <h> Time for celebrations before hard work for an ecosystem revolution ! <p> I am absolutely convinced that SPIR-V is a game changer for the industry just like WebGL before it . However , there is no magic . To become really successful , it will take a lot of efforts to ensure adoption by hardware and platform vendors but also to adapt SPIR-V to the reality of the market and build ( open source ! ) cross compilation tools placing SPIR-V at their centers . <p> The head lines might be all about iPhone6 and Samsung S6 but the reality of the market is that we are seeing a race to the bottom with lot of old ES2 GPU IP shipping everyday . Furthermore , there is already a lot of devices already shipped that will never see @ @ @ @ @ @ @ @ @ @ time . Finally , Vulkan might be great and all but realistically it will take years for the ecosystem to complete this transition . Meanwhile , there is a lot of OpenGL/ES , WebGL , Direct3D , console APIs out there . SPIR-V is solution for all of them ! <p> I am looking forward the shading language revolution that SPIR-V will lead to , one step at a time ! 
@@100664274 @4864274/ <p> This month I had my first experience with Intel OpenGL drivers since four or five years . Back then working on Intel was a nightmare , the implementation would report VBO supports but no entry point would be available ... Intel has been more and more active on the GPU side so that having an Intel GPU on a laptop sounds like a reasonnable option to me ... but is the OpenGL implementation descent ? <p> At this point , the biggest issue is that ARBdebugoutput is still not supported which makes debugging to painful for this modern age . ARBdebugoutput support is definetely my number one feature request for this implementation ! <p> For this new OpenGL status , I refactored the table using Excel to make it easier for me to maintain the status especially now that it includes Intel results . The complete and details status can be download at the end of this post . The PDF version does n't show the comments embedded in the Excel version . <p> All in all , I am quite surprized by the good quality of Intel @ @ @ @ @ @ @ @ @ @ , it sounds reasonable to consider supporting this implementation by our software and the future sounds pretty promessing . Hopefully , in 2013 Intel will provide an OpenGL 4.2 implementation which will lead to some pretty interesting programming across all vendors . 
@@100664275 @4864275/ <p> It 's with a lot of excitement that I went to the Vincent Van Gogh ( 1853 - 1890 ) exhibition displayed at the Royal Academy of Arts . Van Gogh is the painter that I call " the crazy one but crazy like it 's not cool to be " . It implies in my twisted mind a lot of admiration and curiosity for him . <p> The exhibition is subtitled " the artist and his letters " . All along the exhibition , the drawings and paintings comments are based on these letters . During his 10 years of work as a painter , he wrote almost 1000 letters , available for reading , mainly to his brother Theo ( 1857 - 1891 ) but also with other painters like Anthon van Rappard ( 1858 - 1892 ) , Paul Gauguin ( 1848 - 1903 ) , Emile Bernard ( 1868 - 1941 ) ... <p> The duty of the painter is to study nature in depth and to use all his intelligence , to put his feelings into his work so that it becomes comprehensible @ @ @ @ @ @ @ @ @ @ life from place to place he leaved which inspired him : La Hague , Paris , Arles , the asylum of saint-Paul-deMausole and Auvers . It is dedicated to his training , with many drawings . His fascinating how he had period of obsession for one topic , trying and trying again . A proper study of elements that would become a part of his painting few years later . From these topics we find landscape , perspective , peasants , figures and of course colorization . <p> For my part , I 'm wholly absorbed in the vast expanse of wheat fields against the hills , large as a sea , delicate yellow , delicate pale green , delicate purple of a ploughed and weeded piece of land , regularly speckled with the green of flowering potato plants , all under a sky with delicate blue , white , pink , violet tones . I 'm wholly in a mood of almost too much calm , in a mood to paint that . Vincent to Anna and Willemien Van Gogh <p> I leave the exhibition a bit skeptical . @ @ @ @ @ @ @ @ @ @ I find few paintings at least great but some of them where absolutely stunning . I did n't know the white roses painting and I absolutely loved it , I could have spend hours on front of it . However for the rest and the most , the magic did n't take . It got me thinking . <p> Olive Trees with the Alpilles in the Background ( 1889 ) <p> What is giving me these huge feelings from some of his paintings ? In the letters , he does n't sound like a crazy person . The paintings are not actually crazy either . I saw methodologies , a process , techniques , harmonious colors either pale or contrasted . All I saw is a fascination for the world around him , a passion for observation and a man , when executing art , at peace . <p> How I 'd like to talk to you about art again , but now we can only write to each other about it often ; find things beautiful as much as you can , most people find too little beautiful . @ @ @ @ @ @ @ @ @ @ this exhibition . It gives a good view of Van Gogh life as an artist and shows how he became a talented painter by his genius at being a colorist . I am actually quite tempted to go back just to sit and watch for hours the white roses painting which became one of my favorite painting . The perfect color combination , intense but united with an indescribable energy . ? 
@@100664278 @4864278/ <p> Thanks to the release of an OpenGL 4.2 implementation for Intel GPUs , I can finally use atomic counter to have a look at Haswell 's ' Rasterization patterns ' . <p> How to read these images ? A fragment shader is launched each pixel . An atomic counter is increased for each invocation to produce a unique color . It can me seen as a reinterprectcast so that once the pixel color reach 255 to the red channel , the next one will be 1 for the green channel . <p> Haswell 's ' rasterization pattern ' <p> The rasterization is performed on Haswell by scanning the primitives top to bottom from right to left , then left to right on coarse gain tile of 16 by 16 pixels . This is surprisingly the same behavior than Kepler . As a comparison , Southern Islands is very different . It is scanning 512*32 pixel bands in which 8 by 8 pixel tiles are scheduled in Z-order as long as the assigned CUs/ALUs are available . <p> At fine granularity , Haswell GPU is working within 16 by @ @ @ @ @ @ @ @ @ @ that might be scheduled to different Execution Units ( EU ) ( CU on Southern Islands ; SMX on Kepler ) . Hence , the wavefront/warp size is 8 invocations . As a comparison , Kepler works using 4 by 8 pixel vertical blocks ( wrap : 32 invocations ) and Southern Islands uses 8 by 8 pixel blocks ( wavefront : 64 invocations ) where the pixels are executed in Z-order . <p> Finally , Haswell seems to rely on a synchronous architecture , at coarse and fine granularity . The rendering does n't show any long delay for specific tiles . This is either because the architecture is very synchronized so it never has to wait , or it does n't delay the execution of blocks and systematically wait for atomic results . My guess is that it waits that means pretty bad atomic counter performance in my opinion . On Kepler , the architecture is capable of handling very long latencies between coarse grain blocks . With Fermi , it was more extreme , we could even expect that the first coarse tile could be completed last @ @ @ @ @ @ @ @ @ @ it might be because Southern Islands architecture has a Global Data Store ( GDS ) so that synchronization of atomic does n't have to be done down to the memory . 
@@100664280 @4864280/ 45959 @qwx905959 <p> Functions and types that the GLSL specification does n't define , but useful to have for a C++ program . <p> Experimental extensions are useful functions and types , but the development of their API and functionality is not necessarily stable . They can change substantially between versions . Backwards compatibility is not much of an issue for them . <p> Even if it 's highly unrecommended , it 's possible to include all the extensions at once by including &lt;glm/ext.hpp&gt; . Otherwise , each extension needs to be included a specific file . 
@@100664283 @4864283/ <p> One of the annoying aspect of GLM is that sometime angles are expressed in degrees and sometime angles are expressed in radians . Angles expressed in radians are features coming from GLSL where all the angles are expressed in radians and angles expressed in degrees are features coming from OpenGL compatibility profile . <p> GLM provides the define GLMFORCERADIANS to enforce all the angles to be radians . GLM 0.9.5 deprecates degrees so that in GLM 0.9.6 those will be removed . Starting with GLM 0.9.5.1 , warnings will be prompt for each instance of usage degrees . This is designed to help transitioning user code . Defining GLMFORCERADIANS will quiet these messages . 
@@100664284 @4864284/ <p> GLM provides classes and functions designed and implemented with the same naming conventions and functionalities than GLSL so that when a programmer knows GLSL , he knows GLM as well which makes it really easy to use . <p> This library works perfectly with OpenGL but it also ensures interoperability with other third party libraries and SDK . It is a good candidate for software rendering ( raytracing / rasterisation ) , image processing , physic simulations and any development context that requires a simple and convenient mathematics library . <p> GLM is written in C++98 but can take advantage of C++11 when supported by the compiler . It is a platform independent library with no dependence and it officially supports the following compilers : <p> The Doxygen-generated documentation will often state that a type or function is defined in a namespace that is a child of the glm namespace . Please ignore this ; All publicly available types and functions can be accessed as a direct children of the glm namespace. 
@@100664285 @4864285/ <p> GLM provides classes and functions designed and implemented with the same naming conventions and functionalities than GLSL so that when a programmer knows GLSL , he knows GLM as well which makes it really easy to use . <p> This library works perfectly with OpenGL but it also ensures interoperability with other third party libraries and SDK . It is a good candidate for software rendering ( raytracing / rasterisation ) , image processing , physic simulations and any development context that requires a simple and convenient mathematics library . <p> GLM is written in C++98 but can take advantage of C++11 when supported by the compiler . It is a platform independent library with no dependence and it officially supports the following compilers : <p> The Doxygen-generated documentation will often state that a type or function is defined in a namespace that is a child of the glm namespace . Please ignore this ; All publicly available types and functions can be accessed as a direct children of the glm namespace. 
@@100664286 @4864286/ <p> Well , let 's say that I got back to my favorite API : OpenGL . OpenGL 3.0 still sucks but I have some goods expectation for OpenGL 3.1 . <p> First of all some kind of improved bindable uniform seems to be on track because Blizzard study the overload of uniform and it was n't good at all . For me current bindable uniform are already really good but it seems that an improved version could be included in OpenGL 3.1 . <p> We could expect loading of GLSL program from binary as well and hopefully some removed deprecated features Wait and see . <p> Anyway , I 'm working again on OpenGL Framework ( GLF ) . This project is born in 2005 at the same time than GLM but never involved until now days . Basically , the idea is to provide tools and documentations to program with OpenGL . <p> On the documentation side , GLF includes OpenGL , GLSL and all extensions specifications . It also includes an evolution of the G-Tut-Pack , that we could maybe call version 3 . The amount @ @ @ @ @ @ @ @ @ @ find time to push it up . All samples are design in a truly programmable way and currently use OpenGL 2.1 plus extensions but will maybe move to OpenGL 3.0 before the first release . It 's quite the same to be honest . I also expect to provide D3D9 and D3D10 samples as well but probably not soon . <p> On the tools side , it includes GLM but also new libraries : OpenGL Vertex ( GLV ) for mesh generations and vertex data management ; OpenGL Image ( GLI ) for image loading and processing ; and OpenGL Overload , a C++ wrapper using all extensions and making OpenGL simple to stick to the high end programmable features . This is quite a try library , I hope to see good from it but nothing sure yet . <p> I was expecting to release GLF in 2008 but I spend too much time on the new libraries to make this happened . As a preview just check out the SVN repository and feel free to send me your feedback ! 
@@100664289 @4864289/ <p> A fractional part of 0.5 will round toward the nearest even integer . ( Both 3.5 and 4.5 for x will return 4.0 . ) ( From GLMGTXsimdvec4 extension , common function ) Returns a value equal to the nearest integer that is greater than or equal to x . ( From GLMGTXsimdvec4 extension , common function ) <p> detail : : fvec4SIMD glm : : gtx : : simdvec4 : : clamp <p> ( 45961 @qwx905961 <p> x , 45961 @qwx905961 <p> minVal , 45961 @qwx905961 <p> maxVal <p> ) <p> Returns min ( max ( x , minVal ) , maxVal ) for each component in x using the floating-point values minVal and maxVal . <p> Returns the positive square root of x Less accurate but much faster than sqrt . <p> ( From GLMGTXsimdvec4 extension , exponential function ) <p> detail : : fvec4SIMD glm : : gtx : : simdvec4 : : floor <p> ( 45961 @qwx905961 <p> x <p> ) <p> Returns a value equal to the nearest integer that is less then or equal to x . <p> ( From GLMGTXsimdvec4 extension @ @ @ @ @ @ @ @ @ @ : : gtx : : simdvec4 : : fma <p> ( 45961 @qwx905961 <p> a , 45961 @qwx905961 <p> b , 45961 @qwx905961 <p> c <p> ) <p> Returns true if x holds a NaN ( not a number ) representation in the underlying implementation 's set of floating point representations . <p> Returns false otherwise , including for implementations with no NaN representations . ( From GLMGTXsimdvec4 extension , common function ) Returns true if x holds a positive infinity or negative infinity representation in the underlying implementation 's set of floating point representations . Returns false otherwise , including for implementations with no infinity representations . ( From GLMGTXsimdvec4 extension , common function ) Returns a signed or unsigned integer value representing the encoding of a floating-point value . The floatingpoint value 's bit-level representation is preserved . ( From GLMGTXsimdvec4 extension , common function ) Returns a floating-point value corresponding to a signed or unsigned integer encoding of a floating-point value . If an inf or NaN is passed in , it will not signal , and the resulting floating point value is unspecified . Otherwise , @ @ @ @ @ @ @ @ @ @ , common function ) Computes and returns a * b + c . ( From GLMGTXsimdvec4 extension , common function ) <p> detail : : fvec4SIMD glm : : gtx : : simdvec4 : : fract <p> ( 45961 @qwx905961 <p> x <p> ) <p> Return x - floor(x) . <p> ( From GLMGTXsimdvec4 extension , common function ) <p> detail : : fvec4SIMD glm : : gtx : : simdvec4 : : inversesqrt <p> ( 45961 @qwx905961 <p> x <p> ) <p> Returns the reciprocal of the positive square root of x . <p> ( From GLMGTXsimdvec4 extension , exponential function ) <p> float glm : : gtx : : simdvec4 : : length <p> ( 45961 @qwx905961 <p> x <p> ) <p> Splits x into a floating-point significand in the range 0.5 , 1.0 ) and an integral exponent of two , such that : x = significand * exp ( 2 , exponent ) The significand is returned by the function and the exponent is returned in the parameter exp . <p> For a floating-point value of zero , the significant and exponent are both zero . @ @ @ @ @ @ @ @ @ @ not a number , the results are undefined . ( From GLMGTXsimdvec4 extension , common function ) Builds a floating-point number from x and the corresponding integral exponent of two in exp , returning : significand * exp ( 2 , exponent ) If this product is too large to be represented in the floating-point type , the result is undefined . ( From GLMGTXsimdvec4 extension , common function ) Returns the length of x , i.e. , sqrt ( x * x ) . ( From GLMGTXsimdvec4 extension , geometry functions ) <p> detail : : fvec4SIMD glm : : gtx : : simdvec4 : : length4 <p> ( 45961 @qwx905961 <p> x <p> ) <p> Returns the length of x , i.e. , sqrt ( x * x ) . <p> ( From GLMGTXsimdvec4 extension , geometry functions ) <p> detail : : fvec4SIMD glm : : gtx : : simdvec4 : : max <p> ( 45961 @qwx905961 <p> x , 45961 @qwx905961 <p> y <p> ) <p> Returns y if x &lt; y ; otherwise , it returns x . <p> ( From GLMGTXsimdvec4 extension , common @ @ @ @ @ @ @ @ @ @ gtx : : simdvec4 : : min <p> ( 45961 @qwx905961 <p> x , 45961 @qwx905961 <p> y <p> ) <p> Returns the fractional part of x and sets i to the integer part ( as a whole number floating point value ) . <p> Both the return value and the output parameter will have the same sign as x . ( From GLMGTXsimdvec4 extension , common function ) Returns y if y &lt; x ; otherwise , it returns x . ( From GLMGTXsimdvec4 extension , common function ) <p> detail : : fvec4SIMD glm : : gtx : : simdvec4 : : mix <p> ( 45961 @qwx905961 <p> x , 45961 @qwx905961 <p> y , 45961 @qwx905961 <p> a <p> ) <p> ( From GLMGTXsimdvec4 extension , common function ) <p> Returns : <p> If genTypeU is a floating scalar or vector : Returns x * ( 1.0 - a ) + y * a , i.e. , the linear blend of x and y using the floating-point value a . The value for a is not restricted to the range 0 , 1 . <p> If genTypeU @ @ @ @ @ @ @ @ @ @ each returned component comes from . For a component of a that is false , the corresponding component of x is returned . For a component of a that is true , the corresponding component of y is returned . Components of x and y that are not selected are allowed to be invalid floating point values and will have no effect on the results . Thus , this provides different functionality than genType mix ( genType x , genType y , genType(a) ) where a is a Boolean vector . <p> For the incident vector I and surface normal N , and the ratio of indices of refraction eta , return the refraction vector . <p> ( From GLMGTXsimdvec4 extension , geometry functions ) <p> detail : : fvec4SIMD glm : : gtx : : simdvec4 : : round <p> ( 45961 @qwx905961 <p> x <p> ) <p> Returns a value equal to the nearest integer to x . <p> The fraction 0.5 will round in a direction chosen by the implementation , presumably the direction that is fastest . This includes the possibility that round(x) returns the same @ @ @ @ @ @ @ @ @ @ From GLMGTXsimdvec4 extension , common function ) 
@@100664290 @4864290/ <p> It has been a while since my last compiler performance comparison ! Based on my raytracer , which is n't designed to use SSE instructions , I previously highlight that Visual C++ compiler performances were more of less stable , or are even decreasing , since Visual C++ 6 but on the contrary , GCC performances were continuously getting better . <p> For this new review I decided to take advantages of my work ( still in progress ) on GLM 0.9.1 regarding SSE optimizations . Just after " Is my optimizations keep this code working ? " , one of the questions that should always remains while wrtting optimized code is " Is the compiler capable to do a better job than me ? " This is not an easy question to answer and ultimately the performance of the optimized code need to be tested against the compiler optimizations . Nevertheless , there are some scenarios where chances are that our optimizations might be really effective : When the optimizations required a specific level of cleverness , equation simplifications , specific data ordering or mathematical rules . @ @ @ @ @ @ @ @ @ @ computation of a matrix multiplication , a matrix inverse and a matrix determinant . Large arrays of input data are generated and them entirely processed for each operations using prefetches on SSE implementations . On GCC , I used the -O3 , -msse2 and -mfpmath=sse optimizations and on Visual C++ /fp:fast , /Ox and /arch:SSE2. -mfpmath=sse and /arch:SSE2 are only used on SSE tests . The compilers tested are Visual C++ 2005 SP1 , Visual C++ 2008 SP1 , Visual C++ 2010 SP1 Beta and GCC 4.5.1 . I did a couple of test with GCC 4.4.0 and the results were pretty much the same as GCC 4.5.1 so that it did n't felt relevant to include these results . 3 different platforms have been used using 3 differents CPU architechture , Core 2 Q6600 , Core i5 660 and Phenom II X6 1055T . Without waiting any longer , here is my results : <p> With the proper level of compiler optimizations , the compilers manage to increase the program performances when using SSE instructions . What this chart does n't show , is that with the default ' @ @ @ @ @ @ @ @ @ @ slow down the performances . <p> Second point , the level of performance reached by the hand written optimizations is really relevant expect on the determinant case ... I can go review my copy ! Interestingly , Visual C++ seems to make more progresses on optimizations of hand written optimizations with intrinsics than raw C++ code . Visual C++ 2005 seems to have some issues to include hand written optimizations with the rest of the code . However , Visual C++ efficiency to generate SSE code is fairly stable across versions . <p> It 's interesting to see that the behaviour of between the Core 2 and Phenom II processors . I had a look on a Core i5 and the variations are of the same level . <p> Relative level of performance to Visual C++ 2005 and a Core 2 Q6600 ( higher is better ) <p> Relative level of performance to Visual C++ 2005 ( higher is better ) <p> First thing to notice : GCC is astonishingly efficient on FPU optimizations , 50% more efficient than Visual C++ 2010 . On hand written optimizations , GCC is @ @ @ @ @ @ @ @ @ @ but behind Visual C++ 2008 on the Phenom II CPU . On the regard of generated SSE code , the situation is reversed ! <p> GCC is now a perfectly competitive compiler on term of performances . The performance of Visual C++ are still progressing on SSE code but stable on FPU code . 
@@100664292 @4864292/ <p> After my post dedicated to the OpenGL 4.1 drivers status , I receive quite some feedbacks from AMD . My tests are based on my OpenGL Samples Pack 4.1 developed over nVidia OpenGL 4.1 drivers as it has been released since the OpenGL BOF end of July . A conscequence is that my OpenGL 4.1 samples are build upon nVidia implementation which has implied some quite bad results while running on AMD because of implementation philosophy differences . <p> Obviously , before publishing my post , I had a look at the samples trying to figure out what went wrong but when you are facing " unexpected error " messages , it 's pretty hard to make progress . This is how it begins with early drivers either from AMD or nVidia and probably anyone . Hence , Graham Sellers from AMD point me to the direction of understanding AMD implementation throught specification quotes so that I could make my sample work on AMD ... and this is where the separate programs drama began . <h> Drivers implementation philosophy <p> This is something I figure out across the @ @ @ @ @ @ @ @ @ @ differents approach regarding OpenGL . AMD tries to follow the specification by the letter in a quite pedantic maner even if the specification does n't make sense . For nVidia the approach is quite different . Some developers speak about " nVidia 's OpenGL " regarding nVidia 's implementation . nVidia approaches is less strict and more pragmatics with an implementation that does n't hesitate to relax some restrictions and even provides more features not only through extensions . Explicit varying location are implemented since nVidia OpenGL 3.3 beta drivers for example . <h> Separate programs issues <p> Regarding **26;1082;TOOLONG , I assumed some specification details that are actually not valid according to the specification . These assumptions came from good sense , OpenGL uses but also a long interest on nVidia 's separate programs . <p> **26;1110;TOOLONG is the promoted extension to core for **26;1138;TOOLONG a pretty badly designed extension relying on deprecated mecanisms and fixed functions legacy . It became quite interesting once promoted to ARB despite a name which is a total non-sense following the OpenGL tokens dictionary . " Separate shader objects " ? What does @ @ @ @ @ @ @ @ @ @ the beginning ... **27;1166;TOOLONG or **26;1195;TOOLONG would have been better to me but well . <p> One for all stage before rasterisation and one for the fragment stage . <p> One program per-stage , up to 5 with OpenGL 4 hardware class . <p> Etc . <h> Separated programs issues <h> 1 . Differents matching rules being separate and non-separate programs <p> So far with OpenGL , the GLSL linker ensures that the communication between stages was going well and even performs some interesting optimisations removing across stages unused varying variables for example . <p> With separate programs , the compiler has to make some assumptions about inputs provided by the previous stage whatever this stage actually is . For this purpose , a new section called " shader interface matching " has be written in the specification . Unfortunatly , following this section by the letter implies differents shader matching rules for separate and non-separate programs regarding explicit varying locations , which can lead to force OpenGL programmer to write different shaders for both program types ... for no good technical reasons . Let 's take a problematic example @ @ @ @ @ @ @ @ @ @ 1 ) in vec2 Texcoord0 <p> layout ( location = 0 ) in vec2 Texcoord1 <p> Fragment shader : <p> layout ( location = 0 ) in vec2 Texcoord0 <p> layout ( location = 1 ) in vec2 Texcoord1 <p> With separate programs , the location is going to be used for the shader interface matching . However with non-separate programs , the matching is performed per names which implies that the location qualifier is ignored . That does n't make any sense to do this , but this is what the specification says ... <h> 2 . Required verbose separate programs <p> Separate programs and non-separate programs evolves with different set of rules which leaves them apart while technically they are connected . There are good reasons to use non-separate programs for compiler optimizations purposes but there are also good reasons to use seperate programs for software design optimization purposes putting OpenGL programmers in this middle ground . <h> 3 . Not 100% direct state access <p> Since OpenGL 3.1 but especially OpenGL 3.3 , the specifications has made a move to direct state access ( DSA ) and @ @ @ @ @ @ @ @ @ @ a pretty DSA API ... with one exception ! The specification clearly says that a program pipeline object is actually created by binding the object ... <p> Adding verbose declarations , using different matching rules from separate programs and non-separate programs and having to use glBindProgramPipeline to create the effective pipeline object do n't make sense but this is what is written in the specification , what the ARB has agreed on . AMD and nVidia has implemented logically OpenGL 4.1 following their own philosophies : AMD has interpretted the OpenGL specification by the letter implementing some fairly stupid ideas and nVidia has interpretted the OpenGL specification in its own way , a clever way but a non-conformed way ... Well , all in all we are pretty doomed to use the full capabilities of the separate programs . <p> How everything could have been better ? I quite believe that if the ARB has put more attention hen reviewing the specification , which means probably taking more time , these issues would have been fixed as these problems are maybe " details " but quite obvious . <h> My @ @ @ @ @ @ @ @ @ @ DSA issue . As my OpenGL 4.1 samples demonstrated , this grose specification mistake has been implemented by both AMD and nVidia in a way that the program pipeline object can be used as a pure DSA object . AMD and nVidia OpenGL teams are particularly talented , it makes sense to have the implementation writted this way as it does n't make any difference when the implementations are used following strictly the specifications . Could we really rely on this work-around ? What is going to happen when Intel and Apple will provides implementations for OpenGL 4.1 ? ( within 10 years from now ... ) This could be a software bug so I think the specification as to be followed to the letter . Anyway , OpenGL 4.1 is far from being completly DSA which makes it impossible to design a fully DSA renderer . <p> On the regard of the verbose and useless glPerVertex redeclarations , it implies a compilation error on nVidia but this is something that will eventually be fixed , so that unfortunatly it has to be use following the specification . <p> Finally @ @ @ @ @ @ @ @ @ @ love the explicit varying location , as it is n't supported with non separate programs , I think it should not be used . Fortunately , the name matching is working the same way between separate programs and non-separate programs . Using varying structures allows de define a clear protocol between stages . It 's less flexible than explicit varying location but really robust . <h> Updated OpenGL 4.1 samples <p> Following this discussion , I updated the OpenGL 4.1 samples pack to report the drivers status . I really wish that nVidia implementation was what OpenGL specifies but it 's not . The goal of specification is to follow them and weihter of not the specification is good or not is another problem . Hence , for my samples I decided to follow the specification by the letter . However , I decide to add some sort of extented samples using the postfix " gtc " to illustrate the changes I would enjoy for OpenGL 4.2 and wish some are already supported . <p> White : Unsupported . <p> Blue : The sample works but it does n't follow @ @ @ @ @ @ @ @ @ @ following the OpenGL specification . <p> Orange : The sample does n't work correctly but a workaround is possible . <p> Red : The sample does't work and I have n't found any workaround . <p> Black : Really distubing problem ! <p> Drivers : <p> AMD Catalyst 10.10c ( beta ) <p> nVidia Forceware 260.93 ( beta ) <p> 410-debug-output-arb <p> AMDdebugoutput support only <p> 410-program-varying <p> glPerVertex redeclaration involves compiler errors ... <p> 410-program-separate <p> glPerVertex redeclaration involves compiler errors ... <p> 410-program-binary <p> **30;1223;TOOLONG must be set to GLTRUE or ca n't be retrived on fsome platform <p> 410-program-64 <p> glVertexAttribLPointer is null <p> **28;1255;TOOLONG <p> glPerVertex redeclaration involves compiler errors ... <p> **28;1285;TOOLONG <p> glPerVertex redeclaration involves compiler errors ... <p> 410-primitive-instanced <p> Using explicit location silently ignore throw a parsing error . <p> Unexpected warning <p> 410-fbo-layered <p> Unexpected warning <p> **29;1315;TOOLONG <p> **27;1346;TOOLONG <p> 400-texture-buffer-rgb <p> 400-sampler-gather <p> 400-sampler-fetch <p> 400-sampler-array <p> **27;1375;TOOLONG <p> Does n't support varying struct and offensive error message <p> **26;1404;TOOLONG <p> Unexpected warning / glin.length() not fully supported <p> 400-program-subroutine <p> 400-program-64 <p> **26;1432;TOOLONG <p> Unexpected warning <p> **28;1460;TOOLONG @ @ @ @ @ @ @ @ @ @ <p> 400-fbo-rtt <p> 400-fbo-multisample <p> 400-fbo-layered <p> 400-draw-indirect <p> 400-buffer-uniform <p> Unsupported uniform block array <p> 400-blend-rtt <p> 330-texture-array <p> Required glTexParameteri to setup filtering , sampler unsupported <p> 330-sampler-object <p> Sampler object does n't always oversede texture parameters <p> Following some samples that illustrates some OpenGL 4.2+ feature requests I made and taking the " gtc " post-fix . I wrote the following samples as it shows I think either specification bugs , design mistakes , lack of arrucacy or lack of perspectives like the issue discussed in this post . 
@@100664295 @4864295/ <p> With my previous post dedicated to compilers , I recieved a lot of interesting comments . First , I would like to make everyone remember that my test is one scenario and the conclusions does n't extend the scenarios illustrated in the post and I do n't attempt to generalize these bound results as a universal truth about compilers . <p> Thanks to feedbacks , I also learn that GCC 4.5 now support some link time optimizations with the -lto and -wholeprogram flags . In this new post , I would like to show the performances benefit that such options provide in GCC but also in Visual C++ . <p> Finally , I ran the test using 32 bits programs and I think it is about time to switch to 64 bits build that why we are also comparing 32 bits and 64 bits performances . <p> The test have been done with SSE2 optimizations enabled , fast math ( /fp:fast , -fast-math ) , Ox or O3 and link time optimization as specified . With these settings , we are looking for maximum performance and we are @ @ @ @ @ @ @ @ @ @ on a Phenom II X6 1055T and a Core 2 Q6600 running Windows 7 64 . <p> The tests are based on Ovt'sa , a pure C++ program , not especially effective for what it does or optimized for anything . It uses GLM and GLI but no other dependency . Despite using SSE optimizations , the program is n't especially design to take advantage of them and only run on a single thread . No disk access is included in the mesurements . <p> Like we could see in my previous post , Visual C++ 2005 and 2008 were pretty inneficient at generating SSE2 code in 32 bits leaving them behide GCC 4.5 in term of performances . Visual C++ 2010 fixed this issue and provide the same level of performance between the 32 and 64 bits build on the Phenom II but better on the Core 2 , the 64 bits build is more efficient . GCC remains behide Visual C++ 2010 in both cases , but GCC 4.5 provides more performance in 64 bits . <p> The Phenom II is giving a nice looking graph to the @ @ @ @ @ @ @ @ @ @ for each version . However , GCC provides the same level of performance with or without LTO . When LTO is disabled , Visual C++ is losing the lead on GCC . I do n't think it means that GCC would become more efficient with proper LTO optimizations , it 's probably more that optimizations are placed at different places between GCC and Visual C++ . The results on the Core 2 are surprizingly quite fuzzy with the best performance for Visual C++ 2005 and Visual C++ 2008 finishing last . <p> Optimizing a code for a platform is somewhat ok proper mesurements but generalizing optimizing for all platforms is pretty challenging . Accoring to this test , building in 64 bits mode only provide performance benefits . Link time optimizations are pretty mature in Visual C++ but seems to be disabled on GCC 4.5 with such scenario . I am looking forward GCC 4.6 where I expect more benefits for them . 
@@100664297 @4864297/ <p> For this follow up of my previous post , I decided to use my project Ovt'sa , a simple CPU raytracer , including Visual C++ , GCC but also LLVM , using GCC 4.2 front-end . <p> Ovt'sa is a pure C++ program but not especially effective for what it does . It uses GLM and GLI but no other dependency . Despite using SSE optimizations , the program is n't especially design to take advantage of them and only run on a single thread . No disk access is included in the mesurements . The tests have been done on Windows 7 64 and a Phenom II X6 1055T . On Visual C++ , I used /Ox , /fp:fast and link time build optimizations . On GCC and LLVM , I used -O3 and -fast-math but without -lto which is only available on GCC 4.5 but only provides from 0.0% to 2.5% of performance benefice . More information on link-time optimizations on a future post . <p> LLVM is becoming more and more mature and it has build itself a reputation , I was curious to how @ @ @ @ @ @ @ @ @ @ to build the code than GCC but has reached GCC level of performances . However , they both stay slower than Visual Studio which has made good performance improvements in its 2010 release . Since LLVM 2.3 , the performance has evolved with some sort of performance unstability across versions even if in the end the performance level has just slightly progress in LLVM 2.8 . LLVM 2.3 is the first version able to build Ovt'sa succesfully . <p> It 's really interesting to compare the behaviours of Intel CPUs against AMD CPUs . The Phenom II X6 seams less sensitive to the compiler version and optimization flags than Intel CPUs . On the AMD CPU , using the x87 instruction set is just slightly slower . On Intel CPUs , it can double the performance ! <p> Despite huge performance gains , GCC remains a step behind Visual Studio and its progress has only prevent LLVM to be a relevant replacement . 
@@100664298 @4864298/ <p> Few days ago , I finally had a look at my first BPTC/BC7 texture and I must say I have been really impressed by the visual quality . <p> Like DXT5 , BPTC is a 8 bit per pixel format but it does n't contain an alpha channel . Effectively , half of the bits of DXT5 are dedicated to the alpha channel only so that it fells fair to compare BPTC with DXT1 which is a RGB 4 bits per pixel format with an option for 1 alpha bit . To get a better quality , it 's possible to use the alpha channel of DXT5 to store another channel which provides 4 bit per pixel for each channel . This format is usually called DXT5 RXBG and it provides a significantly higher quality alternative to DXT1 despite a feeling of red and blue noise . <p> For the following captures , I used the RGB mode of DXT1 and generated it with The Compressonator from AMD . I generated the RGTC1 texture with the same tool , taking the red channel . From previous tests I @ @ @ @ @ @ @ @ @ @ the tool which provides the best visual quality . The BPTC texture has been generated with the Direct3D 11 SDK encoder with the CPU version of the encoder . <p> I find the result provided by BPTC absolutely stunning . This picture is actually particullary challenging which explains the ugly result provided by DXT1 : It 's blocky , smooth parts becomes stairs and noisy parts become fat pixels . On its side , BPTC remains very close to the uncompressed texture . BPTC even manage to provide more details than RGTC1 in many cases . <p> BPTC is a great texture format for visual quality so that for this property I expect to see it used in place of DXT1 and DXT5 in many cases in the future . However , the BPTC format has a main draw back : It 's slow , very slow to generate ! Chances are that all the realtime compression use cases of DXT5 will stick to this format for a while . 
@@100664299 @4864299/ <p> I had the opportunity to largely discover Gerhard Richter 's portraits two years ago . It was an highly influenciential moment for my practice of portrait photography , missing out this exhibition tour stop in London was n't an option for me . <p> The Reader , Gerhard Richter , 1994 <p> " The Reader " is a good illutration of how Gerhard Richter fades the boundary between painting and photography . In this piece , like in all of his portrait , he created his painting from a photograph which gives this in between look to his representation of modern life . <p> One of the most remarcable work exposed was " Annunciation after Titian " which is built with the same process than his portrait but based on a painting . He actually explored through multiple experiments where to set the bluriness boundary using different levels of figuration and abtraction . <p> Annunciation after Titian , Gerhard Richter , 1973 <p> Annunciation , Titian , 1973 <p> The most inspirational aspect was for me the color charts . There is a part of simplicity in just @ @ @ @ @ @ @ @ @ @ with its neighbours . Also , there is something about the distribution of the colors and the process for choosing which color belong to which case . After some experiments I did by myself , I realized that figuring out which color belong to which box is pretty challenging and random distribution a bitch . This is a rule of probability but even if a case is unlikely to happen , it might happen ! <p> 4096 Colours , Gerhard Richter , 1974 <p> I would like to finish with the experiment " Cage " composed by six pieces designed for him to explore the evolution of his mood over a long period of time . 
@@100664302 @4864302/ <p> I generally do not care much for reality , only for the painted illusion and its accompanoying problems . For this reason certain subjects are more attractive than others . In my opinion , realism 's stength lies cool and objective manner of rendition . It is a copy , not reality . It is meant to be illusory , not deceptive . The only aspect of the relationship between reality and painted illusion that interests me is the fact that reality offers up subjects for paintings . Ralph Goings <p> I am often thinking about the direction painting is taking and I have notice a growing trend for hyper-realism paintings , so real that at first we believe it 's a photograph . This desire for a photorealistic approach is nothing new , looking backward in art history , I ca n't forget the American landscape artists in the late 19 centuary which made me smile when I thought that at the same time in Europe we were filled with impressionnarism . <p> This interest raised my attention to the exhibition " Hyper Real " at the @ @ @ @ @ @ @ @ @ @ painting by Ralph Goings that shows Photo Realism in the contex of Pop art , which I think illustrated to come back of realism in the 70s . Organised in multiple themes this exhibition is commented by the words of artists of this period which allows the visitors a reach a depth understand of the motivations behind it . <p> As taking pictures were allowed and astonished by the qualities of this exhibition , I took some pictures of my favorite pieces displayed bellow . <p> Bowery Derelicts , 1969-1970 , Duane Hanson <p> Footbah Vignette , 1969 , Duane Hanson <p> New Realist painting reflects everyday life or chat we are thinking about , whatever it is , you recognize , imaginary you are confronted with . But it 's not like Pop art , it 's more reserved ; it 's just taking it with no comment . To me that wa n't enough . I wanted to comment and was critized that I was doing it for shock . For me I feel that I have to identify with those lost causes , revolutions and so forth @ @ @ @ @ @ @ @ @ @ that I think you can change it but I just want to express my feelings of dissatisfaction . Duane Hanson <p> Woman in a restaurant booth , 1961 , George Segal <p> Doantown , 1978 , Richard Estes <p> I 'm not trying to reproduce the photograph . I 'm trying to use the photograph to do the painting ... Taking the photograph is the first step . The idea occurs and is involved with the photograph . That 's the creation of it almost , and the painting is just the technique of transmitting , or finishing it up so to speak . Richard Estes <p> Fenstergitter , 1968 , Gerhard Richter <p> The detour by way of painting gives me photographs that can not be maybe by the normal technique of direct enlargements ; and these photographs can be pictures . Pictures - How an I explain it ? Stella , Ryman , Morley , Palerno , where it gets exciting for me ; where the absence of language begins . Gerhard Richter <p> Portrait Kenneth Kock , 1967 , Alex Kofz <p> My paintings and prints are @ @ @ @ @ @ @ @ @ @ They are just images without much depth . Everything is visual ; They are no stories . If it is possible to interpret stories into them , it depends on your own values . Alex Kofz <p> This exhibition turns out to be incredibly interesting and has been the once I spend the most time to explore ( 4 hours ! ) , an exhibition not to miss and running until the 13th of Febrary for 9 ( full admission ) plus an optional 3 for the audioguide which is not really necessary in my option . 
@@100664303 @4864303/ <p> Returns an angle whose tangent is y/x . The signs of x and y are used to determine what quadrant the angle is in . The range of values returned by this function is -PI , PI . Results are undefined if x and y are both 0 . <p> Returns the insertion the bits least-significant bits of insert into base . <p> The result will have bits offset , offset + bits - 1 taken from bits 0 , bits 1 of insert , and all other bits taken directly from the corresponding bits of base . If bits is zero , the result will simply be base . The result will be undefined if offset or bits is negative , or if the sum of offset and bits is greater than the number of bits used to store the operand . <p> Returns the bit number of the most significant bit in the binary representation of value . <p> For positive integers , the result will be the bit number of the most significant bit set to 1 . For negative integers , the result will @ @ @ @ @ @ @ @ @ @ to 0 . For a value of zero or negative one , -1 will be returned . <p> Splits x into a floating-point significand in the range 0.5 , 1.0 ) and an integral exponent of two , such that : x = significand * exp ( 2 , exponent ) <p> The significand is returned by the function and the exponent is returned in the parameter exp . For a floating-point value of zero , the significant and exponent are both zero . For a floating-point value that is an infinity or is not a number , the results are undefined . <p> If genTypeU is a floating scalar or vector : Returns x * ( 1.0 - a ) + y * a , i.e. , the linear blend of x and y using the floating-point value a . The value for a is not restricted to the range 0 , 1 . <p> If genTypeU is a boolean scalar or vector : Selects which vector each returned component comes from . For a component of a that is false , the corresponding component of x is returned @ @ @ @ @ @ @ @ @ @ the corresponding component of y is returned . Components of x and y that are not selected are allowed to be invalid floating point values and will have no effect on the results . Thus , this provides different functionality than genType mix ( genType x , genType y , genType(a) ) where a is a Boolean vector . <p> Returns a double-precision value obtained by packing the components of v into a 64-bit value . <p> If an IEEE 754 Inf or NaN is created , it will not signal , and the resulting floating point value is unspecified . Otherwise , the bit- level representation of v is preserved . The first vector component specifies the 32 least significant bits ; the second component specifies the 32 most significant bits . <p> The fraction 0.5 will round in a direction chosen by the implementation , presumably the direction that is fastest . This includes the possibility that round(x) returns the same value as roundEven(x) for all values of x. 
@@100664304 @4864304/ <p> GLM 0.9.5 will show warning messages at compilation each time a function taking degrees is used . <p> GLM : rotate function taking degrees as a parameter is deprecated. #define GLMFORCERADIANS before including GLM headers to remove this message . <p> If you are using a version of GLM older than GLM 0.9.5.1 , update to GLM 0.9.5.4 before transitioning to GLM 0.9.6 to get this help in that process . <p> Make sure to build and run successfully your application with GLM 0.9.5 with GLMFORCERADIANS , before transistioning to GLM 0.9.6 <p> Finally , here is a list of all the functions that could use degrees in GLM 0.9.5.4 that requires radians in GLM 0.9.6 : rotate ( matrices and quaternions ) , perspective , perspectiveFov , infinitePerspective , **26;1517;TOOLONG , roll , pitch , yaw , angle , angleAxis , polar , euclidean , rotateNormalizedAxis , rotateX , rotateY , rotateZ and orientedAngle . <h> Using GLM template types <p> There are a lot of reasons for using template types : Writing new template classes and functions or defining new types . Unfortunately , until GLM @ @ @ @ @ @ @ @ @ @ namespace indicating there are implementation details that may changed . <p> With GLM 0.9.6 , template types are accessible from the GLM namespace and guarantee to be stable onward . <h> Optimizations <p> With GLM 0.9.5 , the library started to tackle the issue of compilation time by introducing forward declarations through &lt;glm/fwd.hpp&gt; but also by providing an alternative to the monolithic &lt;glm/glm.hpp&gt; headers with &lt;glm/vec2.hpp&gt; , &lt;glm/mat3x2.hpp&gt; and &lt;glm/common.hpp&gt; , etc . <p> With GLM 0.9.6 , the library took advantage of dropping old compilers to replace preprocessor instantiation of the code by template instantiation . The issue of preprocessor instantiation ( among them ! ) is that all the code is generated even if it is never used resulting in building and compiling much bigger header files . <p> Furthermore , a lot of code optimizations have been done to provide better performance at run time by leveraging integer bitfield tricks and compiler intrinsics . The test framework has been extended to include performance tests . The total code size of the tests is now 50% of the library code which is still not enough but pretty solid @ @ @ @ @ @ @ @ @ @ a lot of old compiler versions . If you are really insisting in using an older compiler , you are welcome to keep using GLM 0.9.5. <h> 11/01/2013 - GLM 0.9.5.1 released <p> One of the annoying aspect of GLM is that sometime angles are expressed in degrees and sometime angles are expressed in radians . Angles expressed in radians are features coming from GLSL where all the angles are expressed in radians and angles expressed in degrees are features coming from OpenGL compatibility profile . <p> GLM provides the define GLMFORCERADIANS to enfore all the angles to be radians . GLM 0.9.5 deprecates degrees so that in GLM 0.9.6 those will be removed . Starting with GLM 0.9.5.1 , warnings will be prompt for each instance of usage degrees . This is designed to help transitioning user code . Defining GLMFORCERADIANS will quiet these messages . <h> 25/12/2013 - GLM 0.9.5.0 released <p> First , in previous version GLM switched from including &lt;glm/ext.hpp&gt; to include individual extensions . Just like we can still use &lt;glm/ext.hpp&gt; for global inclusion , with GLM 0.9.5 we can use individual headers to include @ @ @ @ @ @ @ @ @ @ for glm : : vec3 , &lt;glm/mat4x4.hpp&gt; for glm : : mat4 or &lt;glm/geometry.hpp&gt; for all the version of the geometry section of the GLSL specifications . <p> Futhermore , GLM has a new forward declaration header &lt;glm/fwd.hpp&gt; to help reducing dependecies to GLM code . <p> As a result and for experimentation , a simple raytracer can be compile in less than half the time with GLM 0.9.5 than GLM 0.9.4 . <p> Second , the definition of the precision qualifier ( lowp , mediump and highp ) has changed and now express computation precision in term of ULPs . As a conscequence for example sizeof ( glm : : lowpvec2 ) , sizeof ( glm : : mediumpvec2 ) and sizeof ( glm : : highpvec2 ) return the same values . However , the effective computation can be different . For example , the implementation of inversesqrt uses fast inverse square root for lowp . <p> Finally , some efforts have be put into increasing reliability with a larger coverage of assert and staticassert to give more informative compiler error messages . Also , all the half @ @ @ @ @ @ @ @ @ @ used just like any float of double types but such usage were bad usages requiring a lot of conversions from half to float and float to half , hence very slow performances . Instead , GLM 0.9.5 provides a extensive set of packing and unpacking functions ( glm/gtc/packing.hpp ) so that we have to perform arithmetics in float and when it 's done we pack it in half data . <p> For more details , see the changelog following , enjoy ! <p> Changelog : <p> Added forward declarations ( glm/fwd.hpp ) for faster compilations <p> Added per feature headers <p> Minimized GLM internal dependencies <p> Improved Intel Compiler detection <p> Added bitfieldInterleave and mmbitinterleavesi128 functions <p> Added GTXscalarrelational <p> Added GTXdualquaternion <p> Added rotation function to GTXquaternion ( #22 ) <p> Added precision variation of each type <p> Added quaternion comparison functions <p> Fixed GTXmultiple for negative value <p> Removed GTXocltype extension <p> Fixed post increment and decrement operators <p> Fixed perspective with zNear == 0 ( #71 ) <p> Removed l-value swizzle operators <p> Cleaned up compiler detection code for unsupported compilers <p> Replaced C cast by C++ @ @ @ @ @ @ @ @ @ @ and not a sizet <p> Added GLMFORCESIZETLENGTH and glm : : lengtht <p> Removed unnecessary conversions <p> Optimized packing and unpacking functions <p> Removed the normalization of the up argument of lookAt function ( #114 ) <h> 22/12/2012 - GLM 0.9.4.1 released <p> GLM 0.9.4.1 fixes various bugs and clarifies quaternion interpolations . There are now three different functions now : mix , slerp and lerp . <p> lerp performs a linear interpolation between two quaternions . This operation is only defined with interpolation factors between 0 , 1 and does n't perform the rotation at constant speed . slerp perform a spherical linear interpolation between two quaternion . It always takes the short rotation path and it is performed at constant speed for interpolation factors between -inf , +inf . This function is similar to the old shortMix function . mix is an oriented spherical linear interpolation between two quaternion . It is performed at constant speed for interpolation factors between -inf , +inf. <h> 10/05/2012 - GLM 0.9.3.3 released <p> Nearly two months since the previous release of a GLM revision gave enough time to fix few things @ @ @ @ @ @ @ @ @ @ better compatibility with Intel C++ compiler . <h> 15/03/2012 - GLM 0.9.3.2 released <h> 10/03/2012 - GLM on GitHub <p> After years of using SourceForge.net , GLM is moving to GitHub , as least for its repository . GitHub provides easy ways to clone the repository and submit pull requests which seems a definity advantage for the community contribution . It also allows to download snapshots of every branches . <h> 25/01/2012 - GLM 0.9.3.1 released <h> 09/01/2012 - GLM 0.9.3.0 released <p> GLM 0.9.3.0 is finally released . Since the branch 0.9.2 , the test bench and the Doxygen API documentation has been expended significantly leading to an even more reliable implementation and hopefully an even smoother development experience . <p> For the feature set , the GLSL noise functions are added , based on the implementation of webgl-noise . Some users might prefer the promoted GLMGTCnoise extension also based on webgl-noise but with a different interface and three noise methods : Perlin noise , periodic noise and simplex noise . <p> 2D simplex noise with GLMGTCnoise <p> Additionally , the random number generation functions ( GLMGTCrandom ) which @ @ @ @ @ @ @ @ @ @ GLM tool box , the new experimental extension GLMGTXconstants provides a set of constants . <p> Spherical random distribution with GLMGTCrandom <p> Finally , swizzle operators are a challenging task to implement but thanks to the effort of many contributors , GLM 0.9.3.0 provides something interesting , but admittably not perfect . The new implementation is a great improvement considering the incompatibilities with some external libraries in GLM 0.9.2.7 . GLM 0.9.3 provides two implemetanations , one for C++ 98 compilers and one for C++ 11 compilers providing an implemetnation closer to what GLSL does . Indeed the C++ 98 implementation is compatible with C++ 11 compilers . <p> Implementation for C++ 98 compilers : <p> // To declare before including glm.hpp , to use the swizzle operators <p> #define GLMSWIZZLE <p> #include &lt;glm/glm.hpp&gt; <p> void examplecpp98() <p> <p> glm : : vec4 a = glm : : vec4 ( 2 , 0 , 0 , 0 ) ; <p> glm : : vec4 b = glm : : vec4 ( 0 , 2 , 0 , 0 ) ; <p> glm : : vec3 c = vec4 ( ( @ @ @ @ @ @ @ @ @ @ ) ; <p> glm : : vec2 d = glm : : normalize ( glm : : vec2 ( c.yz ( ) ) ) ; <p> a.xyzw() = d.xyxy() ; <p> <p> Implementation for C++ 11 compilers : <p> // To declare before including glm.hpp , to use the swizzle operators <p> #define GLMSWIZZLE <p> #include &lt;glm/glm.hpp&gt; <p> void examplecpp11() <p> <p> glm : : vec4 a = glm : : vec4 ( 2 , 0 , 0 , 0 ) ; <p> glm : : vec4 b = glm : : vec4 ( 0 , 2 , 0 , 0 ) ; <p> glm : : vec4 c = glm : : vec4 ( ( a.zyx() + b.xyz() ) . xyz * 0.5f , 1.0f ) ; <p> // Before being pasted to a function , a swizzle operator needs to be cast into <h> 08/06/2011 - GLM 0.9.2.3 released <h> 02/06/2011 - GLM 0.9.2.2 released <p> The main improvement of this version comes from the extended number of matrix constructors so that a programmer can used different scalar types for each parameter . <p> #include &lt;glm/glm.hpp&gt; <p> // @ @ @ @ @ @ @ @ @ @ ( <p> 1 , 0.0 , 0 , <p> 0.0 , 1.0 , 0.0f , <p> 0 , 0.0 , 1.0f ) ; <p> The quaternion implementation has been updated as well , fixing the various slerp implementation flavours ( mix , shortMix and fastMix ) and providing more completeness : Added interaction with GLMGTXepsilon and missing lowpquat , mediumpquat and highpquat but also none square matrix equivalents . <p> Finally , some efforts have been put to remove warnings across all supported compilers . <h> 24/05/2011 - GLM 0.9.2.1 released <p> GLM 0.9.2.1 significantly improves compiler detection which allows CUDA to be automatically recognized when GLM is used inside a CUDA kernel . By conscequence , GLMFORCECUDA is no longer required to be declared . <p> It fixed a couple of bugs , including Visual C++ supprot when Visual C++ extensions are disabled and fixed implementations of GLMGTXvectorangle and GLMGTXrotatevector extensions . <h> 09/05/2011 - GLM 0.9.2.0 released <p> GLM 0.9.2.0 provides many exciting features which first of all is the CUDA copiler support so that GLM can be used within a CUDA kernel . This is possible only @ @ @ @ @ @ @ @ @ @ source code . <p> New experimental extensions are also available . GLMGTXnoise is based on the work by Stefan Gustavson and Ashima Arts on WebGL-noise which adds perlin and simplex noise functions in a pure computational way . If everything goes well , this extension will be promoted to GLM core as implementation of the GLSL noise functions . <p> GLMGTXulp provides functions to evaluate the number of ULPs between two floating-point values which gives a way to mesure the accuracy of a function compare to a reference function . In the future , this extension could be used to update the documentation of function and gives the level of accuracy they provide . <p> Finally , **25;1545;TOOLONG is an extension developed by Ghenadii Ursachi to extract axis and angle of a 4 by 4 matrix but also directly interpolate between two matrices . This extension works only on linear transformed matrices . <p> Last but not least : with the version 0.9.2 , GLM supports CTest to manage GLM test suite which makes tests much easier to maintain . The number of tests have significantly increase , even if @ @ @ @ @ @ @ @ @ @ is not backward compatible with GLM 0.9.1 with only one point : Quaternion SLERP interpolation ! In GLM 0.9.1 the function ' mix ' always interpolate using the short rotation path but it 's no longer the case . The function ' shortMix ' has to be called for short path interpolation. ' fastMix ' will interpolate two quaternions using a normalized linear quaternion interpolation with non-constant rotation speed . <h> 03/03/2011 - GLM 0.9.1.0 final released <p> Finally , GLM 0.9.1 branch is reaching the status of stable with GLM 0.9.1.0 . <p> From GLM 0.9.1 beta , mainly bugs has been fixed . GLM has evolved on many sides since GLM 0.9.0 : Improved documentation ( manual and doxygen ) , better test framework , simplified **26;1572;TOOLONG of GLM and new experimental SIMD API . <p> GLM 0.9.1.0 is not 100% backward compatile with GLM 0.9.0.8 but mainly advanced usages should be affected by the differencies . Have a look at the GLM manual for more information on how to use GLM 0.9.1. <h> 13/02/2011 - GLM 0.9.0.8 and GLM 0.9.1 beta released <p> The stable version , @ @ @ @ @ @ @ @ @ @ and deprecated the cross function previously used for the same purpose . Also , it clarifies that GLM is a header only library when a user try to build it . Once more , there is nothing to build . <h> 31/01/2011 - GLM 0.9.1 alpha released <p> This new version of GLM is bringing a lot of improvements and maybe too many considering the development time it has required : API exposing SIMD implementation but also some new , safe and feature complet swizzling functions and a new setup API . All this is described in the largely updated GLM manual . <p> With the new setup system , GLM detects automatically the compiler settings to adapt its implementation to the flag set at build time . It will automatically enable C++0x features , SSE optimizations and the display configuration informations at build-time . The automatic setup can be overdrive by the GLM user . <p> The SIMD API maintly focus on vec4 and mat4 implementations that are embodied by the types simdVec4 and simdMat4 . The implemention cover most of the common functions , the geometry functions and @ @ @ @ @ @ @ @ @ @ Because it is hight inefficient to access individual components of a SIMD register , the simdVec4 does n't allow it . To reflect this constraint , the simdVec4 has to be converted to vec4 first which would be effectively handle by the compiler thank to the function simdCast . Furthermore , GLM provides some specials functions like simdDot4 that returns a simdVec4 instead of a float with the duplicated dot product value in each components and ensure that no unnecessary component manipulations are performed ( typically m128 to float and float to m128 ) . This implementation can probably be improve in many ways so do n't hesitate to send me some feedbacks . <p> GLM 0.9.1 is not 100% backward compatible with GLM 0.9.0 but mostly advanced usages should be concerned by this compatibility issues . <h> 01/11/2010 - GLM 0.9.0.5 released <h> 04/10/2010 - GLM 0.9.0.4 released <p> GLM 0.9.0.4 revision mainly fixes bugs . It also contains a contribution by Arnaud Masserann , a autoexp.dat file to make GLM looks nicer in Visual Studio debugger . To take advantage of this file , edit LONG ... file @ @ @ @ @ @ @ @ @ @ GLM 0.9.0.4. <h> 21/06/2010 - GLM 0.9.0.1 released <h> 25/05/2010 - GLM 0.9.0.0 released <p> GLM 0.9.0.0 is finally available ! It brings various API changes from GLM 0.8.4 . X branch which makes it not backward compatible . GLM is now compatible with Objective C++ to be used for MacOS X and iPhone projects . <p> To continue making GLM a better library , 2 mailing lists have been created for users and developers . <h> 03/04/2010 - GLM 0.9 Beta 1 released <p> A new development version of GLM 0.9 is available . <p> This version is based on GLSL 4.0 and supports the new common and integer functions . Also a long and frequently asked feature has been implemented : inplicit conversions . However , the rules defining implicit conversions by GLSL 4.0 are quite weaked and ca n't really be apply in C++ . <p> Reaching the beta status , this new features close the feature list of GLM 0.9 . Further development releases may happen before the final release . <h> 20/02/2010 - GLM 0.9 Alpha 2 released <h> 09/02/2010 - GLM 0.9 Alpha 1 @ @ @ @ @ @ @ @ @ @ with this first alpha of GLM 0.9 . <p> This version brings a large internal redesign to improve the library reliability and optimized some parts . It removed the deprecated features and API which implies that GLM 0.9 is n't backward compatible . <p> For most users the build issues when upgrading to GLM 0.9 should be reduced especially if they follow the deprecation policy . <p> This release is still UNSTABLE and not recommanded for commertial products . <h> 16/11/2009 - GLM 0.8.4.3 released <p> This version fixed half scalars and half vectors arithmetics . This is a really slow practice that should be avoid . Half floating point value should be use only to store GPU data . GPUs have native support for half values , not x86 CPUs. <h> 21/05/2009 - GLM 0.8.3.1 released <h> 06/05/2009 - GLM 0.8.3.0 released <p> This version brings to main changed : Stable extensions and a new extension system . <p> The first stable GLM extensions are : GLMGTCdoublefloat and GLMGTChalffloat for higher and lower vectors and matrices floating point precision . GLMGTCmatrixoperation provides determinant and inverse matrix calculation . GLMGTCmatrixtransform @ @ @ @ @ @ @ @ @ @ GLMGTCmatrixprojection provides varius functions to build projection matrices . Few stable extensions yet but the number is going to grow with the next release ! <p> Both GLM 0.8.2. x extensions use method are deprecated ( but still working ) and replace by a new one . If you wnat to use GLMGTChalffloat just include " glm/gtc/halffloat.hpp " and it is going to be included in GLM namespace . <p> Finally , quite some file have been renamed , using " hpp " instead of " . h " . Old file have been deprecated but are still available so that GLM 0.8.3.0 is fully compatible with GLM 0.8.2. x. <h> 30/10/2008 - GLM 0.8.1 released <h> 23/10/2008 - GLM 0.8.0 final released <p> GLM 0.8.0 is released . This new version is now based on GLSL 1.30 specification which provided new functions and precision qualifiers . <p> Beyond this , lot of changes have been done to make GLM easier to use , easier to develop , more reliable , more conform to C++ ISO98 standard and GLSL specifications . <p> It involves that GLM 0.8. x is not @ @ @ @ @ @ @ @ @ @ application port from GLM 0.7. x to GLM 0.8. x is n't a huge work and actually for some , it wont be work at all . <p> On GLM core side , based on GLSL features , vector types ca n't be automatically cast to pointer anymore for code safety purposes . Vector constructors require a single scalar parameter of the exact number of components . <p> On GLM extension side , the mechanism to use them has changed . The old ***GTX way does n't exist anymore . Have a look on the manual for more information . <p> Have a look on the manual and the changelog for more information . Do n't forget to send your feedback and enjoy ! <h> 04/10/2008 - GLM 0.8.0 beta 2 released <p> This release mainly improves half float vectors support . By default the low precission vectors are based on float numbers not on half numbers <p> It also provides new setup options . GLMUSEONLYXYZW to disable multiple names to access to a single vector component . GLMUSEANONYMOUSUNION to allow multiple component names on half vectors with Visual C++ @ @ @ @ @ @ @ @ @ @ done too . Final release is coming ... <h> 26/09/2008 - GLM 0.8.0 beta 1 released <p> GLM have been updated to support GLSL 1.30 . API documentation had significant improvements to make easier finding of GLSL functions and types . <p> GLM 0.8. x is NOT backward compatible with GLM 0.7. x . Upgrade to GLM 0.8. x could involve build errors for the following cases : A lot of improvements have been made to increase the conformance with GLSL specification . Lot of GLSL 1.30 features were already exposed in extensions that have been deleted . The extension syntaxe based on ARB convension is no long used . <p> Due to the number of changes GLM 0.8.0 is release as beta first . The final release is schedule for october . <h> 08/08/2008 - GLM 0.7.6 released <p> GLM 0.7.6 provides a better C++ conformance so that you can build GLM with pedantic G++ parameter or without Visual Studio extensions . To make GLM more reliable , BOOSTSTATICASSERT are used according developer wishes . <h> 05/07/2008 - GLM 0.7.5 released <p> GLM 0.7.5 is available and introduces a @ @ @ @ @ @ @ @ @ @ configuration with Visual Studio . This mechanism is documented in section 6 of GLM manual . Also , GLM can be built with GCC pedantic options . <h> 24/03/2008 - GLM 0.7.1 released <h> 22/03/2008 - GLM 0.7.0 released <p> GLM 0.7.0 is available under MIT license . LGPL lisence have been discard due to an issue of use for console development . This release contains a lot better documentation based on Doxygen . Lot of bugs have been fixed and the documentation completed . Thanks to all people that has contributed thought bug reports and ideas to make this version a lot better ! <h> 07/10/2007 - GLM 0.6.1 released <h> 16/09/2007 - GLM 0.6.0 released <p> GLM 0.6.0 is available . For this release , work focus on extensions . A new mecanisum allows to integrate GLM extensions as it is actually done for GLSL extension by vendors . Lot of new extensions have been added . <h> 06/01/2007 - GLM 0.5.0 released <p> This release include GLSL 1.2 new feature in the core implementation . Also , it includes swizzle read and write operators and a custom @ @ @ @ @ @ @ @ @ @ new extensions to extend GLSL features but they remain experimental . The next release should provide the first stable extensions . <p> The GLM 0.5.0 packages contain some basic samples and some documentation . The ray tracer sample has been updated to GLM 0.5.0 . Except for specific cases , especially with extensions , GLM 0.5 is backward compatible . <h> 22/05/2006 - GLM 0.4.1 released <p> A GLM update is available . It simply includes some examples for a sweet start with GLM . <p> The examples show how to use GLM with OpenGL intermediate mode and OpenGL vertex arrays . Also , they show how to use GLM extensions to replace GLU and OpenGL function witch could slightly increase performances by decreasing the number of OpenGL states changes . <h> 17/05/2006 - GLM 0.4.0 released <p> This release introduces first GLSL 1.2 features as planed . Also , various new extensions have been added and updated . Finally , it 's not anymore required to include windows.h before glm.h when windows.h is required . <p> The number of features of GLM , including extensions , start to really @ @ @ @ @ @ @ @ @ @ recommended to use precompiled headers. <h> 23/04/2006 - Roadmap for the years <p> Version 0.4 will complete matrices and vectors operators and will add GLSL 1.2 features . First , conversions simplifications will be integrated . Then , 4 per 3 matrices and outer product will be available from extensions . The transpose function is already available from extension . <h> 28/03/2006 - GLM 0.3.1 released <h> 19/02/2006 - GLM 0.3 released <p> A new release of GLM is now available . It improves GLSL data type conversion and construction compliance . Also , It 's adds extensions like some to manage double-precision and half-precision float numbers . Finally a Doxygen documentation has been added . <p> To demo the features of this new version , a sample program is included . It is a simple Ray Tracer supporting reflected and refracted rays , three lights types ( point , directionnal and spot ) , two objects types ( sphere , plan ) , using all of the GLM possibilities . <h> 04/05/2005 - English pages <p> The english section of this site is now available . <h> 21/02/2005 - @ @ @ @ @ @ @ @ @ @ availability of GLM . This library supports a part of GLSL specification : All vector , matrice types , the operators and associated functions . <p> For now , there is n't a detailed documentation , but you can have a look on GLSL specifications . Consider any mismatch between GLSL and GLM as a bug . Keep in mind the library is included in the namespace " glm " . <p> This project is multi-platform and was successfully tested under Visual C++ 7.1 , MinGW 3.4 and GCC 3.4. 
@@100664306 @4864306/ <p> OpenGL Mathematics ( GLM ) is a header only C++ mathematics library for graphics software based on the OpenGL Shading Language ( GLSL ) specification . <p> GLM provides classes and functions designed and implemented with the same naming conventions and functionalities than GLSL so that when a programmer knows GLSL , he knows GLM as well which makes it really easy to use . <p> This library works perfectly with OpenGL but it also ensures interoperability with third party libraries and SDKs . It is a good candidate for software rendering ( Raytracing / Rasterisation ) , image processing , physic simulations and any context that requires a simple and convenient mathematics library . <p> GLM is written in C++98 but can take advantage of C++11 when supported by the compiler . It is a platform independent library with no dependence and officially supports the following compilers : <p> Clang 2.6 and higher <p> CUDA 3.0 and higher <p> GCC 3.4 and higher <p> Intel C++ Composer XE 2013 and higher <p> LLVM 2.3 through GCC 4.2 front-end and higher <p> Visual Studio 2005 and higher <p> @ @ @ @ @ @ @ @ @ @ Doxygen-generated documentation will often state that a type or function is defined in a namespace that is a child of the glm namespace . Please ignore this ; All publicly available types and functions can be accessed as a direct children of the glm namespace. 
@@100664307 @4864307/ <p> I like to give a flavour for each year . It is some sort of a theme to think about through the year , to give it enough time , to hopefully discover some interesting thoughts in the process . 2010 has been a brilliant and pushing boundaries year with the flavour " obsession and exploration " . It leaded me to my 2011 theme " Perspectives " which gave me a special echo to John Wilson work . <p> Last summer , I discovered John Wilson work in an art gallery in San Fransisco . Few weeks ago , I saw another piece at a preivew of the London Art Fair which gives me the privilege to share with friends the unique exoerience of Paul Wilson work . Few evenings ago , I was walking in near cover garden when I came across once again with a Paul Wilson painting , this time in a Artica gallery . <p> John Wilson is one of this artist who brought interactivity to his art from his interest for perspective and maybe more generally space . After , a really @ @ @ @ @ @ @ @ @ @ art , Paul Wilson has continu his exploration of space bringing new shapes for his painting so that the viewer reach a real perception of perpective , like if the painting was continuing 5 meters inside the walk while moving around it thanks to clever perspective tricks . It is just like 3D in the cinemas but without headhache and with a feeling of freedom of exploration , for me John Wilson painting 's demonstrate how immatute this stereoscopic movie technologies remains . <p> With its interactivity and its desire for exploration , John Wilson 's work is , for me , another step toward the use of interactive rendering as a new media for proper art . 
@@100664308 @4864308/ <p> I love my new graphics card ! A Radeon HD 5850 generously provided by AMD to test my work on it . OpenGL 4.0 hardware , silent , 4 screen outputs so that I can plug my 3 24 inch screens on it to have a descent working space for both my programming and photography . Nice ! Thanks you AMD ! <p> If I may analyze this , I will say it 's another demonstration of the increase of interest for OpenGL by AMD . They want the stuff out there to work , it 's good for AMD image related to OpenGL which has n't been good . Since 1 or 2 years , the community starts to see some results from AMD evolution . Now , this image gets better and better as the drivers progress and as AMD is showing a desire to bring innovations through OpenGL publishing AMD extensions . <p> AMD OpenGL drivers are still not at the level of nVidia OpenGL drivers but now they are ' good ' quality . However , in this world there is no space for @ @ @ @ @ @ @ @ @ @ ! Something convenient with nVidia OpenGL drivers is that it " always works " even if it should not . AMD OpenGL drivers are much more strict and I quite appreciate this . Chances are , if it works on AMD , it will work on nVidia . I really hope that AMD is going to keep up the good work and , with my new baby , I am going to keep an eye on it ! 
@@100664310 @4864310/ <p> ATI Stream SDK 2.0 was the first public implementation of OpenCL available to anyone ! This new release is still limited to CPUs and support is not complete but that 's a great platform to learn OpenCL which actually means sens to me as well . <p> ATI Stream SDK 2.0 beta 3 is available for Windows XP/Vista/Seven through Visual Studio 2008 and Linux through GCC 4.3 and ICC 11 . <p> " The GPU version of OpenCL to be bundled with the ATI Stream SDK is scheduled to be available later in Q3 of 2009 " ... " The first production release of the ATI Stream SDK v2.0 with OpenCL 1.0 support is scheduled to be available in Q4 of 2009 . " <p> I expect to see a public release for nVidia soon as an implementation for MacOS X Snow Leopard is available and apparantly working pretty well . ATI implementation for MacOS X is ... almost unexistant. 
@@100664311 @4864311/ <p> We need courage and strength to weather this period of dissonance . It is becuase we are afraid of that dissonance and wanting to adapt to the past that we are not moving forward . The goal is not to adapt : It is to create . Piet Mondrian <p> The Centre Pompidou is hosting once again an unmissable exhibition about De Stijl , a magazine and art movement whose main names are Piet Mondrian ( 1872 - 1944 ) and Theo van Doesburg ( 1883 - 1931 ) . <p> This exhibition is following the evolution of De Stijl mainly through Piet Mondrian 's work , showing from where the " new plastic " araised to its influence after Mondrian 's time and focusing on the evolution of Mondrian 's art inspired by nature . He started to purify it , study balance and proportions of lines and colors and finally introduced rhythm ... Lines and squares only ? Not at all but pure creation of fascination . 
@@100664314 @4864314/ <p> The OpenGL Samples Pack is a collection of OpenGL samples based on the OpenGL " core profile " specifications . This code samples are also used to produce the OpenGL Drivers Status evaluating the quality of OpenGL drivers . <p> Assembling contributions from experienced developers , hardware vendors , researchers , and educators , OpenGL Insights present real-world techniques for intermediate and advanced OpenGL , OpenGL ES , and WebGL developers . Focusing on current and emerging techniques for the OpenGL family of APIs , the book demonstrates the breadth and depth of OpenGL . <h> OpenGL Reviews <p> The OpenGL reviews have been published at the release of new OpenGL versions to highlights new features and the differences from the previous versions . 
@@100664315 @4864315/ <p> The work of Anish Kapoor is perfectly defined by a signature . A fascination for shapes , curves , mirrors , wax and an obsession for pigments especially a very specific dark raspberry . <p> Throughout history the hand of the artist has been hailed as the means by which the expression of art finds a voice . To make art without the hand is a goal that sets art beyond expression.Anish Kapoor <p> Beyond just the pieces themselves , the experience with the pieces out and gives the overall impression , interest and feeling . I think that the accomplishment of Anish Kapoor is that he makes the visitors forget about the techniques about the process to just allow them to live the exhibition which , by the way , turns out to be quite fun ! 
@@100664316 @4864316/ <p> Until the 4th of Junuary 2010 , just a year from today , le Grand Palais displayed a great exibition about the late work of Jean Ausguste Renoir the famious French impressionnist painter who decided to change the orientation of his work following others inspirations from Raphael to Velasquez . <p> This fabulous exhibition pictures all the subject of interest of Renoir during this period : The woman body as a monument , the integration of the subject with the background and a come back to more traditional techniques . <p> I have been especially impression by the way Renoir saw and paint the skin , the flesh . He found beauty to see the woman body as massive and to paint them actually fatter that they were which I find interesting considering the current standard for women beauty . I see Renoir as a master of material , cloth , hair or flesh through Renoir paintings we just see the softness , the density , the thiness . The multi-layer technique to pain the skin stunned me and is actually similar to some implementation of a 3D rendering technique called subsurface scattering . 
@@100664318 @4864318/ <p> Last week I recieved a new toy to enjoy some picture sessions : A Canon EF 70-300mm f4-5.6 IS USM lens . I 'm so pleased with it ! <p> Following my picture inpirations , I enjoy to much the perfectly smooth and soft blur is can produce . So much stronger to much deep that the one produce by my Canon EF-S 18-55mm f/3.5-5.6 IS Lens ! <p> Second crazy amazing feature , the USM motor used for the autofocus . So accurate and so fast ! However , one issue is the desperate need of lights of this lens which evolved some trouble to focalize in such condion . I have also notice some trouble to focalize when lighting is really to strong ( like taking a picture of the sun ) . <p> This lens is stabilize with two different modes : The first mode is the classic full stabilization mode for none moving subject . The second mode is a vertical or horitonal stabilization which allow to move the camera when taking a picture of a moving subject for example . It 's a @ @ @ @ @ @ @ @ @ @ I 'm really happy with this lens with is also perfect for my macro picture with 300mm lens techniques . It needs to take pictures at 2 meters from the subject but the blur is so nice and the picture quite shape for such lens . 
@@100664320 @4864320/ <h> Let 's define a working process ! <p> In this article , I am going to present the development method I am using for G-Truc Creation projects . What 's the ' releases oriented development model ' ? Just a name I came up with , just like the development method I am using . Please , this is not about taking things for granted but about giving some thinking material on the working process . From as long as I started programming , some friends will remember how I spent my time to repeat the importance of project releasing . <p> The only thing that matter , it 's the release ! Not only once , we need to release twice because as long as we manage to release twice , we will be able to release more . ME with my findger up and crazy eyes ! : ) <p> This is quite a passionnate idea quite disconnected from any reasons but I quite believe it remains a base idea for how I work and how I want my way of working to evolve . One @ @ @ @ @ @ @ @ @ @ ' how ' ) affect the result just like what we actually do . The longer the project lives , the higher the working process matter . If the project is meant for one release and then being through away then I would say " who cares about the working process ? " . <p> Allow to release anytime <p> Allow to maintain old versions and sub-versions of a project <p> Allow testing multiple platform simultaneously <p> Allow an easy support of a new platform <p> Keep project dependencies up to date with reliable code <p> Allow an access to the code anytime , anywhere <p> Reduce amount of bugs introduced by accident with maintenance releases . <p> Keep tests and experimental code out of releases . <p> Allow a feature development to fail without poluting the repository . <p> To archive all these challenges my main tools are , as you probably know already , Git , CMake and Trac . <h> Trac for planning ahead <p> My use of Trac is fairly limited as I use it mainly as a bug tracker but also to write down ideas @ @ @ @ @ @ @ @ @ @ I am not really pedentic on which feature will be present for which release . It depends on the work progress of the features and Git is quite an ally for that purpose . I am not an expert in bug trackers and ci and I could probably use another one . Track by itself is great but Track on SF.net is really so slow ! I guess a better alternative would be nice . <h> CMake for cross platform / cross compiler development <p> CMake is a cross platform project generator . It 's good but if one day another similar tool get released , I would definetely have a look expecting a switch . With CMake we define projects and solutions inside script files . Then , CMake generates the project for Visual Studio , GCC/make , XCode , etc . Good in principle but the scripts are quite messy , it 's taugh to read someone else scripts , they contains a lot of ' if ' for platform specific things , the documentation for build-in functions and variables is ok but for the script language documentation @ @ @ @ @ @ @ @ @ @ far from it , but for cross platform projects it 's a good solution ! <p> With some efforts , CMake gives a certain level of cross platform capabilities of a project . The out of source build feature of CMake allows on a same platform to build multiple project out of the same source code . For example , on a unique platform , a project for Visual Studio 2008 , one for Visual Studio 2010 , one for GCC , etc. but also multiple projects for different profiles , debug / release , 32 bits / 64 bits . An update of the script and all the projects will be automatically rebuild and updated with the script changes . There are good sides to CMake , definetely ! <h> Git for releases oriented development <p> Git is a distributed version control system . It has the reputation to be really complicated to use ... I would say , it 's quite disturbing at the beginning and it requires some thoughts to avoid either a very basic use of it or a complete mess . After few months of @ @ @ @ @ @ @ @ @ @ say out loud : I LOVE Git ! <p> I like Git for many reasons from which the branch / merge capabilities are on top . One big difference from Git and SVN is that Git manages changes while SVN manages versions . This behavior becomes abvious while using gitk , a GUI program provided with Git which displayes the changes and the relashionship between repository branches . Merging is so easy and so fast ( git merge xxx and done ) that it is easy to merge several time per working day . Actually , merging often is a good practice to reduce merge conflicts and with Git conflicts could become extremely rare . I actually think that SVN fails with branching , it 's because we ca n't merge often enough . <h> Versions conventions <p> This is where we actually start to discuss about the releases oriented development model through the release name convensions . My project releases are named and numbered with the following convension : project-name-M.N.P.R . <p> M for major <p> N for minor <p> P for patch <p> R for revision <p> I @ @ @ @ @ @ @ @ @ @ It might happen for a massive update , a rewrite or a change of direction of the project . I actually expect that number to last several years . In a way , this number is a statement for stability expect when it is 0 where if could be seen as a beta release or at least some ongoing development . The minor number is updated for important changes , new main features , possible API changes . I expect this number to change few times a year . This is a statement for depth evolution . The patch number update can involve possible new features but backward compatibility is expected . This number is a statement for improvements and could change a lot of time in a year . The revision number implies mainly bug fixes , compatibility and project maintenance . I expect this number to change anytime , as needed , as much as possible . It 's a statement for maintenance . <p> For any project I want something like these levels of release management and these levels of works . If a critical bug is @ @ @ @ @ @ @ @ @ @ within a day and release even if I was working on a big new feature , a large rewrite of a project component or even changes that are never going to be released because of a developement failure ( result not good enough , technical limitation , etc ) . <p> Obviously , this convension has some flexibilities . For example , the major and minor numbers of the OpenGL Samples Pack follows the OpenGL version is supports . Actually the more important concept behind it is the hability of working at various levels of release frequency . <h> Branches conventions <p> The releases oriented development model is articulated around 3 types of branches : <p> The master branch <p> The version branches <p> The feature branches <h> The master branch <p> The master branch is the name given by Git for what SVN call Trunk . It 's the first branch we have when we start a repository . It is a singleton branch used for releases ( with tags of each one ) and submodules . It 's a reliable branch that a user could use if he @ @ @ @ @ @ @ @ @ @ that works . <h> The version branches <p> Version branches is a per-patch branch which life-time is unlimited to ensure that even an old branch could be maintained if needed . When the development of a version is completed and ready for release , the version branch is merged on the master branch and it is tagged . However , if an old version need to be maintained , the old version branch is updated and tag for release directly . Thanks to the amazing merging capabilities of Git and the release oriented developement model , a bug fix in an old branch can easly be apply on all more recent branches with a simple merge . <h> The feature branches <p> Finally , the feature branch . It can be created from one version branch but merge to a more recent version branch when completed . It 's life time will end and it brings development failure possibility . A feature branch is constantly updated with the older version branch it might be merge to make sure that the code does n't diverge too much . <p> This sounds @ @ @ @ @ @ @ @ @ @ ! Let 's have a look on an example based on the OpenGL Samples Pack . In the real repository , the number of commits is much more higher but I reduce their proportion to see all the connections between branches . <p> Branching mecanisum <p> This is actually quite the current state of this project . The OpenGL Samples Pack 3.3.1 is still maintained and any release could be roughly done tomorrow . The development of the OpenGL Samples Pack 4.0.0 is actually finished beside some testings so that the development of the OpenGL Samples Pack 4.0.1 has started . Three versions in parallel , no problem ! Also , thanks to the Git submodule , GLM and GLI remained updated to the last version even if I do n't actually know with one it 's suposed to be . For development clarity , the submodule code is in read only . If I discover a bug in a submodule , I need to update directly in the submodule repository . I might have some improvements to figure out around here ... not sure yet . <p> I am @ @ @ @ @ @ @ @ @ @ areas are to investigate . The main topics left are related to the development pipeline and automation . <p> Tasks for release pipeline automation <p> Automatic testing and reports <p> Automatic packing , daily build <p> My ultimate goal would be to have a push button , that excutes the tests , provides a reports , tag the release , build an archive with the right filenames and the right version number and update the files . From that I would be not to far from a daily build system . This remains a lot of work to do ... 
@@100664322 @4864322/ <p> A first image phrase , or idea would justify itseft in the unfolding of images , phrases and ideas sparoned by the work as it progressed . The imperfect erasures of the succeessive stages of each drawing become a record of the progress of an idea and a record of the passage of time . William Kentridge <p> Some artists of our time are so stunning that we know that we will eventually came accross them anytime soon . That 's what happen to me with William Kentridge . <p> I saw an exhibition of his work earlier this year at Paris ' Jeu de Paume and it was already amazing but this was one of the many exhibitions I saw I just lacked of time to write a report and save it in my life time memory- . This time is was the turn of Vienna 's Albertina to display a compete retrospective of William Kentridge . <p> Between " stone edge " cinema ( as he like to call it ) and some form of innovations , William Kentridge appears to me as a ' **28;1600;TOOLONG @ @ @ @ @ @ @ @ @ @ , the way he reuse them involve the creation of new medias , new ways to experience . <p> This exhibition is running until the 30 of January 2011 at Vienna 's Altertina . It should not be missed for anyone who likes to awake his sense of wonder and creativity . <p> The studio is an enclosed space not just physically but also psychically , like an enlarged head ; the pacing in the studio is the equivalent of ideas spinning round in one 's head , as if the brain is a muscle and can be exercised into fitness , into clarity . William Kentridge 
@@100664325 @4864325/ <p> Congratulation to NVIDIA which new drivers 280.19 run all the OpenGL 4.1 samples successfully . The last bug on the shader interface matching has been fix to archive this result . <p> I am not going to say that everything is perfect , it would be the duty of a conformance test suite but as far as this one hundred samples goes , NVIDIA OpenGL 4.1 drivers works and I believe ready for production . <p> There is maybe one hiccup regarding the way NVIDIA drivers clip point sprites . According to the specification the point pritimitive must be clipped at vertex position but this approach leads to disturbing popping artefact when the size of the point is higher than one pixel . An easy workaround is to take into account the derived size of the point for the clipping using the value output in glPointSize . I do n't if it'a what NVIDIA does but their rendering is pop free which is a feature to me . It might be useful to have a glPointParameter* ( GLCLIPPING , value= " " ) where values could be either @ @ @ @ @ @ @ @ @ @ AMD OpenGL drivers side , no change this month beside a new bug detected on point sprite rendering . A lot of improvements are to be released but until then this is all we got . 
@@100664329 @4864329/ <h> OpenGL driver issues <p> This drivers status is based on the OpenGL Samples Pack 4.4.1.3 . The NVIDIA implementation had 3 issues with the samples , 19 on AMD implementation , 12 on Intel implementation and 13 on Apple implementation . <p> At this point , it seems that essentially the remaining issues in NVIDIA driver is non standard behavior supported by the OpenGL implementation . I have n't spent much time on OpenGL 4.4 and OpenGL 4.3 so I would n't be surprised if there are more issues with this feature . Micro benchmarking also show really reliable level of performance . <p> I considered adding Mesa but I am not sure I got working correctly Mesa 10.1 with the last Intel drivers resulting in basically no sample running ... I tested Debian 7.3 , Ubuntu 13.10 and Mint 16 but there are all stock to Mesa 9.2 , hence OpenGL 3.1 support . Unfortunately , the OpenGL Samples Pack requires OpenGL 3.2 . Updating Mesa and drivers is far less trivial than on Windows and I am not exactly a Linux user so I expect I @ @ @ @ @ @ @ @ @ @ get this working for the next OpenGL status , it would be interesting data to have . <p> Apple OpenGL implementation has n't been updated seen last report , let 's hope MacOSX 10.9.1 fixes the new features . OpenGL 3.2 is okish , but outside of that it 's not great . <p> I ca n't exclude that there is n't bug in the samples , so do n't hesitate to open an issue . <p> OpenGL samples passing on available implementations <h> OpenGL extensions exposed <p> No change for NVIDIA that has already full support of OpenGL 4.4 and the driver is n't exposing new proprietary features . <p> AMD implementation has 7 new extensions including five OpenGL 4.4 onces . The big chunk for OpenGL 4.4 is ARBbufferstorage but this extension remains to be implemented . <p> Intel implementation added 8 new extensions . Intel is still missing 10 extensions to complete their OpenGL 4.3 implementation . Intel has focused their efforts on the most complex OpenGL 4.3 extensions so I am still pretty confident that we will have get OpenGL 4.3 by Siggraph 2014. 
@@100664332 @4864332/ <p> I have been working on SIMD optimizations for GLM for a while so that most of the GLSL functions implemented by GLM have some equivalent based on SIMD instructions ... since 2008 . Unfortunately , in GLM 0.9.0 none of these optimizations are available as I strugle to find a good API to expose these optimizations ... <p> Finally , few weeks ago I merged , the SIMD branch to the GLM 0.9.1 branch as I defined some sort of API based on experimental extension so that I can experience this solution , see how it goes and move it to the right direction . <p> One topic was to let the user select the instruction sets they what to use to that they can define which platform will be supported by this build . <p> Unfortunately the world of x86 processors is quite complex on that matter . These days both AMD processors ( Ahtlon 64 San Diego ) and Intel processors ( Pentium 4 Prescot ) support SSE3 instructions but behond that it 's more complex . SSSE3 ( Core 2 ) SSE4.1 and SSE4.2 instruction @ @ @ @ @ @ @ @ @ @ supported by AMD ( Phenom ) ... A subset of instructions are actually shared between AMD and Intel CPUs ... Fortunately with the future realise of AMD Bulldozer and Intel Sandy Bridge , the situation should get better thanks to the AVX instruction set even if few imcompatibilities might remains . <p> With the rescent released of Visual Studio 2010 SP1 beta , Microsoft has catched up with GCC in term of AVX support . Support for SSSE3 SSE4A , SSE4.1 and SSE4.2 is available in Visual Studio 2008 and SSE , SSE2 and SSE3 in Visual Studio 2005 . GCC 4.4 already support AVX and AES instruction sets , GCC 4.3 brought support for popcnt , SSSE3 SSE4A SSE4.1 and SSE4.2 instruction sets and GCC 4.0 supports SSE , SSE2 and SSE3 instruction sets , <p> Finally , I made a list of all the instruction sets headers that need to be included to use intrinsect functions with GCC and Visual Studio ( and Intel compiler for supported instruction set ) . 
@@100664333 @4864333/ <h> Functions <p> Arc tangent . Returns an angle whose tangent is y/x . The signs of x and y are used to determine what quadrant the angle is in . The range of values returned by this function is -PI , PI . Results are undefined if x and y are both 0 . ( From GLMGTXcompatibility ) <p> Arc tangent . Returns an angle whose tangent is y/x . The signs of x and y are used to determine what quadrant the angle is in . The range of values returned by this function is -PI , PI . Results are undefined if x and y are both 0 . ( From GLMGTXcompatibility ) <p> Arc tangent . Returns an angle whose tangent is y/x . The signs of x and y are used to determine what quadrant the angle is in . The range of values returned by this function is -PI , PI . Results are undefined if x and y are both 0 . ( From GLMGTXcompatibility ) <p> Arc tangent . Returns an angle whose tangent is y/x . The signs of x @ @ @ @ @ @ @ @ @ @ is in . The range of values returned by this function is -PI , PI . Results are undefined if x and y are both 0 . ( From GLMGTXcompatibility ) 
@@100664334 @4864334/ <p> Some programmers are explaining for hours that Lisp , Java , C , C++ , C# , Python are their favorite languages because they are the best language and they can even rationally explain why and find good points . <p> I think this is ways to much dogmatic for me , I 'm a septic person . The world has n't  been build from reasons but from passions ! Everyone will find positive and negative point for languages ... so who cares of the best language ? My favorite language is C++ because it is the one I have the most fun with ! <p> Over the years , I always had more to learn about C++ everyday and this is going to continue probably until I use C++ . Over those years each time I had a question about C++ I create a test project to check it out . I saved a lot of those test programs and I though it might be good idea to use them as a material to speak more about C++ on G-Truc Creation . I decided to make a project of them " C++ Experiments " . 
@@100664335 @4864335/ <p> Salome is also a tragedy based on this antique character written by Oscar Wilde in 1891 in French and then translated in English . The play 's debut in London was halt by a ban in 1892 . The play premiered in Paris in 1896 . <p> While giving an astonishing statement to the stage , I found the universe a bit disturbing considering the historical references in the script . However , a perfect realisation based on this universe , the commitment of the actors and an exhilarating direction lead the play to the edges of what our time socially accept for an absolutely daring and literally stunning play which is going to stay in memories . 
@@100664336 @4864336/ <p> This exhibition was designed over three main axis : The obcession of Edgar Degas ( 1834 - 1917 ) for the Ballet , the interest of the late 19th centuary for the movement and finally the impact of the rise of photography . <p> For a long time in his career , Edgar Degas had a low consideration for the photography media as it was n't able to capture his topic of interest : Movement of the ballet dancers . How to take a picture of ballet dancer in an Opera with such dim light ? However , in 1895 , thanks to the progress of the photography intruments , he started using a camera to produce pictures which are n't without making us remember the Clair Obscur technique , far from what Edgar Degas used to do in his painting . <p> Dancer adjusting her shoulder strap , Edgar Degas , 1895 <p> His study of black and white photography had a direct impact to his painting technique and I have the feeling that he understood better what is the uniqueness that painting can produce but also @ @ @ @ @ @ @ @ @ @ more colorful and his technique evolve to produce a visual which recalls photography noise . 
@@100664338 @4864338/ <p> It has been six months since my last report on the landscape of exposed OpenGL extensions by drivers . <p> Nevertheless , the ecosystem has n't evolved so much with no change for Apple despite MacOSX 10.10 release ; basically no change for Intel drivers ; and just a handful of OpenGL 4.5 extensions for AMD . <p> Numbers of new extensions exposed since last report : <p> AMD : 7 total ; 5 core ; 1 ARB ; 1 vendor <p> Apple : 0 total <p> Intel : 2 total ; 1 ARB ; 1 vendor <p> NVIDIA : 33 total ( BAM ! ) ; 12 core ; 3 ARB ; 18 vendors <p> Obviously , if we do n't care about cross-platform support , it 's a great time to work on NVIDIA with Maxwell 200 series : We have been waiting for a while for OpenGL 4.5 drivers on GM204 but we finally have them . NVIDIA also published a bunch of extensions to expose all sort of great new hardware features : NVconservativeraster , NVsamplelocations or **25;1630;TOOLONG to only mention my favourites . @ @ @ @ @ @ @ @ @ @ produced by NVIDIA after G80 . Not as crazy as G80 for the time but certainly more healthy . 
@@100664339 @4864339/ <p> If anything , at least Mantle created some discussions about graphics API but it remains that I believe it 's a waste of AMD engineering resources that could have benefit their OpenGL drivers for example . <p> Let 's compare what we can compare . What if we want to write a Modern OpenGL program for AMD Southern Islands and NVIDIA Kepler only . Then we only need a tiny subset of the OpenGL API that I have listed below . <p> It still appears that Mantle requires less functions . With a closer look we see that Mantle use state objects to group rasterizer , viewport , depth test states . State objects are a idea because every hardware vendor would want different packing but also because every single OpenGL program would use different packing . To write an efficient OpenGL renderer we need to consider the update frequencies and move every operations at the lower update rate possible . Packing states is requiring to update more often states that should not have change hence adding CPU overhead . So no thank you but I prefer to @ @ @ @ @ @ @ @ @ @ me in the past ( about 2007 ) was to use display lists to create immutable state objects that matched my program needs . I do n't think I want to go this way in 2014 . <p> So OpenGL has evolved , " revolution through evolution " . If we really want to write low overhead OpenGL programs , we can . If that 's not the case right now , my opinion is that the industry did n't put the effort in it because it has higher priority issues to resolve , essentially production issues which include supporting old consoles ( PS3 and XBox , OpenGL 2.1 / Direct3D 9 hardware ) , cross compiling shaders , the development of mobile and the rise of WebGL. 
@@100664340 @4864340/ <p> We have heard of AMDsparsetexture for quite some time but finally the extension is available . It rose quite some excitement from OpenGL programmers : Having textures for which we can allocate and unallocate memory pages sounds great especially for virtual texturing where we need to address large amount of data . It handles case where weca n't espect that all the textures can fit entierely into graphics memory . Sparse texture allows sampling across texture pages without artefacts even with high anisotropic filtering . <p> Creating a sparse texture <p> // Create a sparse texture <p> glGenTextures ( 1 , &amp;TextureName ) ; <p> **37;1657;TOOLONG , GLTEXTURE2D , <p> GLRGBA8 , // Internal format <p> 16384 , 16384 , 1 , // width , height , depth <p> 1 , // layers <p> **28;1696;TOOLONG ) ; // Handle the texture as a sparse texture . ( Not a hint ) <p> Texture pages can be deleted using the same glTextureSubImage2DEXT function but passing NULL for the data . This behavours highlight a design issue with this extension which prevents allocating a texture page without passing data to @ @ @ @ @ @ @ @ @ @ performance impact is to source a pack buffer object , reading ( even garbage ) from GPU memory instead of through the PCI express bus . <p> The texture page size must be multiple of the value returned by the GLVIRTUALPAGESIZEX , Y , ZAMD queries . <p> In practice the texture page memory size must be a multiple a 64 KB so that if the texture internal format store large texels ( RGBA32F = 16 bytes per texels ) , the number of texels per page will be reduced only bound by the 64 KB memory size . Hence , the texture page dimensions for a RGBA32F texture is 64 by 64 texels . For a DXT1/BC1 texture , a texel is encoded with 4 bits which results in a mimimum of 256 by 256 texels per texture page . <p> Sparse textures can be used for texture 2d , texture 2d array and texture 3d . Unfortunately , on Southern Islands GPUs , the texture pages dimensions are always the same shape , flat 2D slices even for texture 3d . An application ( global illumiation with sparse @ @ @ @ @ @ @ @ @ @ ( dices instead of slices ) for texture 3d , unfortunately this shape reflects the texture 3d layout of Southern Islands GPUs memory layout . <p> On the GLSL size , the usual texture sampling language can be used to sample a sparse texture . However , in some cases it can be useful to sample in area where no texture pages have been allocated . For this , AMDsparsetexture provides some new GLSL functions that return a code qualified the result of the sampling . <p> New GLSL functions returning a code : <p> #version 420 core <p> #extension AMDsparsetexture : require <p> layout ( binding = DIFFUSE ) uniform sampler2D Diffuse ; <p> ... <p> void main() <p> vec4 Color ; <p> int Code = sparseTexture ( Diffuse , Texcoord , Color ) ; <p> // Did we fetch somewhere all the texels are resident ? <p> bool Resident = **25;1726;TOOLONG ; <p> // Do we need a texel from any LOD lower than the user specified LOD warning threshold ? <p> bool MinLodWarning = **30;1753;TOOLONG ; <p> int LodWarningFetch = **32;1785;TOOLONG ; <p> ... <p> <p> It @ @ @ @ @ @ @ @ @ @ unfortunately not to depth textures . Supporting depth textures could make high resolution shadow mapping a lot easier and particularly memory efficient . <p> Even if this extension remains quite experimental from my opinion , it defines one of the key feature for post OpenGL 4 hardware . Considering that NVIDIA GPUs support some form of virtual memory system , I would n't be surprise to see them releasing an implementation with at least a subset of the functionnalities given by this extension . <p> Some people will argue that NVIDIA supports bindless textures and hence NVIDIA does n't need sparse textures . This is either a misleading argument , a misunderstanding of the features or simply a marketing lie . Bindless textures are great but bindless and sparse textures are simply complementary features . Bindless textures allows an unlimited number of textures while sparse textures ensure filtering between texture pages . We need both ! 
@@100664346 @4864346/ <p> OpenGL 4.0 is the new specification for GeForce GTX 4** and Radeon HD 5*** hardware : aka Direct3D 11 hardware level . In this review we go through all the new features and explore their details . <h> Tessellation . <p> OpenGL 4.0 brings 3 new processing stages that take place between the vertex shader and geometry shader . <p> Control shader ( Known as Hull shader in Direct3D 11 ) <p> Primitive generator <p> Evaluation shader ( Known as Domain shader in Direct3D 11 ) <p> In a way , the tessellation stages replace the vertex shader stage in the graphics pipeline . Most of the vertex shader tasks will be dispathed in the control shader and the evalution shader . So far , the vertex shader stage is still required but the control shader and the evaluation shader are both optional . <p> Control shaders work on ' patches ' , a set of vertices . Their output per-vertex data and per-patch data used by the primitive generator and available as read only in the evaluation shader . <p> Input per-vertex data are stored in an @ @ @ @ @ @ @ @ @ @ . The elements of glin contain the variables glPosition , glPointSize , glClipDistance and glClipVertex . The per-patch variables are glPatchVerticesIn ( number of vertices in the patch ) , glPrimitiveID ( number of primitives of the draw call ) and glInvocationID ( Invocation number ) . <p> The control shaders have a glout array of per-vertex data which members are glPosition , glPointSize and glClipDistance . They also output per-patch data with the variables glTessLevelOuter and glTesslevelInner to control the tesselation level . <p> A control shader is invoked several times , one by vertex of a patch and each invocation is identified by glInvocationID . These invocations can be synchronised by the built-in function barrier . <p> The primitive generator consumes a patch and produces a set of points , lines or triangles . Each vertex generated are associated with ( u , v , w ) or ( u , v ) position available in the evaluation shader thanks to the variable glTessCoord where u + v + w = 1 . <p> The evaluation shaders provide a glIn array like control shaders . The members of @ @ @ @ @ @ @ @ @ @ for each vertex of a patch . The evaluation shaders have the variables glPatchVerticesIn and glPrimitivesID but also some extra variables glTessLevelOuter and glTessLevelInner which contain the tessellation levels of the patch . <p> Tessellation has a lot more details to understand to work on a real implementation in a project ! Those details are available in GLARBtessellationshader and obviously in OpenGL 4.0 specification . I think the API need some refinements but provides enough to start having fun with tesselation . <h> Subroutine . <p> Subroutines are defined by GLARBshadersubroutine as part of OpenGL 4.0 specification . This mechanism is some sort of C++ function pointer which allows to select , from the C++ program , a specific algorithm to be used in a GLSL program . This feature is a great enhancement for the ' uber-shader ' type of software design where all the algorithms are included in a single shader to handle multiple/every cases . Subroutines allow to select specific shader code-pathes but also to keep the same program and program environment . <p> The following GLSL code sample defines 3 subroutine uniforms , which means 3 @ @ @ @ @ @ @ @ @ @ be defined for a subroutine and a single subroutine function can be used for multiple subroutine uniforms . Subroutine function ca n't be overloaded . Subroutine uniforms are the sort of ' function pointer ' but can only ' point ' on subroutine functions . <p> // Subroutine uniform variables are called the same way functions are called . <p> GreatFeature() ; <p> ... <p> BestFeature() ; <p> ... <p> OtherFeature() ; <p> <p> The subroutine uniforms are assigned using the function glUniformSubroutinesuiv which parameters define the list of the subroutine functions used set to all subroutine uniforms . To get the subroutine function locations , OpenGL provides the function glGetSubroutineIndex . <p> This is basically how transform feedback works with OpenGL 3.0. **27;1819;TOOLONG is a program state that must to be called before GLSL program linking . The last parameter can be either GLSEPARATEATTRIBS or GLINTERLEAVEDATTRIBS . GLSEPARATEATTRIBS is used to save each transform feedback varying in different buffers and GLINTERLEAVEDATTRIBS is used to save all transform feedback varying in the same buffer . <p> **36;1848;TOOLONG is a query that can be used to get the number of primitives @ @ @ @ @ @ @ @ @ @ are captured from a vertex shader and the feedback primitive is the same as the drawn primitive , the number of primitives written in the buffer is likely to be the same as the number of primitives sent at draw call but transform feedback has such flexibility that transform feedback primitive can be different than draw call primitive . <p> Furthermore , transform feedback can capture geometry shader output . As geometry shader can generate or discard primitives , which output vertrices count become unpredictable . Transform feedback buffers can be used as vertex data of further draw calls where the vertrices polygon count might define the draw call primitive count . If you repeat a series of geometry shader and transform feedback , we might have a tessellator ... but a really slow useless one ! <p> This work has been followed by some more work by nVidia in the form of GLNVtransformfeedback2 to finally give us 4 new extensions in OpenGL 4.0 which push the transform feedback boundaries . <p> GLARBtransformfeedback2 defines 3 features . First , it creates a transform feedback object ( sometime called XBO ) @ @ @ @ @ @ @ @ @ @ is to say the transform feedback buffers which with GLINTERLEAVEDATTRIBS is just 1 buffer ... what 's the point ? ! <p> This object allows to pause ( glPauseTransformFeedback ) and resume ( **25;1886;TOOLONG ) transform feedback capture . XBO manages a behaviour ' state ' . This way , multiple transform feedback objects can record the vertex attributes , one after the other but never at the same time . In an OpenGL command flow , we can imagine that some draw calls belong to one transform feedback and others belong to a second transform feedback . <p> Finally , this extension provides the function glDrawTransformFeedback to use transform feedback buffers as vertex shader source without having to query the primitives written count . When querying this count with glGetQueryObjectuiv , the function is going to stall the graphics pipeline waiting for the OpenGL commands to be completed . glDrawTransformFeedback replaces glDrawArrays in this case and does n't need the vertices count , it 's going to use automatically the count of written primitives in the transform feedback object to draw . GLARBtransformfeedback2 is part of OpenGL 4.0 but @ @ @ @ @ @ @ @ @ @ <p> GLARBtransformfeedback3 defines 2 features . First , with OpenGL 3.0 when we capture varying we are limited by 2 dispached methods : GLSEPARATEATTRIBS to write a varying per buffer and GLINTERLEAVEDATTRIBS to write all the varyings in a single buffer . <p> GLARBtransformfeedback3 proposes a much more realistic scenario : It allows to write interleaved varyings in several buffers . Let 's take an example . A transform feedback object could contains 3 buffers . The first buffer could capture 1 varying . The second buffer could capture 3 varying . and the third one could capture 2 varyings . This behaviour is defined with a simple very approach : In the name list given to **27;1913;TOOLONG , we insert the name glNextBuffer as a separator between buffer . <p> Also , this extension has some interactions with GLARBgpushader5 which defines multiple vertex streams in geometry shaders . Multiple vertex streams is a new concept for OpenGL 4.0 . In a way , before OpenGL 4.0 we had a single vertex streams which was use by the rasterizer . The first vertex stream is still used by the raterizer @ @ @ @ @ @ @ @ @ @ . Such possibility requires an extra set of functions to query the written primitives per stream and to be able to draw directly using a specific vertex stream . This is done with **29;1942;TOOLONG , glBeginQueryIndexed , glEndQueryIndexed and glGetQueryIndexediv . <h> Geometry shader ( r ) evolution . <p> OpenGL 4.0 Geometry shader provides streams and also a great improvement of this programmable stage : Geometry instancing . Where others OpenGL instancing techniques execute the entire graphics pipeline for each instance , this fonctionnality allows to run multiple times the geometry shader , each run being identified by glInvocationID . The number of time the geometry shader is invoked is indicated inside the geometry shader using the new input layout qualifier . <p> Geometry shader input layout qualifier : <p> layout ( triangles , invocations = 7 ) in ; <p> The first parameter in the input layout is the input primitive type which can be points , lines , linesadjacency , triangles and trianglesadjacency . <p> Geometry shader also provides new required output layout qualifiers . <p> Geometry shader input layout qualifier : <p> layout ( trianglestrip , @ @ @ @ @ @ @ @ @ @ <p> This layout defines the geometry shader output primitive , points , linestrip or trianglestrip and the maximum number of vertices the shader will ever emit in a single invocation . The maximum value is **27;1973;TOOLONG stream declares the default stream and can be different to 0 only when the output primitive is points . stream number can be declare in the global scoop , for a block or a non-block output variable . Vertrices and primitives are emited to specific streams using the GLSL functions EmitStreamVertex and EndStreamPrimitive <p> This is just the changes in geometry shader , a few of all changes that GLSL 4.0 includes . <h> GLSL 4.0 punch ( in my face ) . <p> GLSL 4.0 evolves a main change in the programming policy . Where GLSL until GLSL 3.3 was all about explicit conversions , GLSL 4.0 provides implicit conversions . It implies a lot of rules to define these conversions ... I 'm really not sure about it , about how good this is for GLSL . At least a concequence is that GLM will use implicit conversion in a future version @ @ @ @ @ @ @ @ @ @ made this switch . <p> GLSL 4.0 introduces a new qualifier call precise that can be use to any variable to ensure that the result of an operation is performed the way the code request it . Compiler performs a lot of optimizations that can affect the result with a little lack of precision for a high performance benefit . precise effectively avoid those optimizations . <p> GLSL 4.00 extends the set of built-in functions with new integer functions ( mainly bitfield manipulation functions ) , floating-point pack and unpack functions and extends the list of common functions . <h> Adaptative multisampling and per-sample processing <p> With GLARBsampleshading , the programmer can force the minimum number of samples that will be compute independently . To be efficient , most implementation share some values between samples like texture coordinates so that a texture fetch can be reused for every samples of a fragment . For example , in case of alpha test based on alpha texture , this behaviour can introduce aliasing . A problem quite obvious in Crysis . <p> The function glMinSampleShading is used to set this mimimum number @ @ @ @ @ @ @ @ @ @ built-in variables : in int glSampleID the number of the sample , a value between 0 and glNumSamples - 1 uniform int glNumSamples is the total number of samples in the framebuffer ; in vec2 glSamplePosition the position of the sample in the pixel ( between 0.0 and 1.0 where 0.5 is the pixel center ) ; out int glSampleMask is used to changed the coverage of a sample , to exclude some samples from further fragment processing but it will never enable uncovered samples . <p> GLARBgpushader5 provides further per-sample controls regarding how in/out data are interpolated using qualifiers . When centroid is used to qualify a variable , a single value can be assigned to that variable for all the samples in the pixel . However , when sample qualify a variable , a separate value must be assigned to that variable for each covered sampled . <p> New built-in interpolation functions interpolateAtCentroid , interpolateAtSample and interpolateAtOffset are available to compute interpolated value of a fragment shader input variable . interpolateAtCentroid will return the value of a variable a centroid location , interpolateAtSample at sample location and interpolateAtOffset @ @ @ @ @ @ @ @ @ @ 0 , 0 ) is the center of the pixel . If an input variable is declared with the qualifier noperspective , the interpolation is computed without perspective correction . <p> GLARBtexturegather is actually a Direct3D 10.1 hardware feature and provides the function textureGather . This function determines the " 2x2 footprint that are used for linear filtering in a texture lookup and it returns a vector consisting of the first component from each of the 4 texels in the footprint " . Nice ... but very limited . <p> GLARBgpushader5 extends this fonctionnaly so that we get a fully programmable texture filtering . The sampler object is no longer useful . It allows to gather any component of a 2x2 footprint . It allows to use an arbitrary offset to select the footprint and even extend this functionnality to a per-component offset . Finally , it allows to perform a per-sample depth comparison . <p> Finally , GLARBtexturequerylod defines the function textureQueryLOD to query , in GLSL , the LOD that would be computed if a texture lookup was performed . <p> With such feature , we can perform @ @ @ @ @ @ @ @ @ @ " is no longer a meaningful concept . <h> Double-precision floating-point support aka FP64 . <p> GLARBgpushaderfp64 is part OpenGL 4.0 and exposes support of FP64 uniforms and FP64 computations in GLSL . I 'm really supprised and actually fairly ceptical about this choice . All Direct3D 11 cards does n't have hardware support for doubles especially on AMD side . It quite makes sens as few users would need it . On the Radeon HD 5XXX series , the only cards that have double support are the Radeon HD 5830 , Radeon HD 5850 , Radeon HD 5870 and Radeon HD 5890 based on RV870 chip . <p> AMD said it will support OpenGL 4.0 on the entire Radeon HD 5XXX line which implies that double float will be emulated and , as a conscequence , really slow ... Well , what is the meaning of " Really slow " ? AMD claims at FireStream 9170 release ( a pro RV670 / Radeon HD 3870 card ) that they emulate double float with 2 single floats and that this result in 1/2 to 1/4 of the single precision performance @ @ @ @ @ @ @ @ @ @ with Cuda I found on nVidia forums , I would say that emulated FP64 would be about 10 to 20 times slowers than FP32 . <p> GLARBgpushaderfp64 is a great extension . I just think it should have stay as an extension but I 'm not sure it would be any problem in practice anyway as the use cases for FP64 are fairly limited , especially with OpenGL . Considering the GPUs that support FP64 , we notice that this is the kind of feature that does n't follow GPU generations but high-end graphics in general . The OpenGL 3 . X cards that support hardware FP64 ( and probably GLARBgpushaderfp64 ) are Radeon HD 4770 , 4830 , 4850 , 4870 , 4890 , 4850 X2 , 4870 X2 ; GeForce GTX 260 , 275 , 280 , 285 , 295 . <p> **27;2002;TOOLONG provides Direct3D 11 compressed formats knowned as BC6H and BC7 and called respectivelly GLBPTCFLOAT and GLBPTC with OpenGL . They aim high dynamic range , low dynamic range texture compression and high quality compression of sharp edges . The compression ratio for GLBPTCFLOAT and GLBPTC @ @ @ @ @ @ @ @ @ @ OpenGL 3.2 has been released about 6 months ago , that OpenGL 3.3 has been release at the same time than OpenGL 4.0 , I would like to say that OpenGL 4.0 is the most impressive work ever done by the ARB even if we still miss some important features . It provides the same hardware level of features than Direct3D 11 but some concepts are missing ( Command lists are missing but this is more a software king of think ) . <p> A set of big new features : Tesselation , programmable filtering , subroutines , programmable multisampling . <p> A set of small useful features : More compressed texture formats , cube map arrays . <p> A clear graphics cards range . <p> A good graphics API . <p> On the drivers side , all the work from the past 2 years by ATI is remarcable . The drivers are know solid on Windows . nVidia has still great drivers and has already published beta drivers for OpenGL 3.3 . OpenGL 4.0 beta drivers should be available at GeForce GTX 480 launch on the 26th of March @ @ @ @ @ @ @ @ @ @ tools follow , I really see OpenGL making it comes back as main API in games even on Windows . There is a long way before this happened but good signs keep popping from everywhere just like the recent news announcing Steam on Mac with actual game running OpenGL . <p> OpenGL 3.3 and OpenGL 4.0 are good graphics APIs and I think we are just 1 or 2 steps away from getting great APIs . I will cover , in the last series article , expectations ( or wishes ? ) for OpenGL 3.4 and OpenGL 4.1 that might fill the gasp separating OpenGL from awesomeness ! 
@@100664347 @4864347/ <p> The Royal Academy hosts David Hockney ( 1937- ) in a brilliant exhibition focussing mainly on his rescent work . <p> I discovered his work during this exhibition which made me pretty astatic : " amazing , beautiful , increadible ! " were the first words that came to my mind during the discovery . <p> The road acrossthe Wolds , David Hockney , 1997 <p> Garrowby Hill , David Hockney , 1998 <p> I would say that I rarely saw that much interest in the pictoral properties of the pictures . Great colorist , interest in season , space and perspectives : variations . <p> A lot of the work presented has been made for this exhibition which was an opportunity for David Hockney to scale up his work to the scale of the Royal Academy walls . It leads him to impressive multiple piece works like " Winter Timber " composed of 15 canvases of 91.4x 121.9cm each . <p> Winter Timber , David Hockney , 2009 <p> However , it seems that it was not big enough for David Hockney so that he works for @ @ @ @ @ @ @ @ @ @ spring in woldgate east yorkshire 2011 " to surround the visitors in a massive room with 32 canvases and 51 iPad drawings ( ! ! ! ) printed on paper recording this time frame . A new media for drawing is arising , almost shocking but this room was such a wonder that David Hockney simply gave it a legimaty . <p> The Arrival of Spring in Woldgate ( part one of a 52-part work ) , David Hockney , 2011 <p> The exhibition is running until the 9th April 2012 and absolutly worth the queuing ! 
@@100664348 @4864348/ <p> Compared to the previous OpenGL status , the major changes are the release of MacOSX 10.9 with OpenGL 4.1 which implementation is tested here and AMD drivers exposing a full OpenGL 4.3 support . <p> Unfortunately , MacOSX OpenGL implementation still suffers of major old flows : 1/ We ca n't render into an offscreen framebuffer larger than the window size . 2/ We ca n't delete shader objects once attached to a program object . Furthermore , only 67% of the OpenGL 4.0 samples are running correctly and only 43% of the OpenGL 4.1 samples . Tessellation OK , layered rendering OK , 64-bit float OK but separate shader programs , geometry instancing , multiple transform feedback streams , subroutines , texture gather , texture LOD query all broken ! And on top of that , there is no supported program binary formats . *oups* . Please Apple , your drivers are the worse of the OpenGL desktop ecosystem so just let the hardware vendor providing their implementations , thanks in advance ! <p> AMD OpenGL driver are now exposing full OpenGL 4.3 support but many issues @ @ @ @ @ @ @ @ @ @ are passing . Since April 2013 , 6 months ago , yes some bugs have been fixed but it seems that the OpenGL implementation have n't change too much . It 's very unfortunate to me . <p> NVIDIA implementation is such great quality that I did n't bother to update the previous drivers status with newer driver . <p> OpenGL feature set exposed by GPU architechtures <p> OpenGL samples passing on available implementations <p> I had some fun with OpenGL 4 manual derivative calculations . Sadly , it does n't work on Intel OpenGL implementation . 
@@100664350 @4864350/ <p> With ' No Love Lost ' , The Wallace Collectionis hosting a much unexpected exhibition . The artist behind it , Damien Hirst , is some kind of heir of the ' weird ' abstract painters where the place usually features classical or even baroque type of art . I personally love both the Wallace Collection and abstract painting but the meeting of both is an outstanding great idea ! <p> Hung in the traditional galleries of The Wallace Collection , your guests will be able to enjoy the visual dialogue between Hirsts works and the Old Master paintings displayed in the museums opulent galleries . <p> Receptions can be held throughout our stunning first floor galleries along side a remarkable array of masterpieces by artists such as Rembrandt , Titian Hals and Velazquez <p> ' No Love Lost ' exhibition contains only 25 pieces in two rooms but I believed I saw maybe 2 paintings that are going to stay in the history of art and at least in my memory as masterpieces . <p> One is called " Floating Skull " . It represents a skull @ @ @ @ @ @ @ @ @ @ makes the painting likes emitting lights . It displays the skull like a 3D object . As a result , the skull seems to free itself from the frame : absolutely stunning ! I think that anyone seeing it , notice how singular it is . <p> I would have love to put a picture of it but no picture can properly display what is does because its effect is mainly based on the reflection of the light , the paint material and the thickness of the brushstrokes . The only way I see to show this piece would but through real-time computer graphics ... It would be quite exciting as an experiment for me ! <p> The second one is called " Requiem , White Roses and Butterflies " and it shows bellow . Again , like with " Floating Skull " , it is remarkable how this painting ignore the frame to exist beyond it . The white perspective lines , the thickness of the roses and butterflies , the brushstrokes and the size of the painting generate a feeling of volume , of large empty space , @ @ @ @ @ @ @ @ @ @ Requiem , White Roses and Butterflies - Damien Hirst <p> An exhibition book is available with all the paintings of this exhibition . The quality is good but the paintings really need to be seen real . It 's not much text but it ends with a conversation between John Hoyland and Damien Hirst that just deserved to be read : Artists they came across , past stories , tastes , inspirations and ' fuck ' everywhere as proper British sentences need to be grammatically correct . <p> The exhibition is on until the 24th January 2010 for free but donations welcome and it should not be missed ! 
@@100664352 @4864352/ <p> Larry Clark ( 1943 - ) is a famous movie director , Kids ( 1995 ) , Bully ( 2001 ) and photographer who is mainly interested in the subject of youth who are part of a specific subculture . <p> At its launch , this exhibition has recieved a lot of attention thanks to a ban of minors . For an exhibition speaking of minors , that 's quite a statement ! <p> Obviously , I had a attent to such exhibition and I must admit that regarding only the content , it quite something but under 18 ban has always being used for porn in France and this is nothing like it . I would have prefer this exhibition to be ban under 16 , like movies of this type would be restricted in France . I have in mind for example " Sal+ , or the 120 Days of Sodom " LONG ... based on a novel of the Marquis de Sade LONG ... which is really a crazy thing compare to this exhibition but only ban for under 16 . Making the presence of @ @ @ @ @ @ @ @ @ @ quite an experience to see but nothing that shocking either . <p> I enjoyed these photographs beyond moral values and ideology but I kept a mix felling about them and about the creation process involves . The recorded moment have n't been lived when the photographs have been taken , I think these moments have being designed which results at kids showing what they want to show not really who they are . <p> All in all , it 's an interesting exhibition running until the 2rd of January for only 5. 
@@100664353 @4864353/ <p> The OpenGL Samples Pack 2.1 is a collection of OpenGL 2.1 samples ... So after OpenGL 3.3 samples I do downgrades ? Yes ! <p> This first version 2.1.0.0 is a Windows ( and probably Linux ) release but the goal is to bring the samples pack on MacOS X for next release . Because of Apple exclusively , MacOS X is way behind Windows and Linux in matter of OpenGL support and remains stock to OpenGL 2.1 + extensions ... not cool ! <p> I still have trouble to use CMake on MacOS X with OpenGL ... if anyone has an experience in this area , please send me a mail ! Thanks in advance ! 
@@100664354 @4864354/ <p> At GDC 2010 , the Khronos Group released two OpenGL specifications : OpenGL 3.3 , for OpenGL 3 hardware class ; and OpenGL 4.0 , for OpenGL 4 hardware class . Since then we did n't had any update of the OpenGL 3 specification , but it does n't mean that all the new extensions are designed only for OpenGL 4 hardware class . Actually a lot of them are OpenGL 3 hardware extensions or hardware independent extensions . In this post , we are studying AMD and NVIDIA OpenGL implementations of OpenGL 4 extensions on OpenGL 3 hardware . <p> It seems that Intel OpenGL implementation is becoming more relevant these days with the release of an OpenGL 4.0 drivers so that we might be able to target OpenGL 3.2 minimum ( Apple implementation on MacOS X 10.7 ) . I hope to come back soon with a discussion about Intel drivers but it might take some time as I do n't have an Ivy Bridge system yets . <p> There are some extensions released after OpenGL 3.3 which could have form OpenGL 3.4 but this is @ @ @ @ @ @ @ @ @ @ OpenGL 3.4 becomes a partial superset of OpenGL 4.0 and 4.1 ? I think , this would only fragment even more the OpenGL ecosystem which is already pretty fragmented as this rescent poll demonstrates . <p> The case of ARBshaderimageloadstore is quite specific . If we really look at it then it seems that most of the extension could be implemented on OpenGL 3 hardware . " Most of it " includes the load and store , the early-z and the memory barrier . AMD and NVIDIA implementations both supports NVtexturebarrier which is nothing less than a subset of ARBshaderimageloadstore memory barrier for texture memory transactions . This is a very important extension allowing rendering without framebuffer ping-pong on iterative image space algorithms . <p> There is no obvious equivalent to Direct3D 10.1 with OpenGL but if we consider OpenGL 3 plus a set of extensions we reach the equivalence . On contrary of Direct3D 11.1 , which monstlys add OpenGL features that were already here basically since its creation , we see from this set of extensions that Direct3D 10.1 added quite a few interesting features . On OpenGL @ @ @ @ @ @ @ @ @ @ on AMD hardware through the HD 3000 and HD 4000 series . On NVIDIA side , there is few low end GeForce 200 and 300 series supporting them on OpenGL 3 hardware class . Indeed , all these features are available on all OpenGL 4 hardware . <p> A lot of new extensions turns out to be hardware independent extensions shwoing a desire for redesign of OpenGL from the ARB : Texture storage which kills texture incomplete issues , separate programs which break the requirement of linked shader stages or debug output which actually says that debugging is the duty of the implementation not the application . <p> I am a huge fan of transform feedback and I believe that there are still under used and to become really useful we need at least a way to store the data in something else than 32 bits floats or ints . Does it make sense to store a color into four 32 bits floats ? Most of the time , no , it just consumes too much bandwidth . Nevertheless , AMD implementation had an early start to bring OpenGL 4 @ @ @ @ @ @ @ @ @ @ from HD 2000 series . <p> I often thought that it would be great to have #include with GLSL because what I really want to do most of the time is sharing structures for my varying and uniform blocks accross a maximum set of shaders . When I saw the release of **25;2031;TOOLONG , I was very exited at first but after reading it , I decided to stick to my home made methods : The extension make it so complex to use includes ! Actually , there is still no sample in the OpenGL Samples Pack demonstrating its usage . Also , I am a C++ programmer and I mostly did C and C++ programming for all my professional life so far and even most of my education ( I chose to forget the rest ... ) . Speaking with others programmers used to others languages , it now appears to me that there are alternatives to #include so maybe we should consider something else for GLSL than something which already feels like an odd hack in C++ . <p> OpenGL with its extension mechanisum provides a lot of @ @ @ @ @ @ @ @ @ @ effort . The desire for an OpenGL 3.4 specification comes from the need of cross platform support and shared code across platform which is certainly not optimal for performance but allows to release an application for a lower developers cost . With this post written , we can build our own OpenGL 3.4 using OpenGL 3.3 and a set of shared extensions across AMD and NVIDIA OpenGL 3 hardware . 
@@100664355 @4864355/ <p> GLM transformation functions take as a first parameter a matrix to transform by the transformation function . It could be not and simply build a transformation matrix to multiply after by this matrix . Because transformation matrix are filled with a lot of zeros , a dedicate implementation instead of the matrix product could be a lot more efficient . <p> I get though all these optimisations and the results are as expected . ' rotate ' from 900 cycles to 675 cycles , translate from 459 cycles to 153 cycles and scale from 432 cycles to 126 cycles . On Q6600 FPU ! <p> Finally , I write the code specifically so that compiler could easily optimized it for SIMD instructions but obviously my next step is to write a SIMD version . 
@@100664356 @4864356/ <p> It 's what I do that teaches me what I 'm looking for.1953 , Pierre Soulages <p> When it goes to France , I become , most of the time , quite extousiat . On the art creation side however , I sadly think that Paris is dead , that Paris rely on the nostalia of itself and whatever that seems to grow does n't last . This feeling have been reenforced by living in London and visiting Berlin where I felt finding life or like a friend tall me , it 's like Paris is close and Berlin is open . <p> Peinture , 300 x 235 cm , 9 juillet 2000 <p> France is n't just Paris , I have been surprised several times in the past of how dynamic and how creative the French province could be . Pierre Soulages is one of this artist that reenforces this idea . <p> Pierre Soulages is a French painter , borned at Rodez in 1919 and state as " the most known French living artist " . From his youth , Pierre Soulages has soon developed a @ @ @ @ @ @ @ @ @ @ would say he has been fascinated by a painting exploration and the relationships with the paintings . On the contrary of most abstract painting , Soulages works have n't been lead by internationalization but by his own explorations and experiences with his own paintings . <p> The reality of a work is the three-way relationship it establishes between the thing that it is , the painter who made it , and the viewer who sees it.Pierre Soulages <p> Pierre Soulages builds a real obsession for black that lead him in 1979 to create what he will called later ' Outrenoir ' . <p> Why black ? The only answer , which covers the unknown reasons that lurk in the obscurest regions of ourselves and of the powers of painting , is : BECAUSE . 1986 , Pierre Soulages <p> ' Outrenoir ' is an exploration based on the relationship between the light and the painting surface : Reflexions , direct and diffuse lighting , the chromatic subtlety and just the material as a ' thing ' . As a result a photograph of one of his late painting is n't @ @ @ @ @ @ @ @ @ @ and requires to be experienced . <p> Outrenoir to signify , beyond black , a light reflected and transmuted by black . Outrenoir : a black that ceases to be itself to become luminous , a source of secret light . Outrenoir : a mental space that is n't that of ordinary black . Pierre Soulages <p> Conscerning the exhibition itself , the layout is just great and were devised with Soulages who really care about how the painting are experienced by the visitors . Finally , a long video present the myth beyond Soulages which is absolutly fascinating . Like I say in these cases : Pierre Soulages is a real person . <p> Exposition presentation <p> La lumi+re du noir <p> I have been so amazed by his last work , by the quantity of the work it represents and that at 89 years , Soulage still continue to explore is topic and show new and interesting results . I would even say that what I prefer in this work , is what he did n't the past 10 years . This exhibition is displayed until 8th of @ @ @ @ @ @ @ @ @ @ if you do n't mind to much the huge crowd ... 
@@100664358 @4864358/ <p> The OpenGL Samples Pack 4.1.4.0 is released . The main change for this release is the new samples featuring the Direct State Access ( DSA ) API provided by GLEXTdirectstateaccess extension . <p> It is now available in both AMD ( since catalyst 10.7 ) and nVidia ( since more than 2 years ) drivers with an excellent support as I have n't found any OpenGL drivers bug yet even with more sophisticated projects than these samples . As it remains an EXT extension , all the samples using this feature use the post-fix ' ext ' . <p> A lot of OpenGL programmers are looking forward for this extension to reach OpenGL core and sooner or later it will happen as the previous OpenGL specifications have shown that the ARB believe it as well . However , this extension is not free of design issues as I have explained in an old OpenGL wishlist . Another area of problems with DSA is actually the lack of compleness that I would like to detail in this post . <h> GLEXTdirectstateaccess is written against OpenGL 3.0 specification <p> Originally @ @ @ @ @ @ @ @ @ @ the OpenGL 2.1 specification and published slightly after the OpenGL 3.0 specification and seen as the only light of hope for OpenGL after the big OpenGL 3.0 controversy . In January 2009 , the extension has been updated against OpenGL 3.0 which has been a huge improvement but OpenGL 3.2 was already release and some gaps remained and still remain . <h> 1 . DSA issues in OpenGL 4.1 specification <p> Since OpenGL 3.1 the ARB is considering the DSA approach when creating new entry point but unfortunatly some issues have appeared like the glBindProgramPipeline example I demonstrated . Basically , to create the real program pipeline object , the object name generated with glGenProgramPipelines need to be binded according to the specification . In practice both AMD and nVidia do n't follow the specification and rely on the DSA principles for this case but still , the specification is a issue . <h> 1.2 . Subroutines have a awkward behaviours mechanisium . <p> When I first tried the subroutine API , the least I can say is that I struggle . First , the all ' index ' and @ @ @ @ @ @ @ @ @ @ is not actually following the DSA principles . glUniformSubroutinesuiv has actually a odd behaviour as it 's a context state but each time a program is binded this state value is invalided ... which makes me feel it should be a program state using DSA . The ( odd ) explaination for this behaviours is to provide the possibility to switch context without resetting subroutines ... None of the rest of the API behave like that which makes it not consistent . My workaround is to set the subroutines each time the corresponding program is binded ... <h> 1.3 . Multisample textures do n't support DSA . <p> Multisample texture is a new feature of OpenGL 3.2 that creates an entry point glTexImage2DMultisample . The new functionnalities provided by the multisampled textures are a superset of what the multisampled renderbuffer provides so that in a way we can consider deprecated the renderbuffer functionnality . The only issue with that : No entry point is available in GLEXTdirectstateaccess , the ARB pretty much forgot to add a dependency to this extension in GLARBtexturemultisample so that a DSA entry point ( **30;2058;TOOLONG @ @ @ @ @ @ @ @ @ @ extension is supported . <h> 1.4 . The VAO API is conceptually an issue for DSA <p> I am really evil with VAO but is it really my fault ? The VAO keeps demonstrating how wrongly designed it has been and when I noticed that OpenGL ES has now a KHR VAO extension ... well , it does n't really made me happy to let this none sense survive in OpenGL . When I think about the VAO , my brain ends up like double locked threads . <p> The first issue is the GLELEMENTARRAYBUFFER binding point which is a VAO state . There is not precedent for glBind* functions being DSA function as all glBind* functions are context state expect this ( stupid ) case . My work around is to consider the GLELEMENTARRAYBUFFER state like a context state that I need to bind after the VAO object ... like subroutines actually . <h> 1.5. glVertexAttribDivisor has no DSA version <p> OpenGL 3.0 was released with a serie of extensions that was n't part of OpenGL 3.0 specification which includes GLARBinstancedarrays , the promoted version of GLNVXinstancedarrays , an @ @ @ @ @ @ @ @ @ @ instancing and written against OpenGL 2.1 . Unfortunately , this extension reached OpenGL spefication only in OpenGL 3.3 but has been integrated ' as it is ' which implies no GLEXTdirectstateaccess dependency and DSA support which in practice makes the use of DSA with VAO no possible . <h> 1.6 . Transform feedback buffer <p> OpenGL 4.0 has brought significant improvements to transform feedback functionnalities even if I still think we need more . OpenGL 4.0 integrates GLARBtransformfeedback2 which add a transform feedback object moving some context states to this new object . OpenGL handles these states using glBindBufferBase a function that does n't have DSA version , like other glBind* functions ... <h> 2 . A bit of perspective on DSA <h> 2.1 . The ideal <p> An interesting point with the DSA approach is the hability of designing a graphics engine without the constraint of handeling the update and the draw phases together but instead seeing them as 2 separated use cases so that the update phase does n't have conscequences on the draw phase stage . This design philosophy makes the graphics engine design much simpler , @ @ @ @ @ @ @ @ @ @ avoid the question of rebinding or resetting states . Finally and maybe most importantly , DSA is really less error prone ! <h> 2.2 . The practice . <p> Unfortunately , in practice a full DSA design approach is n't fully possible simply because the OpenGL DSA support is n't completed yet as demonstrate in section 1 . However , there are already some good parts which will singnificantly improve designs . <p> glProgramUniform allows to set the uniform values without having to bind a program or ' play ' with the selector glActiveShaderProgram introduced with OpenGL 4.1 for separate programs . This is such a great improvement which makes possible to avoid using delayed calls to set uniform variables without constantly binding programs . <p> The other really interesting point is the hability to update buffer and texture objects without affecting the binded buffers for a draw call . This is a great opportunity for data streaming/vitual texture and actually any scenario where the programmer wants to build an advanced and customized buffer and/or texture manager . 
@@100664363 @4864363/ <p> CryEngine ... what a good name for what is still just the most amazing real time graphics engine today for me but I guest for most graphics programmer ! <p> And Crytek write a press release : The CryEngine 3 will be presented at GDC 2009 ( March 25th - 27th ) in San Francisco . So exiting ! But what could we actually espect ? <p> According the press release , the development team increase multi platform support to PS3 and XBox 360 which imply OpenGL , D3D9 and D3D10 support . However , no comment have been made in the graphics improvement but is it really disappointing ? <p> Multiplatform support was really an issue of the CryEngine 2 over the Unreal Engine 3 and honestly when you look at Crysis even now , do n't you have still the moment where you have this string filling that stock you there : " Whahouu , this is freaky amazing ! " <p> For sure when I look at the shadows , I think it 's good but not really estonishing . The flicking draw back of @ @ @ @ @ @ @ @ @ @ illumitation is still very cheap . The terrain rendering is really impressive but SM4 provides quite some capabilities that could lead to better rendering and high performance . Here is four areas when I espect to see improvements in very high quality . Other tech improvement could be better the management of multi core CPUs . Crysis uses just single core for everything in game . <p> I ca n't way to blow my eye , my mind with picture , video and tech presentation ! Take a gasp ... we are going to cry ! 
@@100664364 @4864364/ <p> Like many people who owns a MacBook Pro ( or any Mac ) I upgraded my system with a brand new OS : MacOS X Lion ... then I wondered if anything actually happen . No , I am not disappointed because this -21 brought me OpenGL 3.2 core support on my good old MacBook 13 " I carry everywhere . <p> It seems that Apple decided to make a clean cut on legacy providing two OpenGL implementations . One is the old OpenGL 2.1 for compatibility with legacy software and one which is the OpenGL 3.2 core profile but the OpenGL 3.2 compatibility profile is n't supported . <p> UPDATE : I previously wrote that AMD OpenGL drivers did n't support the compatibility profile which is a mistake . When creating a default contect , this context will be an OpenGL 4.1 compability profile implementation . <p> The cut is clean because the legacy features are not only removed from the core profile , there are also removed from the set of extensions exposed by the drivers . <p> This is really few extensions so we could @ @ @ @ @ @ @ @ @ @ . Looking at it maybe some extensions dependency have n't been considered . For example , EXTtexturesRGB is an extension part of OpenGL 2.1 core specification but only partially because this extension has a dependency on **25;2090;TOOLONG . Because of the S3 patent issue here , **25;2117;TOOLONG is not part of the OpenGL code specification neither can be dependent features . If EXTtexturesRGB is not available then we might not have sRGB support for S3TC texture formats . However , I have no doubt that in fact sRGB on S3TC texture formats is actually supported . <p> Finally , for people who were surprized that Apple brought back Intel Chips in their hardware : You were right ! As the OpenGL Capability Matrix shows , the OpenGL 3.2 implementation is not supported on Intel HD 3000 platform like the brand new MacBook Air and MacBook Pro 13 " . 
@@100664365 @4864365/ <p> The result of this collaboration is wonderful and visually appealing objects which provides new experiences to play music that , along the exhibition , visitors are invited to discover by playing with these instruments . <p> This exhibition has been one of the most stunning I have ever been . Most of the time , I find art pieces great but for someone else living room but this time , I would have love to leave with a couple of instruments ! <p> An exhibition that should not be missed , one of my favorite this year ! 
@@100664367 @4864367/ <p> The OpenGL Samples Pack 4.1.5.1 is a revision which updates the external libraries used , fixes few bugs and add a couple of new samples . <p> One of the main problems fixed is that a lot of OpenGL 3.3 samples were using some functions that are not OpenGL 3.3 but OpenGL 4.0 or 4.1 . I did n't notice any used and as the extension are exposed the functionalities can be used but no extension checking were either done ... This is in a way just a change for the sake of pedanticity . <p> I have also added a really simple sample showing the use of **25;2144;TOOLONG to texture a quad . This is as simple as it can get but AMD drivers does n't handle it properly . I figured out a way to make it works on AMD but this solution did n't seem to follow the spirit of this extension . It 's very possible that this extension specification totally lack of accuracy to be implemented correctly . I personnally had quite some difficulties to figure out how to do right this sample ... 
@@100664370 @4864370/ <p> The OpenGL Samples Pack 4.4.2.0 leverage the work on the new framework introduced in 4.4.1 by adding 26 new OpenGL samples . They essentially focus on catching up with OpenGL 4.4 , 4.3 and ARB extensions functionalities . <h> A look at point rendering <p> Point rendering with OpenGL is a mess . I do n't know how it is with other APIs but that 's something I 'd like to get better . The following screenshots are based on **27;2171;TOOLONG sample but it produces pretty difference outputs for each vendors . <p> AMD point rendering : The green point is clipped because its center went outside the window <p> Intel point rendering : The green point is clipped because its center went outside the window and the point size is clamp to it 's maximum . <p> NVIDIA point rendering : Render the three points with guard band clipping which is not a standard behaviour <p> NVIDIA not following the specification is the only approach that really makes sense . Clipping at the point center leads to visible popping artifacts on the border of the window . @ @ @ @ @ @ @ @ @ @ , Intel and NVIDIA maximum point sizes is respectively 8192.0 , 255.0 , 2047.0 pixels . The drivers are pretty buggy with these as AMD , Intel and NVIDIA drivers report respectively 63.0 , 20.0 and 189.875 . If we look at the code to query the point size , the fixed function queries return the numbers we can observe but the programmable query returns wrong numbers . <p> Querying min and max point sizes : <p> // Fixed function min point size , compatibility profile only : <p> **26;2200;TOOLONG , &amp;POINTSIZEMIN ) ; <p> **26;2228;TOOLONG , &amp;POINTSIZEMAX ) ; <p> // Programmable range point size , returns min and max in one query : <p> **28;2256;TOOLONG , &amp;POINTSIZERANGE0 ) ; <p> One possible alternative is to use geometry shader to expand each point into a triangle strip so that each point is clip as a quad . This provides reliable rendering as we can see with **27;2286;TOOLONG sample . OpenGL ES does n't support geometry shader but also specified a different clipping rule for points which is no clipping at all which effectively behaves like NVIDIA implementation . 
@@100664371 @4864371/ <p> An original feature , this performance takes advantage of videos and animations . I love the use of new media in art but most of the time I think it looks inappropriate or overused . In Yesterday , it was just a perfect appropriation of " new technologies " ! <p> Yesturday <p> Yesterday is mainly based on dance but it involves so much creativity and so many ideas to illustrate , to build the performance and makes the audience fully experience it . With dedicated dancers and the energy they give on stage , Yesterday is an emotional travel from laugh to pain again an again through the different scenes . <p> I notice a dancer during the performance that amazed me by her commitment . After some researches , I found her name : Mafalda Deville . <p> Yesturday <p> In 2009 , I saw many exhibitions and performances but if I had to choose just one , it would be Yesterday . The creativity , the commitment , the passion , the perfect uses of the media reasserts the notion of true beauty and forms the greatest of art performances . 
@@100664372 @4864372/ <p> The time pass but my enthusiasm for Git continues to glow ! Actually , it seams that I am not the only one to enjoy Git as surprisingly my last article on Git became the most read post ( if I can rely on my website statistic ... ) before a lot of OpenGL articles as it can be expected . <p> One great tool with Git is Gitk . I was using it on the OpenGL Samples Pack and suddenly I was amazed by the graph Gitk gave me : A demonstration of the effectiveness of a development process based on Git ! With Git , it 's so easy to work on different things , on different version ... in parallel ! <p> The yellow labels are tags that I use as releases markers and the green labels are branches . Enjoy the branches communications . <p> With the OpenGL Samples Pack the graph is quite complex relatively to the project size . However , it 's just what I need and this is where it 's a success story . G-Truc Creation website development is @ @ @ @ @ @ @ @ @ @ ( quite boring one actually ) graph but it 's still just what I need . <p> In conclusion , I would like to say that Git allows a flexible way to develop a project where features does n't need to be locked into #define but are instead manage by the Version Control System ... just like it should be ! Git makes easy and nice the process of building the feature list of a release using a version branch and several feature branches . If a feature is n't finish for the release , it 's easy to delay it to a future release and if the development of a feature fail or get cancelled , it 's easy to discard it without polluting the code . A whole strategy to build better software but also , I insist on the importance of it , software nicer to work on . 
@@100664377 @4864377/ <p> Splits x into a floating-point significand in the range 0.5 , 1.0 ) and an integral exponent of two , such that : x = significand * exp ( 2 , exponent ) <p> The significand is returned by the function and the exponent is returned in the parameter exp . For a floating-point value of zero , the significant and exponent are both zero . For a floating-point value that is an infinity or is not a number , the results are undefined . <p> If genTypeU is a boolean scalar or vector : Selects which vector each returned component comes from . For a component of that is false , the corresponding component of x is returned . For a component of a that is true , the corresponding component of y is returned . Components of x and y that are not selected are allowed to be invalid floating point values and will have no effect on the results . Thus , this provides different functionality than genType mix ( genType x , genType y , genType(a) ) where a is a Boolean vector . @ @ @ @ @ @ @ @ @ @ by the implementation , presumably the direction that is fastest . This includes the possibility that round(x) returns the same value as roundEven(x) for all values of x. 
@@100664380 @4864380/ <p> OpenGL 4.1 includes the new extension called GLARBvertexattrib64bit " which trivially adds support for double precision floating point scalars and vectors for the vertex attributes . OpenGL already provides such support but usually the double values are converted to single precision floating point values . This extension ensures that this precision will be kept . An important detail is that double attribute can consume more than one location which will have some consequences in the software design . This behaviour is n't new as GLARBgpushaderfp64 introduced it for double uniforms . <p> OpenGL 4.1 also integrates GLARBshaderprecision which is the first extension that defines no value , API functions nor GLSL functions . It simply clarifies the accuracy of various GLSL functions . <p> a+b , a-b , a*b : correctly rounded <p> &lt; , =&lt; , == , &gt; , &gt;= : correct result <p> a/b , 1.0/b : &lt;= 2.5 ULP <p> a*b+c : correctly rounded single operation or sequence of two correctly rounded operations <p> fma() : same as a*b+c <p> pow : &lt;= 16 ULP <p> exp , exp2 : &lt;= 3 ULP <p> log @ @ @ @ @ @ @ @ @ @ 3 ULP <p> inversesqrt : &lt;= 2 ULP <p> conversions : correctly rounded <p> All in all the proper OpenGL 4 hardware features are quite minors unlike what I was expecting but it provides much more interesting features which would actually work on OpenGL 2.1 and OpenGL 3 hardware . <p> OpenGL 4.1 comes along with a new ARB extension which is just so great that I want to speak about it first : With GLARBdebugoutput , the ARB has finally shows some mercy for us OpenGL developers by providing a more advanced mechanism based on callbacks than glGetError for debugging . This extension brings a new era for OpenGL ! <p> GLARBdebugoutput is an extension only and will probably stay as an extension as the ARB thought it is just good for developers , leaving the possibility of user of OpenGL applications to not have such feature . This may imply 2 types of OpenGL drivers in the future , one for developers and one for users . This is an interesting idea even if I actually see in the debug output capabilities , a way to generate a @ @ @ @ @ @ @ @ @ @ drivers and through GLAMDdebugoutput on AMD drivers . For this extension " supported " does n't mean much because it could just return the glGetError but we can also imagine more accurate messages so that it will be the reponsability of AMD and nVidia to make the best of this extension on a long term development process . <p> It allows to independently use shader stages without changing others shader stages . I see two mains reasons for it : Direct3D , Cg and even the old OpenGL ARB program does it but more importantly it brings some software design flexibilities allowing to see the graphics pipeline at a lower granularity . For example , my best enemy the VAO , is a container object that links buffer data , vertex layout data and GLSL program input data . Without a dedicated software design , this means that when I change the material of an object ( a new fragment shader ) , I need different VAO ... It 's fortunately possible to keep the same VAO and only change the program by defining a convention on how to communicate @ @ @ @ @ @ @ @ @ @ works well even if some drawbacks remains . <p> With the separate programs , the fragment shader and vertex shader stages can be independant so that we are free to change the fragment program without touching the VAO . Finally ! It 's incredible all the conscequences of an awfully designed API ( VAOs ) ! <p> So just like Direct3D , OpenGL support separate programs but actually and we should get use to it , OpenGL outperform the Direct3D design . We have had a single program for ages for some reasons : the resource by name convention that requires a linking step across stages but also because it allows some effective compiler optimizations . From those , the one I rank number 1 discards all the unused varying variables ... This consideration has an impact on the design decision of the extension . <p> **27;2315;TOOLONG is a superset of **27;2344;TOOLONG extension including just the right improvements to transform a badly design extension to a great extension . With the ARB version , a new object called pipeline program object is used to attach multiple programs . Also , @ @ @ @ @ @ @ @ @ @ instead of the deprecated varying variables ... GLSL programs can contained multiple shader stages so that multiple stages can be linked and optimized all together . Chances are that vertex , control and evaluation shaders will be design to be use all together and conscenquently we can apply some extra optimizations by linking them . Finally , **27;2373;TOOLONG defines direct state access functions glProgramUniform* for all the glUniform* functions ! <p> Another feature we have been waiting for a long time : Program binaries . I must say , this is one topic I have n't followed closely nor thought about it but for what I have understood , the capabilities of loading and saving GLSL binaries provided by GLARBgetprogrambinary and OpenGL 4.1 is just a subset of the wishes out there . <p> I 'm not sure about how useful this is . This extension comes from the OpenGL ES extensions GLOESgetprogrambinary with a subtle change which favour the retrivable of the program binary after being used or at the end of the program ... and here is my problem . A GLSL program is sometime rebuild considering the @ @ @ @ @ @ @ @ @ @ per program . What actually involves a linking of the program ? This is fairly undocumented so far but I have high expectation from GLARBdebugoutput for that regard . <p> The goal is not to be able to release a software without the GLSL source . A GLSL binary is platform dependant and loading a GLSL binary might fail which involves GLSL sources rebuild . We might see some standard binary formats in the future but so far there is nothing in the OpenGL world . However , binary formats has been present on the OpenGL ES world for a while and many propritary extensions have been released : GLAMDprogrambinaryZ400 , GLIMGprogrambinary , GLARMmalishaderbinary . <p> Conscequently , the program binary is just a cache system for GLSL binaries ... It is really going to make the loading significantly faster ? I have some doubt about it . <p> One difference from Direct3D and OpenGL is that OpenGL allows multiple rendertarget having different sizes . This is actually a contain relaxed from GLEXTframebufferobject when is has been promoted to GLARBframebufferobject and OpenGL 3.0 . Interestingly , this capability seems to @ @ @ @ @ @ @ @ @ @ G-Buffers at various resolutions ( and hence saving some memory bandwidth ) in a single pass before the final G-Buffer compositing for example . I also imagine some interesting use for cascade shadows using layering rendering . It might look like a small feature at first look but for the rendering technique side , it 's actually a key feature from which I expect a lot of performance benefits in lot of cases . <p> To use the extra viewports , GLSL includes a new variable called glViewportIndex that can be written in the geometry shader . <p> It could be hard to believe but OpenGL ES 2.0 has features that OpenGL 4 did n't had until OpenGL 4.1 . GLARBES2compatibility is the last extension integrated to OpenGL 4.1 . This extension is fairly a boring one that only aims completeness and to ensure that OpenGL 4.1 is a superset of OpenGL ES 2.0 . Chances are , I 'm never going to use any of the new functions : glReleaseShaderCompiler allows to unload the GLSL compiler to save some memory ; glShaderBinary to load shader binaries ... but we @ @ @ @ @ @ @ @ @ @ each variable types ( GLLOWFLOAT , GLMEDIUMFLOAT , GLHIGHFLOAT , GLLOWINT , GLMEDIUMINT , GLHIGHINT ) . What if the variable is a uvec* ? ; glDepthRangef and glClearDepthf which takes float parameters instead of doubles . Finally , glVertexAttribPointer can take GLFIXED for its type parameter , for fixed point data . <p> Features for the sake of ... something , why not but I would mark most of them as deprecated . <h> A bunch of things for WebGL <p> I quite believe that a lot of things released with OpenGL 4.1 have been done for WebGL . It 's incredible the entousiam around this technology , probably higher than OpenCL . WebGL involves a large number of developers and users in a medium term : basically everyone all in all ! WebGL is based on OpenGL ES 2.0 so that we really need OpenGL ES 2.0 features on desktop . OpenGL 4.1 contains all the OpenGL ES 2.0 features hence WebGL implementations can rely on OpenGL 4.1 drivers to implement all the features . To reinforce OpenGL ES 2.0 on desktop , an OpenGL ES 2.0 profile @ @ @ @ @ @ @ @ @ @ , this way it will be easier for low-end OpenGL implementations to support OpenGL ES 2.0 and it is n't require to load a large amount of function pointers that anyway should n't be used in a WebGL environment . <p> Following the WebGL requirements , I think the ARB also build the following extensions : **29;2492;TOOLONG , **29;2523;TOOLONG and GLARBrobustness which introduces functions which prevent buffer overflows in a similar way that strncpy is for strcpy ... These extensions will be a great use for Chrome developers , Firefox developers , Opera developers , Safari developers ( Internet Explorer developers ? ) and we really want them to do a good use of them , but for the rest of us , I 'm not sure . <p> OpenCL has made steps toward OpenGL since its release through extensions but for once it 's OpenGL which make a step toward OpenCL with the release of the extension GLARBclevent . This extension only allows to create an OpenGL sync object from an OpenCL sync object for more efficient images and buffers sharing between the 2 APIs . <p> Finally , @ @ @ @ @ @ @ @ @ @ on the stencil buffer . GLARBshaderstencilexport allows to write the reference value of the stencil test from a fragment shader which actually means writing into the stencil buffer when glStencilOp is set to GLREPLACE . <h> Conclusions <p> OpenGL 4.1 has reach Earth in a quite different way I expected it . I expected a OpenGL 4 hardware oriented release but it 's definetly not the case and actually it comes closer to my wish-list than my expectations . <p> Unfortunately , OpenGL 4.1 does n't include GLEXTdirectstateaccess as a lot of people would expect . However , AMD as release drivers supporting this extension so that I presume that the ARB has an agreement on the goods of this approach . Moreover , OpenGL 4.1 integrates through **26;2554;TOOLONG a subset of the direct state access extension . Thus , I think we have here an idea on how the ARB want to bring this approach in core . I do n't think that the deprecated feature will ever have direct state access in the OpenGL Compatibility profile . From my point of view , this would be for the @ @ @ @ @ @ @ @ @ @ access will probably reach core through new extensions . <p> Finally an angry word about the lack of conscistency of this new 4.1 specification . It 's almost unbelievable ! Sometimes it 's so obvious that I stay stunned . I might be able to find in every extension something which does n't follow the OpenGL convensions . This is a growing concern I have seen the OpenGL 3.0 release . OpenGL is a specification where every single word and API token mean something and it actually defines in the specification ... at least , it uses to be . For example , OpenGL 3.0 introduces " geometry shader " while this stage was already cleary defines in the specification by " primitive " . What is a " geometry " in OpenGL ? Do n't ask me I have no idea , it 's undefined . OpenGL 4.1 is now using the token location and index for about everything , confronted to an API declarations or a specific paragraph it happens very often that the uses of some tokens is misleading . OpenGL 4.1 now introduces some new tokens @ @ @ @ @ @ @ @ @ @ set of while arrays have been clearly defines since OpenGL 1.1 . I quite believe that the overall " blocks " concept is mostly unspecified leading really different implementations on AMD and nVidia drivers . etc ! ! ! 
@@100664382 @4864382/ <p> Last summer at Siggraph 2010 , I won 2 licenses for gDEBugger ( one GL and one CL ... ) answering Trivia questions at OpenGL and OpenCL BOFs . A while after , I got my license but gDEBugger licenses are attached to a specific platform and I was on an ongoing process to upgrade my computer with a new CPU and motherboard . About a month ago , I contacted Graphic Remedy to get my license updated for my new platform as I made sure with them I could do earlier . No answer and actually still none Actually , gDEBugger was n't on sale anymore . Its finally today that I discovered why : gDEBugger is now free of use ! This raise the question on how Graphic Remedy is going to finance itself in the future and I expect an official statement anytime soon and hopefully good news . <p> gDEBugger is an OpenGL and OpenCL debugging and profiling program . It is the Open*L counter part of Direct3D 's Pix but probably much more confidential as it was extremely expensive so that many people actually @ @ @ @ @ @ @ @ @ @ on the regard of GLSL step by step debugging . gDEBugger allows breaking an OpenGL program execution , visualisation of the framebuffer , the textures , the buffers values but also realtime editing and rebuild of GLSL programs . To tune the performances , gDEBugger makes easier finding bottlenecks by interactively enable and disable draw calls , raster operations , textures fetches or GLSL program stages . <p> It is available on Windows , Linux and MacOS X but it only supports OpenGL 3.2 , OpenGL ES 1.1 and OpenCL is still in beta . <p> Next move for OpenGL ? Obviously , gDEBugger has to catch up with the lastest OpenGL 4.1 , OpenGL ES 2.0 and finalizes OpenCL support but this is just a piece ( a master piece ) in the developer environment . More OpenGL specification improvements , more OpenGL drivers improvements , more documentation and more and better tools are still required . <p> A perfectly elaborated Chess game strategy , moving toward modern OpenGL programming for OpenGL everywhere for everyone . 
@@100664385 @4864385/ <p> I recently discovered a new good 3D graphics mathematics book which launch again this essential debate : Which book is the best ? There is a lot of 3D graphics math books , I 'm far from liking them all . Let 's talk about my two favorites ones . <p> For year I had my favorite : Mathematics for 3D game programming and computer graphics . Its deal with all the topics that all book deal with : vectors , matrices , transformations , projections , geometry , etc ... This is completed by quaternions , curves , surfaces but even some physics topics , good enough for quite some fun ! A width range of chapters are also dedicated to intersection for visibility determination , collision detection and raytracing . Finally , chapters are dedicated to proper graphics theory like the rasterization pipeline shading and shadows . Just with this book a developer have quite some materials to archive a good demo ! <p> The way this book is written is maybe the best ! Quite theoretical but illustrated with drawing , some code and some @ @ @ @ @ @ @ @ @ @ really like : Essential mathematics for games and interactive applications . It wo n't surprise any person who know both books . There both share the same pedagogy and the topics are quite similar . I think that it 's almost a waste of money to own both of same . However , I have especially notice the chapter titled " real world computer number representation " but in other hand the shadow part is quite brief . <p> My final thought I have to admit , I 'm a huge fan of Mathematics for 3D game but considering the overall , I think that Essential Mathematics is now slightly better . If you already have Mathematics for 3D game , no need to waste any money . You need a new reference , have a look on Essential Mathematics ! 
@@100664386 @4864386/ <p> To test my current framework , I made an update of my raytracer : It uses GLM and GLI . <p> More than 2 years since the previous release , the code has changed a bit but feature wise it 's basically the same raytracer beside few tricks . Intersection with spheres and plans only , I pay much more attention on materials . I just find it much more fun to play with at the time I did it ! <p> Glossy reflexion et reflaction . <p> Adaptative antialiasing . <p> Soft shadows . <p> Procedural materials . <p> Glossy refraction surfaces <p> Soft shadows and ... a bug : / <p> I expect to release a version 1.2 which will support multithreading with OpenMP but also some optimisations allowing the compiler to generate a faster SIMD code . In the end , I will use this raytracer to evaluate Visual Studio 2010 like I did in the past . 
@@100664388 @4864388/ <p> The OpenGL 3 Sample Pack is a collection of OpenGL 3 samples based on " Core " features . OpenGL 3.1 drivers are required for most samples but a sample requires OpenGL 3.2 . <p> The purpose of this samples pack is just to document the new API with some code to get started with a modern way to use OpenGL . <p> This project is using SDL 1.3 beta to create a window with an OpenGL 3 context , GLM 0.8.4.1 as a math library and a replacement for deprecated OpenGL fucntions and GLI 0.1.1.0 to load images , either compressed or not . <p> Added buffer type sample <p> Added buffer update sample <p> Added draw instanced sample <p> Added FBO mipmaps sample <p> Added GLSL 1.4 block sample <p> Added GLSL 1.5 block sample <p> Added Image 2D sample <p> Added Image Array 2D sample <p> Added Compressed Image 2D sample <p> Added Image Rectangle sample <p> Added Rasterizer sample <p> Added Vertex Array Object sample <p> 12 samples are included in this first release but a lot more samples are on their ways , @ @ @ @ @ @ @ @ @ @ future releases ! 
@@100664391 @4864391/ <p> The announcement of Mantle few months ago has triggered a lot of discussions about gragphis API design . I think there are technical issues in OpenGL but those are precise problems that needs to be solve individually and following the hardware designs . These redesigning an entier API might be fun , it is keeping marketing people buzy and it makes OpenGL people communicating about how good is OpenGL . <p> What I like with Direct3D is that Microsoft was important enough to drive IHVs to standardize hardware features . The Khronos Group is certainly getting better at it , the ASTC texture format is a good example as I expect this format will be supported on all mobile and desktop GPUs in the future . How strong is Microsoft these days ? This is something we will be able to judge at GDC . <p> What 's an OpenGL 5 hardware feature ? Following the conversions for OpenGL 3 and OpenGL 4 , it 's any hardware feature that ca n't be implemented on all OpenGL 4 hardware but would be implementable on newer hardware by all @ @ @ @ @ @ @ @ @ @ point at hardware features available through OpenGL extensions and ideas that may or may not be interesting to standardize . As we will see , there is a lot of great features that could build this OpenGL 5 and Direct3D 12 hardware generation . <h> Draw submission <p> Multi draw indirect is part of OpenGL 4.3 core specification but it 's arguably an OpenGL 5 hardware feature allowing the GPU to submit itself draws to be executed . This feature can be implemented through software emulation quite easily using the CPU to push each individual draw but this is really slow . Currently , all the Intel GPU and AMD Evergreen support multi draw in software . Hardware implementation gives another magnitude of performance . <p> With 800000 draws per frame at 60Hz on Kepler and 300000 draws per frame on Southern Islands with a syntheric test rendering 2 triangles per draw on 4 pixels . That huge amount of draws provide an amazing control over the rendering . <p> With OpenGL 4.3 we got shader storage buffers that we can use in place of vertex array object for programmable @ @ @ @ @ @ @ @ @ @ a custom vertex format . To make that approach really useful we were missing access of some useful draw arguments in the vertex shader stage . With this extension we get glBaseVertexARB and glBaseInstanceARB that reflect the draw arguments but also glDrawIDARB , an equivalent of glInstanceID for draws . <p> Only NVIDIA implements this extension at the moment but it should be implementable by Southern Island . However , the performance of glDrawIDARB are poor compared with a dedicated vertex attribute with divisor 1 and a BaseInstance . <p> One idea with multi draw indirect is to use a compute shader to generate the indirect draw buffer . However , with GLARBmultidrawindirect the number of draws is submitted to the GPU through a draw call parameter . Hence , if we generate the list of draws with a compute shader , then we need to query the number of draws to submit it back to the GPU . With GLARBindirectparameters , the number of draws can be stored into a buffer object . <p> This extension is really ugly but the functionnality is really interesting . Instead of having @ @ @ @ @ @ @ @ @ @ can have up to 4 element arrays and we can index each vertex attribute with the element array of our choice . There is quite a few software actually generating meshes using multiple element array so this functionnality sounds extremely useful . Taking advantage of this feature can save bandwidth avoiding duplicating vertex attributes . <h> Resources <p> Bindless resources is a feature supported by Kepler and Southern Islands architechtures . When we bind a texture , the drivers write a texture descriptor in a special location in the GPU . The number of these special locations is fixed , 32 on OpenGL 4 / Direct3D11 hardware . With bindless textures we pass a handle ( a pointer ) directly to the shader stages . The shader invocations fetch and cache the texture descriptors . This approach gives access to an unlimited number of textures but there is chances for texture descriptors cache miss so we need to keep access coherence which multi draw indirect and dynamically uniform expression can provide by design . <p> With OpenGL 4.4 NVIDIA provides bindless buffers but this is still something that we need @ @ @ @ @ @ @ @ @ @ virtual memory supports of GPUs ( Fermi and Southern Islands ) . A sparse texture can be used to create " giant " textures bigger than the graphics card memory size for virtual texturing . AMDsparsetexture is more powerful as it adds shader queries to figure out in a shader invocation whether a texture page is commited or not . <p> There are quite some obvious features that would nice to have : The possibility to share the same texture tile for two texture pages without consuming twice the memory but also the support of actual giant textures . Sparse texture sizes are currently bound to the same limit than non-sparse textures . 16384 * 16384 for a 2D texture it 's big but for a virtual texture , not really . Texture stitching could be an option for large virtual texture where we would use multiple texture 2D array layers and allow filtering accross these layers . Lastly , supporting sparse shadow map would be great and could simplify a lot the shadow rendering by using very high resolution shadow but allocated only where it matters . In ARBsparsetexture @ @ @ @ @ @ @ @ @ @ has standardize a new texture format called ASTC that provides very low bit rate and HDR support . Because , it 's a KHR extensions , it means that both the OpenGL ES group and the OpenGL ARB group voted to support that feature which gives me good hope that we will " soon " have support for this format on all platforms . <p> This feature allows to map the storage of a texture 2D just like we can do it with a buffer . The extension supports linear and tiled formats however if this feature had to be standardize only the linear storage could be supported accross current GPUs . However , linear storage is texture cache inefficient . Each GPU tile format is vendor specific so if we had to have that feature , the texture layout would have to be standardize . <p> Seamless cube map filtering is a functionnality that is globally enabled . AMD Radeon HD 4000 introduced the possibility to toggle this feature for each cube map . Globally enabled seamless cube map is already not that useful but having that toggle for @ @ @ @ @ @ @ @ @ @ for this feature as well . As least that per texture toggle works fine while the global toggle is clunky on all available OpenGL implementation . <h> DMA engines <p> NVIDIA Fermi and AMD Northen Islands have dedicated DMA engines that can live their lifes on their own . Hence a dedicated thread can could be in charge of streaming ressources because at some point the application figure out that they might become useful . During these transfers , the graphics engine can continue his life independently without any required synchronisation . Obviously , the transfers would have to be completed before using the resources but with enough anticipation we could need a synchronisation object only for the purpose of garantying correctness on all possible hardware but without actually hitting that fence . <p> Currently NVIDIA supports this behaviour but only by creating a separated context on a dedicated thread . This is workable but cumbersome and it costs thread safety pernalty for the entire OpenGL implementation . <p> An explicit use of the DMA engine for fully asynchronous transfers and performing transfer outside of the rendering code would be @ @ @ @ @ @ @ @ @ @ extension is the first for a new kind of idea : " Maybe we can make per warp/wavefront decision or work " . For example , let 's say that we are rendering some objects but an area that we cover is actually blurry . Maybe , it is n't very usefull to use the nicest lighting equation for these pixel . If we make this decision per shader invocation we will trigger complex branching mechanisum . If we make this decision per wrap/wavefront we will trigger simple jump instructions keeping performance high . <p> This extension goes into the " super resolution " range of idea where we no long want to think at a fixed pixel resolutions but instead we want to think at higher or lower resolution than the native resolution . GPU does n't actually excute anything on a per pixel or per vertex base but in many different kind of grouping . The warp/wavefront is the grouping for shader invocation and another famous one is the quadpixel , a set of 4 fragments . The texture LOD calculation is computed per quadpixel because it is @ @ @ @ @ @ @ @ @ @ texture LOD computation but it is really easy to compute within a quadpixel : It 's only the different between the values across quadpixels . <p> This extension gives access to quadpixels allowing to swizzle the intermediate results accross each fragments . Let 's say that fragment shader requires 4 texture sampling . In some areas , we could consider that it is not that usefull to sample per fragment and we can deal will sampling per quadpixels . This feature should interact pretty well with GLARBshadergroupvote . <p> This extension extends GLNVshaderthreadgroup to any of the shader invocations of a wrap/wavefront . It seems very likely that we could use GLNVshaderthreadgroup on any GPU because all GPUs use quadpixels however , the warp/wavefront size is different for each GPU vendors . 32 for NVIDIA , 64 for AMD and variable for Intel , between 4 to 16 according to the cases . This feature sounds particularly useful for post processed antialiazing and maybe things like soft shadows . <p> ARBshaderatomiccounters and OpenGL 4.2 introduced the concept of atomic counter operations be those where limited to increment , decrement and @ @ @ @ @ @ @ @ @ @ memory which is faster than image and buffer atomic operations . However , AMD GPUs support more atomic operations from GDS : Increment and decrement with wrap ; addition and subtraction ; minimum and maximum ; bitwise operators ( AND , OR , XOR , etc. ) ; masked OR operator ; exchange , and compare and exchange operators . **27;2582;TOOLONG exposes all these operations . <p> One particularly annoying behaviour of AMD hardware is that the group size have to be known a compilation time . Hence , this is how OpenGL 4.3 specifies it . With **29;2611;TOOLONG , the ARB relax this behaviour howver this extension is only implemented by NVIDIA at the moment . <p> GLSL is pretty limited in term of different types it supports : int , float , double ( GL4 ) . With its OpenGL 4 hardware , NVIDIA provides more storage types including 64 bit integers that can be use with vertex attributes . <p> This extensions what release with Fermi GPUs . It offers many functionnalities that went to core specifications . However , one of the aspect of that specification @ @ @ @ @ @ @ @ @ @ , 16 , 32 bits integers and half-precision floating point types . <p> This extension is a collaboration between Apple and NVIDIA . It is obviously design to handle the high DPI screens . When calling glBlitFramebuffer to resolve a multisampled framebuffer , the OpenGL implementation can resolve and scale the framebuffer . <p> NVIDIA uses something call multisample coverage which allows to have coverage samples than color samplers . Hence , the implementation can adapted the multisampling according to the number of coverage samples covering the color sample . <p> In the second party of this article , we will discuss the possibilities for blending , stencil , profiling , rendering pipeline and misc features . We will discuss the announcements at GDC if there is enough public information given away that I could discuss about revelant things . We will conclude by my personal wish list for OpenGL 5 and Direct3D 12 hardware class . 
@@100664392 @4864392/ 45959 @qwx905959 <p> Non-GLSL types that are used to define precision-based types . <p> The GLSL language allows the user to define the precision of a particular variable . In OpenGL 's GLSL , these precision qualifiers have no effect ; they are there for compatibility with OpenGL ES 's precision qualifiers , where they do have an effect . <p> C++ has no language equivalent to precision qualifiers . So GLM provides the next-best thing : a number of typedefs of the Template types that use a particular precision . <p> None of these types make any guarantees about the actual precision used . <h> Typedef Documentation <p> typedef highpfloatt highpfloat <p> High precision floating-point numbers . <p> There is no guarantee on the actual precision . From GLSL 1.30.8 specification 
@@100664393 @4864393/ <p> First one , just like I announced it in a previous news ATI finally releases their OpenCL 1.0 drivers ! <p> Second one , the drivers finally support OpenGL 3.2 ! On that side , the news is even better ! AMD has worked hard to make progress to catch up on Direct3D 11 features with extensions : **27;2642;TOOLONG , **27;2671;TOOLONG and **30;2700;TOOLONG . I have no idea of what kind of feature brings **30;2732;TOOLONG but **27;2764;TOOLONG probably correspond to BC6 format and **27;2793;TOOLONG to BC7 format . <p> I have updated the OGL3 Samples Pack to make sure it 's compatible with this new drivers , new release soon ! 
@@100664394 @4864394/ <p> The Somerset House is one of my favorite place in London and once again it demonstrates why . <p> Until tomorrow , 12 performances of Counterpoint , a contemporary dance designed by the acknowledged artistic director and choreographer Shobana Jeyasingh , will have been performed at the Somerset House . <p> I love when I am astonished by the lack of random and onces again it hit me : I have been stunned by a dancer during the performance I saw today . Surprisingly she is on the picture of performance web page . I am glade to be able to congratulate Alejandra Ba+o Pelegrin . <p> By the time I am writing this text , only 4 performances are left for Sunday 4th . If you are in London it should not be missed and it 's free ! One advice though : To really enjoy the show it hightly recommand to sit facing the dancers entrance . 
@@100664398 @4864398/ <p> For this wish-list , I thought that instead of just having a view for OpenGL 4.2 , I could have a look at OpenGL for OpenGL 4 hardware class ( I might have been borderline on what 's possible for some features ... ) . <p> I call it ' my OpenGL 4.2+ wish-list ' as I do n't think all the following ideas could be part of OpenGL 4.2 . You can see this wish-list as a statement against the ' close to completed OpenGL idea I read to often after OpenGL 4.1 specifications release . <p> Do n't give me wrong , I think that OpenGL is already great but real-time graphics is still at its youth so that I do n't accept the idea of we are done when plenty of opportunies for new ideas are awaiting for us and I even see a lot of hardware evolutions for OpenGL 5 hardware and beyond even if it 's quite far ahead of us. : ) <h> 1 . Direct state access <p> I have requested direct state access for as long as GLEXTdirectstateaccess extension has @ @ @ @ @ @ @ @ @ @ both AMD and nVidia have implemented it now . However , once again I would like to repeat that in its form , this extension is far from perfect and I really do n't want it included in any OpenGL specification . <p> The ARB has added parts of the direct state access through new API features : Sampler objects with OpenGL 3.3 , separate program objects with OpenGL 4.1 and if we are picky even uniform blocks with OpenGL 3.1 . I like this approach because it avoids to include a lot of already deprecated functions in core : OpenGL is already a big and fat mammouth , especially the compatibility profile , there is no need to make it heavier for no reason , it 's complicated enough to learn ! Old softwares that uses deprecated features are probably using mechanisms which are probably not perfect , but which works and rewrite those to only use DSA functions of deprecated features is just a waste of time . For new code path , it 's also a waste of time to use deprecated features so that there is @ @ @ @ @ @ @ @ @ @ There is still a lot of DSA functions missing and I guess that if we want an improved multithreaded rendering we will need it as I assume that it removes the need of queries which would need to be thread safe and hence potential slow . Reading extensions I find out about a **28;2822;TOOLONG extension which could be a subset of GLEXTdirectstateaccess for buffers and textures . It could cover most of the remaining missing DSA functions . <h> 2 . Multithreaded rendering using command lists <p> Now days , every CPUs sold has multiple cores . Unfortunatly , OpenGL does n't gives a lot of help to program an efficient multithreading renderer unlike Direct3D 11 . <p> On the regard of multithreading , I think that Direct3D 11 gets it right . Thus , for OpenGL I would like the possibility to build command lists with multiple threads , at list one per threads . <p> Let 's admit that compiling a GLSL program is long . I do n't see any good reason to compile a program within the thread that executes the OpenGL command list . Using @ @ @ @ @ @ @ @ @ @ the drivers more opportunities to optimize the final command list used for rendering without slowing down the rendering because the optimization would be hidden in a seperate thread , optimizations that we usually have to take care of ourself using delayed OpenGL calls for examples . <h> 3 . New ' complex ' data access and structures <h> 3.1 . Image and buffer load and store <p> Direct3D 11 mainly sold itself with 3 features : Tessellation , multithreading and compute shaders . This is all good but I really think that one of the most interesting part of Direct3D 11 is the RWBuffer and RWTexture* , what we call image and buffer load and store in OpenGL . <p> When we think about it , image and buffer load and store is one of the most crazy feature integrated in OpenGL 4 hardware ... With this feature it 's possible to read and write to any buffer and any image wherever we want and even perform atomic operations . <p> It 's a wonderful source for new ideas and an other step toward a programmable blending stage after the @ @ @ @ @ @ @ @ @ @ be as efficient or leading to as many hardware optimizations than a proper programmable blend stage could do . The performance is not so good apararently with the current hardware generation but the possibilities are here . These capabilities are embodied by as set of extensions including **25;2852;TOOLONG , GLNVshaderbufferload and GLNVshaderbufferstore . <p> Unfortunatly , the lack of coherence between these extensions show me that there is n't an aggrement on the way it should be designed between AMD and nVidia or at least not in time for OpenGL 4.1 release . <h> 3.2 . UAV buffer / Linked list <p> The image and buffer load and store is a great feature but actually I think it will only reach its best only if we also have an API for what D3D11 calls UAV buffer and which allows to build and browse linked lists on the GPUs for very complex data struture and access ... A step toward hybrid rendering with raytracing or at least raycasting ? Sparse voxel octrees ? <h> 3.3 . Custom structure ( POD ) fetches <p> One good think with the uniform blocks is @ @ @ @ @ @ @ @ @ @ based on AoS ( Array of Structure ) which provides a contiguous memory access between structure elements . When buffer data are accessed on a per-framebuffer , per-program , per-draw call , per-instance , per-primitive , per-vertices and maybe even per-fragment , etc. it reduces the waste of memory bandwidth . This is due to unused data fetched because of memory alignment and because GPUs ( and CPUs too ) ca n't fetch less that a certain amount of data . The GPU is a processor that works per-task so that all the data fetched beyond the current tasks might reach the GPU cache and never be used before being invalidated and fetch again later when the task is actually scheduled . <p> I think that used in a proper way , uniform block can have significant performance benefices as it naturally fetch continious data . Obviously , it 's possible to use arrays inside blocks which might japodize some performance benefices of blocks if the data is not use within the task ... <p> OpenGL 3.1 has introduced texture buffer objects which allow to access to a large amount @ @ @ @ @ @ @ @ @ @ but which also make possible some quite advanced data structures in GPU memory . I believe that in many cases the AoS model is more efficient with texture buffer too . Unfortunately , it does n't feel really natural to use because GLSL only provides the function texelFetch which only provide up to 4 components vertors . Using multiple calls we can actually fetch a continious memory structure and build it back in the shader ... How fastidious ? <p> My request here is a structFetch which allows to directly fetch a data structure from a buffer as it is ( no normalization , no cast ) . There are probably some type limitations for the structure elements in some OpenGL 4 hardware ( in Radeon 5000 series but maybe not in GeForce 400 series ) but as part of the making complex data structures idea , it would be very convenient and hopefully a good guide for best practices of buffer accesses . <h> 3.4 . On GPU image copy ( GLNVcopyimage ) <p> OpenGL 3.1 includes the extension GLARBcopybuffer which allows to copy some data from one buffer @ @ @ @ @ @ @ @ @ @ part of creating complex data structures , I think it would be very convenient to be able to do the same between images . GLNVcopyimage already provides such feature in a very powerful way , allowing cross target , cross dimention and even cross context copy of texture and renderbuffer sub-data . I 'm not sure about the idea to be able to read or write from a renderbuffer ... Since OpenGL 3.2 we can assume that renderbuffer are deprecated if we want to however I quite believe that in the future ( OpenGL 5 hardware ? ) renderbuffer might become interesting againt if we consider renderbuffers like surfaces we ca n't explicitly reused which could bring some hardware optimizations. <h> 3.5 . Improved transform feedback storage types <p> After a test of the GeForce 470 on The Froggy FragSniffer , it quickly appears that the Fermi architechture works per tile of 16 by 16 fragments where each ' GPC ' is working separately . <p> In some ways , I would like to call the Fermi architechture a hybrid tile renderer GPU because I do n't think that on @ @ @ @ @ @ @ @ @ @ , this tiling probably exist only to have big enough ' wraps ' /'work groups ' . <p> Thanks to transform feedbacks , we can simulate a tile renderer behaviours even if is would be quite slow . One issue is that we ca n't control the output format so that everything is saved as floats , ints or uints , an issue that I wish to be able to laverage by being able to setup a different external format thanks to a vertex layout object ... See section 6.1. for more details on this vertex layout object . <h> 4 . Remove some specification limitations <p> In this part I would like to deal with wishes close to the specification which would simply removed some specification limitations , simple mistakes or subtle feature refinements . <p> With OpenGL 4.1 we can use uniform buffers with uniform block array , one buffer per array entry . However , I would rather use only a single buffer for all the per-instance data for example . On top of this , it would be great to have a function to be able @ @ @ @ @ @ @ @ @ @ array . <p> I think that using a uniform block array element for per-instance data is a good thing as it reduces memory bandwidth by forcing the developer to work AoS instead of SoA . <p> Finally , this feature request removed the small buffer allocations overload and reduces the risk of GPU memory fragmentation . <h> 4.2 . Layered rendering on mipmap chain or layers of different sizes <p> With the release of OpenGL 4.1 , I had a lot of expectations for more efficient cascaded shadow mapping rendering thanks to the new GLARBviewportarray extension and core feature which allows to setup multiple viewports . <p> One big difference between Direct3D and OpenGL is that OpenGL does n't require that all the colorbuffers have the same size . However , when a colorbuffer has a smaller size , it clips some pixels . With OpenGL 4.1 , I was expecting to use 1 viewport per layer so that I could rasterize some triangles at lower resolution than others which would be usefull for cascaded shadow maps generation in a single pass as we usually want to use higher resolution @ @ @ @ @ @ @ @ @ @ lower resolution for maps far from the camera position . Unfortunatlly , layered rendering has a limitation : all the layer must have the same size ... I do n't really know if it is a hardware limitation ( in this case , let 's remove it for OpenGL 5 hardware ! ) or just a specification detail . <h> 4.3 . Removed sampler array limitation <p> OpenGL 4.0 brings a proper support for sampler arrays however some limitations remains . It 's not possible to freely access any element of the sampler array , we are restricted to constants and uniform variable indexes . After some tests , I feature out that this limitation does n't apply on nVidia drivers . On AMD drivers these are some lookup issues but it might be possible to fix it . <p> I think that removing this limitation could provide some great benefits for instancing and if there are actually some hardare limitations maybe it could be even less restricted to allow , at least , per-shader invocation indices . <h> 4.4 . Input vertex shader and output fragment shader blocks <p> @ @ @ @ @ @ @ @ @ @ to communicate between shader stages and I especially like this feature to define communication protocoles between stages . With OpenGL 4.1 , there is almost no more constraint except that vertex shader inputs and fragment shader outputs ca n't be blocks . I remember doing some tests on nVidia OpenGL 3.3 beta drivers to see if it was possible and for some reasons it results with linking errors ... It would be nice to have this limitation removed for a fully consistent approach to program shaders with blocks . <h> 4.5 . Program pipeline object for DSA <p> There is a choice I really do n't undestand about the program pipeline object design : Why the pipeline object have to be created by a glBindProgramPipeline ? On the regard of DSA , this makes impossible to consider this object like a DSA object just because of this limitation and even if the rest of the API is perfectly DSA oriented . At draw time , we need to check if the program pipeline is still correct or if , meanwhile , a program pipeline has been created . <p> With @ @ @ @ @ @ @ @ @ @ the object is actually created by the first glSamplerParameter* call . Often with new OpenGL features , the previous specifications already provide solutions . For the program pipeline object it should be the same . <h> 5 . Software design scalability <h> 5.1 . Compiler options and preprocessor definisions <p> I find quite crazy the few possibilities we have on the regard of compiler and preprocessor options . One side of writting an OpenGL ' engine ' is to simulate behaviours that Visual Studio or GCC would provide for us ... <p> From the beginning of Cg , it includes the possibilities to build a shader for a specific ' SM ' version . There is #version preprocessor option to set in the shader but if we want to manage the version from the C++ program ... it 's just hand work . <p> Another very convenient tool is the GCC -D parameter which allows to define a value at build time . More do it yourself with GLSL and it 's the same for the extension list ... <p> OpenGL 4.1 allows to get the binary of a GLSL @ @ @ @ @ @ @ @ @ @ allows to create an offline compiler tool which would allows more optimized GLSL program ... It would be nice to be able to set the optimizations of-source with a finer granularity . <p> To significantly decrease the compilation time of shaders , a good idea is to do the all the queries query after all the builds because querying the logs introduces a delay . We have to wait for the result of the query . Also , we certainly need logs ... but maybe only when the use case is software development ! An option as GCC ' -quiet ' might be really useful to speed up once more the build . <p> Finally , compilers are far from perfect on the regard of following the GLSL specifications and at least for nVidia case , I do n't even think they really want to follow it on a strict manner . My believe is that for nVidia , their compiler should be the GLSL specification and a set of extra-features . Is this bad ? On the regard of cross platform development , yes and on this regard I @ @ @ @ @ @ @ @ @ @ of inovation , no . For the best of these two worlds a simple compiler option like GCC ' -pedantic ' would simply around these two worlds to co-exist on every platforms . <h> 5.2 . Typedef in GLSL for qualifiers and more <p> Through its multiple versions , GLSL has significantly increased the number of qualifiers . All of them have a purpose but the syntax is complex and just so ugly . Why some qualifiers are part of the ' layout ' and why some are outside ? All this seems a bit messy . <p> Possible declaration of a variable with various qualifiers in OpenGL 4.1 ... <p> In C and C++ for that kind of scenarios ( and actually for even simpler scenarios ) we would use typedefs which is part of my wish . Also , GLSL defines an arbitrary order for the qualifiers ... This is a really annoying choice because this order does n't rely on anything logical beside hitorical reasons so I would like this arbitrary order limitation removed . <p> Actually , I am not sure which way would be better @ @ @ @ @ @ @ @ @ @ . I see positive and negative conscequences for both . <h> 5.3 . A ' common ' shader target <p> With OpenGL and GLSL it 's possible to create a program using multiple shaders . This is particulary nice to reuse functions , structures , defines and typedefs for different programs associates to the same program stages . Unfortunatly , it 's still impossible with OpenGL 4.1 to use a single shader object for multiple stage : we need to duplicate shader libraries for each stage ... even it the code is word for word identical ! Not great . For example , I typically would like to reuse the same structure between input and output blocks between program stages . <p> OpenGL 4.1 , Vertex shader : <p> struct vert <p> <p> vec3 Position ; <p> vec3 Normal ; <p> vec2 Texcoord ; <p> vec4 Color ; <p> ; <p> out vert Vert ; <p> OpenGL 4.1 , Fragment shader : <p> struct vert <p> <p> vec3 Position ; <p> vec3 Normal ; <p> vec2 Texcoord ; <p> vec4 Color ; <p> ; <p> in vert Vert ; <p> @ @ @ @ @ @ @ @ @ @ drivers yet and I hope this drivers bug will be fixed soon . <p> We can already do it ourself playing with strings but this is **28;2879;TOOLONG work , not us . Instead , I propose to create a ' common/library shader target ' that could not contain a main function or any build-in variable or per-stage specific items but that could be reuse across program stages . <p> With OpenGL 4.1 and the separate programs , OpenGL had to evolve to replace the old rendezvous by name approach that requires a long linking phase to connect the variables between stages checking strings . This evolustion has been possible thanks to the explicit location qualifier introduced by **27;2909;TOOLONG and generalized to varying variables . <p> We are suposed to be able to set the locations of a varying structures since OpenGL 4.1 but it is still not supported by OpenGL drivers . I hope it 's just a matter of time . <p> I think that the generalization of the location should be extend further to uniform variables and uniform block ( explicit index qualifier ) . On one side @ @ @ @ @ @ @ @ @ @ other side it will improve software modularity and removing strings based queries . <p> Finally , nVidia already has the funtion **29;2938;TOOLONG based on the ' rendezvous by resource ' which is perfect for be promoted in the core specification . <h> 5.5 . Objects checks <p> I find on the OpenGL forum an idea that I find quite interesting : What about having the possibility to check if an OpenGL object is created correctly of if it is completed ? This is something we already have with the framebuffer , shader , program and program pipeline objects by it could be generalized to other objects . It possible that this feature could be implemented as a function or maybe through a message of the debug output extension . <h> 5.6 . Drivers queries <p> Drivers have bugs and will always have some just like any other software and until no one better that humans keep writting them . When using OpenGL , we can check features using the OpenGL context version and also the extensions supported but this is not always enough . It 's not because the drivers @ @ @ @ @ @ @ @ @ @ entirely work . A common practice is to create a database of faulty drivers and to check the drivers version to warn the software users that the drivers have a bug that prevent the software to run properly and advice them to update his drivers with a newer version or a version we recommand because it has be specifically tested . <p> Querying the drivers version ( and release date ? ) could have all sort of uses and it would be great to have this possibility from the OpenGL API . <p> These queries could be extend to the memory quantity , availability , GPU temperatures or even some indications of the GPU performances and a lot more following developer imagination . Some of these features are already exposed by the extensions GLATImeminfo and GLNVXgpumemoryinfo. <h> 5.7 . GLARBgpuassociation <p> I 'm not a big fan of Crossfire and SLI technologies but still , using multiple GPUs is possible and can have some real use cases for research and very expensive computation scenarios . These possibilities are available for years through but the OpenGL support remains limited by vendor @ @ @ @ @ @ @ @ @ @ to get an ARB extensions for this support . <h> 6 . Ideas for new OpenGL objects <p> After debates over debates , I remain a VAO hater even if it 's maybe not that bad for the performances . It 's not bad for the performances but not really good either and it 's a real pain on the software design side . VAOs does n't make sense so that only a simple and stupid design based on a 1 VAO per draw call work fine ... no thank you ! VAO certainly looks pretty at first look but this might even makes it more awfull and in anyway it keeps for me the title of worse idea ever integrated to the OpenGL core specification . <p> To leverage the software constrains of VAO , I suggest to update VAO or create an object that works like a vertex layout object , as the OpenGL community as always requested . This object would only describ the structure of the vertex to tell the GPU how to gather the vertex attributes but also how to output transform feedback varyings . @ @ @ @ @ @ @ @ @ @ . <p> This way , the API highlights the developers on an area of optimization , advice to sort the draw calls by vertex layouts and remains flexible as the array buffer would not be attach to this object providing an escential complete freedom for custom vertex data management . The nVidia bindless graphics already allows this type of approach but it 's possible to design it without GPU pointers too . <p> I am quite up for the GPU pointers but let 's face it : In case of invalid access the drivers restart on Windows 7 and the computer simply freeze on Windows XP ... It feels pretty hard to expect the ARB reaching an aggrement on this . What about having both ? It would be my favorite option ! <p> With a lot of new version of OpenGL we get a new draw call function . In a way we could deprecated the previous functions after each new draw call function introduced . Considering this and the issues with the VAO object , I think that OpenGL would take advantage of a draw object . For @ @ @ @ @ @ @ @ @ @ would be created and we could keep the same draw function and expect default parameter values . If it sounds more likely to the OpenGL drivers teams , the draw object could work as a container . <h> 6.2 . Environment program object <p> With the pipeline program object I saw some opportunities for an environment program object design in an useful way . The environmnt program object is maybe the last promise of Long Peak that we did n't get yet . <p> The idea behind a environment program object is to be able to group all the data that would be use by a program in a single memory location where the drivers would be able to setup how to access to those data . The environment program object is for the programs what the layout object would be for the ' vertex pulling ' . For a succesfull environment program object , it is really important to keep it decoupled from the program objects and from the buffers . This is the only way to keep the level of flexibility we have today and prevent VAOs type @ @ @ @ @ @ @ @ @ @ but uniform block would only hide its level of indirection. <h> 6.3 . Imutable Objects <p> Imutable objects are one of my very old request . For a long time , I liked to use the display list to build some static objects and be able to quicky switch from one object to another . Back at that time ( 2-3 years ago ? ) , I mesure some interesting performance gains . It was convenient to use and it gave me a software design solution to handle the ' lost global states ' . Unfortunatly , display list are deprecated since OpenGL 3.0 so that display list are not an option anymore even if my code usually still group the global states into C++ objects that matches my software design . <p> Direct3D already has some objects for specific groupa of ' lost global states ' but I am not sure if it 's the right approach . I guess that these groups could be quite dependent of the hardware which would make hard to reach an aggrement , expect if OpenGL stricly follows Direct3D . Another idea is @ @ @ @ @ @ @ @ @ @ and let the drivers optimize the states group how they could . This is quite flexible but in practice I am not sure it the drivers would be able to perform a lot of optimizations . At least we could expect the level of efficiency that display list provides which is already great . One draw back is that developers could create imutable objects with a total non-sense and by conscence quite fair . <p> On note : The idea of custom state object could probably come relly well together with the command list designed for multithreading. <h> 7 . The open topics <p> This part is dedicated to ideas that raise my attentions but in which I did n't put enough thoughts or just did n't gather enough clues and experiences to let me settle on any idea of where I think we need to go . <h> 7.1 . A second deprecation pass <p> This is maybe too soon but why not thinking to a second deprecation pass in the OpenGL API ? I 'm not saying removing feature yet but at least to mark some features as @ @ @ @ @ @ @ @ @ @ using this ? Most of the draw call functions or all if we had a draw object . The renderbuffer which is only a subset of what we can do with textures . glViewport , glClear , glClearColor / glClearStencil / glClearDepth , all these functions that have alternatives . The only purpose of this deprecation pass would to simplify the API , to only keep the useful functions . I also think that deprecation should only be seen as an advice for what to use or not . <h> 7.2 . More API and specification coherency <p> API coherency is a long topic that requires much more research and time that what I unfortunately had for this wish-list . However , I think that many of my requests try to leverage some issues of consistency within OpenGL which today might makes OpenGL much harder to learn than Direct3D 11 . <p> For example , the varius rules that handles the ways to set uniform values , subroutines and blocks follows 3 totally differents set of rules ... which in practice we will probably limite to the GCD of these @ @ @ @ @ @ @ @ @ @ the program environment object follows . <p> Other example , when several ' slots ' are used for a feature , we have all sort of post-fixes tokens : ' i ' , ' index ' , ' array ' . <p> The communication between program stages but also between GLSL and C++ programs are build on top of varisous ways that not obvisously works everywhere . The GLSL cast rules are quite awful and follows some specific rules where it would have been nicer and that already exist like the C++ rules or just keep the OpenGL 3.3 rule ( explicit only ) . <p> Some objects ( texture , sampler , program ) use parameter functions to setup their settings or other create a new functions for each new fonctionnality ( draw call functions ) ... <p> Some features works only on DSA ( sampler , uniform blocks ) when other rely on multiple targets ( Buffer , framebuffer ) , some even provide both ways ( program ) and other uses multiple units ( texture ) ... <p> Some object names are reserved with glGen* but some @ @ @ @ @ @ @ @ @ @ multiple with glGen* ... and I could easly find more examples ! <p> I thing that the lack of consistency makes OpenGL a very complex API to work with especially because I believe in OpenGL everywhere for everything , including ' Paint ' type of softwares which means that OpenGL must be usable by developers that does n't have a specific skill in OpenGL or graphics rendering in general . <p> The ARB has spoken about streamlining the OpenGL API when they created the core profile and I think even during Long Peak development . I do n't think that removing features has anything to do with streamlining an API , it has to do with bringing more sense into the API , each element with each element but unfortunatly during the past few years we have assisted to the exact opposit of streamlining ... I believe that a streamlined API is what has made OpenGL a backward comptible API for years and what I have affraid is that in the future OpenGL becomes so complex and irationalized that it would be too complex to evolve and to work with @ @ @ @ @ @ @ @ @ @ One thing I am not interest at all is to add some functions that does nothing but being pretty . I think that GLAMDnamegendelete is one of those extensions that does n't lead to anything new even if the concept remain interesting . Large APIs == More complex API by definition . This extension formally defines the concept of named object and concequently it opens doors for others approaches . Why not intoducing a pointed object or some sort pointer based object access ? It has been an old topic within the ARB but I do n't see why these 2 conventions should n't co-exist if it 's generalized to every objects . <p> In this extension or actually in an extended version of this extension , I also imagine a way to standardize the way named objects would be binded but also a way to create several objects of different types . <p> The purpose of these lasr functions would be for the developer to create some objects that uses severales objects and that are live and are used together . It could give a hint to the drivers @ @ @ @ @ @ @ @ @ @ on GPU <p> With all the possibilities provided by OpenGL 4 hardware , the programming freedom given by this generation of hardware , an OpenGL programer could wish to be able to program on the GPU like he would on the CPU : A wish for object orientation . So far OpenGL and OpenCL has stay out of it because of design decisions . Meanwhile , HLSL11 and Cuda have embrace it at different levels . <p> On one side , Direct3D 11 brings the keyword ' class ' to the language . On other side , Cuda brings some sort of C++ support as part of its language . I do n't know the details on how this is actually possible but it is certainly impressive and it raises to me a question : do we want object orientation in OpenGL and OpenCL through C++ ? <p> Some differences from Cuda to OpenCL are that Cuda is based on an offline compiler and Cuda is platform specific . Like Walter Bright shows in his article on speed of C++ , the language is show to compile by nature . @ @ @ @ @ @ @ @ @ @ compiler but as the language is build on top of C++ , I assume that Cuda compilation is really slow even if it based on the very impressive LLVM . However , even if this compiler is slow , it 's an offine compiler and at the program execution it does n't need to be build again . This is only possible because Cuda is platform specific which means that it is only going to run on nVidia drivers and hardware . <p> With OpenGL 4.1 we finally have the possibility to get the binary of a GLSL program . I am quite skepical about this feature as building GLSL programs is really fast ( compare to C++ program ) and in anyway these binaries can only be used for a cache system because there is no standard binary defined . <p> Thus using an offline compiler is complicated which leads to forget about the idea of using C++ instead of GLSL or the OpenCL language , unless the ARB decides to sit around the table to define a standard binary ... for nothing sooner than OpenGL 5 hardware . @ @ @ @ @ @ @ @ @ @ probably uses , a semi-compiled language that AMD and nVidia would transcode into their own OpenGL 4 hardware binary codes . <p> A standard binary code even open doors for alternative languages other than C++ . C++ programers might have fun to programer the GPU with C++ but I ca n't imagine it would make happy C# , Java , Python programers . Furthermore , nothing prevents GLSL programs to be built into this standard GPU binary code . Other side effects could be some open source works to bring GPU binary support in GCC and LLVM for example . It might become an ongoing topic in the future and I am already impastient to read what people want and think about it ! <p> OpenGL is like all these interesting topics , the more we think about it the more we could find ideas and I bet that in next months I will find more new ideas or refinements . In anyway , with all this , who could still dare to say that OpenGL is ' nearly completed ' ? : p What about all the work required @ @ @ @ @ @ @ @ @ @ not use to it on this website but I would like to give a special thanks to all the people who gives the energy for my endeavor and the ones with whom I shared blossoming OpenGL discussions with but also AMD and nVidia OpenGL teams for their supports which allows me to touch the OpenGL state of the art and beyond . 
@@100664400 @4864400/ <p> These days , I am working on Intel Sandy Bridge architecture OpenGL support . <p> If Intel Ivy Bridge is already pretty hard to support with its OpenGL 4.0 support , Sandy Bridge is another kind of challenge : OpenGL 3.1 support with no core profile . Unfortunately , released in 2011 , Sandy Bridge is a bad GPU with 2009 OpenGL support that is a still a good CPU architecture largely used as Unity stats shows . <p> Unity Windows editor stats for April 2015 <p> Sandy Bridge ( HD 2000 / HD 3000 ) is 9.8% of the Unity editor users and one of the most used GPU architectures . <p> Exposed extensions to all OpenGL 4 hardware on the lastest drivers available to date <p> By giving up on feature support , basically at the release of an architecture , Intel has been able to provide pretty good drivers on the lastest architectures ( Haswell / Broadwell ) , both in term of quality and feature set ( OpenGL 4.3 ) . <p> However , it is very unfortunate that anything older is more complex @ @ @ @ @ @ @ @ @ @ 9 years ago . Sadly , it can get worse ! Older architectures than Sandy Bridge , that is GMA ( OpenGL 1.4 ) , GMA HD ( OpenGL 2.0 ) and Ironlake HD Graphics ( OpenGL 2.1 ) represent 12.9% of the editor users . <p> Lastly , Intel GPU names are dreadful : It was aweful back at the GMA time , it is still just as bad . For example , " Intel HD Graphics " ( without any numbering ) has been used for Clarkdale , Arrandale , Sandy Bridge , Ivy Bridge , Haswell , Bay Trail , Broadwell and Braswell. 
@@100664401 @4864401/ <p> I rescently went to Liverpool and head to the Tate especially because I was curious by the on going exhibition about perspective . However , and despite some interesing piece in this exhibition , from this visit what will remain in my memory is the current exhibition about British sculpture : A set of comptempory sculpture place within a very 70s context with flasing lights , funk music and a disco dance floor for us . <p> I am not especially an amator of body sculptures but I am forced to admit that I enjoy this exhibition not only for its outraguous context which only emphasise the overall twist of the whole exhibitions . Pictures without flash where allowed so I let you enjoy the nature of this installation . <p> A perfect day light head-phone party in the middle of a museum , England never fails to surprise me ! 
@@100664411 @4864411/ <p> Following the schedule I was speaking about few days ago , ATI released the ATI Stream SDK 2.0 Beta 4 with CPU and GPU support . <p> A good information is the list of the supported GPUs : The complet Radeon HD 4*** and Radeon HD 5*** series ! It 's a good confirmation for the HD 4*** serie even if in this case I would also expect the Radeon HD 3*** series to be supported as well . <p> I have few questions remain . Aparrently on MacOS X , it 's not possible to share the memory between different devices , the CPU and the GPU . Is it possible on an AMD platform ? <p> ATI Stream technology is a set of advanced hardware and software technologies that enable AMD graphics processors ( GPU ) , working in concert with the systems central processor ( CPU ) . AMD claim for ATI Stream overview <p> To actually works in concert it needs to be able to share memory between devices . The OpenCL 1.0 specification is not clear about that and it seams to be @ @ @ @ @ @ @ @ @ @ 5*** ... I 'm investigating ! Wait and see ... 
@@100664413 @4864413/ <p> I have updated the OpenGL Hardware Matrix for OpenGL 3 hardware to include Sandy Bridge GPUs . Unfortunately , Intel has gave up on improving the OpenGL support of Sandy Bridge GPUs on Windows despite still shipping processors using this architecture . <p> The status of Sandy Bridge on Windows might be leading OpenGL programmers to quite some headaches when shipping a product that needs to run on a large and broad install base . It 's annoying already , picture that in 3 or 5 years . 
@@100664414 @4864414/ <p> I 'm really annoyed by the fact that Xerces-C and Xalan-C does n't evolve anymore . No support of XSLT 2.0 and XPath 2.0 , also 3 years after the final specification release ... <p> Unfortunately , we do n't have many choices ... I think that libxml and libxslt are awful libraries and not up to date as well . I found few weeks ago a . NET and Java XSLT 2.0 processor : Saxon . I thought I should give it a try especially to make G-Truc Creation build on MacOS X ! <p> Saxon is a great tools , very accurate conformance wise , but it 's probably because it 's Java based : It is awfully slow ! <p> Saxon 9.2 : 16:00.3 minutes <p> Xalan-J 2.7.1 : 10:02.5 minutes <p> Xalan-C 1.10 : 1:09.4 minutes <p> 1 minute is already quite long when I develop on the website , so that I just build the appropriate files . So now 16 minutes with Saxon ... I 'm probably going to keep using Xalan for a while . <p> For years I have been @ @ @ @ @ @ @ @ @ @ varius projects . They are such great libraries and once again I would love to see them maintain at its original level of excellence . 
@@100664416 @4864416/ <p> We all know the famous " Ceci n'est pas une pipe " ( " This is not a pipe " ) paintings representing a pipe . The interpretation of this painting is pretty interesting but I discover that it is just a tiny subset of a larger interest by Magritte for the threesome relationship between the object , its representation and the word with use to identify this object . Maggrite questioned how each of the these three forms can be exchange by another but also the arbitrary in the naming and the representations of objects . <p> This is an exhibition I have been waiting for a long time to go and it was absolutely worth it . I also would like to acknowlegde the great work the Liverpool Tate has done . Yes , the topic is outstanding but the Liverpool Tate perfectly designed this exhibition . Everything combined , this is the best exhibition I have seen in 2011. 
@@100664417 @4864417/ <p> The more I am going to the Tate Britain the more I like it : I rescently went twice , for the very original Susan Hiller exhibition which I like but without really connecting with it and also the watercolor exhibition which turns out so interesting and beautiful : An entire exhibition dedicated to the medium accross art history ! <p> This exhibition is a display of the whole of watercotor media across uses , techniques and history : an exploration of a media from 16 centuary to the present days . <p> The Blue Rigi : Lake of Lucerne , Sunrise ; Joseph Turner ; 1842 <p> January 9 : 1983 : II ; Patrick Heron ; 1983 <p> The exhibition is running until the 21 August 2011 and has been from my favorite this week , so it ca n't be missed ! 
@@100664422 @4864422/ 45959 @qwx905959 <p> Non-GLSL types that are used to define precision-based types . <p> The GLSL language allows the user to define the precision of a particular variable . In OpenGL 's GLSL , these precision qualifiers have no effect ; they are there for compatibility with OpenGL ES 's precision qualifiers , where they do have an effect . <p> C++ has no language equivalent to precision qualifiers . So GLM provides the next-best thing : a number of typedefs of the Template types that use a particular precision . <p> None of these types make any guarantees about the actual precision used . 
@@100664423 @4864423/ <p> During the past 2 years , I think I have n't missed any exhibition as The Photographers ' Gallery as I always end-up to be around at some point and it is free so that i just get in and see what 's on . <p> Unfortunately in this time , I never been blow away by an outstanding exhibition , even tough it 's going from classic photgraphy to comptemporary art until last Saturday when I saw the last exhibition " The Family and the Land " by Sally Mann , her first exhibition in the UK . <p> Sally Mann is an american photographer who is working is focusing on her family and the landscape . Does it sound boring ? Maybe . However , her vision of this topic is as this twist that brings the photograph to what I call true beauty , I daring vision which stimulated controversy in the late 80s . <p> I enjoyed a lot of element of this exhibition . First of all the photogrqphic series which have been perfectly enhanced by a great display . As a big @ @ @ @ @ @ @ @ @ @ the video displyed on a dedicated room which really show how she works , how her work has evoled across the years but also from where she comes from as a human being . <p> This amazing exhibition is runing until the 19th September 2010 for free . 
@@100664426 @4864426/ <p> Rene Gruau ( 1909 2004 ) met Christian Dior ( 1905 - 1957 ) in 1936 while working for the French newspaper Le Figaro , both as illustrators where they built their friendship . <p> Afterwards , He became an illustrator for Christian Dior and gave an image to Christian Dior 's house , especially the perfumes , through his illustrations and the symbols he created : Swans , flowers , fans , hands and an obsessions for women legs . <p> This exhibition is built over 5 themes : " flower woman " , " gesture &amp; attitude " , " l'homme gruau " , " a shared vision " and " line &amp; silhouette " . Cherry on the cake , 5 artists have been invited to create pieces inspired by each exhibition theme . <p> All in all , this exhibition succeed in sharing the vision of Rene Gruau which results in a very inspiring time . 
@@100664431 @4864431/ <p> OpenGL Mathematics ( GLM ) is a C++ mathematics library for graphics software based on the OpenGL Shading Language ( GLSL ) specification . <p> GLM provides classes and functions designed and implemented with the same naming conventions and functionalities than GLSL so that when a programmer knows GLSL , he knows GLM as well which makes it really easy to use . <p> This library works perfectly with OpenGL but it also ensures interoperability with other third party libraries and SDK . It is a good candidate for software rendering ( Raytracing / Rasterisation ) , image processing , physic simulations and any context that requires a simple and convenient mathematics library . <p> GLM is written as a platform independent library with no dependence and officially supports the following compilers : 1 . Clang 2.0 and higher 2 . CUDA 3.0 and higher 3 . GCC 3.4 and higher 4 . LLVM 2.3 through GCC 4.2 front-end and higher 5 . Visual Studio 2005 and higher <p> Note : <p> The Doxygen-generated documentation will often state that a type or function is defined in a namespace @ @ @ @ @ @ @ @ @ @ ignore this ; All publicly available types and functions can be accessed as a direct children of the glm namespace. 
@@100664438 @4864438/ <p> Splits x into a floating-point significand in the range 0.5 , 1.0 ) and an integral exponent of two , such that : x = significand * exp ( 2 , exponent ) <p> The significand is returned by the function and the exponent is returned in the parameter exp . For a floating-point value of zero , the significant and exponent are both zero . For a floating-point value that is an infinity or is not a number , the results are undefined . <p> If genTypeU is a boolean scalar or vector : Selects which vector each returned component comes from . For a component of that is false , the corresponding component of x is returned . For a component of a that is true , the corresponding component of y is returned . Components of x and y that are not selected are allowed to be invalid floating point values and will have no effect on the results . Thus , this provides different functionality than genType mix ( genType x , genType y , genType(a) ) where a is a Boolean vector . @ @ @ @ @ @ @ @ @ @ by the implementation , presumably the direction that is fastest . This includes the possibility that round(x) returns the same value as roundEven(x) for all values of x. 
@@100664442 @4864442/ <p> AMD has released OpenCL 1.1 drivers with the ATI Stream SDK 2.2 ; a release 2 months after the specification release . nVidia has an OpenCL 1.1 drivers but only available for nVidia registred developers . <p> So far , I have n't seen really good results of OpenCL benchmark on AMD . I do n't really know if it 's a hardware limitation or a lack of optimization of the drivers or maybe both . Some people will say that nVidia have a more advanced cache system but this is not true on GeForce 8/9 hardware which remains really efficient . One think is sure , nVidia has more experience through CUDA and their OpenCL implementation is built on top of it . <p> With the progress of AMD on OpenCL , I guess it 's going to be interesting to observe OpenCL benchmarks in the next months ! 
@@100664443 @4864443/ <p> Nathalia Edenmont is a contreversial Swedish photograph born in Yalta in Ukraine . <p> The Wetterling Gallery is displaying her serie title " No feelings " which shows some disturbing pictures of people including children that express no feeling . I would say it 's some empty feeling pictures . Following the always relevant Newton principle " Action , Reaction " , these photographes awake the viewers feelings . <p> I personnaly believe that Nathalia Edenmont display in this series the lack of consideration people could have probably with a focus on the fashion world here . I do n't think it 's a fair view as high street cloths , that we all buy , are actually more subject to a global and massive consideration by who makes them and who makes them . Do you realize that the cloths you buy are made in a dictature , maybe made by children or under paid employees ? 
@@100664445 @4864445/ <p> Since the release of Snow Leopard , David Gohara from MacResearch has been working on some video podcasts about OpenCL . <p> The podcasts are based on commented slides with demos time to time . These podcasts target MacOS X and especially XCode and nVidia GT200 chips . It really is a in depth coverage based on code samples and GPU architecture . <p> Furthermore , a good part of the podcasts is dedicated to the questions from the previous podcast . <p> I highly recommend these podcasts ! There are available through iTune or individual downloads. 
@@100664447 @4864447/ <p> This version adds 4 samples about texture filtering but is actually a major update for development tools support . <p> The version has been tested with Visual Studio 2005 , 2008 and 2010 . An experimental version for Linux is still in development but is also included in this release . This version also brings support for CMake 2.8 . <p> To simplify the use of the pack , the dependence with Boost in GLI has been removed . 
@@100664448 @4864448/ <p> For OpenGL Insights , we created an OpenGL 4.2 and OpenGL ES 2.0 pipeline map . Patrick Cozzi asked me few times to update it for OpenGL 4.3 and OpenGL ES 3.0 but obviously I found interest in making it only to make it a lot more detailed considering that it would not be for printing so it could be as big as I see fit . This endeavor represented a significant amount of work but finally I have completed the OpenGL 4.3 Pipeline Map . <p> Wonder why Larrabee for graphics failed ? I guess when we see all this fixed function functionalities that hardware vendor can implement very effectively , it gives us some clues . 
@@100664449 @4864449/ <p> First step until a major release for GLM with this first alpha of GLM 0.9 . <p> This version brings a large internal redesign to improve the library reliability and optimized some parts . It removed the deprecated features and API which implies that GLM 0.9 is n't backward compatible . <p> For most users the build issues when upgrading to GLM 0.9 should be reduced especially if they follow the deprecation policy . The following examples uses GLM 0.9 conversions . <p> This release is still UNSTABLE and not recommanded for commertial product . 
@@100664463 @4864463/ <p> Futurism was a very controversial avant-garde art movement from 1900 to 1915 from Italy which was very influential in Paris before Russia and London . Most artists at that time were interested by the movement but did n't want being associate with it . Therefore , artists initiate their own movement , French Cubists : Orphism ; Russian : Cubo-Futurism ; British : Vorticism . The Futurism movement stop at the beginning of the first World War when most Italien artists were arrested ... <p> This summer the London Modern Tate celebrated the centuary birthday of the Manifesto of Futurism with an exhibition . 
@@100664465 @4864465/ <p> Martin Parr is a British documentary photographer , photojournalist and collector . A common theme for his photography is wealth where he shows how we should be more worry of wealth rather than poverty . Through is pictures he takes a critical look at modern society . " <p> " This show is currently touring Europe and features all my collections and my new Luxury project . The collections range between Saddam Hussein watches to recent British documentary photographs from other Bristh photographers " Martin Parr <p> Martin Parr has been appointed Guest Curator for Brighton Photo Biennials fourth edition , taking place in October and November 2010. 
@@100664466 @4864466/ <p> Taking place in a time with strong rules of academic painting , the Impressionists were independent Paris-based artists whose group exhibitions brought them to prominence . <p> A refreshing and informative exhibition discently displayed for the pleasure of the eyes and the soul . <p> The Birth of Impressionism exhibition is running until the September 6 , 2010 for $20 and I advice the audio guide . As a preview , have a look at the following pictures of some of the masterpieces display in this exhibition 